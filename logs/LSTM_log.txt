Testing LSTM
2021-09-04
Input Shape:  (8000, 1, 150)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 32)                23424     
_________________________________________________________________
dropout (Dropout)            (None, 32)                0         
_________________________________________________________________
dense (Dense)                (None, 128)               4224      
_________________________________________________________________
dense_1 (Dense)              (None, 128)               16512     
_________________________________________________________________
dense_2 (Dense)              (None, 64)                8256      
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 130       
=================================================================
Total params: 52,546
Trainable params: 52,546
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/72 [..............................] - ETA: 1:20 - loss: 0.6937 - categorical_accuracy: 0.520030/72 [===========>..................] - ETA: 0s - loss: 0.6936 - categorical_accuracy: 0.4968  60/72 [========================>.....] - ETA: 0s - loss: 0.6928 - categorical_accuracy: 0.506572/72 [==============================] - 2s 9ms/step - loss: 0.6924 - categorical_accuracy: 0.5105 - val_loss: 0.6760 - val_categorical_accuracy: 0.6087
Epoch 2/100
 1/72 [..............................] - ETA: 0s - loss: 0.6739 - categorical_accuracy: 0.660031/72 [===========>..................] - ETA: 0s - loss: 0.6698 - categorical_accuracy: 0.624660/72 [========================>.....] - ETA: 0s - loss: 0.6594 - categorical_accuracy: 0.630572/72 [==============================] - 0s 2ms/step - loss: 0.6548 - categorical_accuracy: 0.6339 - val_loss: 0.5722 - val_categorical_accuracy: 0.6925
Epoch 3/100
 1/72 [..............................] - ETA: 0s - loss: 0.5123 - categorical_accuracy: 0.780033/72 [============>.................] - ETA: 0s - loss: 0.5507 - categorical_accuracy: 0.727166/72 [==========================>...] - ETA: 0s - loss: 0.5473 - categorical_accuracy: 0.725872/72 [==============================] - 0s 2ms/step - loss: 0.5463 - categorical_accuracy: 0.7260 - val_loss: 0.5314 - val_categorical_accuracy: 0.7300
Epoch 4/100
 1/72 [..............................] - ETA: 0s - loss: 0.5107 - categorical_accuracy: 0.760036/72 [==============>...............] - ETA: 0s - loss: 0.4844 - categorical_accuracy: 0.766172/72 [==============================] - ETA: 0s - loss: 0.4787 - categorical_accuracy: 0.769172/72 [==============================] - 0s 2ms/step - loss: 0.4786 - categorical_accuracy: 0.7691 - val_loss: 0.4901 - val_categorical_accuracy: 0.7638
Epoch 5/100
 1/72 [..............................] - ETA: 0s - loss: 0.3814 - categorical_accuracy: 0.830036/72 [==============>...............] - ETA: 0s - loss: 0.4229 - categorical_accuracy: 0.806571/72 [============================>.] - ETA: 0s - loss: 0.4276 - categorical_accuracy: 0.801372/72 [==============================] - 0s 2ms/step - loss: 0.4278 - categorical_accuracy: 0.8011 - val_loss: 0.5052 - val_categorical_accuracy: 0.7362
Epoch 6/100
 1/72 [..............................] - ETA: 0s - loss: 0.4601 - categorical_accuracy: 0.810036/72 [==============>...............] - ETA: 0s - loss: 0.3692 - categorical_accuracy: 0.840371/72 [============================>.] - ETA: 0s - loss: 0.3786 - categorical_accuracy: 0.832172/72 [==============================] - 0s 2ms/step - loss: 0.3792 - categorical_accuracy: 0.8317 - val_loss: 0.5173 - val_categorical_accuracy: 0.7362
Epoch 7/100
 1/72 [..............................] - ETA: 0s - loss: 0.3332 - categorical_accuracy: 0.910036/72 [==============>...............] - ETA: 0s - loss: 0.3685 - categorical_accuracy: 0.841071/72 [============================>.] - ETA: 0s - loss: 0.3718 - categorical_accuracy: 0.835572/72 [==============================] - 0s 2ms/step - loss: 0.3719 - categorical_accuracy: 0.8353 - val_loss: 0.5297 - val_categorical_accuracy: 0.7337
Epoch 8/100
 1/72 [..............................] - ETA: 0s - loss: 0.2716 - categorical_accuracy: 0.870036/72 [==============>...............] - ETA: 0s - loss: 0.3296 - categorical_accuracy: 0.847572/72 [==============================] - ETA: 0s - loss: 0.3346 - categorical_accuracy: 0.847672/72 [==============================] - 0s 2ms/step - loss: 0.3348 - categorical_accuracy: 0.8476 - val_loss: 0.5513 - val_categorical_accuracy: 0.7387
Epoch 9/100
 1/72 [..............................] - ETA: 0s - loss: 0.3757 - categorical_accuracy: 0.860035/72 [=============>................] - ETA: 0s - loss: 0.3200 - categorical_accuracy: 0.856269/72 [===========================>..] - ETA: 0s - loss: 0.3234 - categorical_accuracy: 0.854672/72 [==============================] - 0s 2ms/step - loss: 0.3237 - categorical_accuracy: 0.8545 - val_loss: 0.5432 - val_categorical_accuracy: 0.7475
Epoch 10/100
 1/72 [..............................] - ETA: 0s - loss: 0.3050 - categorical_accuracy: 0.880035/72 [=============>................] - ETA: 0s - loss: 0.3110 - categorical_accuracy: 0.856070/72 [============================>.] - ETA: 0s - loss: 0.3094 - categorical_accuracy: 0.859072/72 [==============================] - 0s 2ms/step - loss: 0.3095 - categorical_accuracy: 0.8591 - val_loss: 0.4902 - val_categorical_accuracy: 0.7650
Epoch 11/100
 1/72 [..............................] - ETA: 0s - loss: 0.2486 - categorical_accuracy: 0.880035/72 [=============>................] - ETA: 0s - loss: 0.2814 - categorical_accuracy: 0.877569/72 [===========================>..] - ETA: 0s - loss: 0.2828 - categorical_accuracy: 0.877272/72 [==============================] - 0s 2ms/step - loss: 0.2833 - categorical_accuracy: 0.8770 - val_loss: 0.5403 - val_categorical_accuracy: 0.7513
Epoch 00011: early stopping
Experiment:  1  Set:  ss1 Train Labels:  clean Test Labels:  clean
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.85      0.55      0.67       995
           1       0.67      0.91      0.77      1005

    accuracy                           0.73      2000
   macro avg       0.76      0.73      0.72      2000
weighted avg       0.76      0.73      0.72      2000

Confusion Matrix for this model: 
 [[552 443]
 [ 95 910]]
Experiment:  2  Set:  ss1 Train Labels:  clean Test Labels:  ncar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.82      0.53      0.64       994
           1       0.66      0.88      0.75      1006

    accuracy                           0.71      2000
   macro avg       0.74      0.71      0.70      2000
weighted avg       0.74      0.71      0.70      2000

Confusion Matrix for this model: 
 [[529 465]
 [118 888]]
Experiment:  3  Set:  ss1 Train Labels:  clean Test Labels:  ncar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.51      0.63      1005
           1       0.64      0.87      0.74       995

    accuracy                           0.69      2000
   macro avg       0.72      0.69      0.68      2000
weighted avg       0.72      0.69      0.68      2000

Confusion Matrix for this model: 
 [[517 488]
 [130 865]]
Experiment:  4  Set:  ss1 Train Labels:  clean Test Labels:  nar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.52      0.65      1095
           1       0.61      0.91      0.73       905

    accuracy                           0.69      2000
   macro avg       0.74      0.71      0.69      2000
weighted avg       0.75      0.69      0.69      2000

Confusion Matrix for this model: 
 [[566 529]
 [ 81 824]]
Experiment:  5  Set:  ss1 Train Labels:  clean Test Labels:  nar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      0.48      0.62      1194
           1       0.54      0.91      0.68       806

    accuracy                           0.65      2000
   macro avg       0.71      0.69      0.65      2000
weighted avg       0.74      0.65      0.64      2000

Confusion Matrix for this model: 
 [[571 623]
 [ 76 730]]
Experiment:  6  Set:  ss1 Train Labels:  clean Test Labels:  nnar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      0.54      0.67      1052
           1       0.64      0.92      0.76       948

    accuracy                           0.72      2000
   macro avg       0.76      0.73      0.71      2000
weighted avg       0.77      0.72      0.71      2000

Confusion Matrix for this model: 
 [[568 484]
 [ 79 869]]
Experiment:  7  Set:  ss1 Train Labels:  clean Test Labels:  nnar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.89      0.53      0.66      1086
           1       0.62      0.92      0.74       914

    accuracy                           0.71      2000
   macro avg       0.76      0.73      0.70      2000
weighted avg       0.77      0.71      0.70      2000

Confusion Matrix for this model: 
 [[575 511]
 [ 72 842]]
Input Shape:  (8000, 1, 150)
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 32)                23424     
_________________________________________________________________
dropout_1 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 128)               4224      
_________________________________________________________________
dense_5 (Dense)              (None, 128)               16512     
_________________________________________________________________
dense_6 (Dense)              (None, 64)                8256      
_________________________________________________________________
dense_7 (Dense)              (None, 2)                 130       
=================================================================
Total params: 52,546
Trainable params: 52,546
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/72 [..............................] - ETA: 1:05 - loss: 0.6922 - categorical_accuracy: 0.530035/72 [=============>................] - ETA: 0s - loss: 0.6932 - categorical_accuracy: 0.5005  66/72 [==========================>...] - ETA: 0s - loss: 0.6925 - categorical_accuracy: 0.506972/72 [==============================] - 1s 6ms/step - loss: 0.6923 - categorical_accuracy: 0.5084 - val_loss: 0.6852 - val_categorical_accuracy: 0.5412
Epoch 2/100
 1/72 [..............................] - ETA: 0s - loss: 0.6843 - categorical_accuracy: 0.560035/72 [=============>................] - ETA: 0s - loss: 0.6767 - categorical_accuracy: 0.580669/72 [===========================>..] - ETA: 0s - loss: 0.6705 - categorical_accuracy: 0.590072/72 [==============================] - 0s 2ms/step - loss: 0.6697 - categorical_accuracy: 0.5911 - val_loss: 0.6204 - val_categorical_accuracy: 0.6525
Epoch 3/100
 1/72 [..............................] - ETA: 0s - loss: 0.6028 - categorical_accuracy: 0.650036/72 [==============>...............] - ETA: 0s - loss: 0.5943 - categorical_accuracy: 0.685769/72 [===========================>..] - ETA: 0s - loss: 0.5888 - categorical_accuracy: 0.692372/72 [==============================] - 0s 2ms/step - loss: 0.5883 - categorical_accuracy: 0.6929 - val_loss: 0.5985 - val_categorical_accuracy: 0.6712
Epoch 4/100
 1/72 [..............................] - ETA: 0s - loss: 0.4893 - categorical_accuracy: 0.800035/72 [=============>................] - ETA: 0s - loss: 0.5158 - categorical_accuracy: 0.752068/72 [===========================>..] - ETA: 0s - loss: 0.5173 - categorical_accuracy: 0.748372/72 [==============================] - 0s 2ms/step - loss: 0.5171 - categorical_accuracy: 0.7482 - val_loss: 0.5647 - val_categorical_accuracy: 0.6950
Epoch 5/100
 1/72 [..............................] - ETA: 0s - loss: 0.4199 - categorical_accuracy: 0.800035/72 [=============>................] - ETA: 0s - loss: 0.4777 - categorical_accuracy: 0.773370/72 [============================>.] - ETA: 0s - loss: 0.4760 - categorical_accuracy: 0.773672/72 [==============================] - 0s 2ms/step - loss: 0.4757 - categorical_accuracy: 0.7737 - val_loss: 0.5722 - val_categorical_accuracy: 0.7075
Epoch 6/100
 1/72 [..............................] - ETA: 0s - loss: 0.4591 - categorical_accuracy: 0.780036/72 [==============>...............] - ETA: 0s - loss: 0.4325 - categorical_accuracy: 0.802371/72 [============================>.] - ETA: 0s - loss: 0.4314 - categorical_accuracy: 0.803172/72 [==============================] - 0s 2ms/step - loss: 0.4316 - categorical_accuracy: 0.8029 - val_loss: 0.6177 - val_categorical_accuracy: 0.6787
Epoch 7/100
 1/72 [..............................] - ETA: 0s - loss: 0.4263 - categorical_accuracy: 0.810035/72 [=============>................] - ETA: 0s - loss: 0.4033 - categorical_accuracy: 0.814469/72 [===========================>..] - ETA: 0s - loss: 0.4046 - categorical_accuracy: 0.815872/72 [==============================] - 0s 2ms/step - loss: 0.4049 - categorical_accuracy: 0.8159 - val_loss: 0.6068 - val_categorical_accuracy: 0.6837
Epoch 8/100
 1/72 [..............................] - ETA: 0s - loss: 0.3974 - categorical_accuracy: 0.800034/72 [=============>................] - ETA: 0s - loss: 0.3930 - categorical_accuracy: 0.817962/72 [========================>.....] - ETA: 0s - loss: 0.3927 - categorical_accuracy: 0.819672/72 [==============================] - 0s 2ms/step - loss: 0.3924 - categorical_accuracy: 0.8200 - val_loss: 0.5754 - val_categorical_accuracy: 0.7138
Epoch 9/100
 1/72 [..............................] - ETA: 0s - loss: 0.3053 - categorical_accuracy: 0.890034/72 [=============>................] - ETA: 0s - loss: 0.3596 - categorical_accuracy: 0.845067/72 [==========================>...] - ETA: 0s - loss: 0.3643 - categorical_accuracy: 0.842372/72 [==============================] - 0s 2ms/step - loss: 0.3649 - categorical_accuracy: 0.8418 - val_loss: 0.5801 - val_categorical_accuracy: 0.7138
Epoch 10/100
 1/72 [..............................] - ETA: 0s - loss: 0.3400 - categorical_accuracy: 0.870034/72 [=============>................] - ETA: 0s - loss: 0.3219 - categorical_accuracy: 0.867268/72 [===========================>..] - ETA: 0s - loss: 0.3299 - categorical_accuracy: 0.858872/72 [==============================] - 0s 2ms/step - loss: 0.3312 - categorical_accuracy: 0.8577 - val_loss: 0.6468 - val_categorical_accuracy: 0.6950
Epoch 11/100
 1/72 [..............................] - ETA: 0s - loss: 0.2706 - categorical_accuracy: 0.890036/72 [==============>...............] - ETA: 0s - loss: 0.3359 - categorical_accuracy: 0.856170/72 [============================>.] - ETA: 0s - loss: 0.3350 - categorical_accuracy: 0.856672/72 [==============================] - 0s 2ms/step - loss: 0.3353 - categorical_accuracy: 0.8564 - val_loss: 0.6006 - val_categorical_accuracy: 0.7125
Epoch 00011: early stopping
Experiment:  8  Set:  ss1 Train Labels:  ncar5 Test Labels:  clean
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.85      0.58      0.69       995
           1       0.68      0.90      0.78      1005

    accuracy                           0.74      2000
   macro avg       0.77      0.74      0.73      2000
weighted avg       0.77      0.74      0.73      2000

Confusion Matrix for this model: 
 [[574 421]
 [101 904]]
Experiment:  9  Set:  ss1 Train Labels:  ncar5 Test Labels:  ncar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.81      0.55      0.66       994
           1       0.66      0.88      0.76      1006

    accuracy                           0.72      2000
   macro avg       0.74      0.71      0.71      2000
weighted avg       0.74      0.72      0.71      2000

Confusion Matrix for this model: 
 [[550 444]
 [125 881]]
Experiment:  10  Set:  ss1 Train Labels:  ncar5 Test Labels:  ncar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.78      0.53      0.63      1005
           1       0.64      0.85      0.73       995

    accuracy                           0.69      2000
   macro avg       0.71      0.69      0.68      2000
weighted avg       0.71      0.69      0.68      2000

Confusion Matrix for this model: 
 [[529 476]
 [146 849]]
Experiment:  11  Set:  ss1 Train Labels:  ncar5 Test Labels:  nar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.53      0.66      1095
           1       0.61      0.90      0.73       905

    accuracy                           0.70      2000
   macro avg       0.74      0.72      0.69      2000
weighted avg       0.75      0.70      0.69      2000

Confusion Matrix for this model: 
 [[584 511]
 [ 91 814]]
Experiment:  12  Set:  ss1 Train Labels:  ncar5 Test Labels:  nar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.49      0.63      1194
           1       0.54      0.89      0.67       806

    accuracy                           0.65      2000
   macro avg       0.70      0.69      0.65      2000
weighted avg       0.74      0.65      0.65      2000

Confusion Matrix for this model: 
 [[586 608]
 [ 89 717]]
Experiment:  13  Set:  ss1 Train Labels:  ncar5 Test Labels:  nnar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.56      0.68      1052
           1       0.65      0.91      0.76       948

    accuracy                           0.73      2000
   macro avg       0.76      0.74      0.72      2000
weighted avg       0.77      0.73      0.72      2000

Confusion Matrix for this model: 
 [[590 462]
 [ 85 863]]
Experiment:  14  Set:  ss1 Train Labels:  ncar5 Test Labels:  nnar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      0.55      0.68      1086
           1       0.63      0.91      0.75       914

    accuracy                           0.72      2000
   macro avg       0.76      0.73      0.71      2000
weighted avg       0.77      0.72      0.71      2000

Confusion Matrix for this model: 
 [[596 490]
 [ 79 835]]
Input Shape:  (8000, 1, 150)
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_2 (LSTM)                (None, 32)                23424     
_________________________________________________________________
dropout_2 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_8 (Dense)              (None, 128)               4224      
_________________________________________________________________
dense_9 (Dense)              (None, 128)               16512     
_________________________________________________________________
dense_10 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_11 (Dense)             (None, 2)                 130       
=================================================================
Total params: 52,546
Trainable params: 52,546
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/72 [..............................] - ETA: 1:05 - loss: 0.6928 - categorical_accuracy: 0.530033/72 [============>.................] - ETA: 0s - loss: 0.6926 - categorical_accuracy: 0.5137  65/72 [==========================>...] - ETA: 0s - loss: 0.6924 - categorical_accuracy: 0.515072/72 [==============================] - 1s 6ms/step - loss: 0.6922 - categorical_accuracy: 0.5163 - val_loss: 0.6843 - val_categorical_accuracy: 0.5663
Epoch 2/100
 1/72 [..............................] - ETA: 0s - loss: 0.6746 - categorical_accuracy: 0.590035/72 [=============>................] - ETA: 0s - loss: 0.6743 - categorical_accuracy: 0.591868/72 [===========================>..] - ETA: 0s - loss: 0.6704 - categorical_accuracy: 0.595172/72 [==============================] - 0s 2ms/step - loss: 0.6698 - categorical_accuracy: 0.5958 - val_loss: 0.6374 - val_categorical_accuracy: 0.6313
Epoch 3/100
 1/72 [..............................] - ETA: 0s - loss: 0.6296 - categorical_accuracy: 0.620036/72 [==============>...............] - ETA: 0s - loss: 0.6123 - categorical_accuracy: 0.671769/72 [===========================>..] - ETA: 0s - loss: 0.6078 - categorical_accuracy: 0.675272/72 [==============================] - 0s 2ms/step - loss: 0.6074 - categorical_accuracy: 0.6755 - val_loss: 0.6034 - val_categorical_accuracy: 0.6737
Epoch 4/100
 1/72 [..............................] - ETA: 0s - loss: 0.5506 - categorical_accuracy: 0.700035/72 [=============>................] - ETA: 0s - loss: 0.5620 - categorical_accuracy: 0.709070/72 [============================>.] - ETA: 0s - loss: 0.5610 - categorical_accuracy: 0.710272/72 [==============================] - 0s 2ms/step - loss: 0.5609 - categorical_accuracy: 0.7103 - val_loss: 0.5898 - val_categorical_accuracy: 0.6850
Epoch 5/100
 1/72 [..............................] - ETA: 0s - loss: 0.4977 - categorical_accuracy: 0.710032/72 [============>.................] - ETA: 0s - loss: 0.5146 - categorical_accuracy: 0.739665/72 [==========================>...] - ETA: 0s - loss: 0.5154 - categorical_accuracy: 0.741372/72 [==============================] - 0s 2ms/step - loss: 0.5157 - categorical_accuracy: 0.7411 - val_loss: 0.6207 - val_categorical_accuracy: 0.6587
Epoch 6/100
 1/72 [..............................] - ETA: 0s - loss: 0.5253 - categorical_accuracy: 0.700034/72 [=============>................] - ETA: 0s - loss: 0.4974 - categorical_accuracy: 0.756568/72 [===========================>..] - ETA: 0s - loss: 0.4972 - categorical_accuracy: 0.759372/72 [==============================] - 0s 2ms/step - loss: 0.4971 - categorical_accuracy: 0.7595 - val_loss: 0.6241 - val_categorical_accuracy: 0.6800
Epoch 7/100
 1/72 [..............................] - ETA: 0s - loss: 0.4237 - categorical_accuracy: 0.780034/72 [=============>................] - ETA: 0s - loss: 0.4540 - categorical_accuracy: 0.786869/72 [===========================>..] - ETA: 0s - loss: 0.4577 - categorical_accuracy: 0.786072/72 [==============================] - 0s 2ms/step - loss: 0.4579 - categorical_accuracy: 0.7860 - val_loss: 0.5915 - val_categorical_accuracy: 0.7063
Epoch 8/100
 1/72 [..............................] - ETA: 0s - loss: 0.4562 - categorical_accuracy: 0.800037/72 [==============>...............] - ETA: 0s - loss: 0.4229 - categorical_accuracy: 0.808071/72 [============================>.] - ETA: 0s - loss: 0.4292 - categorical_accuracy: 0.805072/72 [==============================] - 0s 2ms/step - loss: 0.4295 - categorical_accuracy: 0.8048 - val_loss: 0.6362 - val_categorical_accuracy: 0.6750
Epoch 9/100
 1/72 [..............................] - ETA: 0s - loss: 0.3604 - categorical_accuracy: 0.830036/72 [==============>...............] - ETA: 0s - loss: 0.4087 - categorical_accuracy: 0.817170/72 [============================>.] - ETA: 0s - loss: 0.4132 - categorical_accuracy: 0.813872/72 [==============================] - 0s 2ms/step - loss: 0.4135 - categorical_accuracy: 0.8135 - val_loss: 0.5962 - val_categorical_accuracy: 0.7163
Epoch 10/100
 1/72 [..............................] - ETA: 0s - loss: 0.4170 - categorical_accuracy: 0.820035/72 [=============>................] - ETA: 0s - loss: 0.3841 - categorical_accuracy: 0.828068/72 [===========================>..] - ETA: 0s - loss: 0.3904 - categorical_accuracy: 0.823072/72 [==============================] - 0s 2ms/step - loss: 0.3913 - categorical_accuracy: 0.8225 - val_loss: 0.6320 - val_categorical_accuracy: 0.6900
Epoch 11/100
 1/72 [..............................] - ETA: 0s - loss: 0.3816 - categorical_accuracy: 0.850035/72 [=============>................] - ETA: 0s - loss: 0.3876 - categorical_accuracy: 0.828870/72 [============================>.] - ETA: 0s - loss: 0.3879 - categorical_accuracy: 0.826772/72 [==============================] - 0s 2ms/step - loss: 0.3881 - categorical_accuracy: 0.8265 - val_loss: 0.6142 - val_categorical_accuracy: 0.6950
Epoch 00011: early stopping
Experiment:  15  Set:  ss1 Train Labels:  ncar10 Test Labels:  clean
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.62      0.69       995
           1       0.69      0.84      0.76      1005

    accuracy                           0.73      2000
   macro avg       0.74      0.73      0.72      2000
weighted avg       0.74      0.73      0.72      2000

Confusion Matrix for this model: 
 [[613 382]
 [163 842]]
Experiment:  16  Set:  ss1 Train Labels:  ncar10 Test Labels:  ncar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.76      0.59      0.67       994
           1       0.67      0.81      0.73      1006

    accuracy                           0.70      2000
   macro avg       0.71      0.70      0.70      2000
weighted avg       0.71      0.70      0.70      2000

Confusion Matrix for this model: 
 [[589 405]
 [187 819]]
Experiment:  17  Set:  ss1 Train Labels:  ncar10 Test Labels:  ncar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.74      0.57      0.64      1005
           1       0.65      0.80      0.71       995

    accuracy                           0.68      2000
   macro avg       0.69      0.68      0.68      2000
weighted avg       0.69      0.68      0.68      2000

Confusion Matrix for this model: 
 [[574 431]
 [202 793]]
Experiment:  18  Set:  ss1 Train Labels:  ncar10 Test Labels:  nar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.81      0.57      0.67      1095
           1       0.62      0.84      0.71       905

    accuracy                           0.69      2000
   macro avg       0.71      0.71      0.69      2000
weighted avg       0.72      0.69      0.69      2000

Confusion Matrix for this model: 
 [[629 466]
 [147 758]]
Experiment:  19  Set:  ss1 Train Labels:  ncar10 Test Labels:  nar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.82      0.53      0.65      1194
           1       0.54      0.83      0.66       806

    accuracy                           0.65      2000
   macro avg       0.68      0.68      0.65      2000
weighted avg       0.71      0.65      0.65      2000

Confusion Matrix for this model: 
 [[637 557]
 [139 667]]
Experiment:  20  Set:  ss1 Train Labels:  ncar10 Test Labels:  nnar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.82      0.60      0.70      1052
           1       0.66      0.85      0.74       948

    accuracy                           0.72      2000
   macro avg       0.74      0.73      0.72      2000
weighted avg       0.74      0.72      0.72      2000

Confusion Matrix for this model: 
 [[636 416]
 [140 808]]
Experiment:  21  Set:  ss1 Train Labels:  ncar10 Test Labels:  nnar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.83      0.59      0.69      1086
           1       0.64      0.86      0.73       914

    accuracy                           0.71      2000
   macro avg       0.74      0.73      0.71      2000
weighted avg       0.74      0.71      0.71      2000

Confusion Matrix for this model: 
 [[646 440]
 [130 784]]
Input Shape:  (8000, 1, 150)
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_3 (LSTM)                (None, 32)                23424     
_________________________________________________________________
dropout_3 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_12 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_13 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_14 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_15 (Dense)             (None, 2)                 130       
=================================================================
Total params: 52,546
Trainable params: 52,546
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/72 [..............................] - ETA: 1:08 - loss: 0.6942 - categorical_accuracy: 0.470030/72 [===========>..................] - ETA: 0s - loss: 0.6907 - categorical_accuracy: 0.5331  61/72 [========================>.....] - ETA: 0s - loss: 0.6898 - categorical_accuracy: 0.536372/72 [==============================] - 1s 6ms/step - loss: 0.6893 - categorical_accuracy: 0.5379 - val_loss: 0.6675 - val_categorical_accuracy: 0.5875
Epoch 2/100
 1/72 [..............................] - ETA: 0s - loss: 0.6657 - categorical_accuracy: 0.590031/72 [===========>..................] - ETA: 0s - loss: 0.6599 - categorical_accuracy: 0.603062/72 [========================>.....] - ETA: 0s - loss: 0.6553 - categorical_accuracy: 0.609372/72 [==============================] - 0s 2ms/step - loss: 0.6534 - categorical_accuracy: 0.6122 - val_loss: 0.5922 - val_categorical_accuracy: 0.6812
Epoch 3/100
 1/72 [..............................] - ETA: 0s - loss: 0.5625 - categorical_accuracy: 0.760034/72 [=============>................] - ETA: 0s - loss: 0.5770 - categorical_accuracy: 0.694165/72 [==========================>...] - ETA: 0s - loss: 0.5735 - categorical_accuracy: 0.696172/72 [==============================] - 0s 2ms/step - loss: 0.5726 - categorical_accuracy: 0.6967 - val_loss: 0.5526 - val_categorical_accuracy: 0.7075
Epoch 4/100
 1/72 [..............................] - ETA: 0s - loss: 0.5177 - categorical_accuracy: 0.700032/72 [============>.................] - ETA: 0s - loss: 0.5042 - categorical_accuracy: 0.736565/72 [==========================>...] - ETA: 0s - loss: 0.5070 - categorical_accuracy: 0.740372/72 [==============================] - 0s 2ms/step - loss: 0.5076 - categorical_accuracy: 0.7407 - val_loss: 0.5318 - val_categorical_accuracy: 0.7100
Epoch 5/100
 1/72 [..............................] - ETA: 0s - loss: 0.3803 - categorical_accuracy: 0.850033/72 [============>.................] - ETA: 0s - loss: 0.4705 - categorical_accuracy: 0.772665/72 [==========================>...] - ETA: 0s - loss: 0.4759 - categorical_accuracy: 0.769472/72 [==============================] - 0s 2ms/step - loss: 0.4760 - categorical_accuracy: 0.7693 - val_loss: 0.5441 - val_categorical_accuracy: 0.7163
Epoch 6/100
 1/72 [..............................] - ETA: 0s - loss: 0.4370 - categorical_accuracy: 0.760032/72 [============>.................] - ETA: 0s - loss: 0.4322 - categorical_accuracy: 0.801163/72 [=========================>....] - ETA: 0s - loss: 0.4369 - categorical_accuracy: 0.798972/72 [==============================] - 0s 2ms/step - loss: 0.4376 - categorical_accuracy: 0.7983 - val_loss: 0.5407 - val_categorical_accuracy: 0.7337
Epoch 7/100
 1/72 [..............................] - ETA: 0s - loss: 0.4137 - categorical_accuracy: 0.840033/72 [============>.................] - ETA: 0s - loss: 0.4015 - categorical_accuracy: 0.818765/72 [==========================>...] - ETA: 0s - loss: 0.4069 - categorical_accuracy: 0.814272/72 [==============================] - 0s 2ms/step - loss: 0.4079 - categorical_accuracy: 0.8135 - val_loss: 0.5132 - val_categorical_accuracy: 0.7437
Epoch 8/100
 1/72 [..............................] - ETA: 0s - loss: 0.3582 - categorical_accuracy: 0.830033/72 [============>.................] - ETA: 0s - loss: 0.3980 - categorical_accuracy: 0.811464/72 [=========================>....] - ETA: 0s - loss: 0.3983 - categorical_accuracy: 0.814072/72 [==============================] - 0s 2ms/step - loss: 0.3989 - categorical_accuracy: 0.8141 - val_loss: 0.5619 - val_categorical_accuracy: 0.7200
Epoch 9/100
 1/72 [..............................] - ETA: 0s - loss: 0.3607 - categorical_accuracy: 0.790032/72 [============>.................] - ETA: 0s - loss: 0.3721 - categorical_accuracy: 0.831864/72 [=========================>....] - ETA: 0s - loss: 0.3780 - categorical_accuracy: 0.829372/72 [==============================] - 0s 2ms/step - loss: 0.3782 - categorical_accuracy: 0.8292 - val_loss: 0.5401 - val_categorical_accuracy: 0.7237
Epoch 10/100
 1/72 [..............................] - ETA: 0s - loss: 0.3387 - categorical_accuracy: 0.820033/72 [============>.................] - ETA: 0s - loss: 0.3564 - categorical_accuracy: 0.832664/72 [=========================>....] - ETA: 0s - loss: 0.3539 - categorical_accuracy: 0.837572/72 [==============================] - 0s 2ms/step - loss: 0.3538 - categorical_accuracy: 0.8381 - val_loss: 0.5592 - val_categorical_accuracy: 0.7300
Epoch 11/100
 1/72 [..............................] - ETA: 0s - loss: 0.2442 - categorical_accuracy: 0.890031/72 [===========>..................] - ETA: 0s - loss: 0.3305 - categorical_accuracy: 0.853562/72 [========================>.....] - ETA: 0s - loss: 0.3317 - categorical_accuracy: 0.853972/72 [==============================] - 0s 2ms/step - loss: 0.3325 - categorical_accuracy: 0.8536 - val_loss: 0.5376 - val_categorical_accuracy: 0.7387
Epoch 12/100
 1/72 [..............................] - ETA: 0s - loss: 0.2751 - categorical_accuracy: 0.900033/72 [============>.................] - ETA: 0s - loss: 0.3361 - categorical_accuracy: 0.856265/72 [==========================>...] - ETA: 0s - loss: 0.3352 - categorical_accuracy: 0.855372/72 [==============================] - 0s 2ms/step - loss: 0.3353 - categorical_accuracy: 0.8549 - val_loss: 0.5747 - val_categorical_accuracy: 0.7200
Epoch 13/100
 1/72 [..............................] - ETA: 0s - loss: 0.2351 - categorical_accuracy: 0.890034/72 [=============>................] - ETA: 0s - loss: 0.3026 - categorical_accuracy: 0.867566/72 [==========================>...] - ETA: 0s - loss: 0.3121 - categorical_accuracy: 0.863172/72 [==============================] - 0s 2ms/step - loss: 0.3130 - categorical_accuracy: 0.8627 - val_loss: 0.6194 - val_categorical_accuracy: 0.7312
Epoch 14/100
 1/72 [..............................] - ETA: 0s - loss: 0.3009 - categorical_accuracy: 0.850033/72 [============>.................] - ETA: 0s - loss: 0.2956 - categorical_accuracy: 0.868465/72 [==========================>...] - ETA: 0s - loss: 0.2968 - categorical_accuracy: 0.867672/72 [==============================] - 0s 2ms/step - loss: 0.2974 - categorical_accuracy: 0.8672 - val_loss: 0.6137 - val_categorical_accuracy: 0.7275
Epoch 00014: early stopping
Experiment:  22  Set:  ss1 Train Labels:  nar5 Test Labels:  clean
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.53      0.65       995
           1       0.66      0.92      0.77      1005

    accuracy                           0.72      2000
   macro avg       0.77      0.72      0.71      2000
weighted avg       0.77      0.72      0.71      2000

Confusion Matrix for this model: 
 [[523 472]
 [ 79 926]]
Experiment:  23  Set:  ss1 Train Labels:  nar5 Test Labels:  ncar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.83      0.50      0.62       994
           1       0.65      0.90      0.75      1006

    accuracy                           0.70      2000
   macro avg       0.74      0.70      0.69      2000
weighted avg       0.74      0.70      0.69      2000

Confusion Matrix for this model: 
 [[498 496]
 [104 902]]
Experiment:  24  Set:  ss1 Train Labels:  nar5 Test Labels:  ncar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.48      0.60      1005
           1       0.63      0.88      0.73       995

    accuracy                           0.68      2000
   macro avg       0.72      0.68      0.67      2000
weighted avg       0.72      0.68      0.67      2000

Confusion Matrix for this model: 
 [[484 521]
 [118 877]]
Experiment:  25  Set:  ss1 Train Labels:  nar5 Test Labels:  nar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      0.49      0.63      1095
           1       0.60      0.92      0.73       905

    accuracy                           0.68      2000
   macro avg       0.74      0.70      0.68      2000
weighted avg       0.75      0.68      0.67      2000

Confusion Matrix for this model: 
 [[532 563]
 [ 70 835]]
Experiment:  26  Set:  ss1 Train Labels:  nar5 Test Labels:  nar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.89      0.45      0.59      1194
           1       0.53      0.92      0.67       806

    accuracy                           0.64      2000
   macro avg       0.71      0.68      0.63      2000
weighted avg       0.74      0.64      0.62      2000

Confusion Matrix for this model: 
 [[534 660]
 [ 68 738]]
Experiment:  27  Set:  ss1 Train Labels:  nar5 Test Labels:  nnar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.89      0.51      0.64      1052
           1       0.63      0.93      0.75       948

    accuracy                           0.71      2000
   macro avg       0.76      0.72      0.70      2000
weighted avg       0.76      0.71      0.69      2000

Confusion Matrix for this model: 
 [[533 519]
 [ 69 879]]
Experiment:  28  Set:  ss1 Train Labels:  nar5 Test Labels:  nnar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.89      0.50      0.64      1086
           1       0.61      0.93      0.74       914

    accuracy                           0.69      2000
   macro avg       0.75      0.71      0.69      2000
weighted avg       0.76      0.69      0.68      2000

Confusion Matrix for this model: 
 [[538 548]
 [ 64 850]]
Input Shape:  (8000, 1, 150)
Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_4 (LSTM)                (None, 32)                23424     
_________________________________________________________________
dropout_4 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_16 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_17 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_18 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_19 (Dense)             (None, 2)                 130       
=================================================================
Total params: 52,546
Trainable params: 52,546
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/72 [..............................] - ETA: 1:08 - loss: 0.6862 - categorical_accuracy: 0.670032/72 [============>.................] - ETA: 0s - loss: 0.6765 - categorical_accuracy: 0.6090  62/72 [========================>.....] - ETA: 0s - loss: 0.6740 - categorical_accuracy: 0.607372/72 [==============================] - 1s 6ms/step - loss: 0.6734 - categorical_accuracy: 0.6069 - val_loss: 0.6571 - val_categorical_accuracy: 0.6150
Epoch 2/100
 1/72 [..............................] - ETA: 0s - loss: 0.6553 - categorical_accuracy: 0.640032/72 [============>.................] - ETA: 0s - loss: 0.6559 - categorical_accuracy: 0.604962/72 [========================>.....] - ETA: 0s - loss: 0.6524 - categorical_accuracy: 0.606472/72 [==============================] - 0s 2ms/step - loss: 0.6509 - categorical_accuracy: 0.6078 - val_loss: 0.6012 - val_categorical_accuracy: 0.6725
Epoch 3/100
 1/72 [..............................] - ETA: 0s - loss: 0.6115 - categorical_accuracy: 0.630031/72 [===========>..................] - ETA: 0s - loss: 0.5843 - categorical_accuracy: 0.678963/72 [=========================>....] - ETA: 0s - loss: 0.5823 - categorical_accuracy: 0.682072/72 [==============================] - 0s 2ms/step - loss: 0.5826 - categorical_accuracy: 0.6814 - val_loss: 0.5841 - val_categorical_accuracy: 0.6787
Epoch 4/100
 1/72 [..............................] - ETA: 0s - loss: 0.4995 - categorical_accuracy: 0.720034/72 [=============>................] - ETA: 0s - loss: 0.5570 - categorical_accuracy: 0.696965/72 [==========================>...] - ETA: 0s - loss: 0.5552 - categorical_accuracy: 0.697472/72 [==============================] - 0s 2ms/step - loss: 0.5547 - categorical_accuracy: 0.6978 - val_loss: 0.5580 - val_categorical_accuracy: 0.7275
Epoch 5/100
 1/72 [..............................] - ETA: 0s - loss: 0.5185 - categorical_accuracy: 0.680033/72 [============>.................] - ETA: 0s - loss: 0.5253 - categorical_accuracy: 0.720965/72 [==========================>...] - ETA: 0s - loss: 0.5194 - categorical_accuracy: 0.728672/72 [==============================] - 0s 2ms/step - loss: 0.5187 - categorical_accuracy: 0.7294 - val_loss: 0.5526 - val_categorical_accuracy: 0.7188
Epoch 6/100
 1/72 [..............................] - ETA: 0s - loss: 0.5058 - categorical_accuracy: 0.760032/72 [============>.................] - ETA: 0s - loss: 0.4748 - categorical_accuracy: 0.767065/72 [==========================>...] - ETA: 0s - loss: 0.4788 - categorical_accuracy: 0.763872/72 [==============================] - 0s 2ms/step - loss: 0.4798 - categorical_accuracy: 0.7635 - val_loss: 0.5480 - val_categorical_accuracy: 0.7163
Epoch 7/100
 1/72 [..............................] - ETA: 0s - loss: 0.4869 - categorical_accuracy: 0.760032/72 [============>.................] - ETA: 0s - loss: 0.4552 - categorical_accuracy: 0.780563/72 [=========================>....] - ETA: 0s - loss: 0.4538 - categorical_accuracy: 0.782372/72 [==============================] - 0s 2ms/step - loss: 0.4544 - categorical_accuracy: 0.7817 - val_loss: 0.5621 - val_categorical_accuracy: 0.7200
Epoch 8/100
 1/72 [..............................] - ETA: 0s - loss: 0.3834 - categorical_accuracy: 0.850032/72 [============>.................] - ETA: 0s - loss: 0.4150 - categorical_accuracy: 0.817964/72 [=========================>....] - ETA: 0s - loss: 0.4225 - categorical_accuracy: 0.809772/72 [==============================] - 0s 2ms/step - loss: 0.4245 - categorical_accuracy: 0.8077 - val_loss: 0.5571 - val_categorical_accuracy: 0.7138
Epoch 9/100
 1/72 [..............................] - ETA: 0s - loss: 0.2980 - categorical_accuracy: 0.870033/72 [============>.................] - ETA: 0s - loss: 0.4030 - categorical_accuracy: 0.816866/72 [==========================>...] - ETA: 0s - loss: 0.4072 - categorical_accuracy: 0.810972/72 [==============================] - 0s 2ms/step - loss: 0.4082 - categorical_accuracy: 0.8099 - val_loss: 0.5408 - val_categorical_accuracy: 0.7350
Epoch 10/100
 1/72 [..............................] - ETA: 0s - loss: 0.3539 - categorical_accuracy: 0.840033/72 [============>.................] - ETA: 0s - loss: 0.3949 - categorical_accuracy: 0.815064/72 [=========================>....] - ETA: 0s - loss: 0.3989 - categorical_accuracy: 0.812272/72 [==============================] - 0s 2ms/step - loss: 0.3999 - categorical_accuracy: 0.8115 - val_loss: 0.5570 - val_categorical_accuracy: 0.7312
Epoch 11/100
 1/72 [..............................] - ETA: 0s - loss: 0.3754 - categorical_accuracy: 0.800033/72 [============>.................] - ETA: 0s - loss: 0.3727 - categorical_accuracy: 0.828564/72 [=========================>....] - ETA: 0s - loss: 0.3721 - categorical_accuracy: 0.829272/72 [==============================] - 0s 2ms/step - loss: 0.3724 - categorical_accuracy: 0.8290 - val_loss: 0.5730 - val_categorical_accuracy: 0.7325
Epoch 12/100
 1/72 [..............................] - ETA: 0s - loss: 0.3106 - categorical_accuracy: 0.870032/72 [============>.................] - ETA: 0s - loss: 0.3605 - categorical_accuracy: 0.832865/72 [==========================>...] - ETA: 0s - loss: 0.3605 - categorical_accuracy: 0.833172/72 [==============================] - 0s 2ms/step - loss: 0.3606 - categorical_accuracy: 0.8328 - val_loss: 0.5830 - val_categorical_accuracy: 0.7175
Epoch 13/100
 1/72 [..............................] - ETA: 0s - loss: 0.3642 - categorical_accuracy: 0.860034/72 [=============>................] - ETA: 0s - loss: 0.3573 - categorical_accuracy: 0.839367/72 [==========================>...] - ETA: 0s - loss: 0.3571 - categorical_accuracy: 0.839772/72 [==============================] - 0s 2ms/step - loss: 0.3573 - categorical_accuracy: 0.8395 - val_loss: 0.5736 - val_categorical_accuracy: 0.7262
Epoch 14/100
 1/72 [..............................] - ETA: 0s - loss: 0.4645 - categorical_accuracy: 0.790032/72 [============>.................] - ETA: 0s - loss: 0.3724 - categorical_accuracy: 0.838763/72 [=========================>....] - ETA: 0s - loss: 0.3613 - categorical_accuracy: 0.842672/72 [==============================] - 0s 2ms/step - loss: 0.3598 - categorical_accuracy: 0.8425 - val_loss: 0.5897 - val_categorical_accuracy: 0.7200
Epoch 15/100
 1/72 [..............................] - ETA: 0s - loss: 0.3326 - categorical_accuracy: 0.840033/72 [============>.................] - ETA: 0s - loss: 0.3226 - categorical_accuracy: 0.856065/72 [==========================>...] - ETA: 0s - loss: 0.3235 - categorical_accuracy: 0.855672/72 [==============================] - 0s 2ms/step - loss: 0.3239 - categorical_accuracy: 0.8555 - val_loss: 0.6183 - val_categorical_accuracy: 0.7175
Epoch 16/100
 1/72 [..............................] - ETA: 0s - loss: 0.2995 - categorical_accuracy: 0.880032/72 [============>.................] - ETA: 0s - loss: 0.3111 - categorical_accuracy: 0.858165/72 [==========================>...] - ETA: 0s - loss: 0.3163 - categorical_accuracy: 0.856072/72 [==============================] - 0s 2ms/step - loss: 0.3173 - categorical_accuracy: 0.8557 - val_loss: 0.6096 - val_categorical_accuracy: 0.7275
Epoch 00016: early stopping
Experiment:  29  Set:  ss1 Train Labels:  nar10 Test Labels:  clean
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.83      0.54      0.65       995
           1       0.66      0.89      0.76      1005

    accuracy                           0.71      2000
   macro avg       0.74      0.71      0.70      2000
weighted avg       0.74      0.71      0.70      2000

Confusion Matrix for this model: 
 [[534 461]
 [112 893]]
Experiment:  30  Set:  ss1 Train Labels:  nar10 Test Labels:  ncar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.51      0.62       994
           1       0.64      0.86      0.74      1006

    accuracy                           0.69      2000
   macro avg       0.72      0.69      0.68      2000
weighted avg       0.72      0.69      0.68      2000

Confusion Matrix for this model: 
 [[510 484]
 [136 870]]
Experiment:  31  Set:  ss1 Train Labels:  nar10 Test Labels:  ncar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.77      0.50      0.61      1005
           1       0.63      0.85      0.72       995

    accuracy                           0.67      2000
   macro avg       0.70      0.68      0.66      2000
weighted avg       0.70      0.67      0.66      2000

Confusion Matrix for this model: 
 [[500 505]
 [146 849]]
Experiment:  32  Set:  ss1 Train Labels:  nar10 Test Labels:  nar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.84      0.50      0.63      1095
           1       0.59      0.89      0.71       905

    accuracy                           0.67      2000
   macro avg       0.72      0.69      0.67      2000
weighted avg       0.73      0.67      0.66      2000

Confusion Matrix for this model: 
 [[545 550]
 [101 804]]
Experiment:  33  Set:  ss1 Train Labels:  nar10 Test Labels:  nar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.47      0.61      1194
           1       0.53      0.89      0.67       806

    accuracy                           0.64      2000
   macro avg       0.70      0.68      0.64      2000
weighted avg       0.73      0.64      0.63      2000

Confusion Matrix for this model: 
 [[561 633]
 [ 85 721]]
Experiment:  34  Set:  ss1 Train Labels:  nar10 Test Labels:  nnar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.85      0.52      0.65      1052
           1       0.63      0.90      0.74       948

    accuracy                           0.70      2000
   macro avg       0.74      0.71      0.70      2000
weighted avg       0.75      0.70      0.69      2000

Confusion Matrix for this model: 
 [[551 501]
 [ 95 853]]
Experiment:  35  Set:  ss1 Train Labels:  nar10 Test Labels:  nnar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.52      0.65      1086
           1       0.61      0.91      0.73       914

    accuracy                           0.69      2000
   macro avg       0.74      0.71      0.69      2000
weighted avg       0.75      0.69      0.68      2000

Confusion Matrix for this model: 
 [[560 526]
 [ 86 828]]
Input Shape:  (8000, 1, 150)
Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_5 (LSTM)                (None, 32)                23424     
_________________________________________________________________
dropout_5 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_20 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_21 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_22 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_23 (Dense)             (None, 2)                 130       
=================================================================
Total params: 52,546
Trainable params: 52,546
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/72 [..............................] - ETA: 1:05 - loss: 0.6906 - categorical_accuracy: 0.540034/72 [=============>................] - ETA: 0s - loss: 0.6915 - categorical_accuracy: 0.5243  67/72 [==========================>...] - ETA: 0s - loss: 0.6900 - categorical_accuracy: 0.533172/72 [==============================] - 1s 6ms/step - loss: 0.6897 - categorical_accuracy: 0.5345 - val_loss: 0.6703 - val_categorical_accuracy: 0.5950
Epoch 2/100
 1/72 [..............................] - ETA: 0s - loss: 0.6766 - categorical_accuracy: 0.550034/72 [=============>................] - ETA: 0s - loss: 0.6608 - categorical_accuracy: 0.612967/72 [==========================>...] - ETA: 0s - loss: 0.6493 - categorical_accuracy: 0.625472/72 [==============================] - 0s 2ms/step - loss: 0.6476 - categorical_accuracy: 0.6270 - val_loss: 0.5851 - val_categorical_accuracy: 0.6837
Epoch 3/100
 1/72 [..............................] - ETA: 0s - loss: 0.5228 - categorical_accuracy: 0.790035/72 [=============>................] - ETA: 0s - loss: 0.5435 - categorical_accuracy: 0.735767/72 [==========================>...] - ETA: 0s - loss: 0.5437 - categorical_accuracy: 0.729572/72 [==============================] - 0s 2ms/step - loss: 0.5434 - categorical_accuracy: 0.7291 - val_loss: 0.5527 - val_categorical_accuracy: 0.7113
Epoch 4/100
 1/72 [..............................] - ETA: 0s - loss: 0.4325 - categorical_accuracy: 0.780032/72 [============>.................] - ETA: 0s - loss: 0.4886 - categorical_accuracy: 0.755566/72 [==========================>...] - ETA: 0s - loss: 0.4878 - categorical_accuracy: 0.760772/72 [==============================] - 0s 2ms/step - loss: 0.4871 - categorical_accuracy: 0.7614 - val_loss: 0.5467 - val_categorical_accuracy: 0.7275
Epoch 5/100
 1/72 [..............................] - ETA: 0s - loss: 0.4303 - categorical_accuracy: 0.750035/72 [=============>................] - ETA: 0s - loss: 0.4275 - categorical_accuracy: 0.798569/72 [===========================>..] - ETA: 0s - loss: 0.4307 - categorical_accuracy: 0.796572/72 [==============================] - 0s 2ms/step - loss: 0.4314 - categorical_accuracy: 0.7960 - val_loss: 0.5269 - val_categorical_accuracy: 0.7375
Epoch 6/100
 1/72 [..............................] - ETA: 0s - loss: 0.3521 - categorical_accuracy: 0.890034/72 [=============>................] - ETA: 0s - loss: 0.4063 - categorical_accuracy: 0.821968/72 [===========================>..] - ETA: 0s - loss: 0.4074 - categorical_accuracy: 0.816772/72 [==============================] - 0s 2ms/step - loss: 0.4078 - categorical_accuracy: 0.8161 - val_loss: 0.5668 - val_categorical_accuracy: 0.7275
Epoch 7/100
 1/72 [..............................] - ETA: 0s - loss: 0.2887 - categorical_accuracy: 0.860035/72 [=============>................] - ETA: 0s - loss: 0.3733 - categorical_accuracy: 0.827469/72 [===========================>..] - ETA: 0s - loss: 0.3790 - categorical_accuracy: 0.825972/72 [==============================] - 0s 2ms/step - loss: 0.3793 - categorical_accuracy: 0.8258 - val_loss: 0.5199 - val_categorical_accuracy: 0.7513
Epoch 8/100
 1/72 [..............................] - ETA: 0s - loss: 0.2953 - categorical_accuracy: 0.880035/72 [=============>................] - ETA: 0s - loss: 0.3385 - categorical_accuracy: 0.855169/72 [===========================>..] - ETA: 0s - loss: 0.3428 - categorical_accuracy: 0.852072/72 [==============================] - 0s 2ms/step - loss: 0.3433 - categorical_accuracy: 0.8517 - val_loss: 0.5570 - val_categorical_accuracy: 0.7412
Epoch 9/100
 1/72 [..............................] - ETA: 0s - loss: 0.3329 - categorical_accuracy: 0.860034/72 [=============>................] - ETA: 0s - loss: 0.3272 - categorical_accuracy: 0.854268/72 [===========================>..] - ETA: 0s - loss: 0.3311 - categorical_accuracy: 0.852972/72 [==============================] - 0s 2ms/step - loss: 0.3316 - categorical_accuracy: 0.8526 - val_loss: 0.5544 - val_categorical_accuracy: 0.7513
Epoch 10/100
 1/72 [..............................] - ETA: 0s - loss: 0.2862 - categorical_accuracy: 0.870036/72 [==============>...............] - ETA: 0s - loss: 0.3068 - categorical_accuracy: 0.864969/72 [===========================>..] - ETA: 0s - loss: 0.3103 - categorical_accuracy: 0.863572/72 [==============================] - 0s 2ms/step - loss: 0.3107 - categorical_accuracy: 0.8634 - val_loss: 0.5347 - val_categorical_accuracy: 0.7700
Epoch 11/100
 1/72 [..............................] - ETA: 0s - loss: 0.3219 - categorical_accuracy: 0.860034/72 [=============>................] - ETA: 0s - loss: 0.2941 - categorical_accuracy: 0.868968/72 [===========================>..] - ETA: 0s - loss: 0.2980 - categorical_accuracy: 0.869672/72 [==============================] - 0s 2ms/step - loss: 0.2986 - categorical_accuracy: 0.8695 - val_loss: 0.5340 - val_categorical_accuracy: 0.7750
Epoch 12/100
 1/72 [..............................] - ETA: 0s - loss: 0.3143 - categorical_accuracy: 0.840035/72 [=============>................] - ETA: 0s - loss: 0.2838 - categorical_accuracy: 0.876368/72 [===========================>..] - ETA: 0s - loss: 0.2893 - categorical_accuracy: 0.874772/72 [==============================] - 0s 2ms/step - loss: 0.2895 - categorical_accuracy: 0.8747 - val_loss: 0.5893 - val_categorical_accuracy: 0.7563
Epoch 13/100
 1/72 [..............................] - ETA: 0s - loss: 0.2268 - categorical_accuracy: 0.930036/72 [==============>...............] - ETA: 0s - loss: 0.2583 - categorical_accuracy: 0.899569/72 [===========================>..] - ETA: 0s - loss: 0.2648 - categorical_accuracy: 0.893472/72 [==============================] - 0s 2ms/step - loss: 0.2653 - categorical_accuracy: 0.8929 - val_loss: 0.6123 - val_categorical_accuracy: 0.7550
Epoch 14/100
 1/72 [..............................] - ETA: 0s - loss: 0.2481 - categorical_accuracy: 0.920036/72 [==============>...............] - ETA: 0s - loss: 0.2605 - categorical_accuracy: 0.896871/72 [============================>.] - ETA: 0s - loss: 0.2594 - categorical_accuracy: 0.895872/72 [==============================] - 0s 2ms/step - loss: 0.2595 - categorical_accuracy: 0.8957 - val_loss: 0.6218 - val_categorical_accuracy: 0.7538
Epoch 00014: early stopping
Experiment:  36  Set:  ss1 Train Labels:  nnar5 Test Labels:  clean
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.86      0.55      0.67       995
           1       0.67      0.91      0.78      1005

    accuracy                           0.73      2000
   macro avg       0.77      0.73      0.72      2000
weighted avg       0.77      0.73      0.72      2000

Confusion Matrix for this model: 
 [[548 447]
 [ 86 919]]
Experiment:  37  Set:  ss1 Train Labels:  nnar5 Test Labels:  ncar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.82      0.52      0.64       994
           1       0.65      0.89      0.75      1006

    accuracy                           0.71      2000
   macro avg       0.74      0.71      0.70      2000
weighted avg       0.74      0.71      0.70      2000

Confusion Matrix for this model: 
 [[521 473]
 [113 893]]
Experiment:  38  Set:  ss1 Train Labels:  nnar5 Test Labels:  ncar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.51      0.62      1005
           1       0.64      0.87      0.74       995

    accuracy                           0.69      2000
   macro avg       0.72      0.69      0.68      2000
weighted avg       0.72      0.69      0.68      2000

Confusion Matrix for this model: 
 [[508 497]
 [126 869]]
Experiment:  39  Set:  ss1 Train Labels:  nnar5 Test Labels:  nar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      0.51      0.64      1095
           1       0.60      0.91      0.73       905

    accuracy                           0.69      2000
   macro avg       0.74      0.71      0.68      2000
weighted avg       0.75      0.69      0.68      2000

Confusion Matrix for this model: 
 [[555 540]
 [ 79 826]]
Experiment:  40  Set:  ss1 Train Labels:  nnar5 Test Labels:  nar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      0.47      0.61      1194
           1       0.53      0.91      0.67       806

    accuracy                           0.64      2000
   macro avg       0.71      0.69      0.64      2000
weighted avg       0.74      0.64      0.64      2000

Confusion Matrix for this model: 
 [[558 636]
 [ 76 730]]
Experiment:  41  Set:  ss1 Train Labels:  nnar5 Test Labels:  nnar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      0.53      0.66      1052
           1       0.64      0.92      0.76       948

    accuracy                           0.72      2000
   macro avg       0.76      0.73      0.71      2000
weighted avg       0.77      0.72      0.71      2000

Confusion Matrix for this model: 
 [[560 492]
 [ 74 874]]
Experiment:  42  Set:  ss1 Train Labels:  nnar5 Test Labels:  nnar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.89      0.52      0.66      1086
           1       0.62      0.93      0.74       914

    accuracy                           0.71      2000
   macro avg       0.76      0.72      0.70      2000
weighted avg       0.77      0.71      0.70      2000

Confusion Matrix for this model: 
 [[567 519]
 [ 67 847]]
Input Shape:  (8000, 1, 150)
Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_6 (LSTM)                (None, 32)                23424     
_________________________________________________________________
dropout_6 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_24 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_25 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_26 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_27 (Dense)             (None, 2)                 130       
=================================================================
Total params: 52,546
Trainable params: 52,546
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/72 [..............................] - ETA: 1:02 - loss: 0.6933 - categorical_accuracy: 0.510033/72 [============>.................] - ETA: 0s - loss: 0.6905 - categorical_accuracy: 0.5375  67/72 [==========================>...] - ETA: 0s - loss: 0.6887 - categorical_accuracy: 0.541472/72 [==============================] - 1s 6ms/step - loss: 0.6884 - categorical_accuracy: 0.5419 - val_loss: 0.6719 - val_categorical_accuracy: 0.5962
Epoch 2/100
 1/72 [..............................] - ETA: 0s - loss: 0.6798 - categorical_accuracy: 0.540035/72 [=============>................] - ETA: 0s - loss: 0.6609 - categorical_accuracy: 0.607569/72 [===========================>..] - ETA: 0s - loss: 0.6483 - categorical_accuracy: 0.622472/72 [==============================] - 0s 2ms/step - loss: 0.6472 - categorical_accuracy: 0.6235 - val_loss: 0.5855 - val_categorical_accuracy: 0.6900
Epoch 3/100
 1/72 [..............................] - ETA: 0s - loss: 0.5563 - categorical_accuracy: 0.690036/72 [==============>...............] - ETA: 0s - loss: 0.5588 - categorical_accuracy: 0.717970/72 [============================>.] - ETA: 0s - loss: 0.5495 - categorical_accuracy: 0.721872/72 [==============================] - 0s 2ms/step - loss: 0.5490 - categorical_accuracy: 0.7219 - val_loss: 0.5252 - val_categorical_accuracy: 0.7412
Epoch 4/100
 1/72 [..............................] - ETA: 0s - loss: 0.4528 - categorical_accuracy: 0.790036/72 [==============>...............] - ETA: 0s - loss: 0.4645 - categorical_accuracy: 0.777670/72 [============================>.] - ETA: 0s - loss: 0.4696 - categorical_accuracy: 0.775772/72 [==============================] - 0s 2ms/step - loss: 0.4699 - categorical_accuracy: 0.7754 - val_loss: 0.5462 - val_categorical_accuracy: 0.7212
Epoch 5/100
 1/72 [..............................] - ETA: 0s - loss: 0.3759 - categorical_accuracy: 0.830036/72 [==============>...............] - ETA: 0s - loss: 0.4327 - categorical_accuracy: 0.799271/72 [============================>.] - ETA: 0s - loss: 0.4352 - categorical_accuracy: 0.796572/72 [==============================] - 0s 2ms/step - loss: 0.4356 - categorical_accuracy: 0.7962 - val_loss: 0.5023 - val_categorical_accuracy: 0.7500
Epoch 6/100
 1/72 [..............................] - ETA: 0s - loss: 0.4392 - categorical_accuracy: 0.770036/72 [==============>...............] - ETA: 0s - loss: 0.4123 - categorical_accuracy: 0.804371/72 [============================>.] - ETA: 0s - loss: 0.4089 - categorical_accuracy: 0.807572/72 [==============================] - 0s 2ms/step - loss: 0.4090 - categorical_accuracy: 0.8074 - val_loss: 0.5357 - val_categorical_accuracy: 0.7375
Epoch 7/100
 1/72 [..............................] - ETA: 0s - loss: 0.3450 - categorical_accuracy: 0.880035/72 [=============>................] - ETA: 0s - loss: 0.3837 - categorical_accuracy: 0.829470/72 [============================>.] - ETA: 0s - loss: 0.3831 - categorical_accuracy: 0.825472/72 [==============================] - 0s 2ms/step - loss: 0.3832 - categorical_accuracy: 0.8251 - val_loss: 0.5179 - val_categorical_accuracy: 0.7500
Epoch 8/100
 1/72 [..............................] - ETA: 0s - loss: 0.4245 - categorical_accuracy: 0.810035/72 [=============>................] - ETA: 0s - loss: 0.3566 - categorical_accuracy: 0.842768/72 [===========================>..] - ETA: 0s - loss: 0.3593 - categorical_accuracy: 0.840472/72 [==============================] - 0s 2ms/step - loss: 0.3597 - categorical_accuracy: 0.8401 - val_loss: 0.5352 - val_categorical_accuracy: 0.7487
Epoch 9/100
 1/72 [..............................] - ETA: 0s - loss: 0.3031 - categorical_accuracy: 0.870036/72 [==============>...............] - ETA: 0s - loss: 0.3343 - categorical_accuracy: 0.857671/72 [============================>.] - ETA: 0s - loss: 0.3367 - categorical_accuracy: 0.855672/72 [==============================] - 0s 2ms/step - loss: 0.3368 - categorical_accuracy: 0.8554 - val_loss: 0.5470 - val_categorical_accuracy: 0.7387
Epoch 10/100
 1/72 [..............................] - ETA: 0s - loss: 0.3121 - categorical_accuracy: 0.870035/72 [=============>................] - ETA: 0s - loss: 0.3153 - categorical_accuracy: 0.862169/72 [===========================>..] - ETA: 0s - loss: 0.3181 - categorical_accuracy: 0.860572/72 [==============================] - 0s 2ms/step - loss: 0.3184 - categorical_accuracy: 0.8603 - val_loss: 0.5495 - val_categorical_accuracy: 0.7575
Epoch 11/100
 1/72 [..............................] - ETA: 0s - loss: 0.2724 - categorical_accuracy: 0.910034/72 [=============>................] - ETA: 0s - loss: 0.2793 - categorical_accuracy: 0.884367/72 [==========================>...] - ETA: 0s - loss: 0.2861 - categorical_accuracy: 0.878172/72 [==============================] - 0s 2ms/step - loss: 0.2877 - categorical_accuracy: 0.8770 - val_loss: 0.6421 - val_categorical_accuracy: 0.7163
Epoch 12/100
 1/72 [..............................] - ETA: 0s - loss: 0.3346 - categorical_accuracy: 0.830035/72 [=============>................] - ETA: 0s - loss: 0.2940 - categorical_accuracy: 0.868467/72 [==========================>...] - ETA: 0s - loss: 0.2953 - categorical_accuracy: 0.869372/72 [==============================] - 0s 2ms/step - loss: 0.2960 - categorical_accuracy: 0.8692 - val_loss: 0.6273 - val_categorical_accuracy: 0.7250
Epoch 00012: early stopping
Experiment:  43  Set:  ss1 Train Labels:  nnar10 Test Labels:  clean
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      0.49      0.63       995
           1       0.65      0.94      0.77      1005

    accuracy                           0.71      2000
   macro avg       0.77      0.71      0.70      2000
weighted avg       0.77      0.71      0.70      2000

Confusion Matrix for this model: 
 [[483 512]
 [ 63 942]]
Experiment:  44  Set:  ss1 Train Labels:  nnar10 Test Labels:  ncar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.85      0.47      0.60       994
           1       0.64      0.92      0.75      1006

    accuracy                           0.69      2000
   macro avg       0.74      0.69      0.68      2000
weighted avg       0.74      0.69      0.68      2000

Confusion Matrix for this model: 
 [[465 529]
 [ 81 925]]
Experiment:  45  Set:  ss1 Train Labels:  nnar10 Test Labels:  ncar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.83      0.45      0.58      1005
           1       0.62      0.91      0.74       995

    accuracy                           0.68      2000
   macro avg       0.72      0.68      0.66      2000
weighted avg       0.72      0.68      0.66      2000

Confusion Matrix for this model: 
 [[452 553]
 [ 94 901]]
Experiment:  46  Set:  ss1 Train Labels:  nnar10 Test Labels:  nar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.90      0.45      0.60      1095
           1       0.58      0.94      0.72       905

    accuracy                           0.67      2000
   macro avg       0.74      0.69      0.66      2000
weighted avg       0.76      0.67      0.65      2000

Confusion Matrix for this model: 
 [[491 604]
 [ 55 850]]
Experiment:  47  Set:  ss1 Train Labels:  nnar10 Test Labels:  nar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.90      0.41      0.57      1194
           1       0.52      0.94      0.67       806

    accuracy                           0.62      2000
   macro avg       0.71      0.67      0.62      2000
weighted avg       0.75      0.62      0.61      2000

Confusion Matrix for this model: 
 [[494 700]
 [ 52 754]]
Experiment:  48  Set:  ss1 Train Labels:  nnar10 Test Labels:  nnar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.91      0.47      0.62      1052
           1       0.62      0.95      0.75       948

    accuracy                           0.70      2000
   macro avg       0.77      0.71      0.69      2000
weighted avg       0.77      0.70      0.68      2000

Confusion Matrix for this model: 
 [[498 554]
 [ 48 900]]
Experiment:  49  Set:  ss1 Train Labels:  nnar10 Test Labels:  nnar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.92      0.46      0.62      1086
           1       0.60      0.95      0.74       914

    accuracy                           0.69      2000
   macro avg       0.76      0.71      0.68      2000
weighted avg       0.78      0.69      0.67      2000

Confusion Matrix for this model: 
 [[504 582]
 [ 42 872]]
Input Shape:  (24000, 1, 150)
Model: "sequential_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_7 (LSTM)                (None, 32)                23424     
_________________________________________________________________
dropout_7 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_28 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_29 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_30 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_31 (Dense)             (None, 5)                 325       
=================================================================
Total params: 52,741
Trainable params: 52,741
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
  1/216 [..............................] - ETA: 3:24 - loss: 1.6107 - categorical_accuracy: 0.2100 33/216 [===>..........................] - ETA: 0s - loss: 1.6062 - categorical_accuracy: 0.2149   66/216 [========>.....................] - ETA: 0s - loss: 1.5811 - categorical_accuracy: 0.2384 99/216 [============>.................] - ETA: 0s - loss: 1.5419 - categorical_accuracy: 0.2634132/216 [=================>............] - ETA: 0s - loss: 1.5051 - categorical_accuracy: 0.2842165/216 [=====================>........] - ETA: 0s - loss: 1.4736 - categorical_accuracy: 0.3014199/216 [==========================>...] - ETA: 0s - loss: 1.4456 - categorical_accuracy: 0.3167216/216 [==============================] - 2s 3ms/step - loss: 1.4324 - categorical_accuracy: 0.3239 - val_loss: 1.0511 - val_categorical_accuracy: 0.5292
Epoch 2/100
  1/216 [..............................] - ETA: 0s - loss: 1.0836 - categorical_accuracy: 0.5700 34/216 [===>..........................] - ETA: 0s - loss: 1.1043 - categorical_accuracy: 0.5007 66/216 [========>.....................] - ETA: 0s - loss: 1.1016 - categorical_accuracy: 0.4960 97/216 [============>.................] - ETA: 0s - loss: 1.0995 - categorical_accuracy: 0.4962126/216 [================>.............] - ETA: 0s - loss: 1.0956 - categorical_accuracy: 0.4981158/216 [====================>.........] - ETA: 0s - loss: 1.0915 - categorical_accuracy: 0.5005192/216 [=========================>....] - ETA: 0s - loss: 1.0888 - categorical_accuracy: 0.5023216/216 [==============================] - 0s 2ms/step - loss: 1.0870 - categorical_accuracy: 0.5035 - val_loss: 0.9769 - val_categorical_accuracy: 0.5592
Epoch 3/100
  1/216 [..............................] - ETA: 0s - loss: 1.0213 - categorical_accuracy: 0.5900 33/216 [===>..........................] - ETA: 0s - loss: 1.0129 - categorical_accuracy: 0.5582 65/216 [========>.....................] - ETA: 0s - loss: 1.0154 - categorical_accuracy: 0.5531 94/216 [============>.................] - ETA: 0s - loss: 1.0152 - categorical_accuracy: 0.5513128/216 [================>.............] - ETA: 0s - loss: 1.0157 - categorical_accuracy: 0.5497161/216 [=====================>........] - ETA: 0s - loss: 1.0151 - categorical_accuracy: 0.5490194/216 [=========================>....] - ETA: 0s - loss: 1.0144 - categorical_accuracy: 0.5487216/216 [==============================] - 0s 2ms/step - loss: 1.0142 - categorical_accuracy: 0.5483 - val_loss: 0.9410 - val_categorical_accuracy: 0.5929
Epoch 4/100
  1/216 [..............................] - ETA: 0s - loss: 0.9992 - categorical_accuracy: 0.5400 34/216 [===>..........................] - ETA: 0s - loss: 0.9541 - categorical_accuracy: 0.5672 68/216 [========>.....................] - ETA: 0s - loss: 0.9660 - categorical_accuracy: 0.5610102/216 [=============>................] - ETA: 0s - loss: 0.9684 - categorical_accuracy: 0.5609136/216 [=================>............] - ETA: 0s - loss: 0.9689 - categorical_accuracy: 0.5615170/216 [======================>.......] - ETA: 0s - loss: 0.9691 - categorical_accuracy: 0.5616204/216 [===========================>..] - ETA: 0s - loss: 0.9695 - categorical_accuracy: 0.5613216/216 [==============================] - 0s 2ms/step - loss: 0.9696 - categorical_accuracy: 0.5612 - val_loss: 0.9198 - val_categorical_accuracy: 0.5979
Epoch 5/100
  1/216 [..............................] - ETA: 0s - loss: 0.9289 - categorical_accuracy: 0.5400 35/216 [===>..........................] - ETA: 0s - loss: 0.9536 - categorical_accuracy: 0.5556 66/216 [========>.....................] - ETA: 0s - loss: 0.9513 - categorical_accuracy: 0.5623100/216 [============>.................] - ETA: 0s - loss: 0.9474 - categorical_accuracy: 0.5652134/216 [=================>............] - ETA: 0s - loss: 0.9439 - categorical_accuracy: 0.5675168/216 [======================>.......] - ETA: 0s - loss: 0.9420 - categorical_accuracy: 0.5691202/216 [===========================>..] - ETA: 0s - loss: 0.9412 - categorical_accuracy: 0.5700216/216 [==============================] - 0s 2ms/step - loss: 0.9410 - categorical_accuracy: 0.5702 - val_loss: 0.8936 - val_categorical_accuracy: 0.6046
Epoch 6/100
  1/216 [..............................] - ETA: 0s - loss: 0.8667 - categorical_accuracy: 0.6300 35/216 [===>..........................] - ETA: 0s - loss: 0.8796 - categorical_accuracy: 0.6115 69/216 [========>.....................] - ETA: 0s - loss: 0.8884 - categorical_accuracy: 0.6046103/216 [=============>................] - ETA: 0s - loss: 0.8953 - categorical_accuracy: 0.5988138/216 [==================>...........] - ETA: 0s - loss: 0.8998 - categorical_accuracy: 0.5953172/216 [======================>.......] - ETA: 0s - loss: 0.9021 - categorical_accuracy: 0.5935206/216 [===========================>..] - ETA: 0s - loss: 0.9037 - categorical_accuracy: 0.5921216/216 [==============================] - 0s 2ms/step - loss: 0.9042 - categorical_accuracy: 0.5917 - val_loss: 0.8982 - val_categorical_accuracy: 0.6050
Epoch 7/100
  1/216 [..............................] - ETA: 0s - loss: 0.8873 - categorical_accuracy: 0.6500 35/216 [===>..........................] - ETA: 0s - loss: 0.8874 - categorical_accuracy: 0.5970 68/216 [========>.....................] - ETA: 0s - loss: 0.8885 - categorical_accuracy: 0.5934102/216 [=============>................] - ETA: 0s - loss: 0.8886 - categorical_accuracy: 0.5923136/216 [=================>............] - ETA: 0s - loss: 0.8883 - categorical_accuracy: 0.5924169/216 [======================>.......] - ETA: 0s - loss: 0.8883 - categorical_accuracy: 0.5926200/216 [==========================>...] - ETA: 0s - loss: 0.8886 - categorical_accuracy: 0.5926216/216 [==============================] - 0s 2ms/step - loss: 0.8889 - categorical_accuracy: 0.5925 - val_loss: 0.8859 - val_categorical_accuracy: 0.6067
Epoch 8/100
  1/216 [..............................] - ETA: 0s - loss: 0.8252 - categorical_accuracy: 0.6500 34/216 [===>..........................] - ETA: 0s - loss: 0.8474 - categorical_accuracy: 0.6159 67/216 [========>.....................] - ETA: 0s - loss: 0.8548 - categorical_accuracy: 0.6103101/216 [=============>................] - ETA: 0s - loss: 0.8589 - categorical_accuracy: 0.6080134/216 [=================>............] - ETA: 0s - loss: 0.8613 - categorical_accuracy: 0.6065168/216 [======================>.......] - ETA: 0s - loss: 0.8636 - categorical_accuracy: 0.6051202/216 [===========================>..] - ETA: 0s - loss: 0.8652 - categorical_accuracy: 0.6040216/216 [==============================] - 0s 2ms/step - loss: 0.8658 - categorical_accuracy: 0.6037 - val_loss: 0.8633 - val_categorical_accuracy: 0.6067
Epoch 9/100
  1/216 [..............................] - ETA: 0s - loss: 0.8643 - categorical_accuracy: 0.5700 35/216 [===>..........................] - ETA: 0s - loss: 0.8707 - categorical_accuracy: 0.5966 68/216 [========>.....................] - ETA: 0s - loss: 0.8625 - categorical_accuracy: 0.6030101/216 [=============>................] - ETA: 0s - loss: 0.8599 - categorical_accuracy: 0.6045135/216 [=================>............] - ETA: 0s - loss: 0.8589 - categorical_accuracy: 0.6058169/216 [======================>.......] - ETA: 0s - loss: 0.8586 - categorical_accuracy: 0.6065203/216 [===========================>..] - ETA: 0s - loss: 0.8584 - categorical_accuracy: 0.6067216/216 [==============================] - 0s 2ms/step - loss: 0.8583 - categorical_accuracy: 0.6067 - val_loss: 0.8568 - val_categorical_accuracy: 0.6196
Epoch 10/100
  1/216 [..............................] - ETA: 0s - loss: 0.9040 - categorical_accuracy: 0.6600 35/216 [===>..........................] - ETA: 0s - loss: 0.8433 - categorical_accuracy: 0.6343 68/216 [========>.....................] - ETA: 0s - loss: 0.8390 - categorical_accuracy: 0.6303102/216 [=============>................] - ETA: 0s - loss: 0.8375 - categorical_accuracy: 0.6289135/216 [=================>............] - ETA: 0s - loss: 0.8374 - categorical_accuracy: 0.6279165/216 [=====================>........] - ETA: 0s - loss: 0.8381 - categorical_accuracy: 0.6269197/216 [==========================>...] - ETA: 0s - loss: 0.8389 - categorical_accuracy: 0.6258216/216 [==============================] - 0s 2ms/step - loss: 0.8392 - categorical_accuracy: 0.6254 - val_loss: 0.8590 - val_categorical_accuracy: 0.6187
Epoch 11/100
  1/216 [..............................] - ETA: 0s - loss: 0.7083 - categorical_accuracy: 0.6300 35/216 [===>..........................] - ETA: 0s - loss: 0.8155 - categorical_accuracy: 0.6169 69/216 [========>.....................] - ETA: 0s - loss: 0.8213 - categorical_accuracy: 0.6195104/216 [=============>................] - ETA: 0s - loss: 0.8234 - categorical_accuracy: 0.6211138/216 [==================>...........] - ETA: 0s - loss: 0.8247 - categorical_accuracy: 0.6219173/216 [=======================>......] - ETA: 0s - loss: 0.8257 - categorical_accuracy: 0.6225206/216 [===========================>..] - ETA: 0s - loss: 0.8264 - categorical_accuracy: 0.6228216/216 [==============================] - 0s 2ms/step - loss: 0.8266 - categorical_accuracy: 0.6229 - val_loss: 0.8597 - val_categorical_accuracy: 0.6171
Epoch 12/100
  1/216 [..............................] - ETA: 0s - loss: 0.8820 - categorical_accuracy: 0.5500 35/216 [===>..........................] - ETA: 0s - loss: 0.8074 - categorical_accuracy: 0.6246 69/216 [========>.....................] - ETA: 0s - loss: 0.8087 - categorical_accuracy: 0.6275102/216 [=============>................] - ETA: 0s - loss: 0.8096 - categorical_accuracy: 0.6276137/216 [==================>...........] - ETA: 0s - loss: 0.8108 - categorical_accuracy: 0.6279170/216 [======================>.......] - ETA: 0s - loss: 0.8117 - categorical_accuracy: 0.6279204/216 [===========================>..] - ETA: 0s - loss: 0.8122 - categorical_accuracy: 0.6280216/216 [==============================] - 0s 2ms/step - loss: 0.8124 - categorical_accuracy: 0.6279 - val_loss: 0.8550 - val_categorical_accuracy: 0.6217
Epoch 13/100
  1/216 [..............................] - ETA: 0s - loss: 0.7858 - categorical_accuracy: 0.6100 32/216 [===>..........................] - ETA: 0s - loss: 0.8128 - categorical_accuracy: 0.6313 63/216 [=======>......................] - ETA: 0s - loss: 0.8130 - categorical_accuracy: 0.6318 97/216 [============>.................] - ETA: 0s - loss: 0.8105 - categorical_accuracy: 0.6331129/216 [================>.............] - ETA: 0s - loss: 0.8083 - categorical_accuracy: 0.6337164/216 [=====================>........] - ETA: 0s - loss: 0.8076 - categorical_accuracy: 0.6339195/216 [==========================>...] - ETA: 0s - loss: 0.8071 - categorical_accuracy: 0.6340216/216 [==============================] - 0s 2ms/step - loss: 0.8069 - categorical_accuracy: 0.6341 - val_loss: 0.8520 - val_categorical_accuracy: 0.6212
Epoch 14/100
  1/216 [..............................] - ETA: 0s - loss: 0.6614 - categorical_accuracy: 0.7300 35/216 [===>..........................] - ETA: 0s - loss: 0.7776 - categorical_accuracy: 0.6492 69/216 [========>.....................] - ETA: 0s - loss: 0.7829 - categorical_accuracy: 0.6486102/216 [=============>................] - ETA: 0s - loss: 0.7854 - categorical_accuracy: 0.6485135/216 [=================>............] - ETA: 0s - loss: 0.7873 - categorical_accuracy: 0.6476169/216 [======================>.......] - ETA: 0s - loss: 0.7891 - categorical_accuracy: 0.6466202/216 [===========================>..] - ETA: 0s - loss: 0.7902 - categorical_accuracy: 0.6457216/216 [==============================] - 0s 2ms/step - loss: 0.7906 - categorical_accuracy: 0.6453 - val_loss: 0.8345 - val_categorical_accuracy: 0.6288
Epoch 15/100
  1/216 [..............................] - ETA: 0s - loss: 0.6716 - categorical_accuracy: 0.6800 33/216 [===>..........................] - ETA: 0s - loss: 0.7384 - categorical_accuracy: 0.6683 64/216 [=======>......................] - ETA: 0s - loss: 0.7526 - categorical_accuracy: 0.6638 98/216 [============>.................] - ETA: 0s - loss: 0.7612 - categorical_accuracy: 0.6609130/216 [=================>............] - ETA: 0s - loss: 0.7667 - categorical_accuracy: 0.6584161/216 [=====================>........] - ETA: 0s - loss: 0.7699 - categorical_accuracy: 0.6570193/216 [=========================>....] - ETA: 0s - loss: 0.7721 - categorical_accuracy: 0.6561216/216 [==============================] - 0s 2ms/step - loss: 0.7733 - categorical_accuracy: 0.6556 - val_loss: 0.8407 - val_categorical_accuracy: 0.6246
Epoch 16/100
  1/216 [..............................] - ETA: 0s - loss: 0.7592 - categorical_accuracy: 0.6300 35/216 [===>..........................] - ETA: 0s - loss: 0.7804 - categorical_accuracy: 0.6361 64/216 [=======>......................] - ETA: 0s - loss: 0.7776 - categorical_accuracy: 0.6421 94/216 [============>.................] - ETA: 0s - loss: 0.7747 - categorical_accuracy: 0.6446125/216 [================>.............] - ETA: 0s - loss: 0.7744 - categorical_accuracy: 0.6459160/216 [=====================>........] - ETA: 0s - loss: 0.7746 - categorical_accuracy: 0.6465194/216 [=========================>....] - ETA: 0s - loss: 0.7751 - categorical_accuracy: 0.6466216/216 [==============================] - 0s 2ms/step - loss: 0.7753 - categorical_accuracy: 0.6466 - val_loss: 0.8370 - val_categorical_accuracy: 0.6292
Epoch 17/100
  1/216 [..............................] - ETA: 0s - loss: 0.7249 - categorical_accuracy: 0.6900 34/216 [===>..........................] - ETA: 0s - loss: 0.7717 - categorical_accuracy: 0.6551 68/216 [========>.....................] - ETA: 0s - loss: 0.7716 - categorical_accuracy: 0.6545102/216 [=============>................] - ETA: 0s - loss: 0.7723 - categorical_accuracy: 0.6532135/216 [=================>............] - ETA: 0s - loss: 0.7722 - categorical_accuracy: 0.6531167/216 [======================>.......] - ETA: 0s - loss: 0.7716 - categorical_accuracy: 0.6534201/216 [==========================>...] - ETA: 0s - loss: 0.7710 - categorical_accuracy: 0.6536216/216 [==============================] - 0s 2ms/step - loss: 0.7707 - categorical_accuracy: 0.6537 - val_loss: 0.8363 - val_categorical_accuracy: 0.6354
Epoch 18/100
  1/216 [..............................] - ETA: 0s - loss: 0.7028 - categorical_accuracy: 0.7000 35/216 [===>..........................] - ETA: 0s - loss: 0.7303 - categorical_accuracy: 0.6679 68/216 [========>.....................] - ETA: 0s - loss: 0.7418 - categorical_accuracy: 0.6643 94/216 [============>.................] - ETA: 0s - loss: 0.7452 - categorical_accuracy: 0.6626126/216 [================>.............] - ETA: 0s - loss: 0.7486 - categorical_accuracy: 0.6610159/216 [=====================>........] - ETA: 0s - loss: 0.7506 - categorical_accuracy: 0.6604191/216 [=========================>....] - ETA: 0s - loss: 0.7522 - categorical_accuracy: 0.6600216/216 [==============================] - 0s 2ms/step - loss: 0.7534 - categorical_accuracy: 0.6598 - val_loss: 0.8445 - val_categorical_accuracy: 0.6279
Epoch 19/100
  1/216 [..............................] - ETA: 0s - loss: 0.8395 - categorical_accuracy: 0.6100 35/216 [===>..........................] - ETA: 0s - loss: 0.7591 - categorical_accuracy: 0.6604 69/216 [========>.....................] - ETA: 0s - loss: 0.7539 - categorical_accuracy: 0.6611101/216 [=============>................] - ETA: 0s - loss: 0.7501 - categorical_accuracy: 0.6624128/216 [================>.............] - ETA: 0s - loss: 0.7487 - categorical_accuracy: 0.6633161/216 [=====================>........] - ETA: 0s - loss: 0.7489 - categorical_accuracy: 0.6632194/216 [=========================>....] - ETA: 0s - loss: 0.7491 - categorical_accuracy: 0.6630216/216 [==============================] - 0s 2ms/step - loss: 0.7494 - categorical_accuracy: 0.6627 - val_loss: 0.8477 - val_categorical_accuracy: 0.6217
Epoch 20/100
  1/216 [..............................] - ETA: 0s - loss: 0.7560 - categorical_accuracy: 0.6700 34/216 [===>..........................] - ETA: 0s - loss: 0.7638 - categorical_accuracy: 0.6576 68/216 [========>.....................] - ETA: 0s - loss: 0.7583 - categorical_accuracy: 0.6602 99/216 [============>.................] - ETA: 0s - loss: 0.7547 - categorical_accuracy: 0.6617130/216 [=================>............] - ETA: 0s - loss: 0.7524 - categorical_accuracy: 0.6622163/216 [=====================>........] - ETA: 0s - loss: 0.7508 - categorical_accuracy: 0.6624196/216 [==========================>...] - ETA: 0s - loss: 0.7495 - categorical_accuracy: 0.6626216/216 [==============================] - 0s 2ms/step - loss: 0.7488 - categorical_accuracy: 0.6629 - val_loss: 0.8379 - val_categorical_accuracy: 0.6288
Epoch 21/100
  1/216 [..............................] - ETA: 0s - loss: 0.7808 - categorical_accuracy: 0.6400 35/216 [===>..........................] - ETA: 0s - loss: 0.7200 - categorical_accuracy: 0.6810 69/216 [========>.....................] - ETA: 0s - loss: 0.7220 - categorical_accuracy: 0.6760104/216 [=============>................] - ETA: 0s - loss: 0.7267 - categorical_accuracy: 0.6730138/216 [==================>...........] - ETA: 0s - loss: 0.7280 - categorical_accuracy: 0.6718171/216 [======================>.......] - ETA: 0s - loss: 0.7288 - categorical_accuracy: 0.6711204/216 [===========================>..] - ETA: 0s - loss: 0.7299 - categorical_accuracy: 0.6706216/216 [==============================] - 0s 2ms/step - loss: 0.7302 - categorical_accuracy: 0.6705 - val_loss: 0.8111 - val_categorical_accuracy: 0.6450
Epoch 22/100
  1/216 [..............................] - ETA: 0s - loss: 0.8267 - categorical_accuracy: 0.6900 35/216 [===>..........................] - ETA: 0s - loss: 0.7460 - categorical_accuracy: 0.6686 69/216 [========>.....................] - ETA: 0s - loss: 0.7307 - categorical_accuracy: 0.6746103/216 [=============>................] - ETA: 0s - loss: 0.7268 - categorical_accuracy: 0.6753138/216 [==================>...........] - ETA: 0s - loss: 0.7254 - categorical_accuracy: 0.6752172/216 [======================>.......] - ETA: 0s - loss: 0.7246 - categorical_accuracy: 0.6753206/216 [===========================>..] - ETA: 0s - loss: 0.7246 - categorical_accuracy: 0.6752216/216 [==============================] - 0s 2ms/step - loss: 0.7248 - categorical_accuracy: 0.6751 - val_loss: 0.8389 - val_categorical_accuracy: 0.6283
Epoch 23/100
  1/216 [..............................] - ETA: 0s - loss: 0.7064 - categorical_accuracy: 0.6600 23/216 [==>...........................] - ETA: 0s - loss: 0.7178 - categorical_accuracy: 0.6591 52/216 [======>.......................] - ETA: 0s - loss: 0.7162 - categorical_accuracy: 0.6665 79/216 [=========>....................] - ETA: 0s - loss: 0.7164 - categorical_accuracy: 0.6694108/216 [==============>...............] - ETA: 0s - loss: 0.7163 - categorical_accuracy: 0.6708138/216 [==================>...........] - ETA: 0s - loss: 0.7159 - categorical_accuracy: 0.6721165/216 [=====================>........] - ETA: 0s - loss: 0.7161 - categorical_accuracy: 0.6728191/216 [=========================>....] - ETA: 0s - loss: 0.7166 - categorical_accuracy: 0.6732216/216 [==============================] - 0s 2ms/step - loss: 0.7172 - categorical_accuracy: 0.6734 - val_loss: 0.8317 - val_categorical_accuracy: 0.6308
Epoch 24/100
  1/216 [..............................] - ETA: 0s - loss: 0.7212 - categorical_accuracy: 0.6200 29/216 [===>..........................] - ETA: 0s - loss: 0.7199 - categorical_accuracy: 0.6609 59/216 [=======>......................] - ETA: 0s - loss: 0.7183 - categorical_accuracy: 0.6662 91/216 [===========>..................] - ETA: 0s - loss: 0.7173 - categorical_accuracy: 0.6691120/216 [===============>..............] - ETA: 0s - loss: 0.7161 - categorical_accuracy: 0.6713149/216 [===================>..........] - ETA: 0s - loss: 0.7150 - categorical_accuracy: 0.6728179/216 [=======================>......] - ETA: 0s - loss: 0.7149 - categorical_accuracy: 0.6734210/216 [============================>.] - ETA: 0s - loss: 0.7151 - categorical_accuracy: 0.6737216/216 [==============================] - 0s 2ms/step - loss: 0.7152 - categorical_accuracy: 0.6738 - val_loss: 0.8360 - val_categorical_accuracy: 0.6288
Epoch 25/100
  1/216 [..............................] - ETA: 0s - loss: 0.7449 - categorical_accuracy: 0.6700 30/216 [===>..........................] - ETA: 0s - loss: 0.7092 - categorical_accuracy: 0.6881 63/216 [=======>......................] - ETA: 0s - loss: 0.7044 - categorical_accuracy: 0.6907 95/216 [============>.................] - ETA: 0s - loss: 0.7025 - categorical_accuracy: 0.6912127/216 [================>.............] - ETA: 0s - loss: 0.7024 - categorical_accuracy: 0.6902161/216 [=====================>........] - ETA: 0s - loss: 0.7037 - categorical_accuracy: 0.6888194/216 [=========================>....] - ETA: 0s - loss: 0.7048 - categorical_accuracy: 0.6877216/216 [==============================] - 0s 2ms/step - loss: 0.7054 - categorical_accuracy: 0.6872 - val_loss: 0.8313 - val_categorical_accuracy: 0.6329
Epoch 26/100
  1/216 [..............................] - ETA: 0s - loss: 0.7712 - categorical_accuracy: 0.6800 34/216 [===>..........................] - ETA: 0s - loss: 0.7123 - categorical_accuracy: 0.6761 66/216 [========>.....................] - ETA: 0s - loss: 0.7067 - categorical_accuracy: 0.6797 98/216 [============>.................] - ETA: 0s - loss: 0.7038 - categorical_accuracy: 0.6817131/216 [=================>............] - ETA: 0s - loss: 0.7032 - categorical_accuracy: 0.6824163/216 [=====================>........] - ETA: 0s - loss: 0.7033 - categorical_accuracy: 0.6829198/216 [==========================>...] - ETA: 0s - loss: 0.7036 - categorical_accuracy: 0.6830216/216 [==============================] - 0s 2ms/step - loss: 0.7038 - categorical_accuracy: 0.6831 - val_loss: 0.8496 - val_categorical_accuracy: 0.6288
Epoch 27/100
  1/216 [..............................] - ETA: 0s - loss: 0.7870 - categorical_accuracy: 0.6300 27/216 [==>...........................] - ETA: 0s - loss: 0.7116 - categorical_accuracy: 0.6792 58/216 [=======>......................] - ETA: 0s - loss: 0.7004 - categorical_accuracy: 0.6827 91/216 [===========>..................] - ETA: 0s - loss: 0.6990 - categorical_accuracy: 0.6847124/216 [================>.............] - ETA: 0s - loss: 0.6993 - categorical_accuracy: 0.6860159/216 [=====================>........] - ETA: 0s - loss: 0.6997 - categorical_accuracy: 0.6866194/216 [=========================>....] - ETA: 0s - loss: 0.7002 - categorical_accuracy: 0.6868216/216 [==============================] - 0s 2ms/step - loss: 0.7006 - categorical_accuracy: 0.6868 - val_loss: 0.8229 - val_categorical_accuracy: 0.6392
Epoch 28/100
  1/216 [..............................] - ETA: 0s - loss: 0.6144 - categorical_accuracy: 0.7300 37/216 [====>.........................] - ETA: 0s - loss: 0.6598 - categorical_accuracy: 0.7133 72/216 [=========>....................] - ETA: 0s - loss: 0.6679 - categorical_accuracy: 0.7084107/216 [=============>................] - ETA: 0s - loss: 0.6705 - categorical_accuracy: 0.7063141/216 [==================>...........] - ETA: 0s - loss: 0.6730 - categorical_accuracy: 0.7041175/216 [=======================>......] - ETA: 0s - loss: 0.6757 - categorical_accuracy: 0.7020208/216 [===========================>..] - ETA: 0s - loss: 0.6782 - categorical_accuracy: 0.7001216/216 [==============================] - 0s 2ms/step - loss: 0.6787 - categorical_accuracy: 0.6996 - val_loss: 0.8316 - val_categorical_accuracy: 0.6350
Epoch 00028: early stopping
Experiment:  50  Set:  ss2 Train Labels:  clean Test Labels:  clean
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.84      0.78      0.81      1240
           1       0.64      0.59      0.61      1218
           2       0.53      0.58      0.55      1184
           3       0.51      0.54      0.52      1175
           4       0.68      0.68      0.68      1183

    accuracy                           0.63      6000
   macro avg       0.64      0.63      0.64      6000
weighted avg       0.64      0.63      0.64      6000

Confusion Matrix for this model: 
 [[962 270   7   0   1]
 [167 716 321   8   6]
 [  4 119 692 292  77]
 [  0   8 237 633 297]
 [  9   5  53 310 806]]
Experiment:  51  Set:  ss2 Train Labels:  clean Test Labels:  ncar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.75      0.77      1203
           1       0.61      0.56      0.58      1215
           2       0.52      0.56      0.54      1206
           3       0.49      0.51      0.50      1190
           4       0.65      0.65      0.65      1186

    accuracy                           0.60      6000
   macro avg       0.61      0.61      0.61      6000
weighted avg       0.61      0.60      0.61      6000

Confusion Matrix for this model: 
 [[898 263  17  10  15]
 [167 678 314  31  25]
 [ 25 130 679 288  84]
 [ 23  27 236 608 296]
 [ 29  20  64 306 767]]
Experiment:  52  Set:  ss2 Train Labels:  clean Test Labels:  ncar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.75      0.71      0.73      1206
           1       0.60      0.54      0.57      1250
           2       0.48      0.52      0.50      1210
           3       0.47      0.49      0.48      1172
           4       0.61      0.62      0.61      1162

    accuracy                           0.58      6000
   macro avg       0.58      0.58      0.58      6000
weighted avg       0.58      0.58      0.58      6000

Confusion Matrix for this model: 
 [[856 252  39  24  35]
 [183 669 314  48  36]
 [ 31 140 635 293 111]
 [ 33  33 242 579 285]
 [ 39  24  80 299 720]]
Experiment:  53  Set:  ss2 Train Labels:  clean Test Labels:  nar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.61      0.77      0.68       908
           1       0.64      0.59      0.61      1218
           2       0.53      0.58      0.55      1184
           3       0.51      0.42      0.46      1507
           4       0.68      0.68      0.68      1183

    accuracy                           0.59      6000
   macro avg       0.59      0.61      0.60      6000
weighted avg       0.59      0.59      0.59      6000

Confusion Matrix for this model: 
 [[702 199   6   0   1]
 [167 716 321   8   6]
 [  4 119 692 292  77]
 [260  79 238 633 297]
 [  9   5  53 310 806]]
Experiment:  54  Set:  ss2 Train Labels:  clean Test Labels:  nar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.42      0.77      0.54       623
           1       0.64      0.59      0.61      1218
           2       0.53      0.58      0.55      1184
           3       0.51      0.35      0.42      1792
           4       0.68      0.68      0.68      1183

    accuracy                           0.55      6000
   macro avg       0.56      0.60      0.56      6000
weighted avg       0.56      0.55      0.55      6000

Confusion Matrix for this model: 
 [[480 139   3   0   1]
 [167 716 321   8   6]
 [  4 119 692 292  77]
 [482 139 241 633 297]
 [  9   5  53 310 806]]
Experiment:  55  Set:  ss2 Train Labels:  clean Test Labels:  nnar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.78      0.79      0.79      1120
           1       0.68      0.57      0.62      1327
           2       0.53      0.58      0.55      1184
           3       0.51      0.54      0.52      1178
           4       0.68      0.68      0.68      1191

    accuracy                           0.63      6000
   macro avg       0.63      0.63      0.63      6000
weighted avg       0.63      0.63      0.63      6000

Confusion Matrix for this model: 
 [[888 228   3   0   1]
 [232 756 325   8   6]
 [  4 119 692 292  77]
 [  1  10 237 633 297]
 [ 17   5  53 310 806]]
Experiment:  56  Set:  ss2 Train Labels:  clean Test Labels:  nnar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.77      0.80      0.78      1111
           1       0.68      0.57      0.62      1332
           2       0.53      0.58      0.55      1184
           3       0.51      0.54      0.52      1178
           4       0.68      0.67      0.68      1195

    accuracy                           0.63      6000
   macro avg       0.63      0.63      0.63      6000
weighted avg       0.63      0.63      0.63      6000

Confusion Matrix for this model: 
 [[884 223   3   0   1]
 [233 760 325   8   6]
 [  4 119 692 292  77]
 [  1  10 237 633 297]
 [ 20   6  53 310 806]]
Input Shape:  (24000, 1, 150)
Model: "sequential_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_8 (LSTM)                (None, 32)                23424     
_________________________________________________________________
dropout_8 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_32 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_33 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_34 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_35 (Dense)             (None, 5)                 325       
=================================================================
Total params: 52,741
Trainable params: 52,741
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
  1/216 [..............................] - ETA: 3:08 - loss: 1.6110 - categorical_accuracy: 0.1900 33/216 [===>..........................] - ETA: 0s - loss: 1.6021 - categorical_accuracy: 0.2307   67/216 [========>.....................] - ETA: 0s - loss: 1.5720 - categorical_accuracy: 0.2537102/216 [=============>................] - ETA: 0s - loss: 1.5347 - categorical_accuracy: 0.2789137/216 [==================>...........] - ETA: 0s - loss: 1.5030 - categorical_accuracy: 0.2977172/216 [======================>.......] - ETA: 0s - loss: 1.4773 - categorical_accuracy: 0.3130206/216 [===========================>..] - ETA: 0s - loss: 1.4570 - categorical_accuracy: 0.3252216/216 [==============================] - 1s 3ms/step - loss: 1.4511 - categorical_accuracy: 0.3288 - val_loss: 1.1554 - val_categorical_accuracy: 0.5021
Epoch 2/100
  1/216 [..............................] - ETA: 0s - loss: 1.1487 - categorical_accuracy: 0.5500 35/216 [===>..........................] - ETA: 0s - loss: 1.2084 - categorical_accuracy: 0.4853 71/216 [========>.....................] - ETA: 0s - loss: 1.2039 - categorical_accuracy: 0.4865106/216 [=============>................] - ETA: 0s - loss: 1.2034 - categorical_accuracy: 0.4849139/216 [==================>...........] - ETA: 0s - loss: 1.2017 - categorical_accuracy: 0.4849171/216 [======================>.......] - ETA: 0s - loss: 1.1988 - categorical_accuracy: 0.4851207/216 [===========================>..] - ETA: 0s - loss: 1.1960 - categorical_accuracy: 0.4854216/216 [==============================] - 0s 2ms/step - loss: 1.1953 - categorical_accuracy: 0.4855 - val_loss: 1.0945 - val_categorical_accuracy: 0.5333
Epoch 3/100
  1/216 [..............................] - ETA: 0s - loss: 1.0259 - categorical_accuracy: 0.5400 36/216 [====>.........................] - ETA: 0s - loss: 1.1445 - categorical_accuracy: 0.4921 71/216 [========>.....................] - ETA: 0s - loss: 1.1413 - categorical_accuracy: 0.4988107/216 [=============>................] - ETA: 0s - loss: 1.1381 - categorical_accuracy: 0.5021142/216 [==================>...........] - ETA: 0s - loss: 1.1356 - categorical_accuracy: 0.5042178/216 [=======================>......] - ETA: 0s - loss: 1.1339 - categorical_accuracy: 0.5056213/216 [============================>.] - ETA: 0s - loss: 1.1324 - categorical_accuracy: 0.5067216/216 [==============================] - 0s 2ms/step - loss: 1.1322 - categorical_accuracy: 0.5068 - val_loss: 1.0514 - val_categorical_accuracy: 0.5467
Epoch 4/100
  1/216 [..............................] - ETA: 0s - loss: 1.0953 - categorical_accuracy: 0.4900 36/216 [====>.........................] - ETA: 0s - loss: 1.0759 - categorical_accuracy: 0.5412 71/216 [========>.....................] - ETA: 0s - loss: 1.0799 - categorical_accuracy: 0.5368103/216 [=============>................] - ETA: 0s - loss: 1.0803 - categorical_accuracy: 0.5362139/216 [==================>...........] - ETA: 0s - loss: 1.0796 - categorical_accuracy: 0.5369174/216 [=======================>......] - ETA: 0s - loss: 1.0797 - categorical_accuracy: 0.5367209/216 [============================>.] - ETA: 0s - loss: 1.0798 - categorical_accuracy: 0.5362216/216 [==============================] - 0s 2ms/step - loss: 1.0799 - categorical_accuracy: 0.5361 - val_loss: 1.0337 - val_categorical_accuracy: 0.5604
Epoch 5/100
  1/216 [..............................] - ETA: 0s - loss: 1.1017 - categorical_accuracy: 0.4800 36/216 [====>.........................] - ETA: 0s - loss: 1.0514 - categorical_accuracy: 0.5274 71/216 [========>.....................] - ETA: 0s - loss: 1.0486 - categorical_accuracy: 0.5339106/216 [=============>................] - ETA: 0s - loss: 1.0507 - categorical_accuracy: 0.5362136/216 [=================>............] - ETA: 0s - loss: 1.0528 - categorical_accuracy: 0.5368172/216 [======================>.......] - ETA: 0s - loss: 1.0540 - categorical_accuracy: 0.5374207/216 [===========================>..] - ETA: 0s - loss: 1.0544 - categorical_accuracy: 0.5382216/216 [==============================] - 0s 2ms/step - loss: 1.0545 - categorical_accuracy: 0.5383 - val_loss: 1.0155 - val_categorical_accuracy: 0.5746
Epoch 6/100
  1/216 [..............................] - ETA: 0s - loss: 1.0204 - categorical_accuracy: 0.5800 36/216 [====>.........................] - ETA: 0s - loss: 1.0169 - categorical_accuracy: 0.5812 70/216 [========>.....................] - ETA: 0s - loss: 1.0199 - categorical_accuracy: 0.5755105/216 [=============>................] - ETA: 0s - loss: 1.0254 - categorical_accuracy: 0.5716139/216 [==================>...........] - ETA: 0s - loss: 1.0270 - categorical_accuracy: 0.5698172/216 [======================>.......] - ETA: 0s - loss: 1.0278 - categorical_accuracy: 0.5689203/216 [===========================>..] - ETA: 0s - loss: 1.0285 - categorical_accuracy: 0.5681216/216 [==============================] - 0s 2ms/step - loss: 1.0288 - categorical_accuracy: 0.5677 - val_loss: 1.0127 - val_categorical_accuracy: 0.5633
Epoch 7/100
  1/216 [..............................] - ETA: 0s - loss: 0.9091 - categorical_accuracy: 0.5400 33/216 [===>..........................] - ETA: 0s - loss: 1.0040 - categorical_accuracy: 0.5654 66/216 [========>.....................] - ETA: 0s - loss: 1.0101 - categorical_accuracy: 0.5676 96/216 [============>.................] - ETA: 0s - loss: 1.0115 - categorical_accuracy: 0.5676129/216 [================>.............] - ETA: 0s - loss: 1.0119 - categorical_accuracy: 0.5673164/216 [=====================>........] - ETA: 0s - loss: 1.0121 - categorical_accuracy: 0.5671197/216 [==========================>...] - ETA: 0s - loss: 1.0121 - categorical_accuracy: 0.5671216/216 [==============================] - 0s 2ms/step - loss: 1.0123 - categorical_accuracy: 0.5668 - val_loss: 0.9850 - val_categorical_accuracy: 0.5879
Epoch 8/100
  1/216 [..............................] - ETA: 0s - loss: 0.8873 - categorical_accuracy: 0.6700 35/216 [===>..........................] - ETA: 0s - loss: 0.9632 - categorical_accuracy: 0.5899 68/216 [========>.....................] - ETA: 0s - loss: 0.9740 - categorical_accuracy: 0.5888 99/216 [============>.................] - ETA: 0s - loss: 0.9783 - categorical_accuracy: 0.5872126/216 [================>.............] - ETA: 0s - loss: 0.9813 - categorical_accuracy: 0.5852154/216 [====================>.........] - ETA: 0s - loss: 0.9838 - categorical_accuracy: 0.5832176/216 [=======================>......] - ETA: 0s - loss: 0.9852 - categorical_accuracy: 0.5821197/216 [==========================>...] - ETA: 0s - loss: 0.9862 - categorical_accuracy: 0.5812216/216 [==============================] - 0s 2ms/step - loss: 0.9869 - categorical_accuracy: 0.5806 - val_loss: 0.9842 - val_categorical_accuracy: 0.5896
Epoch 9/100
  1/216 [..............................] - ETA: 0s - loss: 0.8565 - categorical_accuracy: 0.6800 29/216 [===>..........................] - ETA: 0s - loss: 0.9602 - categorical_accuracy: 0.6088 56/216 [======>.......................] - ETA: 0s - loss: 0.9687 - categorical_accuracy: 0.6002 86/216 [==========>...................] - ETA: 0s - loss: 0.9736 - categorical_accuracy: 0.5959117/216 [===============>..............] - ETA: 0s - loss: 0.9746 - categorical_accuracy: 0.5941151/216 [===================>..........] - ETA: 0s - loss: 0.9751 - categorical_accuracy: 0.5931186/216 [========================>.....] - ETA: 0s - loss: 0.9754 - categorical_accuracy: 0.5920215/216 [============================>.] - ETA: 0s - loss: 0.9757 - categorical_accuracy: 0.5913216/216 [==============================] - 0s 2ms/step - loss: 0.9758 - categorical_accuracy: 0.5912 - val_loss: 0.9779 - val_categorical_accuracy: 0.5888
Epoch 10/100
  1/216 [..............................] - ETA: 0s - loss: 0.9182 - categorical_accuracy: 0.5700 35/216 [===>..........................] - ETA: 0s - loss: 0.9331 - categorical_accuracy: 0.5972 67/216 [========>.....................] - ETA: 0s - loss: 0.9370 - categorical_accuracy: 0.5972101/216 [=============>................] - ETA: 0s - loss: 0.9413 - categorical_accuracy: 0.5961122/216 [===============>..............] - ETA: 0s - loss: 0.9434 - categorical_accuracy: 0.5961150/216 [===================>..........] - ETA: 0s - loss: 0.9458 - categorical_accuracy: 0.5959178/216 [=======================>......] - ETA: 0s - loss: 0.9475 - categorical_accuracy: 0.5958207/216 [===========================>..] - ETA: 0s - loss: 0.9495 - categorical_accuracy: 0.5953216/216 [==============================] - 0s 2ms/step - loss: 0.9502 - categorical_accuracy: 0.5950 - val_loss: 0.9761 - val_categorical_accuracy: 0.5888
Epoch 11/100
  1/216 [..............................] - ETA: 0s - loss: 0.9634 - categorical_accuracy: 0.5600 34/216 [===>..........................] - ETA: 0s - loss: 0.9359 - categorical_accuracy: 0.6036 63/216 [=======>......................] - ETA: 0s - loss: 0.9396 - categorical_accuracy: 0.6008 89/216 [===========>..................] - ETA: 0s - loss: 0.9435 - categorical_accuracy: 0.5985115/216 [==============>...............] - ETA: 0s - loss: 0.9467 - categorical_accuracy: 0.5969142/216 [==================>...........] - ETA: 0s - loss: 0.9494 - categorical_accuracy: 0.5957164/216 [=====================>........] - ETA: 0s - loss: 0.9508 - categorical_accuracy: 0.5949189/216 [=========================>....] - ETA: 0s - loss: 0.9518 - categorical_accuracy: 0.5944216/216 [==============================] - 0s 2ms/step - loss: 0.9522 - categorical_accuracy: 0.5943 - val_loss: 0.9651 - val_categorical_accuracy: 0.5888
Epoch 12/100
  1/216 [..............................] - ETA: 0s - loss: 0.9445 - categorical_accuracy: 0.6300 35/216 [===>..........................] - ETA: 0s - loss: 0.9497 - categorical_accuracy: 0.5993 69/216 [========>.....................] - ETA: 0s - loss: 0.9486 - categorical_accuracy: 0.5992103/216 [=============>................] - ETA: 0s - loss: 0.9444 - categorical_accuracy: 0.5995137/216 [==================>...........] - ETA: 0s - loss: 0.9420 - categorical_accuracy: 0.6000172/216 [======================>.......] - ETA: 0s - loss: 0.9414 - categorical_accuracy: 0.5995205/216 [===========================>..] - ETA: 0s - loss: 0.9415 - categorical_accuracy: 0.5991216/216 [==============================] - 0s 2ms/step - loss: 0.9415 - categorical_accuracy: 0.5989 - val_loss: 0.9622 - val_categorical_accuracy: 0.6004
Epoch 13/100
  1/216 [..............................] - ETA: 0s - loss: 0.9561 - categorical_accuracy: 0.6100 23/216 [==>...........................] - ETA: 0s - loss: 0.8801 - categorical_accuracy: 0.6463 41/216 [====>.........................] - ETA: 0s - loss: 0.8826 - categorical_accuracy: 0.6413 64/216 [=======>......................] - ETA: 0s - loss: 0.8885 - categorical_accuracy: 0.6352 84/216 [==========>...................] - ETA: 0s - loss: 0.8930 - categorical_accuracy: 0.6319103/216 [=============>................] - ETA: 0s - loss: 0.8969 - categorical_accuracy: 0.6296129/216 [================>.............] - ETA: 0s - loss: 0.9017 - categorical_accuracy: 0.6269156/216 [====================>.........] - ETA: 0s - loss: 0.9052 - categorical_accuracy: 0.6248180/216 [========================>.....] - ETA: 0s - loss: 0.9076 - categorical_accuracy: 0.6233203/216 [===========================>..] - ETA: 0s - loss: 0.9094 - categorical_accuracy: 0.6221216/216 [==============================] - 1s 2ms/step - loss: 0.9105 - categorical_accuracy: 0.6214 - val_loss: 0.9651 - val_categorical_accuracy: 0.6000
Epoch 14/100
  1/216 [..............................] - ETA: 0s - loss: 0.8855 - categorical_accuracy: 0.6300 31/216 [===>..........................] - ETA: 0s - loss: 0.9414 - categorical_accuracy: 0.6091 59/216 [=======>......................] - ETA: 0s - loss: 0.9333 - categorical_accuracy: 0.6129 84/216 [==========>...................] - ETA: 0s - loss: 0.9269 - categorical_accuracy: 0.6146108/216 [==============>...............] - ETA: 0s - loss: 0.9248 - categorical_accuracy: 0.6150133/216 [=================>............] - ETA: 0s - loss: 0.9237 - categorical_accuracy: 0.6149156/216 [====================>.........] - ETA: 0s - loss: 0.9221 - categorical_accuracy: 0.6150179/216 [=======================>......] - ETA: 0s - loss: 0.9209 - categorical_accuracy: 0.6148203/216 [===========================>..] - ETA: 0s - loss: 0.9204 - categorical_accuracy: 0.6145216/216 [==============================] - 0s 2ms/step - loss: 0.9202 - categorical_accuracy: 0.6143 - val_loss: 0.9447 - val_categorical_accuracy: 0.6021
Epoch 15/100
  1/216 [..............................] - ETA: 0s - loss: 0.8250 - categorical_accuracy: 0.6200 28/216 [==>...........................] - ETA: 0s - loss: 0.9065 - categorical_accuracy: 0.6170 55/216 [======>.......................] - ETA: 0s - loss: 0.9086 - categorical_accuracy: 0.6148 79/216 [=========>....................] - ETA: 0s - loss: 0.9084 - categorical_accuracy: 0.6149102/216 [=============>................] - ETA: 0s - loss: 0.9094 - categorical_accuracy: 0.6146128/216 [================>.............] - ETA: 0s - loss: 0.9092 - categorical_accuracy: 0.6146150/216 [===================>..........] - ETA: 0s - loss: 0.9090 - categorical_accuracy: 0.6147174/216 [=======================>......] - ETA: 0s - loss: 0.9091 - categorical_accuracy: 0.6147197/216 [==========================>...] - ETA: 0s - loss: 0.9091 - categorical_accuracy: 0.6147216/216 [==============================] - 0s 2ms/step - loss: 0.9091 - categorical_accuracy: 0.6146 - val_loss: 0.9803 - val_categorical_accuracy: 0.6012
Epoch 16/100
  1/216 [..............................] - ETA: 0s - loss: 0.8629 - categorical_accuracy: 0.6500 29/216 [===>..........................] - ETA: 0s - loss: 0.9142 - categorical_accuracy: 0.6170 55/216 [======>.......................] - ETA: 0s - loss: 0.9108 - categorical_accuracy: 0.6197 84/216 [==========>...................] - ETA: 0s - loss: 0.9089 - categorical_accuracy: 0.6204114/216 [==============>...............] - ETA: 0s - loss: 0.9074 - categorical_accuracy: 0.6202143/216 [==================>...........] - ETA: 0s - loss: 0.9066 - categorical_accuracy: 0.6203166/216 [======================>.......] - ETA: 0s - loss: 0.9054 - categorical_accuracy: 0.6206194/216 [=========================>....] - ETA: 0s - loss: 0.9044 - categorical_accuracy: 0.6209216/216 [==============================] - 0s 2ms/step - loss: 0.9040 - categorical_accuracy: 0.6209 - val_loss: 0.9515 - val_categorical_accuracy: 0.6121
Epoch 17/100
  1/216 [..............................] - ETA: 0s - loss: 0.8759 - categorical_accuracy: 0.6600 27/216 [==>...........................] - ETA: 0s - loss: 0.8813 - categorical_accuracy: 0.6304 59/216 [=======>......................] - ETA: 0s - loss: 0.8883 - categorical_accuracy: 0.6261 92/216 [===========>..................] - ETA: 0s - loss: 0.8892 - categorical_accuracy: 0.6251119/216 [===============>..............] - ETA: 0s - loss: 0.8900 - categorical_accuracy: 0.6248142/216 [==================>...........] - ETA: 0s - loss: 0.8900 - categorical_accuracy: 0.6247166/216 [======================>.......] - ETA: 0s - loss: 0.8906 - categorical_accuracy: 0.6245191/216 [=========================>....] - ETA: 0s - loss: 0.8910 - categorical_accuracy: 0.6245216/216 [==============================] - 0s 2ms/step - loss: 0.8914 - categorical_accuracy: 0.6244 - val_loss: 0.9602 - val_categorical_accuracy: 0.6079
Epoch 18/100
  1/216 [..............................] - ETA: 0s - loss: 0.7979 - categorical_accuracy: 0.6800 27/216 [==>...........................] - ETA: 0s - loss: 0.8474 - categorical_accuracy: 0.6547 53/216 [======>.......................] - ETA: 0s - loss: 0.8604 - categorical_accuracy: 0.6442 79/216 [=========>....................] - ETA: 0s - loss: 0.8669 - categorical_accuracy: 0.6406109/216 [==============>...............] - ETA: 0s - loss: 0.8725 - categorical_accuracy: 0.6379142/216 [==================>...........] - ETA: 0s - loss: 0.8760 - categorical_accuracy: 0.6362176/216 [=======================>......] - ETA: 0s - loss: 0.8780 - categorical_accuracy: 0.6351210/216 [============================>.] - ETA: 0s - loss: 0.8793 - categorical_accuracy: 0.6343216/216 [==============================] - 0s 2ms/step - loss: 0.8795 - categorical_accuracy: 0.6342 - val_loss: 0.9548 - val_categorical_accuracy: 0.6067
Epoch 19/100
  1/216 [..............................] - ETA: 0s - loss: 0.8317 - categorical_accuracy: 0.6400 34/216 [===>..........................] - ETA: 0s - loss: 0.8445 - categorical_accuracy: 0.6424 67/216 [========>.....................] - ETA: 0s - loss: 0.8478 - categorical_accuracy: 0.6452101/216 [=============>................] - ETA: 0s - loss: 0.8509 - categorical_accuracy: 0.6446136/216 [=================>............] - ETA: 0s - loss: 0.8537 - categorical_accuracy: 0.6435171/216 [======================>.......] - ETA: 0s - loss: 0.8561 - categorical_accuracy: 0.6426204/216 [===========================>..] - ETA: 0s - loss: 0.8581 - categorical_accuracy: 0.6418216/216 [==============================] - 0s 2ms/step - loss: 0.8587 - categorical_accuracy: 0.6415 - val_loss: 0.9721 - val_categorical_accuracy: 0.5983
Epoch 20/100
  1/216 [..............................] - ETA: 0s - loss: 0.8165 - categorical_accuracy: 0.6500 37/216 [====>.........................] - ETA: 0s - loss: 0.8559 - categorical_accuracy: 0.6422 71/216 [========>.....................] - ETA: 0s - loss: 0.8626 - categorical_accuracy: 0.6376106/216 [=============>................] - ETA: 0s - loss: 0.8669 - categorical_accuracy: 0.6351139/216 [==================>...........] - ETA: 0s - loss: 0.8688 - categorical_accuracy: 0.6340172/216 [======================>.......] - ETA: 0s - loss: 0.8701 - categorical_accuracy: 0.6335206/216 [===========================>..] - ETA: 0s - loss: 0.8711 - categorical_accuracy: 0.6333216/216 [==============================] - 0s 2ms/step - loss: 0.8713 - categorical_accuracy: 0.6332 - val_loss: 0.9502 - val_categorical_accuracy: 0.6104
Epoch 21/100
  1/216 [..............................] - ETA: 0s - loss: 0.8364 - categorical_accuracy: 0.6300 34/216 [===>..........................] - ETA: 0s - loss: 0.8504 - categorical_accuracy: 0.6513 68/216 [========>.....................] - ETA: 0s - loss: 0.8534 - categorical_accuracy: 0.6494102/216 [=============>................] - ETA: 0s - loss: 0.8562 - categorical_accuracy: 0.6474137/216 [==================>...........] - ETA: 0s - loss: 0.8583 - categorical_accuracy: 0.6458173/216 [=======================>......] - ETA: 0s - loss: 0.8599 - categorical_accuracy: 0.6446209/216 [============================>.] - ETA: 0s - loss: 0.8609 - categorical_accuracy: 0.6438216/216 [==============================] - 0s 2ms/step - loss: 0.8610 - categorical_accuracy: 0.6437 - val_loss: 0.9429 - val_categorical_accuracy: 0.6146
Epoch 22/100
  1/216 [..............................] - ETA: 0s - loss: 0.8202 - categorical_accuracy: 0.6600 36/216 [====>.........................] - ETA: 0s - loss: 0.8473 - categorical_accuracy: 0.6589 71/216 [========>.....................] - ETA: 0s - loss: 0.8541 - categorical_accuracy: 0.6515105/216 [=============>................] - ETA: 0s - loss: 0.8550 - categorical_accuracy: 0.6496138/216 [==================>...........] - ETA: 0s - loss: 0.8558 - categorical_accuracy: 0.6480173/216 [=======================>......] - ETA: 0s - loss: 0.8556 - categorical_accuracy: 0.6473207/216 [===========================>..] - ETA: 0s - loss: 0.8553 - categorical_accuracy: 0.6470216/216 [==============================] - 0s 2ms/step - loss: 0.8553 - categorical_accuracy: 0.6469 - val_loss: 0.9575 - val_categorical_accuracy: 0.6017
Epoch 23/100
  1/216 [..............................] - ETA: 0s - loss: 0.9390 - categorical_accuracy: 0.6200 36/216 [====>.........................] - ETA: 0s - loss: 0.8526 - categorical_accuracy: 0.6465 72/216 [=========>....................] - ETA: 0s - loss: 0.8455 - categorical_accuracy: 0.6487107/216 [=============>................] - ETA: 0s - loss: 0.8436 - categorical_accuracy: 0.6494141/216 [==================>...........] - ETA: 0s - loss: 0.8439 - categorical_accuracy: 0.6490174/216 [=======================>......] - ETA: 0s - loss: 0.8439 - categorical_accuracy: 0.6489208/216 [===========================>..] - ETA: 0s - loss: 0.8444 - categorical_accuracy: 0.6488216/216 [==============================] - 0s 2ms/step - loss: 0.8444 - categorical_accuracy: 0.6488 - val_loss: 0.9605 - val_categorical_accuracy: 0.6017
Epoch 24/100
  1/216 [..............................] - ETA: 0s - loss: 0.8654 - categorical_accuracy: 0.5800 33/216 [===>..........................] - ETA: 0s - loss: 0.8539 - categorical_accuracy: 0.6323 66/216 [========>.....................] - ETA: 0s - loss: 0.8496 - categorical_accuracy: 0.6377 96/216 [============>.................] - ETA: 0s - loss: 0.8477 - categorical_accuracy: 0.6405130/216 [=================>............] - ETA: 0s - loss: 0.8474 - categorical_accuracy: 0.6413165/216 [=====================>........] - ETA: 0s - loss: 0.8472 - categorical_accuracy: 0.6418200/216 [==========================>...] - ETA: 0s - loss: 0.8466 - categorical_accuracy: 0.6423216/216 [==============================] - 0s 2ms/step - loss: 0.8465 - categorical_accuracy: 0.6424 - val_loss: 0.9872 - val_categorical_accuracy: 0.5917
Epoch 25/100
  1/216 [..............................] - ETA: 0s - loss: 0.8838 - categorical_accuracy: 0.6300 35/216 [===>..........................] - ETA: 0s - loss: 0.8202 - categorical_accuracy: 0.6523 70/216 [========>.....................] - ETA: 0s - loss: 0.8253 - categorical_accuracy: 0.6514105/216 [=============>................] - ETA: 0s - loss: 0.8291 - categorical_accuracy: 0.6515140/216 [==================>...........] - ETA: 0s - loss: 0.8313 - categorical_accuracy: 0.6514174/216 [=======================>......] - ETA: 0s - loss: 0.8314 - categorical_accuracy: 0.6519203/216 [===========================>..] - ETA: 0s - loss: 0.8320 - categorical_accuracy: 0.6520216/216 [==============================] - 0s 2ms/step - loss: 0.8325 - categorical_accuracy: 0.6519 - val_loss: 0.9489 - val_categorical_accuracy: 0.6092
Epoch 26/100
  1/216 [..............................] - ETA: 0s - loss: 0.8095 - categorical_accuracy: 0.7200 30/216 [===>..........................] - ETA: 0s - loss: 0.8292 - categorical_accuracy: 0.6665 60/216 [=======>......................] - ETA: 0s - loss: 0.8250 - categorical_accuracy: 0.6653 94/216 [============>.................] - ETA: 0s - loss: 0.8241 - categorical_accuracy: 0.6629125/216 [================>.............] - ETA: 0s - loss: 0.8264 - categorical_accuracy: 0.6604154/216 [====================>.........] - ETA: 0s - loss: 0.8287 - categorical_accuracy: 0.6583183/216 [========================>.....] - ETA: 0s - loss: 0.8304 - categorical_accuracy: 0.6568214/216 [============================>.] - ETA: 0s - loss: 0.8315 - categorical_accuracy: 0.6557216/216 [==============================] - 0s 2ms/step - loss: 0.8316 - categorical_accuracy: 0.6556 - val_loss: 0.9506 - val_categorical_accuracy: 0.6133
Epoch 27/100
  1/216 [..............................] - ETA: 0s - loss: 0.8604 - categorical_accuracy: 0.6700 31/216 [===>..........................] - ETA: 0s - loss: 0.8386 - categorical_accuracy: 0.6483 61/216 [=======>......................] - ETA: 0s - loss: 0.8352 - categorical_accuracy: 0.6493 89/216 [===========>..................] - ETA: 0s - loss: 0.8343 - categorical_accuracy: 0.6504121/216 [===============>..............] - ETA: 0s - loss: 0.8338 - categorical_accuracy: 0.6507156/216 [====================>.........] - ETA: 0s - loss: 0.8335 - categorical_accuracy: 0.6510191/216 [=========================>....] - ETA: 0s - loss: 0.8326 - categorical_accuracy: 0.6517216/216 [==============================] - 0s 2ms/step - loss: 0.8324 - categorical_accuracy: 0.6517 - val_loss: 0.9369 - val_categorical_accuracy: 0.6167
Epoch 28/100
  1/216 [..............................] - ETA: 0s - loss: 0.7101 - categorical_accuracy: 0.7100 36/216 [====>.........................] - ETA: 0s - loss: 0.8153 - categorical_accuracy: 0.6627 70/216 [========>.....................] - ETA: 0s - loss: 0.8141 - categorical_accuracy: 0.6620106/216 [=============>................] - ETA: 0s - loss: 0.8130 - categorical_accuracy: 0.6616141/216 [==================>...........] - ETA: 0s - loss: 0.8134 - categorical_accuracy: 0.6607176/216 [=======================>......] - ETA: 0s - loss: 0.8141 - categorical_accuracy: 0.6600211/216 [============================>.] - ETA: 0s - loss: 0.8148 - categorical_accuracy: 0.6594216/216 [==============================] - 0s 2ms/step - loss: 0.8150 - categorical_accuracy: 0.6593 - val_loss: 0.9448 - val_categorical_accuracy: 0.6137
Epoch 29/100
  1/216 [..............................] - ETA: 0s - loss: 0.7597 - categorical_accuracy: 0.6600 36/216 [====>.........................] - ETA: 0s - loss: 0.8115 - categorical_accuracy: 0.6467 70/216 [========>.....................] - ETA: 0s - loss: 0.8127 - categorical_accuracy: 0.6540105/216 [=============>................] - ETA: 0s - loss: 0.8111 - categorical_accuracy: 0.6580138/216 [==================>...........] - ETA: 0s - loss: 0.8112 - categorical_accuracy: 0.6594172/216 [======================>.......] - ETA: 0s - loss: 0.8113 - categorical_accuracy: 0.6598206/216 [===========================>..] - ETA: 0s - loss: 0.8114 - categorical_accuracy: 0.6602216/216 [==============================] - 0s 2ms/step - loss: 0.8116 - categorical_accuracy: 0.6603 - val_loss: 0.9890 - val_categorical_accuracy: 0.5871
Epoch 30/100
  1/216 [..............................] - ETA: 0s - loss: 0.6266 - categorical_accuracy: 0.8000 36/216 [====>.........................] - ETA: 0s - loss: 0.7584 - categorical_accuracy: 0.6933 71/216 [========>.....................] - ETA: 0s - loss: 0.7707 - categorical_accuracy: 0.6857106/216 [=============>................] - ETA: 0s - loss: 0.7772 - categorical_accuracy: 0.6817140/216 [==================>...........] - ETA: 0s - loss: 0.7828 - categorical_accuracy: 0.6785174/216 [=======================>......] - ETA: 0s - loss: 0.7874 - categorical_accuracy: 0.6760209/216 [============================>.] - ETA: 0s - loss: 0.7915 - categorical_accuracy: 0.6739216/216 [==============================] - 0s 2ms/step - loss: 0.7923 - categorical_accuracy: 0.6734 - val_loss: 0.9479 - val_categorical_accuracy: 0.6167
Epoch 31/100
  1/216 [..............................] - ETA: 0s - loss: 0.7855 - categorical_accuracy: 0.7100 36/216 [====>.........................] - ETA: 0s - loss: 0.7852 - categorical_accuracy: 0.6725 71/216 [========>.....................] - ETA: 0s - loss: 0.7882 - categorical_accuracy: 0.6705106/216 [=============>................] - ETA: 0s - loss: 0.7913 - categorical_accuracy: 0.6689141/216 [==================>...........] - ETA: 0s - loss: 0.7933 - categorical_accuracy: 0.6680176/216 [=======================>......] - ETA: 0s - loss: 0.7947 - categorical_accuracy: 0.6675211/216 [============================>.] - ETA: 0s - loss: 0.7963 - categorical_accuracy: 0.6669216/216 [==============================] - 0s 2ms/step - loss: 0.7966 - categorical_accuracy: 0.6668 - val_loss: 0.9643 - val_categorical_accuracy: 0.5992
Epoch 32/100
  1/216 [..............................] - ETA: 0s - loss: 0.8655 - categorical_accuracy: 0.6500 31/216 [===>..........................] - ETA: 0s - loss: 0.7963 - categorical_accuracy: 0.6796 62/216 [=======>......................] - ETA: 0s - loss: 0.7980 - categorical_accuracy: 0.6765 93/216 [===========>..................] - ETA: 0s - loss: 0.7986 - categorical_accuracy: 0.6739123/216 [================>.............] - ETA: 0s - loss: 0.7999 - categorical_accuracy: 0.6717155/216 [====================>.........] - ETA: 0s - loss: 0.8005 - categorical_accuracy: 0.6705190/216 [=========================>....] - ETA: 0s - loss: 0.8009 - categorical_accuracy: 0.6696216/216 [==============================] - 0s 2ms/step - loss: 0.8015 - categorical_accuracy: 0.6690 - val_loss: 0.9586 - val_categorical_accuracy: 0.6108
Epoch 33/100
  1/216 [..............................] - ETA: 0s - loss: 0.7380 - categorical_accuracy: 0.6900 32/216 [===>..........................] - ETA: 0s - loss: 0.7430 - categorical_accuracy: 0.7045 67/216 [========>.....................] - ETA: 0s - loss: 0.7579 - categorical_accuracy: 0.6930102/216 [=============>................] - ETA: 0s - loss: 0.7654 - categorical_accuracy: 0.6873137/216 [==================>...........] - ETA: 0s - loss: 0.7714 - categorical_accuracy: 0.6833168/216 [======================>.......] - ETA: 0s - loss: 0.7755 - categorical_accuracy: 0.6809198/216 [==========================>...] - ETA: 0s - loss: 0.7785 - categorical_accuracy: 0.6794216/216 [==============================] - 0s 2ms/step - loss: 0.7801 - categorical_accuracy: 0.6785 - val_loss: 0.9661 - val_categorical_accuracy: 0.6025
Epoch 34/100
  1/216 [..............................] - ETA: 0s - loss: 0.8174 - categorical_accuracy: 0.6500 35/216 [===>..........................] - ETA: 0s - loss: 0.7701 - categorical_accuracy: 0.6812 65/216 [========>.....................] - ETA: 0s - loss: 0.7778 - categorical_accuracy: 0.6787 95/216 [============>.................] - ETA: 0s - loss: 0.7834 - categorical_accuracy: 0.6760126/216 [================>.............] - ETA: 0s - loss: 0.7862 - categorical_accuracy: 0.6745157/216 [====================>.........] - ETA: 0s - loss: 0.7880 - categorical_accuracy: 0.6732185/216 [========================>.....] - ETA: 0s - loss: 0.7883 - categorical_accuracy: 0.6730216/216 [==============================] - ETA: 0s - loss: 0.7887 - categorical_accuracy: 0.6726216/216 [==============================] - 0s 2ms/step - loss: 0.7887 - categorical_accuracy: 0.6726 - val_loss: 0.9591 - val_categorical_accuracy: 0.6092
Epoch 00034: early stopping
Experiment:  57  Set:  ss2 Train Labels:  ncar5 Test Labels:  clean
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      0.66      0.76      1240
           1       0.60      0.62      0.61      1218
           2       0.53      0.61      0.57      1184
           3       0.50      0.43      0.46      1175
           4       0.62      0.74      0.67      1183

    accuracy                           0.61      6000
   macro avg       0.62      0.61      0.61      6000
weighted avg       0.63      0.61      0.62      6000

Confusion Matrix for this model: 
 [[822 400  18   0   0]
 [105 760 326  16  11]
 [  2  91 722 262 107]
 [  0   7 240 508 420]
 [  8   7  59 234 875]]
Experiment:  58  Set:  ss2 Train Labels:  ncar5 Test Labels:  ncar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.82      0.64      0.72      1203
           1       0.57      0.60      0.58      1215
           2       0.52      0.59      0.55      1206
           3       0.48      0.41      0.44      1190
           4       0.59      0.70      0.64      1186

    accuracy                           0.59      6000
   macro avg       0.60      0.59      0.59      6000
weighted avg       0.60      0.59      0.59      6000

Confusion Matrix for this model: 
 [[770 381  26   9  17]
 [106 723 315  34  37]
 [ 20 104 709 256 117]
 [ 18  30 240 491 411]
 [ 23  27  75 230 831]]
Experiment:  59  Set:  ss2 Train Labels:  ncar5 Test Labels:  ncar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.78      0.61      0.68      1206
           1       0.56      0.57      0.56      1250
           2       0.49      0.55      0.51      1210
           3       0.45      0.39      0.42      1172
           4       0.55      0.67      0.61      1162

    accuracy                           0.56      6000
   macro avg       0.57      0.56      0.56      6000
weighted avg       0.57      0.56      0.56      6000

Confusion Matrix for this model: 
 [[731 370  44  26  35]
 [120 708 320  52  50]
 [ 26 115 663 259 147]
 [ 28  37 248 461 398]
 [ 32  35  90 222 783]]
Experiment:  60  Set:  ss2 Train Labels:  ncar5 Test Labels:  nar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.66      0.65       908
           1       0.60      0.62      0.61      1218
           2       0.53      0.61      0.57      1184
           3       0.50      0.34      0.40      1507
           4       0.62      0.74      0.67      1183

    accuracy                           0.58      6000
   macro avg       0.58      0.59      0.58      6000
weighted avg       0.57      0.58      0.57      6000

Confusion Matrix for this model: 
 [[599 296  13   0   0]
 [105 760 326  16  11]
 [  2  91 722 262 107]
 [223 111 245 508 420]
 [  8   7  59 234 875]]
Experiment:  61  Set:  ss2 Train Labels:  ncar5 Test Labels:  nar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.44      0.66      0.53       623
           1       0.60      0.62      0.61      1218
           2       0.53      0.61      0.57      1184
           3       0.50      0.28      0.36      1792
           4       0.62      0.74      0.67      1183

    accuracy                           0.55      6000
   macro avg       0.54      0.58      0.55      6000
weighted avg       0.54      0.55      0.53      6000

Confusion Matrix for this model: 
 [[413 202   8   0   0]
 [105 760 326  16  11]
 [  2  91 722 262 107]
 [409 205 250 508 420]
 [  8   7  59 234 875]]
Experiment:  62  Set:  ss2 Train Labels:  ncar5 Test Labels:  nnar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.82      0.69      0.75      1120
           1       0.65      0.62      0.63      1327
           2       0.53      0.61      0.57      1184
           3       0.50      0.43      0.46      1178
           4       0.62      0.73      0.67      1191

    accuracy                           0.62      6000
   macro avg       0.62      0.62      0.62      6000
weighted avg       0.62      0.62      0.62      6000

Confusion Matrix for this model: 
 [[770 340  10   0   0]
 [150 817 333  16  11]
 [  2  91 722 262 107]
 [  0   9 241 508 420]
 [ 15   8  59 234 875]]
Experiment:  63  Set:  ss2 Train Labels:  ncar5 Test Labels:  nnar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.82      0.69      0.75      1111
           1       0.65      0.62      0.63      1332
           2       0.53      0.61      0.57      1184
           3       0.50      0.43      0.46      1178
           4       0.62      0.73      0.67      1195

    accuracy                           0.62      6000
   macro avg       0.62      0.62      0.62      6000
weighted avg       0.62      0.62      0.61      6000

Confusion Matrix for this model: 
 [[766 336   9   0   0]
 [151 820 334  16  11]
 [  2  91 722 262 107]
 [  0   9 241 508 420]
 [ 18   9  59 234 875]]
Input Shape:  (24000, 1, 150)
Model: "sequential_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_9 (LSTM)                (None, 32)                23424     
_________________________________________________________________
dropout_9 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_36 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_37 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_38 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_39 (Dense)             (None, 5)                 325       
=================================================================
Total params: 52,741
Trainable params: 52,741
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
  1/216 [..............................] - ETA: 3:04 - loss: 1.6021 - categorical_accuracy: 0.2400 35/216 [===>..........................] - ETA: 0s - loss: 1.6021 - categorical_accuracy: 0.2167   69/216 [========>.....................] - ETA: 0s - loss: 1.5812 - categorical_accuracy: 0.2377104/216 [=============>................] - ETA: 0s - loss: 1.5528 - categorical_accuracy: 0.2616138/216 [==================>...........] - ETA: 0s - loss: 1.5283 - categorical_accuracy: 0.2798171/216 [======================>.......] - ETA: 0s - loss: 1.5084 - categorical_accuracy: 0.2941200/216 [==========================>...] - ETA: 0s - loss: 1.4933 - categorical_accuracy: 0.3046216/216 [==============================] - 2s 3ms/step - loss: 1.4853 - categorical_accuracy: 0.3101 - val_loss: 1.2449 - val_categorical_accuracy: 0.4667
Epoch 2/100
  1/216 [..............................] - ETA: 0s - loss: 1.4327 - categorical_accuracy: 0.4500 36/216 [====>.........................] - ETA: 0s - loss: 1.2939 - categorical_accuracy: 0.4564 69/216 [========>.....................] - ETA: 0s - loss: 1.2808 - categorical_accuracy: 0.4584101/216 [=============>................] - ETA: 0s - loss: 1.2749 - categorical_accuracy: 0.4598134/216 [=================>............] - ETA: 0s - loss: 1.2709 - categorical_accuracy: 0.4606166/216 [======================>.......] - ETA: 0s - loss: 1.2674 - categorical_accuracy: 0.4613201/216 [==========================>...] - ETA: 0s - loss: 1.2647 - categorical_accuracy: 0.4618216/216 [==============================] - 0s 2ms/step - loss: 1.2636 - categorical_accuracy: 0.4619 - val_loss: 1.1813 - val_categorical_accuracy: 0.5021
Epoch 3/100
  1/216 [..............................] - ETA: 0s - loss: 1.3312 - categorical_accuracy: 0.4100 35/216 [===>..........................] - ETA: 0s - loss: 1.2386 - categorical_accuracy: 0.4706 68/216 [========>.....................] - ETA: 0s - loss: 1.2338 - categorical_accuracy: 0.4735102/216 [=============>................] - ETA: 0s - loss: 1.2296 - categorical_accuracy: 0.4762137/216 [==================>...........] - ETA: 0s - loss: 1.2246 - categorical_accuracy: 0.4792173/216 [=======================>......] - ETA: 0s - loss: 1.2204 - categorical_accuracy: 0.4816207/216 [===========================>..] - ETA: 0s - loss: 1.2181 - categorical_accuracy: 0.4828216/216 [==============================] - 0s 2ms/step - loss: 1.2176 - categorical_accuracy: 0.4831 - val_loss: 1.1588 - val_categorical_accuracy: 0.5125
Epoch 4/100
  1/216 [..............................] - ETA: 0s - loss: 1.0928 - categorical_accuracy: 0.5300 34/216 [===>..........................] - ETA: 0s - loss: 1.1723 - categorical_accuracy: 0.5114 62/216 [=======>......................] - ETA: 0s - loss: 1.1717 - categorical_accuracy: 0.5108 89/216 [===========>..................] - ETA: 0s - loss: 1.1701 - categorical_accuracy: 0.5108119/216 [===============>..............] - ETA: 0s - loss: 1.1696 - categorical_accuracy: 0.5096149/216 [===================>..........] - ETA: 0s - loss: 1.1692 - categorical_accuracy: 0.5083183/216 [========================>.....] - ETA: 0s - loss: 1.1690 - categorical_accuracy: 0.5077216/216 [==============================] - 0s 2ms/step - loss: 1.1695 - categorical_accuracy: 0.5071 - val_loss: 1.1541 - val_categorical_accuracy: 0.5167
Epoch 5/100
  1/216 [..............................] - ETA: 0s - loss: 1.1378 - categorical_accuracy: 0.5700 36/216 [====>.........................] - ETA: 0s - loss: 1.1427 - categorical_accuracy: 0.5200 71/216 [========>.....................] - ETA: 0s - loss: 1.1445 - categorical_accuracy: 0.5214106/216 [=============>................] - ETA: 0s - loss: 1.1476 - categorical_accuracy: 0.5203137/216 [==================>...........] - ETA: 0s - loss: 1.1499 - categorical_accuracy: 0.5194170/216 [======================>.......] - ETA: 0s - loss: 1.1513 - categorical_accuracy: 0.5186203/216 [===========================>..] - ETA: 0s - loss: 1.1521 - categorical_accuracy: 0.5179216/216 [==============================] - 0s 2ms/step - loss: 1.1523 - categorical_accuracy: 0.5177 - val_loss: 1.1243 - val_categorical_accuracy: 0.5292
Epoch 6/100
  1/216 [..............................] - ETA: 0s - loss: 1.1628 - categorical_accuracy: 0.5300 35/216 [===>..........................] - ETA: 0s - loss: 1.1487 - categorical_accuracy: 0.5362 69/216 [========>.....................] - ETA: 0s - loss: 1.1411 - categorical_accuracy: 0.5338104/216 [=============>................] - ETA: 0s - loss: 1.1370 - categorical_accuracy: 0.5319139/216 [==================>...........] - ETA: 0s - loss: 1.1360 - categorical_accuracy: 0.5300173/216 [=======================>......] - ETA: 0s - loss: 1.1347 - categorical_accuracy: 0.5296207/216 [===========================>..] - ETA: 0s - loss: 1.1341 - categorical_accuracy: 0.5292216/216 [==============================] - 0s 2ms/step - loss: 1.1340 - categorical_accuracy: 0.5290 - val_loss: 1.1344 - val_categorical_accuracy: 0.5250
Epoch 7/100
  1/216 [..............................] - ETA: 0s - loss: 1.1105 - categorical_accuracy: 0.5200 34/216 [===>..........................] - ETA: 0s - loss: 1.1040 - categorical_accuracy: 0.5317 69/216 [========>.....................] - ETA: 0s - loss: 1.1038 - categorical_accuracy: 0.5322103/216 [=============>................] - ETA: 0s - loss: 1.1063 - categorical_accuracy: 0.5331136/216 [=================>............] - ETA: 0s - loss: 1.1070 - categorical_accuracy: 0.5343168/216 [======================>.......] - ETA: 0s - loss: 1.1081 - categorical_accuracy: 0.5348200/216 [==========================>...] - ETA: 0s - loss: 1.1089 - categorical_accuracy: 0.5351216/216 [==============================] - 0s 2ms/step - loss: 1.1093 - categorical_accuracy: 0.5352 - val_loss: 1.1247 - val_categorical_accuracy: 0.5337
Epoch 8/100
  1/216 [..............................] - ETA: 0s - loss: 1.1426 - categorical_accuracy: 0.5100 35/216 [===>..........................] - ETA: 0s - loss: 1.0973 - categorical_accuracy: 0.5394 67/216 [========>.....................] - ETA: 0s - loss: 1.0951 - categorical_accuracy: 0.5393101/216 [=============>................] - ETA: 0s - loss: 1.0949 - categorical_accuracy: 0.5403135/216 [=================>............] - ETA: 0s - loss: 1.0942 - categorical_accuracy: 0.5412171/216 [======================>.......] - ETA: 0s - loss: 1.0932 - categorical_accuracy: 0.5418205/216 [===========================>..] - ETA: 0s - loss: 1.0929 - categorical_accuracy: 0.5422216/216 [==============================] - 0s 2ms/step - loss: 1.0931 - categorical_accuracy: 0.5421 - val_loss: 1.1181 - val_categorical_accuracy: 0.5462
Epoch 9/100
  1/216 [..............................] - ETA: 0s - loss: 1.0664 - categorical_accuracy: 0.5500 34/216 [===>..........................] - ETA: 0s - loss: 1.0854 - categorical_accuracy: 0.5393 69/216 [========>.....................] - ETA: 0s - loss: 1.0826 - categorical_accuracy: 0.5412104/216 [=============>................] - ETA: 0s - loss: 1.0820 - categorical_accuracy: 0.5427137/216 [==================>...........] - ETA: 0s - loss: 1.0814 - categorical_accuracy: 0.5440170/216 [======================>.......] - ETA: 0s - loss: 1.0815 - categorical_accuracy: 0.5447203/216 [===========================>..] - ETA: 0s - loss: 1.0822 - categorical_accuracy: 0.5451216/216 [==============================] - 0s 2ms/step - loss: 1.0825 - categorical_accuracy: 0.5451 - val_loss: 1.1052 - val_categorical_accuracy: 0.5487
Epoch 10/100
  1/216 [..............................] - ETA: 0s - loss: 0.8806 - categorical_accuracy: 0.6300 35/216 [===>..........................] - ETA: 0s - loss: 1.0430 - categorical_accuracy: 0.5688 69/216 [========>.....................] - ETA: 0s - loss: 1.0515 - categorical_accuracy: 0.5660 95/216 [============>.................] - ETA: 0s - loss: 1.0554 - categorical_accuracy: 0.5632121/216 [===============>..............] - ETA: 0s - loss: 1.0575 - categorical_accuracy: 0.5617148/216 [===================>..........] - ETA: 0s - loss: 1.0595 - categorical_accuracy: 0.5605175/216 [=======================>......] - ETA: 0s - loss: 1.0615 - categorical_accuracy: 0.5597203/216 [===========================>..] - ETA: 0s - loss: 1.0628 - categorical_accuracy: 0.5592216/216 [==============================] - 0s 2ms/step - loss: 1.0633 - categorical_accuracy: 0.5590 - val_loss: 1.1141 - val_categorical_accuracy: 0.5400
Epoch 11/100
  1/216 [..............................] - ETA: 0s - loss: 1.1479 - categorical_accuracy: 0.5100 30/216 [===>..........................] - ETA: 0s - loss: 1.0641 - categorical_accuracy: 0.5538 55/216 [======>.......................] - ETA: 0s - loss: 1.0529 - categorical_accuracy: 0.5614 81/216 [==========>...................] - ETA: 0s - loss: 1.0497 - categorical_accuracy: 0.5622107/216 [=============>................] - ETA: 0s - loss: 1.0509 - categorical_accuracy: 0.5609137/216 [==================>...........] - ETA: 0s - loss: 1.0519 - categorical_accuracy: 0.5602166/216 [======================>.......] - ETA: 0s - loss: 1.0525 - categorical_accuracy: 0.5599196/216 [==========================>...] - ETA: 0s - loss: 1.0532 - categorical_accuracy: 0.5597216/216 [==============================] - 0s 2ms/step - loss: 1.0537 - categorical_accuracy: 0.5595 - val_loss: 1.0939 - val_categorical_accuracy: 0.5679
Epoch 12/100
  1/216 [..............................] - ETA: 0s - loss: 0.9954 - categorical_accuracy: 0.5200 26/216 [==>...........................] - ETA: 0s - loss: 1.0291 - categorical_accuracy: 0.5499 53/216 [======>.......................] - ETA: 0s - loss: 1.0301 - categorical_accuracy: 0.5524 77/216 [=========>....................] - ETA: 0s - loss: 1.0321 - categorical_accuracy: 0.5539105/216 [=============>................] - ETA: 0s - loss: 1.0346 - categorical_accuracy: 0.5554137/216 [==================>...........] - ETA: 0s - loss: 1.0364 - categorical_accuracy: 0.5567171/216 [======================>.......] - ETA: 0s - loss: 1.0380 - categorical_accuracy: 0.5580204/216 [===========================>..] - ETA: 0s - loss: 1.0395 - categorical_accuracy: 0.5588216/216 [==============================] - 0s 2ms/step - loss: 1.0400 - categorical_accuracy: 0.5591 - val_loss: 1.0994 - val_categorical_accuracy: 0.5625
Epoch 13/100
  1/216 [..............................] - ETA: 0s - loss: 0.9743 - categorical_accuracy: 0.5800 35/216 [===>..........................] - ETA: 0s - loss: 1.0647 - categorical_accuracy: 0.5681 69/216 [========>.....................] - ETA: 0s - loss: 1.0527 - categorical_accuracy: 0.5712102/216 [=============>................] - ETA: 0s - loss: 1.0472 - categorical_accuracy: 0.5715136/216 [=================>............] - ETA: 0s - loss: 1.0447 - categorical_accuracy: 0.5710170/216 [======================>.......] - ETA: 0s - loss: 1.0442 - categorical_accuracy: 0.5705204/216 [===========================>..] - ETA: 0s - loss: 1.0438 - categorical_accuracy: 0.5703216/216 [==============================] - 0s 2ms/step - loss: 1.0435 - categorical_accuracy: 0.5704 - val_loss: 1.1100 - val_categorical_accuracy: 0.5467
Epoch 14/100
  1/216 [..............................] - ETA: 0s - loss: 0.9928 - categorical_accuracy: 0.5700 34/216 [===>..........................] - ETA: 0s - loss: 1.0346 - categorical_accuracy: 0.5636 68/216 [========>.....................] - ETA: 0s - loss: 1.0383 - categorical_accuracy: 0.5656103/216 [=============>................] - ETA: 0s - loss: 1.0389 - categorical_accuracy: 0.5669138/216 [==================>...........] - ETA: 0s - loss: 1.0374 - categorical_accuracy: 0.5683174/216 [=======================>......] - ETA: 0s - loss: 1.0363 - categorical_accuracy: 0.5694208/216 [===========================>..] - ETA: 0s - loss: 1.0350 - categorical_accuracy: 0.5705216/216 [==============================] - 0s 2ms/step - loss: 1.0348 - categorical_accuracy: 0.5707 - val_loss: 1.0967 - val_categorical_accuracy: 0.5696
Epoch 15/100
  1/216 [..............................] - ETA: 0s - loss: 0.9331 - categorical_accuracy: 0.6200 37/216 [====>.........................] - ETA: 0s - loss: 0.9911 - categorical_accuracy: 0.5900 73/216 [=========>....................] - ETA: 0s - loss: 1.0009 - categorical_accuracy: 0.5915106/216 [=============>................] - ETA: 0s - loss: 1.0057 - categorical_accuracy: 0.5897138/216 [==================>...........] - ETA: 0s - loss: 1.0079 - categorical_accuracy: 0.5891169/216 [======================>.......] - ETA: 0s - loss: 1.0097 - categorical_accuracy: 0.5887200/216 [==========================>...] - ETA: 0s - loss: 1.0110 - categorical_accuracy: 0.5884216/216 [==============================] - 0s 2ms/step - loss: 1.0117 - categorical_accuracy: 0.5882 - val_loss: 1.0897 - val_categorical_accuracy: 0.5671
Epoch 16/100
  1/216 [..............................] - ETA: 0s - loss: 0.9617 - categorical_accuracy: 0.5600 31/216 [===>..........................] - ETA: 0s - loss: 0.9966 - categorical_accuracy: 0.5990 60/216 [=======>......................] - ETA: 0s - loss: 0.9987 - categorical_accuracy: 0.5936 88/216 [===========>..................] - ETA: 0s - loss: 1.0031 - categorical_accuracy: 0.5900118/216 [===============>..............] - ETA: 0s - loss: 1.0054 - categorical_accuracy: 0.5888147/216 [===================>..........] - ETA: 0s - loss: 1.0068 - categorical_accuracy: 0.5884180/216 [========================>.....] - ETA: 0s - loss: 1.0075 - categorical_accuracy: 0.5880210/216 [============================>.] - ETA: 0s - loss: 1.0081 - categorical_accuracy: 0.5875216/216 [==============================] - 0s 2ms/step - loss: 1.0082 - categorical_accuracy: 0.5874 - val_loss: 1.0980 - val_categorical_accuracy: 0.5525
Epoch 17/100
  1/216 [..............................] - ETA: 0s - loss: 1.0917 - categorical_accuracy: 0.5700 32/216 [===>..........................] - ETA: 0s - loss: 1.0028 - categorical_accuracy: 0.5893 66/216 [========>.....................] - ETA: 0s - loss: 1.0034 - categorical_accuracy: 0.5892100/216 [============>.................] - ETA: 0s - loss: 1.0032 - categorical_accuracy: 0.5898134/216 [=================>............] - ETA: 0s - loss: 1.0031 - categorical_accuracy: 0.5896170/216 [======================>.......] - ETA: 0s - loss: 1.0032 - categorical_accuracy: 0.5896205/216 [===========================>..] - ETA: 0s - loss: 1.0033 - categorical_accuracy: 0.5894216/216 [==============================] - 0s 2ms/step - loss: 1.0034 - categorical_accuracy: 0.5893 - val_loss: 1.0919 - val_categorical_accuracy: 0.5650
Epoch 18/100
  1/216 [..............................] - ETA: 0s - loss: 1.0886 - categorical_accuracy: 0.5500 37/216 [====>.........................] - ETA: 0s - loss: 0.9997 - categorical_accuracy: 0.5829 73/216 [=========>....................] - ETA: 0s - loss: 0.9985 - categorical_accuracy: 0.5863108/216 [==============>...............] - ETA: 0s - loss: 0.9966 - categorical_accuracy: 0.5878144/216 [===================>..........] - ETA: 0s - loss: 0.9957 - categorical_accuracy: 0.5884179/216 [=======================>......] - ETA: 0s - loss: 0.9957 - categorical_accuracy: 0.5884215/216 [============================>.] - ETA: 0s - loss: 0.9957 - categorical_accuracy: 0.5884216/216 [==============================] - 0s 2ms/step - loss: 0.9957 - categorical_accuracy: 0.5884 - val_loss: 1.1030 - val_categorical_accuracy: 0.5633
Epoch 19/100
  1/216 [..............................] - ETA: 0s - loss: 1.1188 - categorical_accuracy: 0.5600 37/216 [====>.........................] - ETA: 0s - loss: 0.9791 - categorical_accuracy: 0.6049 72/216 [=========>....................] - ETA: 0s - loss: 0.9823 - categorical_accuracy: 0.6016108/216 [==============>...............] - ETA: 0s - loss: 0.9851 - categorical_accuracy: 0.6003143/216 [==================>...........] - ETA: 0s - loss: 0.9874 - categorical_accuracy: 0.5993179/216 [=======================>......] - ETA: 0s - loss: 0.9888 - categorical_accuracy: 0.5985215/216 [============================>.] - ETA: 0s - loss: 0.9893 - categorical_accuracy: 0.5979216/216 [==============================] - 0s 2ms/step - loss: 0.9894 - categorical_accuracy: 0.5979 - val_loss: 1.0893 - val_categorical_accuracy: 0.5688
Epoch 20/100
  1/216 [..............................] - ETA: 0s - loss: 0.9258 - categorical_accuracy: 0.5800 37/216 [====>.........................] - ETA: 0s - loss: 0.9652 - categorical_accuracy: 0.6068 72/216 [=========>....................] - ETA: 0s - loss: 0.9719 - categorical_accuracy: 0.6031107/216 [=============>................] - ETA: 0s - loss: 0.9752 - categorical_accuracy: 0.6011142/216 [==================>...........] - ETA: 0s - loss: 0.9767 - categorical_accuracy: 0.6002176/216 [=======================>......] - ETA: 0s - loss: 0.9774 - categorical_accuracy: 0.6001210/216 [============================>.] - ETA: 0s - loss: 0.9788 - categorical_accuracy: 0.5997216/216 [==============================] - 0s 2ms/step - loss: 0.9791 - categorical_accuracy: 0.5997 - val_loss: 1.0916 - val_categorical_accuracy: 0.5696
Epoch 21/100
  1/216 [..............................] - ETA: 0s - loss: 0.9255 - categorical_accuracy: 0.5900 35/216 [===>..........................] - ETA: 0s - loss: 0.9535 - categorical_accuracy: 0.6042 69/216 [========>.....................] - ETA: 0s - loss: 0.9626 - categorical_accuracy: 0.6033104/216 [=============>................] - ETA: 0s - loss: 0.9649 - categorical_accuracy: 0.6031139/216 [==================>...........] - ETA: 0s - loss: 0.9660 - categorical_accuracy: 0.6030174/216 [=======================>......] - ETA: 0s - loss: 0.9666 - categorical_accuracy: 0.6030209/216 [============================>.] - ETA: 0s - loss: 0.9676 - categorical_accuracy: 0.6028216/216 [==============================] - 0s 2ms/step - loss: 0.9679 - categorical_accuracy: 0.6028 - val_loss: 1.1217 - val_categorical_accuracy: 0.5471
Epoch 22/100
  1/216 [..............................] - ETA: 0s - loss: 1.0611 - categorical_accuracy: 0.5400 37/216 [====>.........................] - ETA: 0s - loss: 0.9879 - categorical_accuracy: 0.6004 72/216 [=========>....................] - ETA: 0s - loss: 0.9832 - categorical_accuracy: 0.6036107/216 [=============>................] - ETA: 0s - loss: 0.9796 - categorical_accuracy: 0.6054141/216 [==================>...........] - ETA: 0s - loss: 0.9773 - categorical_accuracy: 0.6063176/216 [=======================>......] - ETA: 0s - loss: 0.9762 - categorical_accuracy: 0.6063211/216 [============================>.] - ETA: 0s - loss: 0.9757 - categorical_accuracy: 0.6062216/216 [==============================] - 0s 2ms/step - loss: 0.9755 - categorical_accuracy: 0.6061 - val_loss: 1.0921 - val_categorical_accuracy: 0.5692
Epoch 23/100
  1/216 [..............................] - ETA: 0s - loss: 1.0095 - categorical_accuracy: 0.6300 36/216 [====>.........................] - ETA: 0s - loss: 0.9645 - categorical_accuracy: 0.6031 71/216 [========>.....................] - ETA: 0s - loss: 0.9632 - categorical_accuracy: 0.6041106/216 [=============>................] - ETA: 0s - loss: 0.9624 - categorical_accuracy: 0.6046142/216 [==================>...........] - ETA: 0s - loss: 0.9628 - categorical_accuracy: 0.6044178/216 [=======================>......] - ETA: 0s - loss: 0.9634 - categorical_accuracy: 0.6040213/216 [============================>.] - ETA: 0s - loss: 0.9633 - categorical_accuracy: 0.6041216/216 [==============================] - 0s 2ms/step - loss: 0.9633 - categorical_accuracy: 0.6041 - val_loss: 1.0920 - val_categorical_accuracy: 0.5763
Epoch 24/100
  1/216 [..............................] - ETA: 0s - loss: 0.8386 - categorical_accuracy: 0.6200 37/216 [====>.........................] - ETA: 0s - loss: 0.9047 - categorical_accuracy: 0.6206 73/216 [=========>....................] - ETA: 0s - loss: 0.9227 - categorical_accuracy: 0.6202109/216 [==============>...............] - ETA: 0s - loss: 0.9322 - categorical_accuracy: 0.6185145/216 [===================>..........] - ETA: 0s - loss: 0.9378 - categorical_accuracy: 0.6169180/216 [========================>.....] - ETA: 0s - loss: 0.9416 - categorical_accuracy: 0.6157215/216 [============================>.] - ETA: 0s - loss: 0.9442 - categorical_accuracy: 0.6149216/216 [==============================] - 0s 2ms/step - loss: 0.9444 - categorical_accuracy: 0.6148 - val_loss: 1.0911 - val_categorical_accuracy: 0.5663
Epoch 25/100
  1/216 [..............................] - ETA: 0s - loss: 1.1387 - categorical_accuracy: 0.5900 37/216 [====>.........................] - ETA: 0s - loss: 0.9477 - categorical_accuracy: 0.6183 71/216 [========>.....................] - ETA: 0s - loss: 0.9477 - categorical_accuracy: 0.6140106/216 [=============>................] - ETA: 0s - loss: 0.9486 - categorical_accuracy: 0.6120141/216 [==================>...........] - ETA: 0s - loss: 0.9496 - categorical_accuracy: 0.6109177/216 [=======================>......] - ETA: 0s - loss: 0.9499 - categorical_accuracy: 0.6104212/216 [============================>.] - ETA: 0s - loss: 0.9500 - categorical_accuracy: 0.6101216/216 [==============================] - 0s 2ms/step - loss: 0.9501 - categorical_accuracy: 0.6101 - val_loss: 1.1039 - val_categorical_accuracy: 0.5675
Epoch 26/100
  1/216 [..............................] - ETA: 0s - loss: 0.9358 - categorical_accuracy: 0.5800 37/216 [====>.........................] - ETA: 0s - loss: 0.9400 - categorical_accuracy: 0.6115 73/216 [=========>....................] - ETA: 0s - loss: 0.9341 - categorical_accuracy: 0.6168108/216 [==============>...............] - ETA: 0s - loss: 0.9341 - categorical_accuracy: 0.6185143/216 [==================>...........] - ETA: 0s - loss: 0.9355 - categorical_accuracy: 0.6190178/216 [=======================>......] - ETA: 0s - loss: 0.9368 - categorical_accuracy: 0.6188212/216 [============================>.] - ETA: 0s - loss: 0.9380 - categorical_accuracy: 0.6185216/216 [==============================] - 0s 2ms/step - loss: 0.9381 - categorical_accuracy: 0.6185 - val_loss: 1.1123 - val_categorical_accuracy: 0.5550
Epoch 00026: early stopping
Experiment:  64  Set:  ss2 Train Labels:  ncar10 Test Labels:  clean
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.82      0.73      0.77      1240
           1       0.59      0.55      0.57      1218
           2       0.51      0.47      0.49      1184
           3       0.48      0.56      0.52      1175
           4       0.65      0.70      0.67      1183

    accuracy                           0.60      6000
   macro avg       0.61      0.60      0.60      6000
weighted avg       0.61      0.60      0.61      6000

Confusion Matrix for this model: 
 [[903 326   7   0   4]
 [179 672 327  23  17]
 [  5 131 559 407  82]
 [  0  11 164 662 338]
 [ 11   7  45 293 827]]
Experiment:  65  Set:  ss2 Train Labels:  ncar10 Test Labels:  ncar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.77      0.70      0.73      1203
           1       0.56      0.53      0.54      1215
           2       0.50      0.46      0.48      1206
           3       0.46      0.53      0.49      1190
           4       0.62      0.66      0.64      1186

    accuracy                           0.58      6000
   macro avg       0.58      0.58      0.58      6000
weighted avg       0.58      0.58      0.58      6000

Confusion Matrix for this model: 
 [[845 314  15  14  15]
 [176 638 317  44  40]
 [ 23 143 552 396  92]
 [ 22  30 166 634 338]
 [ 32  22  52 297 783]]
Experiment:  66  Set:  ss2 Train Labels:  ncar10 Test Labels:  ncar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.73      0.67      0.70      1206
           1       0.54      0.50      0.52      1250
           2       0.47      0.43      0.45      1210
           3       0.44      0.52      0.48      1172
           4       0.57      0.63      0.60      1162

    accuracy                           0.55      6000
   macro avg       0.55      0.55      0.55      6000
weighted avg       0.55      0.55      0.55      6000

Confusion Matrix for this model: 
 [[803 308  30  24  41]
 [189 625 317  59  60]
 [ 35 148 523 391 113]
 [ 33  36 169 609 325]
 [ 38  30  63 302 729]]
Experiment:  67  Set:  ss2 Train Labels:  ncar10 Test Labels:  nar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.59      0.72      0.65       908
           1       0.59      0.55      0.57      1218
           2       0.51      0.47      0.49      1184
           3       0.48      0.44      0.46      1507
           4       0.65      0.70      0.67      1183

    accuracy                           0.56      6000
   macro avg       0.56      0.58      0.57      6000
weighted avg       0.56      0.56      0.56      6000

Confusion Matrix for this model: 
 [[652 250   2   0   4]
 [179 672 327  23  17]
 [  5 131 559 407  82]
 [251  87 169 662 338]
 [ 11   7  45 293 827]]
Experiment:  68  Set:  ss2 Train Labels:  ncar10 Test Labels:  nar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.41      0.72      0.52       623
           1       0.59      0.55      0.57      1218
           2       0.51      0.47      0.49      1184
           3       0.48      0.37      0.42      1792
           4       0.65      0.70      0.67      1183

    accuracy                           0.53      6000
   macro avg       0.53      0.56      0.53      6000
weighted avg       0.53      0.53      0.52      6000

Confusion Matrix for this model: 
 [[448 171   3   0   1]
 [179 672 327  23  17]
 [  5 131 559 407  82]
 [455 166 168 662 341]
 [ 11   7  45 293 827]]
Experiment:  69  Set:  ss2 Train Labels:  ncar10 Test Labels:  nnar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.76      0.75      0.75      1120
           1       0.63      0.54      0.58      1327
           2       0.51      0.47      0.49      1184
           3       0.48      0.56      0.52      1178
           4       0.65      0.69      0.67      1191

    accuracy                           0.60      6000
   macro avg       0.61      0.60      0.60      6000
weighted avg       0.60      0.60      0.60      6000

Confusion Matrix for this model: 
 [[836 273   7   0   4]
 [239 721 327  23  17]
 [  5 131 559 407  82]
 [  1  13 164 662 338]
 [ 17   9  45 293 827]]
Experiment:  70  Set:  ss2 Train Labels:  ncar10 Test Labels:  nnar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.76      0.75      0.75      1111
           1       0.63      0.54      0.58      1332
           2       0.51      0.47      0.49      1184
           3       0.48      0.56      0.52      1178
           4       0.65      0.69      0.67      1195

    accuracy                           0.60      6000
   macro avg       0.61      0.60      0.60      6000
weighted avg       0.60      0.60      0.60      6000

Confusion Matrix for this model: 
 [[831 269   7   0   4]
 [240 725 327  23  17]
 [  5 131 559 407  82]
 [  1  13 164 662 338]
 [ 21   9  45 293 827]]
Input Shape:  (24000, 1, 150)
Model: "sequential_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_10 (LSTM)               (None, 32)                23424     
_________________________________________________________________
dropout_10 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_40 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_41 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_42 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_43 (Dense)             (None, 5)                 325       
=================================================================
Total params: 52,741
Trainable params: 52,741
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
  1/216 [..............................] - ETA: 3:05 - loss: 1.6079 - categorical_accuracy: 0.2500 34/216 [===>..........................] - ETA: 0s - loss: 1.5953 - categorical_accuracy: 0.2652   67/216 [========>.....................] - ETA: 0s - loss: 1.5588 - categorical_accuracy: 0.2979101/216 [=============>................] - ETA: 0s - loss: 1.5154 - categorical_accuracy: 0.3212135/216 [=================>............] - ETA: 0s - loss: 1.4785 - categorical_accuracy: 0.3384170/216 [======================>.......] - ETA: 0s - loss: 1.4481 - categorical_accuracy: 0.3518204/216 [===========================>..] - ETA: 0s - loss: 1.4233 - categorical_accuracy: 0.3627216/216 [==============================] - 1s 3ms/step - loss: 1.4149 - categorical_accuracy: 0.3663 - val_loss: 1.0944 - val_categorical_accuracy: 0.5063
Epoch 2/100
  1/216 [..............................] - ETA: 0s - loss: 1.2533 - categorical_accuracy: 0.5000 35/216 [===>..........................] - ETA: 0s - loss: 1.1078 - categorical_accuracy: 0.5209 70/216 [========>.....................] - ETA: 0s - loss: 1.1006 - categorical_accuracy: 0.5195104/216 [=============>................] - ETA: 0s - loss: 1.1010 - categorical_accuracy: 0.5178139/216 [==================>...........] - ETA: 0s - loss: 1.1014 - categorical_accuracy: 0.5156174/216 [=======================>......] - ETA: 0s - loss: 1.1018 - categorical_accuracy: 0.5140208/216 [===========================>..] - ETA: 0s - loss: 1.1021 - categorical_accuracy: 0.5129216/216 [==============================] - 0s 2ms/step - loss: 1.1021 - categorical_accuracy: 0.5126 - val_loss: 1.0279 - val_categorical_accuracy: 0.5412
Epoch 3/100
  1/216 [..............................] - ETA: 0s - loss: 1.0978 - categorical_accuracy: 0.4900 36/216 [====>.........................] - ETA: 0s - loss: 1.0501 - categorical_accuracy: 0.5280 70/216 [========>.....................] - ETA: 0s - loss: 1.0501 - categorical_accuracy: 0.5282105/216 [=============>................] - ETA: 0s - loss: 1.0484 - categorical_accuracy: 0.5280140/216 [==================>...........] - ETA: 0s - loss: 1.0489 - categorical_accuracy: 0.5267174/216 [=======================>......] - ETA: 0s - loss: 1.0494 - categorical_accuracy: 0.5258208/216 [===========================>..] - ETA: 0s - loss: 1.0496 - categorical_accuracy: 0.5254216/216 [==============================] - 0s 2ms/step - loss: 1.0496 - categorical_accuracy: 0.5252 - val_loss: 0.9884 - val_categorical_accuracy: 0.5663
Epoch 4/100
  1/216 [..............................] - ETA: 0s - loss: 1.0548 - categorical_accuracy: 0.5600 34/216 [===>..........................] - ETA: 0s - loss: 1.0304 - categorical_accuracy: 0.5368 67/216 [========>.....................] - ETA: 0s - loss: 1.0293 - categorical_accuracy: 0.5340 98/216 [============>.................] - ETA: 0s - loss: 1.0251 - categorical_accuracy: 0.5358133/216 [=================>............] - ETA: 0s - loss: 1.0213 - categorical_accuracy: 0.5376167/216 [======================>.......] - ETA: 0s - loss: 1.0194 - categorical_accuracy: 0.5387201/216 [==========================>...] - ETA: 0s - loss: 1.0182 - categorical_accuracy: 0.5396216/216 [==============================] - 0s 2ms/step - loss: 1.0178 - categorical_accuracy: 0.5399 - val_loss: 0.9664 - val_categorical_accuracy: 0.5654
Epoch 5/100
  1/216 [..............................] - ETA: 0s - loss: 0.9106 - categorical_accuracy: 0.6600 36/216 [====>.........................] - ETA: 0s - loss: 0.9488 - categorical_accuracy: 0.5870 70/216 [========>.....................] - ETA: 0s - loss: 0.9578 - categorical_accuracy: 0.5784105/216 [=============>................] - ETA: 0s - loss: 0.9639 - categorical_accuracy: 0.5732140/216 [==================>...........] - ETA: 0s - loss: 0.9668 - categorical_accuracy: 0.5706175/216 [=======================>......] - ETA: 0s - loss: 0.9687 - categorical_accuracy: 0.5691209/216 [============================>.] - ETA: 0s - loss: 0.9705 - categorical_accuracy: 0.5679216/216 [==============================] - 0s 2ms/step - loss: 0.9708 - categorical_accuracy: 0.5676 - val_loss: 0.9465 - val_categorical_accuracy: 0.5738
Epoch 6/100
  1/216 [..............................] - ETA: 0s - loss: 0.8972 - categorical_accuracy: 0.6300 35/216 [===>..........................] - ETA: 0s - loss: 0.9650 - categorical_accuracy: 0.5657 70/216 [========>.....................] - ETA: 0s - loss: 0.9712 - categorical_accuracy: 0.5624105/216 [=============>................] - ETA: 0s - loss: 0.9710 - categorical_accuracy: 0.5628139/216 [==================>...........] - ETA: 0s - loss: 0.9696 - categorical_accuracy: 0.5635173/216 [=======================>......] - ETA: 0s - loss: 0.9681 - categorical_accuracy: 0.5645208/216 [===========================>..] - ETA: 0s - loss: 0.9668 - categorical_accuracy: 0.5652216/216 [==============================] - 0s 2ms/step - loss: 0.9664 - categorical_accuracy: 0.5654 - val_loss: 0.9428 - val_categorical_accuracy: 0.5742
Epoch 7/100
  1/216 [..............................] - ETA: 0s - loss: 0.8587 - categorical_accuracy: 0.6300 36/216 [====>.........................] - ETA: 0s - loss: 0.9221 - categorical_accuracy: 0.5837 71/216 [========>.....................] - ETA: 0s - loss: 0.9206 - categorical_accuracy: 0.5839105/216 [=============>................] - ETA: 0s - loss: 0.9204 - categorical_accuracy: 0.5844139/216 [==================>...........] - ETA: 0s - loss: 0.9218 - categorical_accuracy: 0.5847175/216 [=======================>......] - ETA: 0s - loss: 0.9238 - categorical_accuracy: 0.5843209/216 [============================>.] - ETA: 0s - loss: 0.9257 - categorical_accuracy: 0.5836216/216 [==============================] - 0s 2ms/step - loss: 0.9262 - categorical_accuracy: 0.5835 - val_loss: 0.9240 - val_categorical_accuracy: 0.5913
Epoch 8/100
  1/216 [..............................] - ETA: 0s - loss: 0.8764 - categorical_accuracy: 0.5600 35/216 [===>..........................] - ETA: 0s - loss: 0.9113 - categorical_accuracy: 0.5734 71/216 [========>.....................] - ETA: 0s - loss: 0.9170 - categorical_accuracy: 0.5774106/216 [=============>................] - ETA: 0s - loss: 0.9166 - categorical_accuracy: 0.5796141/216 [==================>...........] - ETA: 0s - loss: 0.9159 - categorical_accuracy: 0.5815176/216 [=======================>......] - ETA: 0s - loss: 0.9160 - categorical_accuracy: 0.5825211/216 [============================>.] - ETA: 0s - loss: 0.9160 - categorical_accuracy: 0.5834216/216 [==============================] - 0s 2ms/step - loss: 0.9160 - categorical_accuracy: 0.5835 - val_loss: 0.9306 - val_categorical_accuracy: 0.5921
Epoch 9/100
  1/216 [..............................] - ETA: 0s - loss: 0.8569 - categorical_accuracy: 0.6200 36/216 [====>.........................] - ETA: 0s - loss: 0.9062 - categorical_accuracy: 0.5835 71/216 [========>.....................] - ETA: 0s - loss: 0.9069 - categorical_accuracy: 0.5850106/216 [=============>................] - ETA: 0s - loss: 0.9072 - categorical_accuracy: 0.5869141/216 [==================>...........] - ETA: 0s - loss: 0.9057 - categorical_accuracy: 0.5889175/216 [=======================>......] - ETA: 0s - loss: 0.9044 - categorical_accuracy: 0.5900210/216 [============================>.] - ETA: 0s - loss: 0.9035 - categorical_accuracy: 0.5910216/216 [==============================] - 0s 2ms/step - loss: 0.9034 - categorical_accuracy: 0.5911 - val_loss: 0.9055 - val_categorical_accuracy: 0.6017
Epoch 10/100
  1/216 [..............................] - ETA: 0s - loss: 0.9122 - categorical_accuracy: 0.6300 37/216 [====>.........................] - ETA: 0s - loss: 0.8759 - categorical_accuracy: 0.6042 71/216 [========>.....................] - ETA: 0s - loss: 0.8765 - categorical_accuracy: 0.6039107/216 [=============>................] - ETA: 0s - loss: 0.8766 - categorical_accuracy: 0.6037141/216 [==================>...........] - ETA: 0s - loss: 0.8774 - categorical_accuracy: 0.6029176/216 [=======================>......] - ETA: 0s - loss: 0.8787 - categorical_accuracy: 0.6021211/216 [============================>.] - ETA: 0s - loss: 0.8796 - categorical_accuracy: 0.6016216/216 [==============================] - 0s 2ms/step - loss: 0.8797 - categorical_accuracy: 0.6015 - val_loss: 0.9142 - val_categorical_accuracy: 0.5904
Epoch 11/100
  1/216 [..............................] - ETA: 0s - loss: 0.8561 - categorical_accuracy: 0.6500 35/216 [===>..........................] - ETA: 0s - loss: 0.8570 - categorical_accuracy: 0.6192 69/216 [========>.....................] - ETA: 0s - loss: 0.8629 - categorical_accuracy: 0.6135104/216 [=============>................] - ETA: 0s - loss: 0.8658 - categorical_accuracy: 0.6120139/216 [==================>...........] - ETA: 0s - loss: 0.8681 - categorical_accuracy: 0.6117174/216 [=======================>......] - ETA: 0s - loss: 0.8690 - categorical_accuracy: 0.6119209/216 [============================>.] - ETA: 0s - loss: 0.8695 - categorical_accuracy: 0.6120216/216 [==============================] - 0s 2ms/step - loss: 0.8696 - categorical_accuracy: 0.6120 - val_loss: 0.9273 - val_categorical_accuracy: 0.6029
Epoch 12/100
  1/216 [..............................] - ETA: 0s - loss: 0.8306 - categorical_accuracy: 0.6600 36/216 [====>.........................] - ETA: 0s - loss: 0.8333 - categorical_accuracy: 0.6337 70/216 [========>.....................] - ETA: 0s - loss: 0.8402 - categorical_accuracy: 0.6291106/216 [=============>................] - ETA: 0s - loss: 0.8445 - categorical_accuracy: 0.6258140/216 [==================>...........] - ETA: 0s - loss: 0.8475 - categorical_accuracy: 0.6230175/216 [=======================>......] - ETA: 0s - loss: 0.8494 - categorical_accuracy: 0.6214209/216 [============================>.] - ETA: 0s - loss: 0.8505 - categorical_accuracy: 0.6204216/216 [==============================] - 0s 2ms/step - loss: 0.8508 - categorical_accuracy: 0.6201 - val_loss: 0.8939 - val_categorical_accuracy: 0.6087
Epoch 13/100
  1/216 [..............................] - ETA: 0s - loss: 0.7649 - categorical_accuracy: 0.6300 36/216 [====>.........................] - ETA: 0s - loss: 0.8307 - categorical_accuracy: 0.6261 71/216 [========>.....................] - ETA: 0s - loss: 0.8405 - categorical_accuracy: 0.6235106/216 [=============>................] - ETA: 0s - loss: 0.8436 - categorical_accuracy: 0.6227141/216 [==================>...........] - ETA: 0s - loss: 0.8452 - categorical_accuracy: 0.6228176/216 [=======================>......] - ETA: 0s - loss: 0.8464 - categorical_accuracy: 0.6228211/216 [============================>.] - ETA: 0s - loss: 0.8474 - categorical_accuracy: 0.6227216/216 [==============================] - 0s 2ms/step - loss: 0.8475 - categorical_accuracy: 0.6227 - val_loss: 0.8825 - val_categorical_accuracy: 0.6112
Epoch 14/100
  1/216 [..............................] - ETA: 0s - loss: 0.9659 - categorical_accuracy: 0.5700 32/216 [===>..........................] - ETA: 0s - loss: 0.8380 - categorical_accuracy: 0.6237 64/216 [=======>......................] - ETA: 0s - loss: 0.8376 - categorical_accuracy: 0.6269 99/216 [============>.................] - ETA: 0s - loss: 0.8349 - categorical_accuracy: 0.6295132/216 [=================>............] - ETA: 0s - loss: 0.8335 - categorical_accuracy: 0.6308167/216 [======================>.......] - ETA: 0s - loss: 0.8333 - categorical_accuracy: 0.6307202/216 [===========================>..] - ETA: 0s - loss: 0.8339 - categorical_accuracy: 0.6303216/216 [==============================] - 0s 2ms/step - loss: 0.8342 - categorical_accuracy: 0.6302 - val_loss: 0.8824 - val_categorical_accuracy: 0.6121
Epoch 15/100
  1/216 [..............................] - ETA: 0s - loss: 0.8925 - categorical_accuracy: 0.6200 35/216 [===>..........................] - ETA: 0s - loss: 0.8208 - categorical_accuracy: 0.6422 71/216 [========>.....................] - ETA: 0s - loss: 0.8203 - categorical_accuracy: 0.6411105/216 [=============>................] - ETA: 0s - loss: 0.8214 - categorical_accuracy: 0.6398140/216 [==================>...........] - ETA: 0s - loss: 0.8237 - categorical_accuracy: 0.6390174/216 [=======================>......] - ETA: 0s - loss: 0.8252 - categorical_accuracy: 0.6379209/216 [============================>.] - ETA: 0s - loss: 0.8258 - categorical_accuracy: 0.6371216/216 [==============================] - 0s 2ms/step - loss: 0.8260 - categorical_accuracy: 0.6369 - val_loss: 0.8911 - val_categorical_accuracy: 0.6154
Epoch 16/100
  1/216 [..............................] - ETA: 0s - loss: 0.7717 - categorical_accuracy: 0.6300 36/216 [====>.........................] - ETA: 0s - loss: 0.7913 - categorical_accuracy: 0.6450 71/216 [========>.....................] - ETA: 0s - loss: 0.8016 - categorical_accuracy: 0.6415104/216 [=============>................] - ETA: 0s - loss: 0.8047 - categorical_accuracy: 0.6405139/216 [==================>...........] - ETA: 0s - loss: 0.8070 - categorical_accuracy: 0.6400174/216 [=======================>......] - ETA: 0s - loss: 0.8091 - categorical_accuracy: 0.6393209/216 [============================>.] - ETA: 0s - loss: 0.8104 - categorical_accuracy: 0.6390216/216 [==============================] - 0s 2ms/step - loss: 0.8106 - categorical_accuracy: 0.6391 - val_loss: 0.8705 - val_categorical_accuracy: 0.6125
Epoch 17/100
  1/216 [..............................] - ETA: 0s - loss: 0.7859 - categorical_accuracy: 0.6300 36/216 [====>.........................] - ETA: 0s - loss: 0.7918 - categorical_accuracy: 0.6533 71/216 [========>.....................] - ETA: 0s - loss: 0.7971 - categorical_accuracy: 0.6528106/216 [=============>................] - ETA: 0s - loss: 0.7988 - categorical_accuracy: 0.6527140/216 [==================>...........] - ETA: 0s - loss: 0.8005 - categorical_accuracy: 0.6518175/216 [=======================>......] - ETA: 0s - loss: 0.8021 - categorical_accuracy: 0.6506210/216 [============================>.] - ETA: 0s - loss: 0.8033 - categorical_accuracy: 0.6495216/216 [==============================] - 0s 2ms/step - loss: 0.8035 - categorical_accuracy: 0.6493 - val_loss: 0.9033 - val_categorical_accuracy: 0.6050
Epoch 18/100
  1/216 [..............................] - ETA: 0s - loss: 0.7826 - categorical_accuracy: 0.6800 36/216 [====>.........................] - ETA: 0s - loss: 0.7913 - categorical_accuracy: 0.6535 71/216 [========>.....................] - ETA: 0s - loss: 0.7966 - categorical_accuracy: 0.6501106/216 [=============>................] - ETA: 0s - loss: 0.7992 - categorical_accuracy: 0.6482140/216 [==================>...........] - ETA: 0s - loss: 0.8004 - categorical_accuracy: 0.6470175/216 [=======================>......] - ETA: 0s - loss: 0.8015 - categorical_accuracy: 0.6460210/216 [============================>.] - ETA: 0s - loss: 0.8022 - categorical_accuracy: 0.6451216/216 [==============================] - 0s 2ms/step - loss: 0.8023 - categorical_accuracy: 0.6450 - val_loss: 0.8785 - val_categorical_accuracy: 0.6117
Epoch 19/100
  1/216 [..............................] - ETA: 0s - loss: 0.8368 - categorical_accuracy: 0.6600 36/216 [====>.........................] - ETA: 0s - loss: 0.7820 - categorical_accuracy: 0.6610 72/216 [=========>....................] - ETA: 0s - loss: 0.7807 - categorical_accuracy: 0.6591107/216 [=============>................] - ETA: 0s - loss: 0.7827 - categorical_accuracy: 0.6566142/216 [==================>...........] - ETA: 0s - loss: 0.7858 - categorical_accuracy: 0.6540177/216 [=======================>......] - ETA: 0s - loss: 0.7885 - categorical_accuracy: 0.6521211/216 [============================>.] - ETA: 0s - loss: 0.7904 - categorical_accuracy: 0.6510216/216 [==============================] - 0s 2ms/step - loss: 0.7907 - categorical_accuracy: 0.6509 - val_loss: 0.9031 - val_categorical_accuracy: 0.6058
Epoch 20/100
  1/216 [..............................] - ETA: 0s - loss: 0.7708 - categorical_accuracy: 0.6800 35/216 [===>..........................] - ETA: 0s - loss: 0.7559 - categorical_accuracy: 0.6668 69/216 [========>.....................] - ETA: 0s - loss: 0.7648 - categorical_accuracy: 0.6633104/216 [=============>................] - ETA: 0s - loss: 0.7711 - categorical_accuracy: 0.6610138/216 [==================>...........] - ETA: 0s - loss: 0.7746 - categorical_accuracy: 0.6592173/216 [=======================>......] - ETA: 0s - loss: 0.7765 - categorical_accuracy: 0.6580208/216 [===========================>..] - ETA: 0s - loss: 0.7779 - categorical_accuracy: 0.6572216/216 [==============================] - 0s 2ms/step - loss: 0.7782 - categorical_accuracy: 0.6570 - val_loss: 0.8915 - val_categorical_accuracy: 0.6158
Epoch 21/100
  1/216 [..............................] - ETA: 0s - loss: 0.7613 - categorical_accuracy: 0.6800 36/216 [====>.........................] - ETA: 0s - loss: 0.7554 - categorical_accuracy: 0.6682 71/216 [========>.....................] - ETA: 0s - loss: 0.7588 - categorical_accuracy: 0.6668106/216 [=============>................] - ETA: 0s - loss: 0.7622 - categorical_accuracy: 0.6653141/216 [==================>...........] - ETA: 0s - loss: 0.7652 - categorical_accuracy: 0.6637177/216 [=======================>......] - ETA: 0s - loss: 0.7677 - categorical_accuracy: 0.6624211/216 [============================>.] - ETA: 0s - loss: 0.7695 - categorical_accuracy: 0.6614216/216 [==============================] - 0s 2ms/step - loss: 0.7697 - categorical_accuracy: 0.6612 - val_loss: 0.8949 - val_categorical_accuracy: 0.6050
Epoch 22/100
  1/216 [..............................] - ETA: 0s - loss: 0.7505 - categorical_accuracy: 0.6300 36/216 [====>.........................] - ETA: 0s - loss: 0.7801 - categorical_accuracy: 0.6435 71/216 [========>.....................] - ETA: 0s - loss: 0.7758 - categorical_accuracy: 0.6476106/216 [=============>................] - ETA: 0s - loss: 0.7738 - categorical_accuracy: 0.6494141/216 [==================>...........] - ETA: 0s - loss: 0.7736 - categorical_accuracy: 0.6506176/216 [=======================>......] - ETA: 0s - loss: 0.7734 - categorical_accuracy: 0.6515211/216 [============================>.] - ETA: 0s - loss: 0.7734 - categorical_accuracy: 0.6521216/216 [==============================] - 0s 2ms/step - loss: 0.7734 - categorical_accuracy: 0.6522 - val_loss: 0.8829 - val_categorical_accuracy: 0.6217
Epoch 23/100
  1/216 [..............................] - ETA: 0s - loss: 0.8761 - categorical_accuracy: 0.6200 36/216 [====>.........................] - ETA: 0s - loss: 0.7637 - categorical_accuracy: 0.6582 71/216 [========>.....................] - ETA: 0s - loss: 0.7544 - categorical_accuracy: 0.6652104/216 [=============>................] - ETA: 0s - loss: 0.7519 - categorical_accuracy: 0.6666138/216 [==================>...........] - ETA: 0s - loss: 0.7518 - categorical_accuracy: 0.6667173/216 [=======================>......] - ETA: 0s - loss: 0.7529 - categorical_accuracy: 0.6664207/216 [===========================>..] - ETA: 0s - loss: 0.7550 - categorical_accuracy: 0.6653216/216 [==============================] - 0s 2ms/step - loss: 0.7556 - categorical_accuracy: 0.6650 - val_loss: 0.9022 - val_categorical_accuracy: 0.6146
Epoch 00023: early stopping
Experiment:  71  Set:  ss2 Train Labels:  nar5 Test Labels:  clean
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.82      0.83      0.82      1240
           1       0.63      0.63      0.63      1218
           2       0.58      0.37      0.45      1184
           3       0.45      0.40      0.42      1175
           4       0.57      0.84      0.68      1183

    accuracy                           0.61      6000
   macro avg       0.61      0.61      0.60      6000
weighted avg       0.61      0.61      0.60      6000

Confusion Matrix for this model: 
 [[1026  214    0    0    0]
 [ 216  762  192   35   13]
 [   6  195  438  383  162]
 [   1   17  112  465  580]
 [   9   15   14  152  993]]
Experiment:  72  Set:  ss2 Train Labels:  nar5 Test Labels:  ncar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.76      0.80      0.78      1203
           1       0.60      0.59      0.60      1215
           2       0.57      0.36      0.44      1206
           3       0.43      0.38      0.40      1190
           4       0.54      0.80      0.64      1186

    accuracy                           0.58      6000
   macro avg       0.58      0.58      0.57      6000
weighted avg       0.58      0.58      0.57      6000

Confusion Matrix for this model: 
 [[959 208   7  11  18]
 [219 722 187  44  43]
 [ 26 204 429 375 172]
 [ 26  33 113 448 570]
 [ 28  36  20 157 945]]
Experiment:  73  Set:  ss2 Train Labels:  nar5 Test Labels:  ncar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.72      0.76      0.74      1206
           1       0.59      0.57      0.58      1250
           2       0.51      0.32      0.39      1210
           3       0.41      0.36      0.38      1172
           4       0.51      0.76      0.61      1162

    accuracy                           0.55      6000
   macro avg       0.55      0.55      0.54      6000
weighted avg       0.55      0.55      0.54      6000

Confusion Matrix for this model: 
 [[911 207  19  26  43]
 [229 707 188  60  66]
 [ 40 211 388 365 206]
 [ 37  42 121 424 548]
 [ 41  36  40 160 885]]
Experiment:  74  Set:  ss2 Train Labels:  nar5 Test Labels:  nar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.60      0.83      0.69       908
           1       0.63      0.63      0.63      1218
           2       0.58      0.37      0.45      1184
           3       0.45      0.31      0.37      1507
           4       0.57      0.84      0.68      1183

    accuracy                           0.57      6000
   macro avg       0.57      0.59      0.56      6000
weighted avg       0.56      0.57      0.55      6000

Confusion Matrix for this model: 
 [[750 158   0   0   0]
 [216 762 192  35  13]
 [  6 195 438 383 162]
 [277  73 112 465 580]
 [  9  15  14 152 993]]
Experiment:  75  Set:  ss2 Train Labels:  nar5 Test Labels:  nar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.41      0.83      0.55       623
           1       0.63      0.63      0.63      1218
           2       0.58      0.37      0.45      1184
           3       0.45      0.26      0.33      1792
           4       0.57      0.84      0.68      1183

    accuracy                           0.53      6000
   macro avg       0.53      0.58      0.53      6000
weighted avg       0.53      0.53      0.51      6000

Confusion Matrix for this model: 
 [[516 107   0   0   0]
 [216 762 192  35  13]
 [  6 195 438 383 162]
 [511 124 112 465 580]
 [  9  15  14 152 993]]
Experiment:  76  Set:  ss2 Train Labels:  nar5 Test Labels:  nnar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.75      0.84      0.80      1120
           1       0.66      0.60      0.63      1327
           2       0.58      0.37      0.45      1184
           3       0.45      0.39      0.42      1178
           4       0.57      0.83      0.68      1191

    accuracy                           0.61      6000
   macro avg       0.60      0.61      0.59      6000
weighted avg       0.60      0.61      0.59      6000

Confusion Matrix for this model: 
 [[946 174   0   0   0]
 [288 799 192  35  13]
 [  6 195 438 383 162]
 [  2  19 112 465 580]
 [ 16  16  14 152 993]]
Experiment:  77  Set:  ss2 Train Labels:  nar5 Test Labels:  nnar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.75      0.85      0.79      1111
           1       0.67      0.60      0.63      1332
           2       0.58      0.37      0.45      1184
           3       0.45      0.39      0.42      1178
           4       0.57      0.83      0.67      1195

    accuracy                           0.61      6000
   macro avg       0.60      0.61      0.59      6000
weighted avg       0.60      0.61      0.59      6000

Confusion Matrix for this model: 
 [[941 170   0   0   0]
 [290 802 192  35  13]
 [  6 195 438 383 162]
 [  2  19 112 465 580]
 [ 19  17  14 152 993]]
Input Shape:  (24000, 1, 150)
Model: "sequential_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_11 (LSTM)               (None, 32)                23424     
_________________________________________________________________
dropout_11 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_44 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_45 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_46 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_47 (Dense)             (None, 5)                 325       
=================================================================
Total params: 52,741
Trainable params: 52,741
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
  1/216 [..............................] - ETA: 3:06 - loss: 1.6185 - categorical_accuracy: 0.1300 33/216 [===>..........................] - ETA: 0s - loss: 1.5869 - categorical_accuracy: 0.2515   67/216 [========>.....................] - ETA: 0s - loss: 1.5498 - categorical_accuracy: 0.2919101/216 [=============>................] - ETA: 0s - loss: 1.5083 - categorical_accuracy: 0.3183135/216 [=================>............] - ETA: 0s - loss: 1.4708 - categorical_accuracy: 0.3394170/216 [======================>.......] - ETA: 0s - loss: 1.4386 - categorical_accuracy: 0.3563205/216 [===========================>..] - ETA: 0s - loss: 1.4120 - categorical_accuracy: 0.3698216/216 [==============================] - 1s 3ms/step - loss: 1.4040 - categorical_accuracy: 0.3737 - val_loss: 1.0757 - val_categorical_accuracy: 0.5292
Epoch 2/100
  1/216 [..............................] - ETA: 0s - loss: 1.0918 - categorical_accuracy: 0.4700 36/216 [====>.........................] - ETA: 0s - loss: 1.0990 - categorical_accuracy: 0.5193 70/216 [========>.....................] - ETA: 0s - loss: 1.0993 - categorical_accuracy: 0.5212105/216 [=============>................] - ETA: 0s - loss: 1.0976 - categorical_accuracy: 0.5218139/216 [==================>...........] - ETA: 0s - loss: 1.0945 - categorical_accuracy: 0.5234174/216 [=======================>......] - ETA: 0s - loss: 1.0920 - categorical_accuracy: 0.5246208/216 [===========================>..] - ETA: 0s - loss: 1.0902 - categorical_accuracy: 0.5255216/216 [==============================] - 0s 2ms/step - loss: 1.0897 - categorical_accuracy: 0.5257 - val_loss: 1.0065 - val_categorical_accuracy: 0.5667
Epoch 3/100
  1/216 [..............................] - ETA: 0s - loss: 0.9519 - categorical_accuracy: 0.5500 36/216 [====>.........................] - ETA: 0s - loss: 1.0250 - categorical_accuracy: 0.5593 69/216 [========>.....................] - ETA: 0s - loss: 1.0323 - categorical_accuracy: 0.5555103/216 [=============>................] - ETA: 0s - loss: 1.0352 - categorical_accuracy: 0.5550138/216 [==================>...........] - ETA: 0s - loss: 1.0374 - categorical_accuracy: 0.5538173/216 [=======================>......] - ETA: 0s - loss: 1.0383 - categorical_accuracy: 0.5533208/216 [===========================>..] - ETA: 0s - loss: 1.0382 - categorical_accuracy: 0.5532216/216 [==============================] - 0s 2ms/step - loss: 1.0380 - categorical_accuracy: 0.5532 - val_loss: 0.9849 - val_categorical_accuracy: 0.5750
Epoch 4/100
  1/216 [..............................] - ETA: 0s - loss: 1.0234 - categorical_accuracy: 0.5600 36/216 [====>.........................] - ETA: 0s - loss: 0.9810 - categorical_accuracy: 0.5844 71/216 [========>.....................] - ETA: 0s - loss: 0.9829 - categorical_accuracy: 0.5815106/216 [=============>................] - ETA: 0s - loss: 0.9856 - categorical_accuracy: 0.5782140/216 [==================>...........] - ETA: 0s - loss: 0.9878 - categorical_accuracy: 0.5762175/216 [=======================>......] - ETA: 0s - loss: 0.9894 - categorical_accuracy: 0.5751209/216 [============================>.] - ETA: 0s - loss: 0.9906 - categorical_accuracy: 0.5744216/216 [==============================] - 0s 2ms/step - loss: 0.9908 - categorical_accuracy: 0.5742 - val_loss: 0.9585 - val_categorical_accuracy: 0.5875
Epoch 5/100
  1/216 [..............................] - ETA: 0s - loss: 0.9151 - categorical_accuracy: 0.5200 37/216 [====>.........................] - ETA: 0s - loss: 0.9819 - categorical_accuracy: 0.5583 71/216 [========>.....................] - ETA: 0s - loss: 0.9818 - categorical_accuracy: 0.5632106/216 [=============>................] - ETA: 0s - loss: 0.9812 - categorical_accuracy: 0.5655141/216 [==================>...........] - ETA: 0s - loss: 0.9794 - categorical_accuracy: 0.5676175/216 [=======================>......] - ETA: 0s - loss: 0.9784 - categorical_accuracy: 0.5690210/216 [============================>.] - ETA: 0s - loss: 0.9779 - categorical_accuracy: 0.5701216/216 [==============================] - 0s 2ms/step - loss: 0.9777 - categorical_accuracy: 0.5703 - val_loss: 0.9339 - val_categorical_accuracy: 0.5996
Epoch 6/100
  1/216 [..............................] - ETA: 0s - loss: 0.9601 - categorical_accuracy: 0.6500 36/216 [====>.........................] - ETA: 0s - loss: 0.9351 - categorical_accuracy: 0.6065 71/216 [========>.....................] - ETA: 0s - loss: 0.9347 - categorical_accuracy: 0.6053105/216 [=============>................] - ETA: 0s - loss: 0.9387 - categorical_accuracy: 0.6010140/216 [==================>...........] - ETA: 0s - loss: 0.9397 - categorical_accuracy: 0.5992175/216 [=======================>......] - ETA: 0s - loss: 0.9396 - categorical_accuracy: 0.5984210/216 [============================>.] - ETA: 0s - loss: 0.9398 - categorical_accuracy: 0.5976216/216 [==============================] - 0s 2ms/step - loss: 0.9399 - categorical_accuracy: 0.5974 - val_loss: 0.9477 - val_categorical_accuracy: 0.5900
Epoch 7/100
  1/216 [..............................] - ETA: 0s - loss: 0.8895 - categorical_accuracy: 0.6100 36/216 [====>.........................] - ETA: 0s - loss: 0.9393 - categorical_accuracy: 0.5891 71/216 [========>.....................] - ETA: 0s - loss: 0.9384 - categorical_accuracy: 0.5882105/216 [=============>................] - ETA: 0s - loss: 0.9369 - categorical_accuracy: 0.5889139/216 [==================>...........] - ETA: 0s - loss: 0.9356 - categorical_accuracy: 0.5896174/216 [=======================>......] - ETA: 0s - loss: 0.9346 - categorical_accuracy: 0.5902208/216 [===========================>..] - ETA: 0s - loss: 0.9337 - categorical_accuracy: 0.5910216/216 [==============================] - 0s 2ms/step - loss: 0.9335 - categorical_accuracy: 0.5912 - val_loss: 0.9196 - val_categorical_accuracy: 0.6008
Epoch 8/100
  1/216 [..............................] - ETA: 0s - loss: 0.8972 - categorical_accuracy: 0.6300 35/216 [===>..........................] - ETA: 0s - loss: 0.9045 - categorical_accuracy: 0.6135 70/216 [========>.....................] - ETA: 0s - loss: 0.9042 - categorical_accuracy: 0.6112105/216 [=============>................] - ETA: 0s - loss: 0.9050 - categorical_accuracy: 0.6094140/216 [==================>...........] - ETA: 0s - loss: 0.9067 - categorical_accuracy: 0.6078174/216 [=======================>......] - ETA: 0s - loss: 0.9072 - categorical_accuracy: 0.6071209/216 [============================>.] - ETA: 0s - loss: 0.9078 - categorical_accuracy: 0.6068216/216 [==============================] - 0s 2ms/step - loss: 0.9079 - categorical_accuracy: 0.6067 - val_loss: 0.9085 - val_categorical_accuracy: 0.6037
Epoch 9/100
  1/216 [..............................] - ETA: 0s - loss: 0.7997 - categorical_accuracy: 0.6500 37/216 [====>.........................] - ETA: 0s - loss: 0.8641 - categorical_accuracy: 0.6194 72/216 [=========>....................] - ETA: 0s - loss: 0.8724 - categorical_accuracy: 0.6160107/216 [=============>................] - ETA: 0s - loss: 0.8784 - categorical_accuracy: 0.6136141/216 [==================>...........] - ETA: 0s - loss: 0.8816 - categorical_accuracy: 0.6128176/216 [=======================>......] - ETA: 0s - loss: 0.8831 - categorical_accuracy: 0.6126211/216 [============================>.] - ETA: 0s - loss: 0.8844 - categorical_accuracy: 0.6126216/216 [==============================] - 0s 2ms/step - loss: 0.8845 - categorical_accuracy: 0.6126 - val_loss: 0.9067 - val_categorical_accuracy: 0.5971
Epoch 10/100
  1/216 [..............................] - ETA: 0s - loss: 1.0768 - categorical_accuracy: 0.5500 31/216 [===>..........................] - ETA: 0s - loss: 0.8937 - categorical_accuracy: 0.6092 62/216 [=======>......................] - ETA: 0s - loss: 0.8895 - categorical_accuracy: 0.6080 95/216 [============>.................] - ETA: 0s - loss: 0.8839 - categorical_accuracy: 0.6099130/216 [=================>............] - ETA: 0s - loss: 0.8825 - categorical_accuracy: 0.6109164/216 [=====================>........] - ETA: 0s - loss: 0.8827 - categorical_accuracy: 0.6111199/216 [==========================>...] - ETA: 0s - loss: 0.8830 - categorical_accuracy: 0.6113216/216 [==============================] - 0s 2ms/step - loss: 0.8830 - categorical_accuracy: 0.6115 - val_loss: 0.9130 - val_categorical_accuracy: 0.5971
Epoch 11/100
  1/216 [..............................] - ETA: 0s - loss: 0.9058 - categorical_accuracy: 0.5900 36/216 [====>.........................] - ETA: 0s - loss: 0.8840 - categorical_accuracy: 0.6129 71/216 [========>.....................] - ETA: 0s - loss: 0.8753 - categorical_accuracy: 0.6193106/216 [=============>................] - ETA: 0s - loss: 0.8725 - categorical_accuracy: 0.6208141/216 [==================>...........] - ETA: 0s - loss: 0.8711 - categorical_accuracy: 0.6217175/216 [=======================>......] - ETA: 0s - loss: 0.8699 - categorical_accuracy: 0.6226209/216 [============================>.] - ETA: 0s - loss: 0.8688 - categorical_accuracy: 0.6231216/216 [==============================] - 0s 2ms/step - loss: 0.8686 - categorical_accuracy: 0.6232 - val_loss: 0.9357 - val_categorical_accuracy: 0.5833
Epoch 12/100
  1/216 [..............................] - ETA: 0s - loss: 0.7436 - categorical_accuracy: 0.7100 36/216 [====>.........................] - ETA: 0s - loss: 0.8492 - categorical_accuracy: 0.6316 71/216 [========>.....................] - ETA: 0s - loss: 0.8548 - categorical_accuracy: 0.6284105/216 [=============>................] - ETA: 0s - loss: 0.8573 - categorical_accuracy: 0.6279140/216 [==================>...........] - ETA: 0s - loss: 0.8582 - categorical_accuracy: 0.6271174/216 [=======================>......] - ETA: 0s - loss: 0.8576 - categorical_accuracy: 0.6271209/216 [============================>.] - ETA: 0s - loss: 0.8569 - categorical_accuracy: 0.6275216/216 [==============================] - 0s 2ms/step - loss: 0.8568 - categorical_accuracy: 0.6276 - val_loss: 0.9143 - val_categorical_accuracy: 0.5950
Epoch 13/100
  1/216 [..............................] - ETA: 0s - loss: 0.8398 - categorical_accuracy: 0.6600 36/216 [====>.........................] - ETA: 0s - loss: 0.8199 - categorical_accuracy: 0.6514 71/216 [========>.....................] - ETA: 0s - loss: 0.8331 - categorical_accuracy: 0.6427107/216 [=============>................] - ETA: 0s - loss: 0.8367 - categorical_accuracy: 0.6404141/216 [==================>...........] - ETA: 0s - loss: 0.8377 - categorical_accuracy: 0.6397176/216 [=======================>......] - ETA: 0s - loss: 0.8391 - categorical_accuracy: 0.6388211/216 [============================>.] - ETA: 0s - loss: 0.8402 - categorical_accuracy: 0.6381216/216 [==============================] - 0s 2ms/step - loss: 0.8404 - categorical_accuracy: 0.6380 - val_loss: 0.8930 - val_categorical_accuracy: 0.6125
Epoch 14/100
  1/216 [..............................] - ETA: 0s - loss: 0.8093 - categorical_accuracy: 0.6300 36/216 [====>.........................] - ETA: 0s - loss: 0.8160 - categorical_accuracy: 0.6384 71/216 [========>.....................] - ETA: 0s - loss: 0.8237 - categorical_accuracy: 0.6390106/216 [=============>................] - ETA: 0s - loss: 0.8255 - categorical_accuracy: 0.6398141/216 [==================>...........] - ETA: 0s - loss: 0.8266 - categorical_accuracy: 0.6403175/216 [=======================>......] - ETA: 0s - loss: 0.8283 - categorical_accuracy: 0.6398210/216 [============================>.] - ETA: 0s - loss: 0.8292 - categorical_accuracy: 0.6397216/216 [==============================] - 0s 2ms/step - loss: 0.8293 - categorical_accuracy: 0.6397 - val_loss: 0.8971 - val_categorical_accuracy: 0.5987
Epoch 15/100
  1/216 [..............................] - ETA: 0s - loss: 0.7682 - categorical_accuracy: 0.6600 36/216 [====>.........................] - ETA: 0s - loss: 0.8118 - categorical_accuracy: 0.6405 71/216 [========>.....................] - ETA: 0s - loss: 0.8117 - categorical_accuracy: 0.6455106/216 [=============>................] - ETA: 0s - loss: 0.8124 - categorical_accuracy: 0.6471141/216 [==================>...........] - ETA: 0s - loss: 0.8133 - categorical_accuracy: 0.6479176/216 [=======================>......] - ETA: 0s - loss: 0.8143 - categorical_accuracy: 0.6480211/216 [============================>.] - ETA: 0s - loss: 0.8155 - categorical_accuracy: 0.6476216/216 [==============================] - 0s 2ms/step - loss: 0.8157 - categorical_accuracy: 0.6475 - val_loss: 0.9018 - val_categorical_accuracy: 0.6050
Epoch 16/100
  1/216 [..............................] - ETA: 0s - loss: 0.8111 - categorical_accuracy: 0.6200 36/216 [====>.........................] - ETA: 0s - loss: 0.8147 - categorical_accuracy: 0.6485 71/216 [========>.....................] - ETA: 0s - loss: 0.8101 - categorical_accuracy: 0.6520106/216 [=============>................] - ETA: 0s - loss: 0.8085 - categorical_accuracy: 0.6522141/216 [==================>...........] - ETA: 0s - loss: 0.8076 - categorical_accuracy: 0.6519176/216 [=======================>......] - ETA: 0s - loss: 0.8077 - categorical_accuracy: 0.6515211/216 [============================>.] - ETA: 0s - loss: 0.8083 - categorical_accuracy: 0.6510216/216 [==============================] - 0s 2ms/step - loss: 0.8085 - categorical_accuracy: 0.6510 - val_loss: 0.8851 - val_categorical_accuracy: 0.6075
Epoch 17/100
  1/216 [..............................] - ETA: 0s - loss: 0.8367 - categorical_accuracy: 0.6300 35/216 [===>..........................] - ETA: 0s - loss: 0.7960 - categorical_accuracy: 0.6553 70/216 [========>.....................] - ETA: 0s - loss: 0.7984 - categorical_accuracy: 0.6537105/216 [=============>................] - ETA: 0s - loss: 0.8010 - categorical_accuracy: 0.6526139/216 [==================>...........] - ETA: 0s - loss: 0.8027 - categorical_accuracy: 0.6515173/216 [=======================>......] - ETA: 0s - loss: 0.8035 - categorical_accuracy: 0.6509209/216 [============================>.] - ETA: 0s - loss: 0.8041 - categorical_accuracy: 0.6504216/216 [==============================] - 0s 2ms/step - loss: 0.8043 - categorical_accuracy: 0.6503 - val_loss: 0.8885 - val_categorical_accuracy: 0.6121
Epoch 18/100
  1/216 [..............................] - ETA: 0s - loss: 0.8598 - categorical_accuracy: 0.6000 37/216 [====>.........................] - ETA: 0s - loss: 0.8031 - categorical_accuracy: 0.6533 72/216 [=========>....................] - ETA: 0s - loss: 0.7891 - categorical_accuracy: 0.6616106/216 [=============>................] - ETA: 0s - loss: 0.7890 - categorical_accuracy: 0.6610141/216 [==================>...........] - ETA: 0s - loss: 0.7900 - categorical_accuracy: 0.6593176/216 [=======================>......] - ETA: 0s - loss: 0.7910 - categorical_accuracy: 0.6580210/216 [============================>.] - ETA: 0s - loss: 0.7918 - categorical_accuracy: 0.6571216/216 [==============================] - 0s 2ms/step - loss: 0.7920 - categorical_accuracy: 0.6569 - val_loss: 0.8777 - val_categorical_accuracy: 0.6217
Epoch 19/100
  1/216 [..............................] - ETA: 0s - loss: 0.8931 - categorical_accuracy: 0.6200 35/216 [===>..........................] - ETA: 0s - loss: 0.8001 - categorical_accuracy: 0.6403 70/216 [========>.....................] - ETA: 0s - loss: 0.7933 - categorical_accuracy: 0.6449105/216 [=============>................] - ETA: 0s - loss: 0.7920 - categorical_accuracy: 0.6473140/216 [==================>...........] - ETA: 0s - loss: 0.7903 - categorical_accuracy: 0.6486175/216 [=======================>......] - ETA: 0s - loss: 0.7898 - categorical_accuracy: 0.6496210/216 [============================>.] - ETA: 0s - loss: 0.7899 - categorical_accuracy: 0.6501216/216 [==============================] - 0s 2ms/step - loss: 0.7900 - categorical_accuracy: 0.6502 - val_loss: 0.9095 - val_categorical_accuracy: 0.6029
Epoch 20/100
  1/216 [..............................] - ETA: 0s - loss: 0.8386 - categorical_accuracy: 0.6400 36/216 [====>.........................] - ETA: 0s - loss: 0.7754 - categorical_accuracy: 0.6636 70/216 [========>.....................] - ETA: 0s - loss: 0.7733 - categorical_accuracy: 0.6642105/216 [=============>................] - ETA: 0s - loss: 0.7741 - categorical_accuracy: 0.6631140/216 [==================>...........] - ETA: 0s - loss: 0.7747 - categorical_accuracy: 0.6630176/216 [=======================>......] - ETA: 0s - loss: 0.7753 - categorical_accuracy: 0.6627211/216 [============================>.] - ETA: 0s - loss: 0.7758 - categorical_accuracy: 0.6623216/216 [==============================] - 0s 2ms/step - loss: 0.7758 - categorical_accuracy: 0.6623 - val_loss: 0.8944 - val_categorical_accuracy: 0.6096
Epoch 21/100
  1/216 [..............................] - ETA: 0s - loss: 0.7757 - categorical_accuracy: 0.6800 36/216 [====>.........................] - ETA: 0s - loss: 0.7715 - categorical_accuracy: 0.6630 71/216 [========>.....................] - ETA: 0s - loss: 0.7709 - categorical_accuracy: 0.6619106/216 [=============>................] - ETA: 0s - loss: 0.7701 - categorical_accuracy: 0.6634141/216 [==================>...........] - ETA: 0s - loss: 0.7705 - categorical_accuracy: 0.6640175/216 [=======================>......] - ETA: 0s - loss: 0.7708 - categorical_accuracy: 0.6639209/216 [============================>.] - ETA: 0s - loss: 0.7714 - categorical_accuracy: 0.6636216/216 [==============================] - 0s 2ms/step - loss: 0.7715 - categorical_accuracy: 0.6636 - val_loss: 0.9099 - val_categorical_accuracy: 0.5954
Epoch 22/100
  1/216 [..............................] - ETA: 0s - loss: 0.7951 - categorical_accuracy: 0.6200 37/216 [====>.........................] - ETA: 0s - loss: 0.7767 - categorical_accuracy: 0.6552 71/216 [========>.....................] - ETA: 0s - loss: 0.7676 - categorical_accuracy: 0.6633106/216 [=============>................] - ETA: 0s - loss: 0.7653 - categorical_accuracy: 0.6652140/216 [==================>...........] - ETA: 0s - loss: 0.7646 - categorical_accuracy: 0.6659176/216 [=======================>......] - ETA: 0s - loss: 0.7646 - categorical_accuracy: 0.6660211/216 [============================>.] - ETA: 0s - loss: 0.7650 - categorical_accuracy: 0.6658216/216 [==============================] - 0s 2ms/step - loss: 0.7650 - categorical_accuracy: 0.6658 - val_loss: 0.8947 - val_categorical_accuracy: 0.6104
Epoch 23/100
  1/216 [..............................] - ETA: 0s - loss: 0.7809 - categorical_accuracy: 0.6400 36/216 [====>.........................] - ETA: 0s - loss: 0.7405 - categorical_accuracy: 0.6738 71/216 [========>.....................] - ETA: 0s - loss: 0.7433 - categorical_accuracy: 0.6723106/216 [=============>................] - ETA: 0s - loss: 0.7481 - categorical_accuracy: 0.6693141/216 [==================>...........] - ETA: 0s - loss: 0.7519 - categorical_accuracy: 0.6674177/216 [=======================>......] - ETA: 0s - loss: 0.7542 - categorical_accuracy: 0.6662212/216 [============================>.] - ETA: 0s - loss: 0.7557 - categorical_accuracy: 0.6656216/216 [==============================] - 0s 2ms/step - loss: 0.7559 - categorical_accuracy: 0.6655 - val_loss: 0.8641 - val_categorical_accuracy: 0.6275
Epoch 24/100
  1/216 [..............................] - ETA: 0s - loss: 0.8151 - categorical_accuracy: 0.6100 36/216 [====>.........................] - ETA: 0s - loss: 0.7521 - categorical_accuracy: 0.6672 71/216 [========>.....................] - ETA: 0s - loss: 0.7480 - categorical_accuracy: 0.6695106/216 [=============>................] - ETA: 0s - loss: 0.7483 - categorical_accuracy: 0.6701141/216 [==================>...........] - ETA: 0s - loss: 0.7485 - categorical_accuracy: 0.6707176/216 [=======================>......] - ETA: 0s - loss: 0.7480 - categorical_accuracy: 0.6714212/216 [============================>.] - ETA: 0s - loss: 0.7478 - categorical_accuracy: 0.6718216/216 [==============================] - 0s 2ms/step - loss: 0.7479 - categorical_accuracy: 0.6718 - val_loss: 0.8930 - val_categorical_accuracy: 0.6054
Epoch 25/100
  1/216 [..............................] - ETA: 0s - loss: 0.7660 - categorical_accuracy: 0.6500 36/216 [====>.........................] - ETA: 0s - loss: 0.7235 - categorical_accuracy: 0.6807 71/216 [========>.....................] - ETA: 0s - loss: 0.7258 - categorical_accuracy: 0.6822106/216 [=============>................] - ETA: 0s - loss: 0.7272 - categorical_accuracy: 0.6817140/216 [==================>...........] - ETA: 0s - loss: 0.7287 - categorical_accuracy: 0.6811176/216 [=======================>......] - ETA: 0s - loss: 0.7304 - categorical_accuracy: 0.6802210/216 [============================>.] - ETA: 0s - loss: 0.7323 - categorical_accuracy: 0.6793216/216 [==============================] - 0s 2ms/step - loss: 0.7328 - categorical_accuracy: 0.6791 - val_loss: 0.9221 - val_categorical_accuracy: 0.5992
Epoch 26/100
  1/216 [..............................] - ETA: 0s - loss: 0.8008 - categorical_accuracy: 0.6600 36/216 [====>.........................] - ETA: 0s - loss: 0.7303 - categorical_accuracy: 0.6815 70/216 [========>.....................] - ETA: 0s - loss: 0.7336 - categorical_accuracy: 0.6782104/216 [=============>................] - ETA: 0s - loss: 0.7342 - categorical_accuracy: 0.6788139/216 [==================>...........] - ETA: 0s - loss: 0.7346 - categorical_accuracy: 0.6791174/216 [=======================>......] - ETA: 0s - loss: 0.7347 - categorical_accuracy: 0.6795210/216 [============================>.] - ETA: 0s - loss: 0.7354 - categorical_accuracy: 0.6794216/216 [==============================] - 0s 2ms/step - loss: 0.7356 - categorical_accuracy: 0.6794 - val_loss: 0.8815 - val_categorical_accuracy: 0.6137
Epoch 27/100
  1/216 [..............................] - ETA: 0s - loss: 0.7141 - categorical_accuracy: 0.6900 37/216 [====>.........................] - ETA: 0s - loss: 0.7206 - categorical_accuracy: 0.6978 72/216 [=========>....................] - ETA: 0s - loss: 0.7274 - categorical_accuracy: 0.6927107/216 [=============>................] - ETA: 0s - loss: 0.7312 - categorical_accuracy: 0.6892142/216 [==================>...........] - ETA: 0s - loss: 0.7341 - categorical_accuracy: 0.6866177/216 [=======================>......] - ETA: 0s - loss: 0.7360 - categorical_accuracy: 0.6849211/216 [============================>.] - ETA: 0s - loss: 0.7373 - categorical_accuracy: 0.6836216/216 [==============================] - 0s 2ms/step - loss: 0.7375 - categorical_accuracy: 0.6834 - val_loss: 0.8898 - val_categorical_accuracy: 0.6125
Epoch 28/100
  1/216 [..............................] - ETA: 0s - loss: 0.7095 - categorical_accuracy: 0.6600 36/216 [====>.........................] - ETA: 0s - loss: 0.7234 - categorical_accuracy: 0.6821 71/216 [========>.....................] - ETA: 0s - loss: 0.7206 - categorical_accuracy: 0.6823106/216 [=============>................] - ETA: 0s - loss: 0.7225 - categorical_accuracy: 0.6816142/216 [==================>...........] - ETA: 0s - loss: 0.7247 - categorical_accuracy: 0.6811176/216 [=======================>......] - ETA: 0s - loss: 0.7258 - categorical_accuracy: 0.6808211/216 [============================>.] - ETA: 0s - loss: 0.7272 - categorical_accuracy: 0.6802216/216 [==============================] - 0s 2ms/step - loss: 0.7274 - categorical_accuracy: 0.6801 - val_loss: 0.8923 - val_categorical_accuracy: 0.6146
Epoch 29/100
  1/216 [..............................] - ETA: 0s - loss: 0.8111 - categorical_accuracy: 0.6600 35/216 [===>..........................] - ETA: 0s - loss: 0.7372 - categorical_accuracy: 0.6804 69/216 [========>.....................] - ETA: 0s - loss: 0.7303 - categorical_accuracy: 0.6814103/216 [=============>................] - ETA: 0s - loss: 0.7281 - categorical_accuracy: 0.6816138/216 [==================>...........] - ETA: 0s - loss: 0.7268 - categorical_accuracy: 0.6814173/216 [=======================>......] - ETA: 0s - loss: 0.7262 - categorical_accuracy: 0.6813208/216 [===========================>..] - ETA: 0s - loss: 0.7266 - categorical_accuracy: 0.6812216/216 [==============================] - 0s 2ms/step - loss: 0.7267 - categorical_accuracy: 0.6811 - val_loss: 0.8827 - val_categorical_accuracy: 0.6183
Epoch 30/100
  1/216 [..............................] - ETA: 0s - loss: 0.6057 - categorical_accuracy: 0.7700 36/216 [====>.........................] - ETA: 0s - loss: 0.6880 - categorical_accuracy: 0.6948 70/216 [========>.....................] - ETA: 0s - loss: 0.7007 - categorical_accuracy: 0.6909105/216 [=============>................] - ETA: 0s - loss: 0.7032 - categorical_accuracy: 0.6910139/216 [==================>...........] - ETA: 0s - loss: 0.7064 - categorical_accuracy: 0.6900174/216 [=======================>......] - ETA: 0s - loss: 0.7088 - categorical_accuracy: 0.6895208/216 [===========================>..] - ETA: 0s - loss: 0.7106 - categorical_accuracy: 0.6890216/216 [==============================] - 0s 2ms/step - loss: 0.7110 - categorical_accuracy: 0.6889 - val_loss: 0.8836 - val_categorical_accuracy: 0.6271
Epoch 00030: early stopping
Experiment:  78  Set:  ss2 Train Labels:  nar10 Test Labels:  clean
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.83      0.80      0.81      1240
           1       0.52      0.79      0.62      1218
           2       0.62      0.03      0.06      1184
           3       0.45      0.56      0.50      1175
           4       0.63      0.77      0.69      1183

    accuracy                           0.59      6000
   macro avg       0.61      0.59      0.54      6000
weighted avg       0.61      0.59      0.54      6000

Confusion Matrix for this model: 
 [[991 248   0   0   1]
 [187 963  10  47  11]
 [  6 538  40 504  96]
 [  1  89  14 654 417]
 [  9  30   1 237 906]]
Experiment:  79  Set:  ss2 Train Labels:  nar10 Test Labels:  ncar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.78      0.77      0.78      1203
           1       0.50      0.76      0.60      1215
           2       0.62      0.03      0.06      1206
           3       0.44      0.53      0.48      1190
           4       0.60      0.73      0.66      1186

    accuracy                           0.57      6000
   macro avg       0.59      0.57      0.52      6000
weighted avg       0.59      0.57      0.52      6000

Confusion Matrix for this model: 
 [[932 241   1  14  15]
 [181 926  10  64  34]
 [ 24 539  40 490 113]
 [ 26 110  14 634 406]
 [ 31  52   0 240 863]]
Experiment:  80  Set:  ss2 Train Labels:  nar10 Test Labels:  ncar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.73      0.73      0.73      1206
           1       0.48      0.72      0.58      1250
           2       0.55      0.03      0.06      1210
           3       0.42      0.51      0.46      1172
           4       0.57      0.70      0.63      1162

    accuracy                           0.54      6000
   macro avg       0.55      0.54      0.49      6000
weighted avg       0.55      0.54      0.49      6000

Confusion Matrix for this model: 
 [[877 259   1  32  37]
 [199 902  11  84  54]
 [ 37 524  36 484 129]
 [ 40 119  14 601 398]
 [ 41  64   3 241 813]]
Experiment:  81  Set:  ss2 Train Labels:  nar10 Test Labels:  nar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.61      0.80      0.69       908
           1       0.52      0.79      0.62      1218
           2       0.62      0.03      0.06      1184
           3       0.45      0.43      0.44      1507
           4       0.63      0.77      0.69      1183

    accuracy                           0.55      6000
   macro avg       0.57      0.57      0.50      6000
weighted avg       0.56      0.55      0.49      6000

Confusion Matrix for this model: 
 [[729 179   0   0   0]
 [187 963  10  47  11]
 [  6 538  40 504  96]
 [263 158  14 654 418]
 [  9  30   1 237 906]]
Experiment:  82  Set:  ss2 Train Labels:  nar10 Test Labels:  nar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.41      0.79      0.54       623
           1       0.52      0.79      0.62      1218
           2       0.62      0.03      0.06      1184
           3       0.45      0.36      0.40      1792
           4       0.63      0.77      0.69      1183

    accuracy                           0.51      6000
   macro avg       0.53      0.55      0.47      6000
weighted avg       0.53      0.51      0.45      6000

Confusion Matrix for this model: 
 [[494 129   0   0   0]
 [187 963  10  47  11]
 [  6 538  40 504  96]
 [498 208  14 654 418]
 [  9  30   1 237 906]]
Experiment:  83  Set:  ss2 Train Labels:  nar10 Test Labels:  nnar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.77      0.82      0.79      1120
           1       0.54      0.76      0.63      1327
           2       0.62      0.03      0.06      1184
           3       0.45      0.56      0.50      1178
           4       0.63      0.76      0.69      1191

    accuracy                           0.59      6000
   macro avg       0.60      0.58      0.53      6000
weighted avg       0.60      0.59      0.53      6000

Confusion Matrix for this model: 
 [[ 915  204    0    0    1]
 [ 256 1003   10   47   11]
 [   6  538   40  504   96]
 [   1   92   14  654  417]
 [  16   31    1  237  906]]
Experiment:  84  Set:  ss2 Train Labels:  nar10 Test Labels:  nnar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.76      0.82      0.79      1111
           1       0.54      0.75      0.63      1332
           2       0.62      0.03      0.06      1184
           3       0.45      0.56      0.50      1178
           4       0.63      0.76      0.69      1195

    accuracy                           0.59      6000
   macro avg       0.60      0.58      0.53      6000
weighted avg       0.60      0.59      0.53      6000

Confusion Matrix for this model: 
 [[ 907  203    0    0    1]
 [ 260 1004   10   47   11]
 [   6  538   40  504   96]
 [   1   92   14  654  417]
 [  20   31    1  237  906]]
Input Shape:  (24000, 1, 150)
Model: "sequential_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_12 (LSTM)               (None, 32)                23424     
_________________________________________________________________
dropout_12 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_48 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_49 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_50 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_51 (Dense)             (None, 5)                 325       
=================================================================
Total params: 52,741
Trainable params: 52,741
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
  1/216 [..............................] - ETA: 3:07 - loss: 1.6099 - categorical_accuracy: 0.1600 33/216 [===>..........................] - ETA: 0s - loss: 1.5937 - categorical_accuracy: 0.2449   67/216 [========>.....................] - ETA: 0s - loss: 1.5512 - categorical_accuracy: 0.2755100/216 [============>.................] - ETA: 0s - loss: 1.5079 - categorical_accuracy: 0.2988134/216 [=================>............] - ETA: 0s - loss: 1.4697 - categorical_accuracy: 0.3188167/216 [======================>.......] - ETA: 0s - loss: 1.4390 - categorical_accuracy: 0.3348202/216 [===========================>..] - ETA: 0s - loss: 1.4119 - categorical_accuracy: 0.3484216/216 [==============================] - 2s 3ms/step - loss: 1.4017 - categorical_accuracy: 0.3534 - val_loss: 1.0639 - val_categorical_accuracy: 0.5221
Epoch 2/100
  1/216 [..............................] - ETA: 0s - loss: 1.1036 - categorical_accuracy: 0.5600 36/216 [====>.........................] - ETA: 0s - loss: 1.0916 - categorical_accuracy: 0.4916 71/216 [========>.....................] - ETA: 0s - loss: 1.0917 - categorical_accuracy: 0.4928106/216 [=============>................] - ETA: 0s - loss: 1.0904 - categorical_accuracy: 0.4958141/216 [==================>...........] - ETA: 0s - loss: 1.0899 - categorical_accuracy: 0.4977176/216 [=======================>......] - ETA: 0s - loss: 1.0887 - categorical_accuracy: 0.4997209/216 [============================>.] - ETA: 0s - loss: 1.0870 - categorical_accuracy: 0.5014216/216 [==============================] - 0s 2ms/step - loss: 1.0866 - categorical_accuracy: 0.5018 - val_loss: 0.9853 - val_categorical_accuracy: 0.5433
Epoch 3/100
  1/216 [..............................] - ETA: 0s - loss: 1.0754 - categorical_accuracy: 0.4900 35/216 [===>..........................] - ETA: 0s - loss: 1.0390 - categorical_accuracy: 0.5265 70/216 [========>.....................] - ETA: 0s - loss: 1.0350 - categorical_accuracy: 0.5295105/216 [=============>................] - ETA: 0s - loss: 1.0325 - categorical_accuracy: 0.5314140/216 [==================>...........] - ETA: 0s - loss: 1.0295 - categorical_accuracy: 0.5327175/216 [=======================>......] - ETA: 0s - loss: 1.0277 - categorical_accuracy: 0.5335210/216 [============================>.] - ETA: 0s - loss: 1.0265 - categorical_accuracy: 0.5341216/216 [==============================] - 0s 2ms/step - loss: 1.0262 - categorical_accuracy: 0.5342 - val_loss: 0.9351 - val_categorical_accuracy: 0.5804
Epoch 4/100
  1/216 [..............................] - ETA: 0s - loss: 0.9414 - categorical_accuracy: 0.5300 36/216 [====>.........................] - ETA: 0s - loss: 0.9724 - categorical_accuracy: 0.5569 71/216 [========>.....................] - ETA: 0s - loss: 0.9716 - categorical_accuracy: 0.5588106/216 [=============>................] - ETA: 0s - loss: 0.9712 - categorical_accuracy: 0.5593141/216 [==================>...........] - ETA: 0s - loss: 0.9712 - categorical_accuracy: 0.5591176/216 [=======================>......] - ETA: 0s - loss: 0.9711 - categorical_accuracy: 0.5589210/216 [============================>.] - ETA: 0s - loss: 0.9711 - categorical_accuracy: 0.5590216/216 [==============================] - 0s 2ms/step - loss: 0.9711 - categorical_accuracy: 0.5591 - val_loss: 0.9175 - val_categorical_accuracy: 0.5871
Epoch 5/100
  1/216 [..............................] - ETA: 0s - loss: 0.8490 - categorical_accuracy: 0.6100 34/216 [===>..........................] - ETA: 0s - loss: 0.9351 - categorical_accuracy: 0.5723 69/216 [========>.....................] - ETA: 0s - loss: 0.9306 - categorical_accuracy: 0.5745104/216 [=============>................] - ETA: 0s - loss: 0.9307 - categorical_accuracy: 0.5741139/216 [==================>...........] - ETA: 0s - loss: 0.9323 - categorical_accuracy: 0.5741173/216 [=======================>......] - ETA: 0s - loss: 0.9332 - categorical_accuracy: 0.5745209/216 [============================>.] - ETA: 0s - loss: 0.9343 - categorical_accuracy: 0.5746216/216 [==============================] - 0s 2ms/step - loss: 0.9345 - categorical_accuracy: 0.5747 - val_loss: 0.9333 - val_categorical_accuracy: 0.5642
Epoch 6/100
  1/216 [..............................] - ETA: 0s - loss: 0.9003 - categorical_accuracy: 0.6300 35/216 [===>..........................] - ETA: 0s - loss: 0.9085 - categorical_accuracy: 0.5995 70/216 [========>.....................] - ETA: 0s - loss: 0.9062 - categorical_accuracy: 0.5989104/216 [=============>................] - ETA: 0s - loss: 0.9078 - categorical_accuracy: 0.5961139/216 [==================>...........] - ETA: 0s - loss: 0.9113 - categorical_accuracy: 0.5927172/216 [======================>.......] - ETA: 0s - loss: 0.9131 - categorical_accuracy: 0.5909207/216 [===========================>..] - ETA: 0s - loss: 0.9144 - categorical_accuracy: 0.5895216/216 [==============================] - 0s 2ms/step - loss: 0.9146 - categorical_accuracy: 0.5893 - val_loss: 0.8964 - val_categorical_accuracy: 0.5875
Epoch 7/100
  1/216 [..............................] - ETA: 0s - loss: 0.9265 - categorical_accuracy: 0.5800 36/216 [====>.........................] - ETA: 0s - loss: 0.8982 - categorical_accuracy: 0.6009 69/216 [========>.....................] - ETA: 0s - loss: 0.8933 - categorical_accuracy: 0.5985104/216 [=============>................] - ETA: 0s - loss: 0.8934 - categorical_accuracy: 0.5971139/216 [==================>...........] - ETA: 0s - loss: 0.8937 - categorical_accuracy: 0.5961175/216 [=======================>......] - ETA: 0s - loss: 0.8933 - categorical_accuracy: 0.5959209/216 [============================>.] - ETA: 0s - loss: 0.8932 - categorical_accuracy: 0.5955216/216 [==============================] - 0s 2ms/step - loss: 0.8933 - categorical_accuracy: 0.5953 - val_loss: 0.8932 - val_categorical_accuracy: 0.5883
Epoch 8/100
  1/216 [..............................] - ETA: 0s - loss: 0.9944 - categorical_accuracy: 0.5800 36/216 [====>.........................] - ETA: 0s - loss: 0.8588 - categorical_accuracy: 0.6152 71/216 [========>.....................] - ETA: 0s - loss: 0.8618 - categorical_accuracy: 0.6145105/216 [=============>................] - ETA: 0s - loss: 0.8642 - categorical_accuracy: 0.6131140/216 [==================>...........] - ETA: 0s - loss: 0.8664 - categorical_accuracy: 0.6114175/216 [=======================>......] - ETA: 0s - loss: 0.8688 - categorical_accuracy: 0.6097209/216 [============================>.] - ETA: 0s - loss: 0.8710 - categorical_accuracy: 0.6083216/216 [==============================] - 0s 2ms/step - loss: 0.8715 - categorical_accuracy: 0.6081 - val_loss: 0.8865 - val_categorical_accuracy: 0.5925
Epoch 9/100
  1/216 [..............................] - ETA: 0s - loss: 0.7936 - categorical_accuracy: 0.6300 37/216 [====>.........................] - ETA: 0s - loss: 0.8214 - categorical_accuracy: 0.6340 72/216 [=========>....................] - ETA: 0s - loss: 0.8286 - categorical_accuracy: 0.6307108/216 [==============>...............] - ETA: 0s - loss: 0.8352 - categorical_accuracy: 0.6279142/216 [==================>...........] - ETA: 0s - loss: 0.8396 - categorical_accuracy: 0.6259177/216 [=======================>......] - ETA: 0s - loss: 0.8431 - categorical_accuracy: 0.6242212/216 [============================>.] - ETA: 0s - loss: 0.8457 - categorical_accuracy: 0.6226216/216 [==============================] - 0s 2ms/step - loss: 0.8460 - categorical_accuracy: 0.6224 - val_loss: 0.8585 - val_categorical_accuracy: 0.6179
Epoch 10/100
  1/216 [..............................] - ETA: 0s - loss: 0.8030 - categorical_accuracy: 0.6200 36/216 [====>.........................] - ETA: 0s - loss: 0.8449 - categorical_accuracy: 0.6179 71/216 [========>.....................] - ETA: 0s - loss: 0.8494 - categorical_accuracy: 0.6158106/216 [=============>................] - ETA: 0s - loss: 0.8485 - categorical_accuracy: 0.6174142/216 [==================>...........] - ETA: 0s - loss: 0.8481 - categorical_accuracy: 0.6180177/216 [=======================>......] - ETA: 0s - loss: 0.8478 - categorical_accuracy: 0.6188213/216 [============================>.] - ETA: 0s - loss: 0.8483 - categorical_accuracy: 0.6189216/216 [==============================] - 0s 2ms/step - loss: 0.8484 - categorical_accuracy: 0.6189 - val_loss: 0.8544 - val_categorical_accuracy: 0.6150
Epoch 11/100
  1/216 [..............................] - ETA: 0s - loss: 0.7870 - categorical_accuracy: 0.6100 36/216 [====>.........................] - ETA: 0s - loss: 0.8241 - categorical_accuracy: 0.6125 69/216 [========>.....................] - ETA: 0s - loss: 0.8293 - categorical_accuracy: 0.6143104/216 [=============>................] - ETA: 0s - loss: 0.8325 - categorical_accuracy: 0.6143139/216 [==================>...........] - ETA: 0s - loss: 0.8347 - categorical_accuracy: 0.6141174/216 [=======================>......] - ETA: 0s - loss: 0.8366 - categorical_accuracy: 0.6140209/216 [============================>.] - ETA: 0s - loss: 0.8376 - categorical_accuracy: 0.6143216/216 [==============================] - 0s 2ms/step - loss: 0.8379 - categorical_accuracy: 0.6144 - val_loss: 0.8929 - val_categorical_accuracy: 0.5962
Epoch 12/100
  1/216 [..............................] - ETA: 0s - loss: 0.7589 - categorical_accuracy: 0.6900 36/216 [====>.........................] - ETA: 0s - loss: 0.7853 - categorical_accuracy: 0.6506 71/216 [========>.....................] - ETA: 0s - loss: 0.8006 - categorical_accuracy: 0.6394104/216 [=============>................] - ETA: 0s - loss: 0.8077 - categorical_accuracy: 0.6346140/216 [==================>...........] - ETA: 0s - loss: 0.8122 - categorical_accuracy: 0.6323174/216 [=======================>......] - ETA: 0s - loss: 0.8147 - categorical_accuracy: 0.6313209/216 [============================>.] - ETA: 0s - loss: 0.8168 - categorical_accuracy: 0.6305216/216 [==============================] - 0s 2ms/step - loss: 0.8172 - categorical_accuracy: 0.6303 - val_loss: 0.8790 - val_categorical_accuracy: 0.5938
Epoch 13/100
  1/216 [..............................] - ETA: 0s - loss: 0.7067 - categorical_accuracy: 0.7200 36/216 [====>.........................] - ETA: 0s - loss: 0.7812 - categorical_accuracy: 0.6495 71/216 [========>.....................] - ETA: 0s - loss: 0.7905 - categorical_accuracy: 0.6445105/216 [=============>................] - ETA: 0s - loss: 0.7949 - categorical_accuracy: 0.6432139/216 [==================>...........] - ETA: 0s - loss: 0.7984 - categorical_accuracy: 0.6417173/216 [=======================>......] - ETA: 0s - loss: 0.8011 - categorical_accuracy: 0.6410208/216 [===========================>..] - ETA: 0s - loss: 0.8030 - categorical_accuracy: 0.6404216/216 [==============================] - 0s 2ms/step - loss: 0.8035 - categorical_accuracy: 0.6402 - val_loss: 0.8416 - val_categorical_accuracy: 0.6200
Epoch 14/100
  1/216 [..............................] - ETA: 0s - loss: 0.7852 - categorical_accuracy: 0.6600 36/216 [====>.........................] - ETA: 0s - loss: 0.7986 - categorical_accuracy: 0.6486 72/216 [=========>....................] - ETA: 0s - loss: 0.8034 - categorical_accuracy: 0.6402107/216 [=============>................] - ETA: 0s - loss: 0.8035 - categorical_accuracy: 0.6385142/216 [==================>...........] - ETA: 0s - loss: 0.8042 - categorical_accuracy: 0.6380176/216 [=======================>......] - ETA: 0s - loss: 0.8045 - categorical_accuracy: 0.6378211/216 [============================>.] - ETA: 0s - loss: 0.8049 - categorical_accuracy: 0.6375216/216 [==============================] - 0s 2ms/step - loss: 0.8049 - categorical_accuracy: 0.6374 - val_loss: 0.8333 - val_categorical_accuracy: 0.6208
Epoch 15/100
  1/216 [..............................] - ETA: 0s - loss: 0.8040 - categorical_accuracy: 0.5900 36/216 [====>.........................] - ETA: 0s - loss: 0.7939 - categorical_accuracy: 0.6296 72/216 [=========>....................] - ETA: 0s - loss: 0.7992 - categorical_accuracy: 0.6323107/216 [=============>................] - ETA: 0s - loss: 0.8007 - categorical_accuracy: 0.6344141/216 [==================>...........] - ETA: 0s - loss: 0.8001 - categorical_accuracy: 0.6362177/216 [=======================>......] - ETA: 0s - loss: 0.7988 - categorical_accuracy: 0.6377210/216 [============================>.] - ETA: 0s - loss: 0.7984 - categorical_accuracy: 0.6386216/216 [==============================] - 0s 2ms/step - loss: 0.7984 - categorical_accuracy: 0.6386 - val_loss: 0.8434 - val_categorical_accuracy: 0.6096
Epoch 16/100
  1/216 [..............................] - ETA: 0s - loss: 0.7449 - categorical_accuracy: 0.6700 37/216 [====>.........................] - ETA: 0s - loss: 0.7933 - categorical_accuracy: 0.6492 71/216 [========>.....................] - ETA: 0s - loss: 0.7871 - categorical_accuracy: 0.6488106/216 [=============>................] - ETA: 0s - loss: 0.7843 - categorical_accuracy: 0.6491141/216 [==================>...........] - ETA: 0s - loss: 0.7841 - categorical_accuracy: 0.6488176/216 [=======================>......] - ETA: 0s - loss: 0.7844 - categorical_accuracy: 0.6485210/216 [============================>.] - ETA: 0s - loss: 0.7846 - categorical_accuracy: 0.6481216/216 [==============================] - 0s 2ms/step - loss: 0.7847 - categorical_accuracy: 0.6480 - val_loss: 0.8664 - val_categorical_accuracy: 0.6096
Epoch 17/100
  1/216 [..............................] - ETA: 0s - loss: 0.6987 - categorical_accuracy: 0.7300 36/216 [====>.........................] - ETA: 0s - loss: 0.7635 - categorical_accuracy: 0.6526 71/216 [========>.....................] - ETA: 0s - loss: 0.7687 - categorical_accuracy: 0.6497105/216 [=============>................] - ETA: 0s - loss: 0.7698 - categorical_accuracy: 0.6494140/216 [==================>...........] - ETA: 0s - loss: 0.7710 - categorical_accuracy: 0.6494175/216 [=======================>......] - ETA: 0s - loss: 0.7726 - categorical_accuracy: 0.6489210/216 [============================>.] - ETA: 0s - loss: 0.7738 - categorical_accuracy: 0.6485216/216 [==============================] - 0s 2ms/step - loss: 0.7740 - categorical_accuracy: 0.6484 - val_loss: 0.8544 - val_categorical_accuracy: 0.6158
Epoch 18/100
  1/216 [..............................] - ETA: 0s - loss: 0.6919 - categorical_accuracy: 0.7000 36/216 [====>.........................] - ETA: 0s - loss: 0.7762 - categorical_accuracy: 0.6562 70/216 [========>.....................] - ETA: 0s - loss: 0.7775 - categorical_accuracy: 0.6536106/216 [=============>................] - ETA: 0s - loss: 0.7769 - categorical_accuracy: 0.6538140/216 [==================>...........] - ETA: 0s - loss: 0.7753 - categorical_accuracy: 0.6543174/216 [=======================>......] - ETA: 0s - loss: 0.7738 - categorical_accuracy: 0.6555209/216 [============================>.] - ETA: 0s - loss: 0.7732 - categorical_accuracy: 0.6559216/216 [==============================] - 0s 2ms/step - loss: 0.7730 - categorical_accuracy: 0.6560 - val_loss: 0.8238 - val_categorical_accuracy: 0.6225
Epoch 19/100
  1/216 [..............................] - ETA: 0s - loss: 0.7034 - categorical_accuracy: 0.6700 36/216 [====>.........................] - ETA: 0s - loss: 0.7323 - categorical_accuracy: 0.6782 72/216 [=========>....................] - ETA: 0s - loss: 0.7409 - categorical_accuracy: 0.6731107/216 [=============>................] - ETA: 0s - loss: 0.7438 - categorical_accuracy: 0.6704143/216 [==================>...........] - ETA: 0s - loss: 0.7472 - categorical_accuracy: 0.6677178/216 [=======================>......] - ETA: 0s - loss: 0.7502 - categorical_accuracy: 0.6655214/216 [============================>.] - ETA: 0s - loss: 0.7520 - categorical_accuracy: 0.6643216/216 [==============================] - 0s 2ms/step - loss: 0.7522 - categorical_accuracy: 0.6642 - val_loss: 0.8802 - val_categorical_accuracy: 0.5996
Epoch 20/100
  1/216 [..............................] - ETA: 0s - loss: 0.8287 - categorical_accuracy: 0.6000 36/216 [====>.........................] - ETA: 0s - loss: 0.7760 - categorical_accuracy: 0.6452 71/216 [========>.....................] - ETA: 0s - loss: 0.7741 - categorical_accuracy: 0.6474106/216 [=============>................] - ETA: 0s - loss: 0.7719 - categorical_accuracy: 0.6498140/216 [==================>...........] - ETA: 0s - loss: 0.7695 - categorical_accuracy: 0.6513176/216 [=======================>......] - ETA: 0s - loss: 0.7676 - categorical_accuracy: 0.6523210/216 [============================>.] - ETA: 0s - loss: 0.7668 - categorical_accuracy: 0.6528216/216 [==============================] - 0s 2ms/step - loss: 0.7668 - categorical_accuracy: 0.6529 - val_loss: 0.8856 - val_categorical_accuracy: 0.5933
Epoch 21/100
  1/216 [..............................] - ETA: 0s - loss: 0.7443 - categorical_accuracy: 0.7300 34/216 [===>..........................] - ETA: 0s - loss: 0.7350 - categorical_accuracy: 0.6759 69/216 [========>.....................] - ETA: 0s - loss: 0.7465 - categorical_accuracy: 0.6652104/216 [=============>................] - ETA: 0s - loss: 0.7512 - categorical_accuracy: 0.6620139/216 [==================>...........] - ETA: 0s - loss: 0.7520 - categorical_accuracy: 0.6618174/216 [=======================>......] - ETA: 0s - loss: 0.7521 - categorical_accuracy: 0.6620209/216 [============================>.] - ETA: 0s - loss: 0.7519 - categorical_accuracy: 0.6622216/216 [==============================] - 0s 2ms/step - loss: 0.7518 - categorical_accuracy: 0.6623 - val_loss: 0.8573 - val_categorical_accuracy: 0.6033
Epoch 22/100
  1/216 [..............................] - ETA: 0s - loss: 0.8211 - categorical_accuracy: 0.6800 37/216 [====>.........................] - ETA: 0s - loss: 0.7590 - categorical_accuracy: 0.6683 72/216 [=========>....................] - ETA: 0s - loss: 0.7535 - categorical_accuracy: 0.6641107/216 [=============>................] - ETA: 0s - loss: 0.7526 - categorical_accuracy: 0.6627141/216 [==================>...........] - ETA: 0s - loss: 0.7515 - categorical_accuracy: 0.6626176/216 [=======================>......] - ETA: 0s - loss: 0.7512 - categorical_accuracy: 0.6623211/216 [============================>.] - ETA: 0s - loss: 0.7507 - categorical_accuracy: 0.6620216/216 [==============================] - 0s 2ms/step - loss: 0.7507 - categorical_accuracy: 0.6620 - val_loss: 0.8462 - val_categorical_accuracy: 0.6179
Epoch 23/100
  1/216 [..............................] - ETA: 0s - loss: 0.6695 - categorical_accuracy: 0.7300 36/216 [====>.........................] - ETA: 0s - loss: 0.7131 - categorical_accuracy: 0.6833 71/216 [========>.....................] - ETA: 0s - loss: 0.7206 - categorical_accuracy: 0.6776106/216 [=============>................] - ETA: 0s - loss: 0.7220 - categorical_accuracy: 0.6765141/216 [==================>...........] - ETA: 0s - loss: 0.7243 - categorical_accuracy: 0.6749176/216 [=======================>......] - ETA: 0s - loss: 0.7259 - categorical_accuracy: 0.6740211/216 [============================>.] - ETA: 0s - loss: 0.7270 - categorical_accuracy: 0.6736216/216 [==============================] - 0s 2ms/step - loss: 0.7272 - categorical_accuracy: 0.6735 - val_loss: 0.8309 - val_categorical_accuracy: 0.6208
Epoch 24/100
  1/216 [..............................] - ETA: 0s - loss: 0.7425 - categorical_accuracy: 0.6500 36/216 [====>.........................] - ETA: 0s - loss: 0.7088 - categorical_accuracy: 0.6736 71/216 [========>.....................] - ETA: 0s - loss: 0.7169 - categorical_accuracy: 0.6725106/216 [=============>................] - ETA: 0s - loss: 0.7215 - categorical_accuracy: 0.6723141/216 [==================>...........] - ETA: 0s - loss: 0.7251 - categorical_accuracy: 0.6715175/216 [=======================>......] - ETA: 0s - loss: 0.7267 - categorical_accuracy: 0.6712210/216 [============================>.] - ETA: 0s - loss: 0.7279 - categorical_accuracy: 0.6709216/216 [==============================] - 0s 2ms/step - loss: 0.7281 - categorical_accuracy: 0.6709 - val_loss: 0.8737 - val_categorical_accuracy: 0.6050
Epoch 25/100
  1/216 [..............................] - ETA: 0s - loss: 0.7075 - categorical_accuracy: 0.6900 37/216 [====>.........................] - ETA: 0s - loss: 0.7255 - categorical_accuracy: 0.6815 71/216 [========>.....................] - ETA: 0s - loss: 0.7229 - categorical_accuracy: 0.6798106/216 [=============>................] - ETA: 0s - loss: 0.7224 - categorical_accuracy: 0.6791140/216 [==================>...........] - ETA: 0s - loss: 0.7217 - categorical_accuracy: 0.6791175/216 [=======================>......] - ETA: 0s - loss: 0.7214 - categorical_accuracy: 0.6790210/216 [============================>.] - ETA: 0s - loss: 0.7218 - categorical_accuracy: 0.6785216/216 [==============================] - 0s 2ms/step - loss: 0.7220 - categorical_accuracy: 0.6783 - val_loss: 0.8413 - val_categorical_accuracy: 0.6192
Epoch 00025: early stopping
Experiment:  85  Set:  ss2 Train Labels:  nnar5 Test Labels:  clean
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.86      0.75      0.80      1240
           1       0.63      0.67      0.65      1218
           2       0.58      0.46      0.51      1184
           3       0.48      0.48      0.48      1175
           4       0.62      0.78      0.69      1183

    accuracy                           0.63      6000
   macro avg       0.63      0.63      0.63      6000
weighted avg       0.63      0.63      0.63      6000

Confusion Matrix for this model: 
 [[930 306   4   0   0]
 [144 817 230  22   5]
 [  2 149 547 385 101]
 [  0  15 131 565 464]
 [ 10  19  34 199 921]]
Experiment:  86  Set:  ss2 Train Labels:  nnar5 Test Labels:  ncar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.72      0.76      1203
           1       0.59      0.64      0.61      1215
           2       0.56      0.44      0.50      1206
           3       0.47      0.46      0.46      1190
           4       0.59      0.74      0.66      1186

    accuracy                           0.60      6000
   macro avg       0.60      0.60      0.60      6000
weighted avg       0.60      0.60      0.60      6000

Confusion Matrix for this model: 
 [[869 297  12  12  13]
 [149 772 223  38  33]
 [ 18 167 533 376 112]
 [ 20  36 134 547 453]
 [ 30  34  44 198 880]]
Experiment:  87  Set:  ss2 Train Labels:  nnar5 Test Labels:  ncar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.76      0.69      0.72      1206
           1       0.58      0.61      0.59      1250
           2       0.53      0.42      0.47      1210
           3       0.45      0.45      0.45      1172
           4       0.55      0.70      0.62      1162

    accuracy                           0.57      6000
   macro avg       0.57      0.57      0.57      6000
weighted avg       0.58      0.57      0.57      6000

Confusion Matrix for this model: 
 [[830 287  27  20  42]
 [159 757 227  53  54]
 [ 30 174 503 364 139]
 [ 35  38 134 526 439]
 [ 32  50  55 208 817]]
Experiment:  88  Set:  ss2 Train Labels:  nnar5 Test Labels:  nar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.62      0.74      0.68       908
           1       0.63      0.67      0.65      1218
           2       0.58      0.46      0.51      1184
           3       0.48      0.37      0.42      1507
           4       0.62      0.78      0.69      1183

    accuracy                           0.59      6000
   macro avg       0.59      0.61      0.59      6000
weighted avg       0.58      0.59      0.58      6000

Confusion Matrix for this model: 
 [[675 229   4   0   0]
 [144 817 230  22   5]
 [  2 149 547 385 101]
 [255  92 131 565 464]
 [ 10  19  34 199 921]]
Experiment:  89  Set:  ss2 Train Labels:  nnar5 Test Labels:  nar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.44      0.76      0.56       623
           1       0.63      0.67      0.65      1218
           2       0.58      0.46      0.51      1184
           3       0.48      0.32      0.38      1792
           4       0.62      0.78      0.69      1183

    accuracy                           0.55      6000
   macro avg       0.55      0.60      0.56      6000
weighted avg       0.55      0.55      0.54      6000

Confusion Matrix for this model: 
 [[475 146   2   0   0]
 [144 817 230  22   5]
 [  2 149 547 385 101]
 [455 175 133 565 464]
 [ 10  19  34 199 921]]
Experiment:  90  Set:  ss2 Train Labels:  nnar5 Test Labels:  nnar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.77      0.78      1120
           1       0.66      0.65      0.66      1327
           2       0.58      0.46      0.51      1184
           3       0.48      0.48      0.48      1178
           4       0.62      0.77      0.69      1191

    accuracy                           0.63      6000
   macro avg       0.63      0.63      0.62      6000
weighted avg       0.63      0.63      0.62      6000

Confusion Matrix for this model: 
 [[862 255   3   0   0]
 [203 866 231  22   5]
 [  2 149 547 385 101]
 [  1  17 131 565 464]
 [ 18  19  34 199 921]]
Experiment:  91  Set:  ss2 Train Labels:  nnar5 Test Labels:  nnar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.77      0.78      1111
           1       0.66      0.65      0.66      1332
           2       0.58      0.46      0.51      1184
           3       0.48      0.48      0.48      1178
           4       0.62      0.77      0.69      1195

    accuracy                           0.63      6000
   macro avg       0.63      0.63      0.62      6000
weighted avg       0.63      0.63      0.62      6000

Confusion Matrix for this model: 
 [[856 252   3   0   0]
 [206 868 231  22   5]
 [  2 149 547 385 101]
 [  1  17 131 565 464]
 [ 21  20  34 199 921]]
Input Shape:  (24000, 1, 150)
Model: "sequential_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_13 (LSTM)               (None, 32)                23424     
_________________________________________________________________
dropout_13 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_52 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_53 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_54 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_55 (Dense)             (None, 5)                 325       
=================================================================
Total params: 52,741
Trainable params: 52,741
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
  1/216 [..............................] - ETA: 4:42 - loss: 1.6054 - categorical_accuracy: 0.1700 24/216 [==>...........................] - ETA: 0s - loss: 1.5815 - categorical_accuracy: 0.2613   47/216 [=====>........................] - ETA: 0s - loss: 1.5528 - categorical_accuracy: 0.2724 70/216 [========>.....................] - ETA: 0s - loss: 1.5227 - categorical_accuracy: 0.2891 91/216 [===========>..................] - ETA: 0s - loss: 1.4951 - categorical_accuracy: 0.3033111/216 [==============>...............] - ETA: 0s - loss: 1.4708 - categorical_accuracy: 0.3152131/216 [=================>............] - ETA: 0s - loss: 1.4490 - categorical_accuracy: 0.3264153/216 [====================>.........] - ETA: 0s - loss: 1.4277 - categorical_accuracy: 0.3375172/216 [======================>.......] - ETA: 0s - loss: 1.4115 - categorical_accuracy: 0.3460193/216 [=========================>....] - ETA: 0s - loss: 1.3956 - categorical_accuracy: 0.3543216/216 [==============================] - 2s 4ms/step - loss: 1.3794 - categorical_accuracy: 0.3629 - val_loss: 1.0459 - val_categorical_accuracy: 0.5446
Epoch 2/100
  1/216 [..............................] - ETA: 0s - loss: 1.0118 - categorical_accuracy: 0.6200 33/216 [===>..........................] - ETA: 0s - loss: 1.0889 - categorical_accuracy: 0.5355 64/216 [=======>......................] - ETA: 0s - loss: 1.0907 - categorical_accuracy: 0.5276 96/216 [============>.................] - ETA: 0s - loss: 1.0894 - categorical_accuracy: 0.5246130/216 [=================>............] - ETA: 0s - loss: 1.0862 - categorical_accuracy: 0.5241161/216 [=====================>........] - ETA: 0s - loss: 1.0838 - categorical_accuracy: 0.5244196/216 [==========================>...] - ETA: 0s - loss: 1.0810 - categorical_accuracy: 0.5249216/216 [==============================] - 0s 2ms/step - loss: 1.0793 - categorical_accuracy: 0.5253 - val_loss: 0.9962 - val_categorical_accuracy: 0.5629
Epoch 3/100
  1/216 [..............................] - ETA: 0s - loss: 1.0519 - categorical_accuracy: 0.5200 37/216 [====>.........................] - ETA: 0s - loss: 1.0150 - categorical_accuracy: 0.5565 71/216 [========>.....................] - ETA: 0s - loss: 1.0169 - categorical_accuracy: 0.5546105/216 [=============>................] - ETA: 0s - loss: 1.0154 - categorical_accuracy: 0.5546138/216 [==================>...........] - ETA: 0s - loss: 1.0135 - categorical_accuracy: 0.5554172/216 [======================>.......] - ETA: 0s - loss: 1.0124 - categorical_accuracy: 0.5558206/216 [===========================>..] - ETA: 0s - loss: 1.0119 - categorical_accuracy: 0.5559216/216 [==============================] - 0s 2ms/step - loss: 1.0118 - categorical_accuracy: 0.5559 - val_loss: 0.9515 - val_categorical_accuracy: 0.5800
Epoch 4/100
  1/216 [..............................] - ETA: 0s - loss: 0.8461 - categorical_accuracy: 0.6400 36/216 [====>.........................] - ETA: 0s - loss: 0.9538 - categorical_accuracy: 0.5825 68/216 [========>.....................] - ETA: 0s - loss: 0.9618 - categorical_accuracy: 0.5769103/216 [=============>................] - ETA: 0s - loss: 0.9619 - categorical_accuracy: 0.5776138/216 [==================>...........] - ETA: 0s - loss: 0.9622 - categorical_accuracy: 0.5776173/216 [=======================>......] - ETA: 0s - loss: 0.9622 - categorical_accuracy: 0.5777208/216 [===========================>..] - ETA: 0s - loss: 0.9620 - categorical_accuracy: 0.5777216/216 [==============================] - 0s 2ms/step - loss: 0.9620 - categorical_accuracy: 0.5778 - val_loss: 0.9121 - val_categorical_accuracy: 0.6025
Epoch 5/100
  1/216 [..............................] - ETA: 0s - loss: 0.9348 - categorical_accuracy: 0.6700 32/216 [===>..........................] - ETA: 0s - loss: 0.9073 - categorical_accuracy: 0.6159 64/216 [=======>......................] - ETA: 0s - loss: 0.9151 - categorical_accuracy: 0.6063 99/216 [============>.................] - ETA: 0s - loss: 0.9239 - categorical_accuracy: 0.5985130/216 [=================>............] - ETA: 0s - loss: 0.9282 - categorical_accuracy: 0.5949165/216 [=====================>........] - ETA: 0s - loss: 0.9308 - categorical_accuracy: 0.5922200/216 [==========================>...] - ETA: 0s - loss: 0.9316 - categorical_accuracy: 0.5911216/216 [==============================] - 0s 2ms/step - loss: 0.9318 - categorical_accuracy: 0.5907 - val_loss: 0.9028 - val_categorical_accuracy: 0.6033
Epoch 6/100
  1/216 [..............................] - ETA: 0s - loss: 0.8649 - categorical_accuracy: 0.5700 36/216 [====>.........................] - ETA: 0s - loss: 0.9058 - categorical_accuracy: 0.5939 72/216 [=========>....................] - ETA: 0s - loss: 0.9073 - categorical_accuracy: 0.5938107/216 [=============>................] - ETA: 0s - loss: 0.9084 - categorical_accuracy: 0.5931139/216 [==================>...........] - ETA: 0s - loss: 0.9089 - categorical_accuracy: 0.5927172/216 [======================>.......] - ETA: 0s - loss: 0.9095 - categorical_accuracy: 0.5925207/216 [===========================>..] - ETA: 0s - loss: 0.9100 - categorical_accuracy: 0.5924216/216 [==============================] - 0s 2ms/step - loss: 0.9101 - categorical_accuracy: 0.5923 - val_loss: 0.8802 - val_categorical_accuracy: 0.6104
Epoch 7/100
  1/216 [..............................] - ETA: 0s - loss: 0.9100 - categorical_accuracy: 0.6100 37/216 [====>.........................] - ETA: 0s - loss: 0.8964 - categorical_accuracy: 0.6087 72/216 [=========>....................] - ETA: 0s - loss: 0.8859 - categorical_accuracy: 0.6123107/216 [=============>................] - ETA: 0s - loss: 0.8814 - categorical_accuracy: 0.6132142/216 [==================>...........] - ETA: 0s - loss: 0.8805 - categorical_accuracy: 0.6124178/216 [=======================>......] - ETA: 0s - loss: 0.8807 - categorical_accuracy: 0.6118213/216 [============================>.] - ETA: 0s - loss: 0.8813 - categorical_accuracy: 0.6111216/216 [==============================] - 0s 2ms/step - loss: 0.8814 - categorical_accuracy: 0.6110 - val_loss: 0.8679 - val_categorical_accuracy: 0.6229
Epoch 8/100
  1/216 [..............................] - ETA: 0s - loss: 0.8087 - categorical_accuracy: 0.6100 36/216 [====>.........................] - ETA: 0s - loss: 0.8773 - categorical_accuracy: 0.6068 71/216 [========>.....................] - ETA: 0s - loss: 0.8762 - categorical_accuracy: 0.6075102/216 [=============>................] - ETA: 0s - loss: 0.8748 - categorical_accuracy: 0.6085136/216 [=================>............] - ETA: 0s - loss: 0.8734 - categorical_accuracy: 0.6095170/216 [======================>.......] - ETA: 0s - loss: 0.8722 - categorical_accuracy: 0.6103206/216 [===========================>..] - ETA: 0s - loss: 0.8714 - categorical_accuracy: 0.6108216/216 [==============================] - 0s 2ms/step - loss: 0.8713 - categorical_accuracy: 0.6108 - val_loss: 0.8547 - val_categorical_accuracy: 0.6187
Epoch 9/100
  1/216 [..............................] - ETA: 0s - loss: 0.7327 - categorical_accuracy: 0.6800 36/216 [====>.........................] - ETA: 0s - loss: 0.8369 - categorical_accuracy: 0.6309 70/216 [========>.....................] - ETA: 0s - loss: 0.8408 - categorical_accuracy: 0.6288106/216 [=============>................] - ETA: 0s - loss: 0.8432 - categorical_accuracy: 0.6280141/216 [==================>...........] - ETA: 0s - loss: 0.8442 - categorical_accuracy: 0.6274176/216 [=======================>......] - ETA: 0s - loss: 0.8452 - categorical_accuracy: 0.6267211/216 [============================>.] - ETA: 0s - loss: 0.8461 - categorical_accuracy: 0.6263216/216 [==============================] - 0s 2ms/step - loss: 0.8462 - categorical_accuracy: 0.6262 - val_loss: 0.8501 - val_categorical_accuracy: 0.6167
Epoch 10/100
  1/216 [..............................] - ETA: 0s - loss: 0.8159 - categorical_accuracy: 0.6600 34/216 [===>..........................] - ETA: 0s - loss: 0.8377 - categorical_accuracy: 0.6370 68/216 [========>.....................] - ETA: 0s - loss: 0.8400 - categorical_accuracy: 0.6334103/216 [=============>................] - ETA: 0s - loss: 0.8423 - categorical_accuracy: 0.6305138/216 [==================>...........] - ETA: 0s - loss: 0.8434 - categorical_accuracy: 0.6285173/216 [=======================>......] - ETA: 0s - loss: 0.8441 - categorical_accuracy: 0.6274207/216 [===========================>..] - ETA: 0s - loss: 0.8443 - categorical_accuracy: 0.6269216/216 [==============================] - 0s 2ms/step - loss: 0.8442 - categorical_accuracy: 0.6269 - val_loss: 0.8572 - val_categorical_accuracy: 0.6137
Epoch 11/100
  1/216 [..............................] - ETA: 0s - loss: 0.8674 - categorical_accuracy: 0.6100 37/216 [====>.........................] - ETA: 0s - loss: 0.8259 - categorical_accuracy: 0.6307 71/216 [========>.....................] - ETA: 0s - loss: 0.8233 - categorical_accuracy: 0.6327106/216 [=============>................] - ETA: 0s - loss: 0.8221 - categorical_accuracy: 0.6331141/216 [==================>...........] - ETA: 0s - loss: 0.8221 - categorical_accuracy: 0.6334176/216 [=======================>......] - ETA: 0s - loss: 0.8230 - categorical_accuracy: 0.6335211/216 [============================>.] - ETA: 0s - loss: 0.8231 - categorical_accuracy: 0.6339216/216 [==============================] - 0s 2ms/step - loss: 0.8231 - categorical_accuracy: 0.6339 - val_loss: 0.8371 - val_categorical_accuracy: 0.6329
Epoch 12/100
  1/216 [..............................] - ETA: 0s - loss: 0.7856 - categorical_accuracy: 0.6000 37/216 [====>.........................] - ETA: 0s - loss: 0.7809 - categorical_accuracy: 0.6429 72/216 [=========>....................] - ETA: 0s - loss: 0.7907 - categorical_accuracy: 0.6429107/216 [=============>................] - ETA: 0s - loss: 0.7961 - categorical_accuracy: 0.6425142/216 [==================>...........] - ETA: 0s - loss: 0.8000 - categorical_accuracy: 0.6421176/216 [=======================>......] - ETA: 0s - loss: 0.8029 - categorical_accuracy: 0.6414211/216 [============================>.] - ETA: 0s - loss: 0.8050 - categorical_accuracy: 0.6407216/216 [==============================] - 0s 2ms/step - loss: 0.8053 - categorical_accuracy: 0.6405 - val_loss: 0.8430 - val_categorical_accuracy: 0.6237
Epoch 13/100
  1/216 [..............................] - ETA: 0s - loss: 0.7128 - categorical_accuracy: 0.7200 36/216 [====>.........................] - ETA: 0s - loss: 0.7885 - categorical_accuracy: 0.6554 71/216 [========>.....................] - ETA: 0s - loss: 0.7944 - categorical_accuracy: 0.6504104/216 [=============>................] - ETA: 0s - loss: 0.7968 - categorical_accuracy: 0.6491139/216 [==================>...........] - ETA: 0s - loss: 0.7980 - categorical_accuracy: 0.6483173/216 [=======================>......] - ETA: 0s - loss: 0.7987 - categorical_accuracy: 0.6477209/216 [============================>.] - ETA: 0s - loss: 0.7995 - categorical_accuracy: 0.6468216/216 [==============================] - 0s 2ms/step - loss: 0.7997 - categorical_accuracy: 0.6467 - val_loss: 0.8307 - val_categorical_accuracy: 0.6371
Epoch 14/100
  1/216 [..............................] - ETA: 0s - loss: 0.7841 - categorical_accuracy: 0.6400 36/216 [====>.........................] - ETA: 0s - loss: 0.7577 - categorical_accuracy: 0.6670 70/216 [========>.....................] - ETA: 0s - loss: 0.7638 - categorical_accuracy: 0.6652105/216 [=============>................] - ETA: 0s - loss: 0.7720 - categorical_accuracy: 0.6608139/216 [==================>...........] - ETA: 0s - loss: 0.7766 - categorical_accuracy: 0.6585175/216 [=======================>......] - ETA: 0s - loss: 0.7803 - categorical_accuracy: 0.6568208/216 [===========================>..] - ETA: 0s - loss: 0.7826 - categorical_accuracy: 0.6556216/216 [==============================] - 0s 2ms/step - loss: 0.7832 - categorical_accuracy: 0.6553 - val_loss: 0.8362 - val_categorical_accuracy: 0.6358
Epoch 15/100
  1/216 [..............................] - ETA: 0s - loss: 0.6917 - categorical_accuracy: 0.7600 35/216 [===>..........................] - ETA: 0s - loss: 0.7538 - categorical_accuracy: 0.6816 70/216 [========>.....................] - ETA: 0s - loss: 0.7644 - categorical_accuracy: 0.6703105/216 [=============>................] - ETA: 0s - loss: 0.7698 - categorical_accuracy: 0.6648141/216 [==================>...........] - ETA: 0s - loss: 0.7736 - categorical_accuracy: 0.6616175/216 [=======================>......] - ETA: 0s - loss: 0.7755 - categorical_accuracy: 0.6598210/216 [============================>.] - ETA: 0s - loss: 0.7766 - categorical_accuracy: 0.6588216/216 [==============================] - 0s 2ms/step - loss: 0.7769 - categorical_accuracy: 0.6586 - val_loss: 0.8367 - val_categorical_accuracy: 0.6271
Epoch 16/100
  1/216 [..............................] - ETA: 0s - loss: 0.6883 - categorical_accuracy: 0.7000 36/216 [====>.........................] - ETA: 0s - loss: 0.7778 - categorical_accuracy: 0.6487 71/216 [========>.....................] - ETA: 0s - loss: 0.7750 - categorical_accuracy: 0.6519106/216 [=============>................] - ETA: 0s - loss: 0.7745 - categorical_accuracy: 0.6528141/216 [==================>...........] - ETA: 0s - loss: 0.7738 - categorical_accuracy: 0.6530176/216 [=======================>......] - ETA: 0s - loss: 0.7738 - categorical_accuracy: 0.6532211/216 [============================>.] - ETA: 0s - loss: 0.7741 - categorical_accuracy: 0.6533216/216 [==============================] - 0s 2ms/step - loss: 0.7743 - categorical_accuracy: 0.6533 - val_loss: 0.8403 - val_categorical_accuracy: 0.6346
Epoch 17/100
  1/216 [..............................] - ETA: 0s - loss: 0.6755 - categorical_accuracy: 0.7100 35/216 [===>..........................] - ETA: 0s - loss: 0.7431 - categorical_accuracy: 0.6763 70/216 [========>.....................] - ETA: 0s - loss: 0.7554 - categorical_accuracy: 0.6661105/216 [=============>................] - ETA: 0s - loss: 0.7600 - categorical_accuracy: 0.6624139/216 [==================>...........] - ETA: 0s - loss: 0.7617 - categorical_accuracy: 0.6617173/216 [=======================>......] - ETA: 0s - loss: 0.7629 - categorical_accuracy: 0.6612208/216 [===========================>..] - ETA: 0s - loss: 0.7640 - categorical_accuracy: 0.6606216/216 [==============================] - 0s 2ms/step - loss: 0.7643 - categorical_accuracy: 0.6604 - val_loss: 0.8186 - val_categorical_accuracy: 0.6425
Epoch 18/100
  1/216 [..............................] - ETA: 0s - loss: 0.7151 - categorical_accuracy: 0.6900 36/216 [====>.........................] - ETA: 0s - loss: 0.7364 - categorical_accuracy: 0.6644 71/216 [========>.....................] - ETA: 0s - loss: 0.7385 - categorical_accuracy: 0.6661103/216 [=============>................] - ETA: 0s - loss: 0.7405 - categorical_accuracy: 0.6664136/216 [=================>............] - ETA: 0s - loss: 0.7433 - categorical_accuracy: 0.6659170/216 [======================>.......] - ETA: 0s - loss: 0.7463 - categorical_accuracy: 0.6650200/216 [==========================>...] - ETA: 0s - loss: 0.7484 - categorical_accuracy: 0.6641216/216 [==============================] - 0s 2ms/step - loss: 0.7494 - categorical_accuracy: 0.6638 - val_loss: 0.8417 - val_categorical_accuracy: 0.6350
Epoch 19/100
  1/216 [..............................] - ETA: 0s - loss: 0.7672 - categorical_accuracy: 0.6200 30/216 [===>..........................] - ETA: 0s - loss: 0.7487 - categorical_accuracy: 0.6660 62/216 [=======>......................] - ETA: 0s - loss: 0.7407 - categorical_accuracy: 0.6726 92/216 [===========>..................] - ETA: 0s - loss: 0.7406 - categorical_accuracy: 0.6721123/216 [================>.............] - ETA: 0s - loss: 0.7411 - categorical_accuracy: 0.6713158/216 [====================>.........] - ETA: 0s - loss: 0.7419 - categorical_accuracy: 0.6707193/216 [=========================>....] - ETA: 0s - loss: 0.7434 - categorical_accuracy: 0.6697216/216 [==============================] - 0s 2ms/step - loss: 0.7445 - categorical_accuracy: 0.6690 - val_loss: 0.8265 - val_categorical_accuracy: 0.6375
Epoch 20/100
  1/216 [..............................] - ETA: 0s - loss: 0.6943 - categorical_accuracy: 0.6900 36/216 [====>.........................] - ETA: 0s - loss: 0.7268 - categorical_accuracy: 0.6790 72/216 [=========>....................] - ETA: 0s - loss: 0.7342 - categorical_accuracy: 0.6742106/216 [=============>................] - ETA: 0s - loss: 0.7368 - categorical_accuracy: 0.6731140/216 [==================>...........] - ETA: 0s - loss: 0.7379 - categorical_accuracy: 0.6730173/216 [=======================>......] - ETA: 0s - loss: 0.7390 - categorical_accuracy: 0.6727209/216 [============================>.] - ETA: 0s - loss: 0.7408 - categorical_accuracy: 0.6718216/216 [==============================] - 0s 2ms/step - loss: 0.7412 - categorical_accuracy: 0.6717 - val_loss: 0.8195 - val_categorical_accuracy: 0.6454
Epoch 21/100
  1/216 [..............................] - ETA: 0s - loss: 0.7588 - categorical_accuracy: 0.6400 37/216 [====>.........................] - ETA: 0s - loss: 0.7188 - categorical_accuracy: 0.6856 72/216 [=========>....................] - ETA: 0s - loss: 0.7227 - categorical_accuracy: 0.6846107/216 [=============>................] - ETA: 0s - loss: 0.7264 - categorical_accuracy: 0.6829142/216 [==================>...........] - ETA: 0s - loss: 0.7297 - categorical_accuracy: 0.6805176/216 [=======================>......] - ETA: 0s - loss: 0.7324 - categorical_accuracy: 0.6783209/216 [============================>.] - ETA: 0s - loss: 0.7341 - categorical_accuracy: 0.6770216/216 [==============================] - 0s 2ms/step - loss: 0.7344 - categorical_accuracy: 0.6768 - val_loss: 0.8243 - val_categorical_accuracy: 0.6400
Epoch 22/100
  1/216 [..............................] - ETA: 0s - loss: 0.8001 - categorical_accuracy: 0.6300 36/216 [====>.........................] - ETA: 0s - loss: 0.7504 - categorical_accuracy: 0.6736 71/216 [========>.....................] - ETA: 0s - loss: 0.7423 - categorical_accuracy: 0.6765107/216 [=============>................] - ETA: 0s - loss: 0.7380 - categorical_accuracy: 0.6770142/216 [==================>...........] - ETA: 0s - loss: 0.7369 - categorical_accuracy: 0.6769177/216 [=======================>......] - ETA: 0s - loss: 0.7363 - categorical_accuracy: 0.6768212/216 [============================>.] - ETA: 0s - loss: 0.7363 - categorical_accuracy: 0.6764216/216 [==============================] - 0s 2ms/step - loss: 0.7363 - categorical_accuracy: 0.6763 - val_loss: 0.8217 - val_categorical_accuracy: 0.6504
Epoch 23/100
  1/216 [..............................] - ETA: 0s - loss: 0.7107 - categorical_accuracy: 0.6800 36/216 [====>.........................] - ETA: 0s - loss: 0.7253 - categorical_accuracy: 0.6799 72/216 [=========>....................] - ETA: 0s - loss: 0.7277 - categorical_accuracy: 0.6796107/216 [=============>................] - ETA: 0s - loss: 0.7276 - categorical_accuracy: 0.6798141/216 [==================>...........] - ETA: 0s - loss: 0.7273 - categorical_accuracy: 0.6800175/216 [=======================>......] - ETA: 0s - loss: 0.7268 - categorical_accuracy: 0.6802210/216 [============================>.] - ETA: 0s - loss: 0.7263 - categorical_accuracy: 0.6801216/216 [==============================] - 0s 2ms/step - loss: 0.7263 - categorical_accuracy: 0.6801 - val_loss: 0.8151 - val_categorical_accuracy: 0.6496
Epoch 24/100
  1/216 [..............................] - ETA: 0s - loss: 0.6344 - categorical_accuracy: 0.7000 37/216 [====>.........................] - ETA: 0s - loss: 0.7086 - categorical_accuracy: 0.6894 72/216 [=========>....................] - ETA: 0s - loss: 0.7128 - categorical_accuracy: 0.6884108/216 [==============>...............] - ETA: 0s - loss: 0.7153 - categorical_accuracy: 0.6871143/216 [==================>...........] - ETA: 0s - loss: 0.7168 - categorical_accuracy: 0.6861178/216 [=======================>......] - ETA: 0s - loss: 0.7176 - categorical_accuracy: 0.6851213/216 [============================>.] - ETA: 0s - loss: 0.7186 - categorical_accuracy: 0.6842216/216 [==============================] - 0s 2ms/step - loss: 0.7187 - categorical_accuracy: 0.6841 - val_loss: 0.8257 - val_categorical_accuracy: 0.6492
Epoch 25/100
  1/216 [..............................] - ETA: 0s - loss: 0.7672 - categorical_accuracy: 0.6400 36/216 [====>.........................] - ETA: 0s - loss: 0.7007 - categorical_accuracy: 0.6895 72/216 [=========>....................] - ETA: 0s - loss: 0.7048 - categorical_accuracy: 0.6862108/216 [==============>...............] - ETA: 0s - loss: 0.7071 - categorical_accuracy: 0.6843144/216 [===================>..........] - ETA: 0s - loss: 0.7086 - categorical_accuracy: 0.6834178/216 [=======================>......] - ETA: 0s - loss: 0.7095 - categorical_accuracy: 0.6832212/216 [============================>.] - ETA: 0s - loss: 0.7099 - categorical_accuracy: 0.6834216/216 [==============================] - 0s 2ms/step - loss: 0.7100 - categorical_accuracy: 0.6834 - val_loss: 0.8197 - val_categorical_accuracy: 0.6479
Epoch 26/100
  1/216 [..............................] - ETA: 0s - loss: 0.7838 - categorical_accuracy: 0.7200 36/216 [====>.........................] - ETA: 0s - loss: 0.7153 - categorical_accuracy: 0.6903 69/216 [========>.....................] - ETA: 0s - loss: 0.7087 - categorical_accuracy: 0.6909104/216 [=============>................] - ETA: 0s - loss: 0.7087 - categorical_accuracy: 0.6897137/216 [==================>...........] - ETA: 0s - loss: 0.7091 - categorical_accuracy: 0.6888172/216 [======================>.......] - ETA: 0s - loss: 0.7094 - categorical_accuracy: 0.6884206/216 [===========================>..] - ETA: 0s - loss: 0.7099 - categorical_accuracy: 0.6878216/216 [==============================] - 0s 2ms/step - loss: 0.7100 - categorical_accuracy: 0.6876 - val_loss: 0.8184 - val_categorical_accuracy: 0.6496
Epoch 27/100
  1/216 [..............................] - ETA: 0s - loss: 0.7417 - categorical_accuracy: 0.6500 36/216 [====>.........................] - ETA: 0s - loss: 0.6859 - categorical_accuracy: 0.6914 71/216 [========>.....................] - ETA: 0s - loss: 0.6875 - categorical_accuracy: 0.6932107/216 [=============>................] - ETA: 0s - loss: 0.6912 - categorical_accuracy: 0.6922142/216 [==================>...........] - ETA: 0s - loss: 0.6926 - categorical_accuracy: 0.6918177/216 [=======================>......] - ETA: 0s - loss: 0.6943 - categorical_accuracy: 0.6910212/216 [============================>.] - ETA: 0s - loss: 0.6960 - categorical_accuracy: 0.6900216/216 [==============================] - 0s 2ms/step - loss: 0.6963 - categorical_accuracy: 0.6899 - val_loss: 0.8073 - val_categorical_accuracy: 0.6521
Epoch 28/100
  1/216 [..............................] - ETA: 0s - loss: 0.7091 - categorical_accuracy: 0.7000 36/216 [====>.........................] - ETA: 0s - loss: 0.6573 - categorical_accuracy: 0.7139 71/216 [========>.....................] - ETA: 0s - loss: 0.6727 - categorical_accuracy: 0.7054106/216 [=============>................] - ETA: 0s - loss: 0.6777 - categorical_accuracy: 0.7021140/216 [==================>...........] - ETA: 0s - loss: 0.6814 - categorical_accuracy: 0.6995175/216 [=======================>......] - ETA: 0s - loss: 0.6842 - categorical_accuracy: 0.6976209/216 [============================>.] - ETA: 0s - loss: 0.6865 - categorical_accuracy: 0.6964216/216 [==============================] - 0s 2ms/step - loss: 0.6870 - categorical_accuracy: 0.6961 - val_loss: 0.8138 - val_categorical_accuracy: 0.6475
Epoch 29/100
  1/216 [..............................] - ETA: 0s - loss: 0.6861 - categorical_accuracy: 0.7000 36/216 [====>.........................] - ETA: 0s - loss: 0.6874 - categorical_accuracy: 0.7092 70/216 [========>.....................] - ETA: 0s - loss: 0.6858 - categorical_accuracy: 0.7043104/216 [=============>................] - ETA: 0s - loss: 0.6854 - categorical_accuracy: 0.7014139/216 [==================>...........] - ETA: 0s - loss: 0.6864 - categorical_accuracy: 0.6992175/216 [=======================>......] - ETA: 0s - loss: 0.6865 - categorical_accuracy: 0.6983210/216 [============================>.] - ETA: 0s - loss: 0.6865 - categorical_accuracy: 0.6977216/216 [==============================] - 0s 2ms/step - loss: 0.6866 - categorical_accuracy: 0.6975 - val_loss: 0.8281 - val_categorical_accuracy: 0.6367
Epoch 30/100
  1/216 [..............................] - ETA: 0s - loss: 0.7755 - categorical_accuracy: 0.6600 36/216 [====>.........................] - ETA: 0s - loss: 0.6833 - categorical_accuracy: 0.6953 71/216 [========>.....................] - ETA: 0s - loss: 0.6890 - categorical_accuracy: 0.6915105/216 [=============>................] - ETA: 0s - loss: 0.6891 - categorical_accuracy: 0.6921140/216 [==================>...........] - ETA: 0s - loss: 0.6880 - categorical_accuracy: 0.6928175/216 [=======================>......] - ETA: 0s - loss: 0.6876 - categorical_accuracy: 0.6931208/216 [===========================>..] - ETA: 0s - loss: 0.6876 - categorical_accuracy: 0.6931216/216 [==============================] - 0s 2ms/step - loss: 0.6877 - categorical_accuracy: 0.6931 - val_loss: 0.8375 - val_categorical_accuracy: 0.6358
Epoch 31/100
  1/216 [..............................] - ETA: 0s - loss: 0.5832 - categorical_accuracy: 0.7100 32/216 [===>..........................] - ETA: 0s - loss: 0.6542 - categorical_accuracy: 0.7092 64/216 [=======>......................] - ETA: 0s - loss: 0.6679 - categorical_accuracy: 0.7059 97/216 [============>.................] - ETA: 0s - loss: 0.6725 - categorical_accuracy: 0.7037131/216 [=================>............] - ETA: 0s - loss: 0.6743 - categorical_accuracy: 0.7027166/216 [======================>.......] - ETA: 0s - loss: 0.6757 - categorical_accuracy: 0.7019199/216 [==========================>...] - ETA: 0s - loss: 0.6766 - categorical_accuracy: 0.7013216/216 [==============================] - 0s 2ms/step - loss: 0.6771 - categorical_accuracy: 0.7010 - val_loss: 0.8324 - val_categorical_accuracy: 0.6371
Epoch 32/100
  1/216 [..............................] - ETA: 0s - loss: 0.7367 - categorical_accuracy: 0.6700 36/216 [====>.........................] - ETA: 0s - loss: 0.6711 - categorical_accuracy: 0.7044 69/216 [========>.....................] - ETA: 0s - loss: 0.6747 - categorical_accuracy: 0.7020105/216 [=============>................] - ETA: 0s - loss: 0.6760 - categorical_accuracy: 0.7007140/216 [==================>...........] - ETA: 0s - loss: 0.6775 - categorical_accuracy: 0.6999176/216 [=======================>......] - ETA: 0s - loss: 0.6779 - categorical_accuracy: 0.6999211/216 [============================>.] - ETA: 0s - loss: 0.6787 - categorical_accuracy: 0.6996216/216 [==============================] - 0s 2ms/step - loss: 0.6788 - categorical_accuracy: 0.6995 - val_loss: 0.8331 - val_categorical_accuracy: 0.6367
Epoch 33/100
  1/216 [..............................] - ETA: 0s - loss: 0.7375 - categorical_accuracy: 0.6700 37/216 [====>.........................] - ETA: 0s - loss: 0.6789 - categorical_accuracy: 0.6935 72/216 [=========>....................] - ETA: 0s - loss: 0.6750 - categorical_accuracy: 0.6955107/216 [=============>................] - ETA: 0s - loss: 0.6738 - categorical_accuracy: 0.6970142/216 [==================>...........] - ETA: 0s - loss: 0.6750 - categorical_accuracy: 0.6969176/216 [=======================>......] - ETA: 0s - loss: 0.6758 - categorical_accuracy: 0.6968211/216 [============================>.] - ETA: 0s - loss: 0.6763 - categorical_accuracy: 0.6969216/216 [==============================] - 0s 2ms/step - loss: 0.6764 - categorical_accuracy: 0.6969 - val_loss: 0.8062 - val_categorical_accuracy: 0.6558
Epoch 34/100
  1/216 [..............................] - ETA: 0s - loss: 0.7874 - categorical_accuracy: 0.6300 36/216 [====>.........................] - ETA: 0s - loss: 0.6808 - categorical_accuracy: 0.6951 69/216 [========>.....................] - ETA: 0s - loss: 0.6767 - categorical_accuracy: 0.6991104/216 [=============>................] - ETA: 0s - loss: 0.6735 - categorical_accuracy: 0.7013139/216 [==================>...........] - ETA: 0s - loss: 0.6731 - categorical_accuracy: 0.7021174/216 [=======================>......] - ETA: 0s - loss: 0.6731 - categorical_accuracy: 0.7021209/216 [============================>.] - ETA: 0s - loss: 0.6730 - categorical_accuracy: 0.7021216/216 [==============================] - 0s 2ms/step - loss: 0.6730 - categorical_accuracy: 0.7021 - val_loss: 0.8252 - val_categorical_accuracy: 0.6413
Epoch 35/100
  1/216 [..............................] - ETA: 0s - loss: 0.6679 - categorical_accuracy: 0.7200 36/216 [====>.........................] - ETA: 0s - loss: 0.6797 - categorical_accuracy: 0.7010 70/216 [========>.....................] - ETA: 0s - loss: 0.6734 - categorical_accuracy: 0.6999105/216 [=============>................] - ETA: 0s - loss: 0.6714 - categorical_accuracy: 0.7001140/216 [==================>...........] - ETA: 0s - loss: 0.6715 - categorical_accuracy: 0.7001175/216 [=======================>......] - ETA: 0s - loss: 0.6710 - categorical_accuracy: 0.7005210/216 [============================>.] - ETA: 0s - loss: 0.6705 - categorical_accuracy: 0.7008216/216 [==============================] - 0s 2ms/step - loss: 0.6704 - categorical_accuracy: 0.7008 - val_loss: 0.8076 - val_categorical_accuracy: 0.6521
Epoch 36/100
  1/216 [..............................] - ETA: 0s - loss: 0.5263 - categorical_accuracy: 0.7500 36/216 [====>.........................] - ETA: 0s - loss: 0.6159 - categorical_accuracy: 0.7234 72/216 [=========>....................] - ETA: 0s - loss: 0.6330 - categorical_accuracy: 0.7153107/216 [=============>................] - ETA: 0s - loss: 0.6400 - categorical_accuracy: 0.7131142/216 [==================>...........] - ETA: 0s - loss: 0.6438 - categorical_accuracy: 0.7122177/216 [=======================>......] - ETA: 0s - loss: 0.6463 - categorical_accuracy: 0.7113212/216 [============================>.] - ETA: 0s - loss: 0.6487 - categorical_accuracy: 0.7102216/216 [==============================] - 0s 2ms/step - loss: 0.6490 - categorical_accuracy: 0.7100 - val_loss: 0.8167 - val_categorical_accuracy: 0.6500
Epoch 37/100
  1/216 [..............................] - ETA: 0s - loss: 0.7041 - categorical_accuracy: 0.6700 36/216 [====>.........................] - ETA: 0s - loss: 0.6651 - categorical_accuracy: 0.6918 71/216 [========>.....................] - ETA: 0s - loss: 0.6621 - categorical_accuracy: 0.6944106/216 [=============>................] - ETA: 0s - loss: 0.6592 - categorical_accuracy: 0.6973141/216 [==================>...........] - ETA: 0s - loss: 0.6584 - categorical_accuracy: 0.6991175/216 [=======================>......] - ETA: 0s - loss: 0.6581 - categorical_accuracy: 0.7004210/216 [============================>.] - ETA: 0s - loss: 0.6584 - categorical_accuracy: 0.7011216/216 [==============================] - 0s 2ms/step - loss: 0.6585 - categorical_accuracy: 0.7011 - val_loss: 0.8227 - val_categorical_accuracy: 0.6446
Epoch 38/100
  1/216 [..............................] - ETA: 0s - loss: 0.6212 - categorical_accuracy: 0.7000 36/216 [====>.........................] - ETA: 0s - loss: 0.6180 - categorical_accuracy: 0.7250 71/216 [========>.....................] - ETA: 0s - loss: 0.6298 - categorical_accuracy: 0.7192106/216 [=============>................] - ETA: 0s - loss: 0.6352 - categorical_accuracy: 0.7171141/216 [==================>...........] - ETA: 0s - loss: 0.6396 - categorical_accuracy: 0.7152176/216 [=======================>......] - ETA: 0s - loss: 0.6427 - categorical_accuracy: 0.7138211/216 [============================>.] - ETA: 0s - loss: 0.6450 - categorical_accuracy: 0.7125216/216 [==============================] - 0s 2ms/step - loss: 0.6454 - categorical_accuracy: 0.7123 - val_loss: 0.8443 - val_categorical_accuracy: 0.6442
Epoch 39/100
  1/216 [..............................] - ETA: 0s - loss: 0.6455 - categorical_accuracy: 0.6200 37/216 [====>.........................] - ETA: 0s - loss: 0.6117 - categorical_accuracy: 0.7133 72/216 [=========>....................] - ETA: 0s - loss: 0.6244 - categorical_accuracy: 0.7146107/216 [=============>................] - ETA: 0s - loss: 0.6320 - categorical_accuracy: 0.7144142/216 [==================>...........] - ETA: 0s - loss: 0.6375 - categorical_accuracy: 0.7137177/216 [=======================>......] - ETA: 0s - loss: 0.6407 - categorical_accuracy: 0.7130212/216 [============================>.] - ETA: 0s - loss: 0.6432 - categorical_accuracy: 0.7122216/216 [==============================] - 0s 2ms/step - loss: 0.6435 - categorical_accuracy: 0.7121 - val_loss: 0.8141 - val_categorical_accuracy: 0.6467
Epoch 40/100
  1/216 [..............................] - ETA: 0s - loss: 0.6074 - categorical_accuracy: 0.6800 36/216 [====>.........................] - ETA: 0s - loss: 0.6457 - categorical_accuracy: 0.7066 71/216 [========>.....................] - ETA: 0s - loss: 0.6424 - categorical_accuracy: 0.7096106/216 [=============>................] - ETA: 0s - loss: 0.6409 - categorical_accuracy: 0.7115141/216 [==================>...........] - ETA: 0s - loss: 0.6416 - categorical_accuracy: 0.7119176/216 [=======================>......] - ETA: 0s - loss: 0.6427 - categorical_accuracy: 0.7115211/216 [============================>.] - ETA: 0s - loss: 0.6436 - categorical_accuracy: 0.7113216/216 [==============================] - 0s 2ms/step - loss: 0.6438 - categorical_accuracy: 0.7112 - val_loss: 0.8446 - val_categorical_accuracy: 0.6408
Epoch 00040: early stopping
Experiment:  92  Set:  ss2 Train Labels:  nnar10 Test Labels:  clean
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.86      0.75      0.80      1240
           1       0.62      0.71      0.66      1218
           2       0.57      0.22      0.32      1184
           3       0.42      0.61      0.50      1175
           4       0.64      0.74      0.69      1183

    accuracy                           0.61      6000
   macro avg       0.62      0.61      0.59      6000
weighted avg       0.63      0.61      0.60      6000

Confusion Matrix for this model: 
 [[926 313   0   0   1]
 [134 863 132  83   6]
 [  1 194 259 640  90]
 [  0  12  54 722 387]
 [ 10  12   8 276 877]]
Experiment:  93  Set:  ss2 Train Labels:  nnar10 Test Labels:  ncar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.81      0.72      0.76      1203
           1       0.59      0.67      0.63      1215
           2       0.57      0.21      0.31      1206
           3       0.41      0.59      0.48      1190
           4       0.61      0.70      0.65      1186

    accuracy                           0.58      6000
   macro avg       0.60      0.58      0.57      6000
weighted avg       0.60      0.58      0.57      6000

Confusion Matrix for this model: 
 [[865 305   5  16  12]
 [133 819 126 107  30]
 [ 21 208 256 619 102]
 [ 24  30  54 699 383]
 [ 28  32  12 280 834]]
Experiment:  94  Set:  ss2 Train Labels:  nnar10 Test Labels:  ncar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.77      0.68      0.72      1206
           1       0.58      0.64      0.61      1250
           2       0.54      0.20      0.29      1210
           3       0.39      0.57      0.46      1172
           4       0.57      0.67      0.62      1162

    accuracy                           0.55      6000
   macro avg       0.57      0.55      0.54      6000
weighted avg       0.57      0.55      0.54      6000

Confusion Matrix for this model: 
 [[822 295   8  44  37]
 [148 805 123 127  47]
 [ 29 212 244 598 127]
 [ 36  42  58 665 371]
 [ 36  40  20 287 779]]
Experiment:  95  Set:  ss2 Train Labels:  nnar10 Test Labels:  nar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.63      0.75      0.69       908
           1       0.62      0.71      0.66      1218
           2       0.57      0.22      0.32      1184
           3       0.42      0.48      0.45      1507
           4       0.64      0.74      0.69      1183

    accuracy                           0.57      6000
   macro avg       0.58      0.58      0.56      6000
weighted avg       0.57      0.57      0.55      6000

Confusion Matrix for this model: 
 [[679 228   0   0   1]
 [134 863 132  83   6]
 [  1 194 259 640  90]
 [247  97  54 722 387]
 [ 10  12   8 276 877]]
Experiment:  96  Set:  ss2 Train Labels:  nnar10 Test Labels:  nar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.43      0.75      0.55       623
           1       0.62      0.71      0.66      1218
           2       0.57      0.22      0.32      1184
           3       0.42      0.40      0.41      1792
           4       0.64      0.74      0.69      1183

    accuracy                           0.53      6000
   macro avg       0.54      0.56      0.53      6000
weighted avg       0.54      0.53      0.51      6000

Confusion Matrix for this model: 
 [[465 158   0   0   0]
 [134 863 132  83   6]
 [  1 194 259 640  90]
 [461 167  54 722 388]
 [ 10  12   8 276 877]]
Experiment:  97  Set:  ss2 Train Labels:  nnar10 Test Labels:  nnar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.76      0.78      1120
           1       0.65      0.69      0.67      1327
           2       0.57      0.22      0.32      1184
           3       0.42      0.61      0.50      1178
           4       0.64      0.74      0.69      1191

    accuracy                           0.60      6000
   macro avg       0.62      0.60      0.59      6000
weighted avg       0.62      0.60      0.59      6000

Confusion Matrix for this model: 
 [[856 263   0   0   1]
 [195 911 132  83   6]
 [  1 194 259 640  90]
 [  1  14  54 722 387]
 [ 18  12   8 276 877]]
Experiment:  98  Set:  ss2 Train Labels:  nnar10 Test Labels:  nnar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.77      0.78      1111
           1       0.66      0.69      0.67      1332
           2       0.57      0.22      0.32      1184
           3       0.42      0.61      0.50      1178
           4       0.64      0.73      0.69      1195

    accuracy                           0.60      6000
   macro avg       0.62      0.60      0.59      6000
weighted avg       0.62      0.60      0.59      6000

Confusion Matrix for this model: 
 [[851 259   0   0   1]
 [197 914 132  83   6]
 [  1 194 259 640  90]
 [  1  14  54 722 387]
 [ 21  13   8 276 877]]
Input Shape:  (17020, 1, 1000)
Model: "sequential_14"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_14 (LSTM)               (None, 32)                132224    
_________________________________________________________________
dropout_14 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_56 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_57 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_58 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_59 (Dense)             (None, 2)                 130       
=================================================================
Total params: 161,346
Trainable params: 161,346
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
  1/154 [..............................] - ETA: 2:40 - loss: 0.6956 - categorical_accuracy: 0.4300 23/154 [===>..........................] - ETA: 0s - loss: 0.6811 - categorical_accuracy: 0.5817   45/154 [=======>......................] - ETA: 0s - loss: 0.6751 - categorical_accuracy: 0.5965 68/154 [============>.................] - ETA: 0s - loss: 0.6723 - categorical_accuracy: 0.6028 90/154 [================>.............] - ETA: 0s - loss: 0.6707 - categorical_accuracy: 0.6061113/154 [=====================>........] - ETA: 0s - loss: 0.6695 - categorical_accuracy: 0.6081135/154 [=========================>....] - ETA: 0s - loss: 0.6687 - categorical_accuracy: 0.6094154/154 [==============================] - 2s 4ms/step - loss: 0.6681 - categorical_accuracy: 0.6103 - val_loss: 0.6654 - val_categorical_accuracy: 0.6116
Epoch 2/100
  1/154 [..............................] - ETA: 0s - loss: 0.6474 - categorical_accuracy: 0.6200 21/154 [===>..........................] - ETA: 0s - loss: 0.6442 - categorical_accuracy: 0.6161 43/154 [=======>......................] - ETA: 0s - loss: 0.6427 - categorical_accuracy: 0.6148 65/154 [===========>..................] - ETA: 0s - loss: 0.6417 - categorical_accuracy: 0.6131 87/154 [===============>..............] - ETA: 0s - loss: 0.6408 - categorical_accuracy: 0.6133109/154 [====================>.........] - ETA: 0s - loss: 0.6403 - categorical_accuracy: 0.6141132/154 [========================>.....] - ETA: 0s - loss: 0.6394 - categorical_accuracy: 0.6155154/154 [==============================] - 0s 2ms/step - loss: 0.6385 - categorical_accuracy: 0.6170 - val_loss: 0.6698 - val_categorical_accuracy: 0.5858
Epoch 3/100
  1/154 [..............................] - ETA: 0s - loss: 0.5976 - categorical_accuracy: 0.6800 24/154 [===>..........................] - ETA: 0s - loss: 0.5681 - categorical_accuracy: 0.7068 47/154 [========>.....................] - ETA: 0s - loss: 0.5650 - categorical_accuracy: 0.7052 70/154 [============>.................] - ETA: 0s - loss: 0.5624 - categorical_accuracy: 0.7055 93/154 [=================>............] - ETA: 0s - loss: 0.5615 - categorical_accuracy: 0.7058116/154 [=====================>........] - ETA: 0s - loss: 0.5614 - categorical_accuracy: 0.7055139/154 [==========================>...] - ETA: 0s - loss: 0.5620 - categorical_accuracy: 0.7050154/154 [==============================] - 0s 2ms/step - loss: 0.5626 - categorical_accuracy: 0.7044 - val_loss: 0.6934 - val_categorical_accuracy: 0.5564
Epoch 4/100
  1/154 [..............................] - ETA: 0s - loss: 0.4688 - categorical_accuracy: 0.7900 24/154 [===>..........................] - ETA: 0s - loss: 0.4737 - categorical_accuracy: 0.7934 47/154 [========>.....................] - ETA: 0s - loss: 0.4668 - categorical_accuracy: 0.7924 70/154 [============>.................] - ETA: 0s - loss: 0.4641 - categorical_accuracy: 0.7907 92/154 [================>.............] - ETA: 0s - loss: 0.4641 - categorical_accuracy: 0.7888114/154 [=====================>........] - ETA: 0s - loss: 0.4653 - categorical_accuracy: 0.7866137/154 [=========================>....] - ETA: 0s - loss: 0.4670 - categorical_accuracy: 0.7844154/154 [==============================] - 0s 2ms/step - loss: 0.4686 - categorical_accuracy: 0.7825 - val_loss: 0.7614 - val_categorical_accuracy: 0.5617
Epoch 5/100
  1/154 [..............................] - ETA: 0s - loss: 0.3162 - categorical_accuracy: 0.9000 24/154 [===>..........................] - ETA: 0s - loss: 0.3803 - categorical_accuracy: 0.8366 47/154 [========>.....................] - ETA: 0s - loss: 0.3818 - categorical_accuracy: 0.8351 70/154 [============>.................] - ETA: 0s - loss: 0.3811 - categorical_accuracy: 0.8348 93/154 [=================>............] - ETA: 0s - loss: 0.3816 - categorical_accuracy: 0.8334116/154 [=====================>........] - ETA: 0s - loss: 0.3835 - categorical_accuracy: 0.8314139/154 [==========================>...] - ETA: 0s - loss: 0.3859 - categorical_accuracy: 0.8291154/154 [==============================] - 0s 2ms/step - loss: 0.3875 - categorical_accuracy: 0.8276 - val_loss: 0.8675 - val_categorical_accuracy: 0.5417
Epoch 6/100
  1/154 [..............................] - ETA: 0s - loss: 0.3772 - categorical_accuracy: 0.8500 23/154 [===>..........................] - ETA: 0s - loss: 0.3134 - categorical_accuracy: 0.8717 46/154 [=======>......................] - ETA: 0s - loss: 0.3150 - categorical_accuracy: 0.8675 69/154 [============>.................] - ETA: 0s - loss: 0.3175 - categorical_accuracy: 0.8645 92/154 [================>.............] - ETA: 0s - loss: 0.3196 - categorical_accuracy: 0.8626115/154 [=====================>........] - ETA: 0s - loss: 0.3218 - categorical_accuracy: 0.8610138/154 [=========================>....] - ETA: 0s - loss: 0.3246 - categorical_accuracy: 0.8591154/154 [==============================] - 0s 2ms/step - loss: 0.3266 - categorical_accuracy: 0.8578 - val_loss: 0.9494 - val_categorical_accuracy: 0.5488
Epoch 7/100
  1/154 [..............................] - ETA: 0s - loss: 0.2428 - categorical_accuracy: 0.9100 24/154 [===>..........................] - ETA: 0s - loss: 0.2789 - categorical_accuracy: 0.8888 47/154 [========>.....................] - ETA: 0s - loss: 0.2773 - categorical_accuracy: 0.8864 70/154 [============>.................] - ETA: 0s - loss: 0.2794 - categorical_accuracy: 0.8850 93/154 [=================>............] - ETA: 0s - loss: 0.2814 - categorical_accuracy: 0.8838116/154 [=====================>........] - ETA: 0s - loss: 0.2833 - categorical_accuracy: 0.8826139/154 [==========================>...] - ETA: 0s - loss: 0.2852 - categorical_accuracy: 0.8813154/154 [==============================] - 0s 2ms/step - loss: 0.2865 - categorical_accuracy: 0.8804 - val_loss: 1.0348 - val_categorical_accuracy: 0.5388
Epoch 8/100
  1/154 [..............................] - ETA: 0s - loss: 0.2288 - categorical_accuracy: 0.9300 24/154 [===>..........................] - ETA: 0s - loss: 0.2478 - categorical_accuracy: 0.8953 47/154 [========>.....................] - ETA: 0s - loss: 0.2486 - categorical_accuracy: 0.8935 70/154 [============>.................] - ETA: 0s - loss: 0.2494 - categorical_accuracy: 0.8931 92/154 [================>.............] - ETA: 0s - loss: 0.2506 - categorical_accuracy: 0.8926115/154 [=====================>........] - ETA: 0s - loss: 0.2521 - categorical_accuracy: 0.8916138/154 [=========================>....] - ETA: 0s - loss: 0.2537 - categorical_accuracy: 0.8906154/154 [==============================] - 0s 2ms/step - loss: 0.2551 - categorical_accuracy: 0.8898 - val_loss: 1.1813 - val_categorical_accuracy: 0.5529
Epoch 00008: early stopping
Experiment:  99  Set:  bs1 Train Labels:  clean Test Labels:  clean
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.63      0.52      0.57     10699
           1       0.39      0.51      0.44      6544

    accuracy                           0.52     17243
   macro avg       0.51      0.52      0.51     17243
weighted avg       0.54      0.52      0.52     17243

Confusion Matrix for this model: 
 [[5593 5106]
 [3223 3321]]
Experiment:  100  Set:  bs1 Train Labels:  clean Test Labels:  ncar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.62      0.52      0.56     10457
           1       0.40      0.50      0.45      6786

    accuracy                           0.51     17243
   macro avg       0.51      0.51      0.51     17243
weighted avg       0.53      0.51      0.52     17243

Confusion Matrix for this model: 
 [[5441 5016]
 [3375 3411]]
Experiment:  101  Set:  bs1 Train Labels:  clean Test Labels:  ncar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.60      0.52      0.56     10234
           1       0.42      0.50      0.46      7009

    accuracy                           0.51     17243
   macro avg       0.51      0.51      0.51     17243
weighted avg       0.53      0.51      0.52     17243

Confusion Matrix for this model: 
 [[5330 4904]
 [3486 3523]]
Experiment:  102  Set:  bs1 Train Labels:  clean Test Labels:  nar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.58      0.52      0.55      9738
           1       0.45      0.51      0.48      7505

    accuracy                           0.52     17243
   macro avg       0.51      0.51      0.51     17243
weighted avg       0.52      0.52      0.52     17243

Confusion Matrix for this model: 
 [[5103 4635]
 [3713 3792]]
Experiment:  103  Set:  bs1 Train Labels:  clean Test Labels:  nar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.52      0.52      0.52      8829
           1       0.50      0.50      0.50      8414

    accuracy                           0.51     17243
   macro avg       0.51      0.51      0.51     17243
weighted avg       0.51      0.51      0.51     17243

Confusion Matrix for this model: 
 [[4598 4231]
 [4218 4196]]
Experiment:  104  Set:  bs1 Train Labels:  clean Test Labels:  nnar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.63      0.52      0.57     10699
           1       0.39      0.51      0.44      6544

    accuracy                           0.52     17243
   macro avg       0.51      0.52      0.51     17243
weighted avg       0.54      0.52      0.52     17243

Confusion Matrix for this model: 
 [[5593 5106]
 [3223 3321]]
Experiment:  105  Set:  bs1 Train Labels:  clean Test Labels:  nnar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.63      0.52      0.57     10699
           1       0.39      0.51      0.44      6544

    accuracy                           0.52     17243
   macro avg       0.51      0.52      0.51     17243
weighted avg       0.54      0.52      0.52     17243

Confusion Matrix for this model: 
 [[5593 5106]
 [3223 3321]]
Input Shape:  (17020, 1, 1000)
Model: "sequential_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_15 (LSTM)               (None, 32)                132224    
_________________________________________________________________
dropout_15 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_60 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_61 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_62 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_63 (Dense)             (None, 2)                 130       
=================================================================
Total params: 161,346
Trainable params: 161,346
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
  1/154 [..............................] - ETA: 3:14 - loss: 0.6877 - categorical_accuracy: 0.6200 23/154 [===>..........................] - ETA: 0s - loss: 0.6785 - categorical_accuracy: 0.6041   45/154 [=======>......................] - ETA: 0s - loss: 0.6774 - categorical_accuracy: 0.5987 68/154 [============>.................] - ETA: 0s - loss: 0.6767 - categorical_accuracy: 0.5972 91/154 [================>.............] - ETA: 0s - loss: 0.6763 - categorical_accuracy: 0.5965114/154 [=====================>........] - ETA: 0s - loss: 0.6756 - categorical_accuracy: 0.5968136/154 [=========================>....] - ETA: 0s - loss: 0.6749 - categorical_accuracy: 0.5974154/154 [==============================] - 2s 5ms/step - loss: 0.6743 - categorical_accuracy: 0.5982 - val_loss: 0.6710 - val_categorical_accuracy: 0.5999
Epoch 2/100
  1/154 [..............................] - ETA: 0s - loss: 0.6689 - categorical_accuracy: 0.5700 22/154 [===>..........................] - ETA: 0s - loss: 0.6578 - categorical_accuracy: 0.5933 42/154 [=======>......................] - ETA: 0s - loss: 0.6555 - categorical_accuracy: 0.5928 65/154 [===========>..................] - ETA: 0s - loss: 0.6528 - categorical_accuracy: 0.5964 87/154 [===============>..............] - ETA: 0s - loss: 0.6510 - categorical_accuracy: 0.5995109/154 [====================>.........] - ETA: 0s - loss: 0.6498 - categorical_accuracy: 0.6020131/154 [========================>.....] - ETA: 0s - loss: 0.6488 - categorical_accuracy: 0.6040154/154 [==============================] - ETA: 0s - loss: 0.6481 - categorical_accuracy: 0.6057154/154 [==============================] - 0s 3ms/step - loss: 0.6481 - categorical_accuracy: 0.6058 - val_loss: 0.6794 - val_categorical_accuracy: 0.5875
Epoch 3/100
  1/154 [..............................] - ETA: 0s - loss: 0.5469 - categorical_accuracy: 0.7200 24/154 [===>..........................] - ETA: 0s - loss: 0.5725 - categorical_accuracy: 0.7038 47/154 [========>.....................] - ETA: 0s - loss: 0.5751 - categorical_accuracy: 0.6978 70/154 [============>.................] - ETA: 0s - loss: 0.5770 - categorical_accuracy: 0.6951 92/154 [================>.............] - ETA: 0s - loss: 0.5778 - categorical_accuracy: 0.6936115/154 [=====================>........] - ETA: 0s - loss: 0.5785 - categorical_accuracy: 0.6919138/154 [=========================>....] - ETA: 0s - loss: 0.5792 - categorical_accuracy: 0.6905154/154 [==============================] - 0s 2ms/step - loss: 0.5798 - categorical_accuracy: 0.6894 - val_loss: 0.7160 - val_categorical_accuracy: 0.5217
Epoch 4/100
  1/154 [..............................] - ETA: 0s - loss: 0.4544 - categorical_accuracy: 0.8100 23/154 [===>..........................] - ETA: 0s - loss: 0.4855 - categorical_accuracy: 0.7963 41/154 [======>.......................] - ETA: 0s - loss: 0.4775 - categorical_accuracy: 0.7952 64/154 [===========>..................] - ETA: 0s - loss: 0.4751 - categorical_accuracy: 0.7911 87/154 [===============>..............] - ETA: 0s - loss: 0.4774 - categorical_accuracy: 0.7858108/154 [====================>.........] - ETA: 0s - loss: 0.4802 - categorical_accuracy: 0.7818130/154 [========================>.....] - ETA: 0s - loss: 0.4828 - categorical_accuracy: 0.7781152/154 [============================>.] - ETA: 0s - loss: 0.4853 - categorical_accuracy: 0.7749154/154 [==============================] - 0s 3ms/step - loss: 0.4856 - categorical_accuracy: 0.7744 - val_loss: 0.7811 - val_categorical_accuracy: 0.5123
Epoch 5/100
  1/154 [..............................] - ETA: 0s - loss: 0.4303 - categorical_accuracy: 0.8400 24/154 [===>..........................] - ETA: 0s - loss: 0.4013 - categorical_accuracy: 0.8255 47/154 [========>.....................] - ETA: 0s - loss: 0.3997 - categorical_accuracy: 0.8209 70/154 [============>.................] - ETA: 0s - loss: 0.3990 - categorical_accuracy: 0.8194 93/154 [=================>............] - ETA: 0s - loss: 0.3992 - categorical_accuracy: 0.8186116/154 [=====================>........] - ETA: 0s - loss: 0.4006 - categorical_accuracy: 0.8172139/154 [==========================>...] - ETA: 0s - loss: 0.4026 - categorical_accuracy: 0.8157154/154 [==============================] - 0s 2ms/step - loss: 0.4041 - categorical_accuracy: 0.8145 - val_loss: 0.8508 - val_categorical_accuracy: 0.5071
Epoch 6/100
  1/154 [..............................] - ETA: 0s - loss: 0.3946 - categorical_accuracy: 0.8300 17/154 [==>...........................] - ETA: 0s - loss: 0.3454 - categorical_accuracy: 0.8608 31/154 [=====>........................] - ETA: 0s - loss: 0.3430 - categorical_accuracy: 0.8583 50/154 [========>.....................] - ETA: 0s - loss: 0.3395 - categorical_accuracy: 0.8578 72/154 [=============>................] - ETA: 0s - loss: 0.3392 - categorical_accuracy: 0.8561 89/154 [================>.............] - ETA: 0s - loss: 0.3396 - categorical_accuracy: 0.8547106/154 [===================>..........] - ETA: 0s - loss: 0.3411 - categorical_accuracy: 0.8531121/154 [======================>.......] - ETA: 0s - loss: 0.3429 - categorical_accuracy: 0.8517137/154 [=========================>....] - ETA: 0s - loss: 0.3444 - categorical_accuracy: 0.8504154/154 [==============================] - ETA: 0s - loss: 0.3460 - categorical_accuracy: 0.8491154/154 [==============================] - 1s 3ms/step - loss: 0.3460 - categorical_accuracy: 0.8491 - val_loss: 0.9452 - val_categorical_accuracy: 0.5288
Epoch 7/100
  1/154 [..............................] - ETA: 0s - loss: 0.2848 - categorical_accuracy: 0.8900 17/154 [==>...........................] - ETA: 0s - loss: 0.2938 - categorical_accuracy: 0.8711 33/154 [=====>........................] - ETA: 0s - loss: 0.2856 - categorical_accuracy: 0.8744 50/154 [========>.....................] - ETA: 0s - loss: 0.2842 - categorical_accuracy: 0.8754 65/154 [===========>..................] - ETA: 0s - loss: 0.2850 - categorical_accuracy: 0.8747 80/154 [==============>...............] - ETA: 0s - loss: 0.2861 - categorical_accuracy: 0.8741 96/154 [=================>............] - ETA: 0s - loss: 0.2875 - categorical_accuracy: 0.8733112/154 [====================>.........] - ETA: 0s - loss: 0.2888 - categorical_accuracy: 0.8727131/154 [========================>.....] - ETA: 0s - loss: 0.2900 - categorical_accuracy: 0.8721151/154 [============================>.] - ETA: 0s - loss: 0.2917 - categorical_accuracy: 0.8712154/154 [==============================] - 1s 3ms/step - loss: 0.2921 - categorical_accuracy: 0.8709 - val_loss: 1.0273 - val_categorical_accuracy: 0.5165
Epoch 8/100
  1/154 [..............................] - ETA: 0s - loss: 0.3292 - categorical_accuracy: 0.8500 18/154 [==>...........................] - ETA: 0s - loss: 0.2848 - categorical_accuracy: 0.8779 38/154 [======>.......................] - ETA: 0s - loss: 0.2755 - categorical_accuracy: 0.8846 58/154 [==========>...................] - ETA: 0s - loss: 0.2701 - categorical_accuracy: 0.8868 78/154 [==============>...............] - ETA: 0s - loss: 0.2679 - categorical_accuracy: 0.8874 97/154 [=================>............] - ETA: 0s - loss: 0.2669 - categorical_accuracy: 0.8871110/154 [====================>.........] - ETA: 0s - loss: 0.2669 - categorical_accuracy: 0.8867126/154 [=======================>......] - ETA: 0s - loss: 0.2672 - categorical_accuracy: 0.8861143/154 [==========================>...] - ETA: 0s - loss: 0.2675 - categorical_accuracy: 0.8856154/154 [==============================] - 0s 3ms/step - loss: 0.2677 - categorical_accuracy: 0.8853 - val_loss: 1.1945 - val_categorical_accuracy: 0.5423
Epoch 00008: early stopping
Experiment:  106  Set:  bs1 Train Labels:  ncar5 Test Labels:  clean
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.63      0.56      0.59     10699
           1       0.40      0.47      0.43      6544

    accuracy                           0.53     17243
   macro avg       0.51      0.52      0.51     17243
weighted avg       0.54      0.53      0.53     17243

Confusion Matrix for this model: 
 [[5951 4748]
 [3441 3103]]
Experiment:  107  Set:  bs1 Train Labels:  ncar5 Test Labels:  ncar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.62      0.56      0.59     10457
           1       0.41      0.47      0.44      6786

    accuracy                           0.52     17243
   macro avg       0.51      0.52      0.51     17243
weighted avg       0.54      0.52      0.53     17243

Confusion Matrix for this model: 
 [[5821 4636]
 [3571 3215]]
Experiment:  108  Set:  bs1 Train Labels:  ncar5 Test Labels:  ncar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.60      0.55      0.58     10234
           1       0.42      0.47      0.44      7009

    accuracy                           0.52     17243
   macro avg       0.51      0.51      0.51     17243
weighted avg       0.53      0.52      0.52     17243

Confusion Matrix for this model: 
 [[5644 4590]
 [3748 3261]]
Experiment:  109  Set:  bs1 Train Labels:  ncar5 Test Labels:  nar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.58      0.56      0.57      9738
           1       0.45      0.47      0.46      7505

    accuracy                           0.52     17243
   macro avg       0.51      0.51      0.51     17243
weighted avg       0.52      0.52      0.52     17243

Confusion Matrix for this model: 
 [[5423 4315]
 [3969 3536]]
Experiment:  110  Set:  bs1 Train Labels:  ncar5 Test Labels:  nar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.52      0.55      0.54      8829
           1       0.50      0.46      0.48      8414

    accuracy                           0.51     17243
   macro avg       0.51      0.51      0.51     17243
weighted avg       0.51      0.51      0.51     17243

Confusion Matrix for this model: 
 [[4879 3950]
 [4513 3901]]
Experiment:  111  Set:  bs1 Train Labels:  ncar5 Test Labels:  nnar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.63      0.56      0.59     10699
           1       0.40      0.47      0.43      6544

    accuracy                           0.53     17243
   macro avg       0.51      0.52      0.51     17243
weighted avg       0.54      0.53      0.53     17243

Confusion Matrix for this model: 
 [[5951 4748]
 [3441 3103]]
Experiment:  112  Set:  bs1 Train Labels:  ncar5 Test Labels:  nnar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.63      0.56      0.59     10699
           1       0.40      0.47      0.43      6544

    accuracy                           0.53     17243
   macro avg       0.51      0.52      0.51     17243
weighted avg       0.54      0.53      0.53     17243

Confusion Matrix for this model: 
 [[5951 4748]
 [3441 3103]]
Input Shape:  (17020, 1, 1000)
Model: "sequential_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_16 (LSTM)               (None, 32)                132224    
_________________________________________________________________
dropout_16 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_64 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_65 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_66 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_67 (Dense)             (None, 2)                 130       
=================================================================
Total params: 161,346
Trainable params: 161,346
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
  1/154 [..............................] - ETA: 2:38 - loss: 0.6951 - categorical_accuracy: 0.4100 23/154 [===>..........................] - ETA: 0s - loss: 0.6875 - categorical_accuracy: 0.5491   45/154 [=======>......................] - ETA: 0s - loss: 0.6849 - categorical_accuracy: 0.5628 67/154 [============>.................] - ETA: 0s - loss: 0.6829 - categorical_accuracy: 0.5704 89/154 [================>.............] - ETA: 0s - loss: 0.6816 - categorical_accuracy: 0.5750111/154 [====================>.........] - ETA: 0s - loss: 0.6808 - categorical_accuracy: 0.5773133/154 [========================>.....] - ETA: 0s - loss: 0.6804 - categorical_accuracy: 0.5783154/154 [==============================] - 2s 4ms/step - loss: 0.6800 - categorical_accuracy: 0.5793 - val_loss: 0.6725 - val_categorical_accuracy: 0.5934
Epoch 2/100
  1/154 [..............................] - ETA: 0s - loss: 0.6253 - categorical_accuracy: 0.6500 24/154 [===>..........................] - ETA: 0s - loss: 0.6526 - categorical_accuracy: 0.6105 46/154 [=======>......................] - ETA: 0s - loss: 0.6545 - categorical_accuracy: 0.6044 69/154 [============>.................] - ETA: 0s - loss: 0.6547 - categorical_accuracy: 0.6020 91/154 [================>.............] - ETA: 0s - loss: 0.6546 - categorical_accuracy: 0.6016113/154 [=====================>........] - ETA: 0s - loss: 0.6547 - categorical_accuracy: 0.6014135/154 [=========================>....] - ETA: 0s - loss: 0.6548 - categorical_accuracy: 0.6012154/154 [==============================] - 0s 2ms/step - loss: 0.6549 - categorical_accuracy: 0.6013 - val_loss: 0.6767 - val_categorical_accuracy: 0.5517
Epoch 3/100
  1/154 [..............................] - ETA: 0s - loss: 0.6343 - categorical_accuracy: 0.6200 23/154 [===>..........................] - ETA: 0s - loss: 0.5981 - categorical_accuracy: 0.6739 46/154 [=======>......................] - ETA: 0s - loss: 0.5909 - categorical_accuracy: 0.6830 69/154 [============>.................] - ETA: 0s - loss: 0.5900 - categorical_accuracy: 0.6840 92/154 [================>.............] - ETA: 0s - loss: 0.5913 - categorical_accuracy: 0.6816114/154 [=====================>........] - ETA: 0s - loss: 0.5928 - categorical_accuracy: 0.6791136/154 [=========================>....] - ETA: 0s - loss: 0.5942 - categorical_accuracy: 0.6770154/154 [==============================] - 0s 2ms/step - loss: 0.5952 - categorical_accuracy: 0.6754 - val_loss: 0.7008 - val_categorical_accuracy: 0.5482
Epoch 4/100
  1/154 [..............................] - ETA: 0s - loss: 0.5501 - categorical_accuracy: 0.6800 24/154 [===>..........................] - ETA: 0s - loss: 0.5191 - categorical_accuracy: 0.7477 47/154 [========>.....................] - ETA: 0s - loss: 0.5096 - categorical_accuracy: 0.7539 70/154 [============>.................] - ETA: 0s - loss: 0.5065 - categorical_accuracy: 0.7552 93/154 [=================>............] - ETA: 0s - loss: 0.5054 - categorical_accuracy: 0.7554116/154 [=====================>........] - ETA: 0s - loss: 0.5063 - categorical_accuracy: 0.7542139/154 [==========================>...] - ETA: 0s - loss: 0.5079 - categorical_accuracy: 0.7521154/154 [==============================] - 0s 2ms/step - loss: 0.5092 - categorical_accuracy: 0.7504 - val_loss: 0.7383 - val_categorical_accuracy: 0.5488
Epoch 5/100
  1/154 [..............................] - ETA: 0s - loss: 0.4784 - categorical_accuracy: 0.7600 23/154 [===>..........................] - ETA: 0s - loss: 0.4389 - categorical_accuracy: 0.7987 45/154 [=======>......................] - ETA: 0s - loss: 0.4293 - categorical_accuracy: 0.8004 68/154 [============>.................] - ETA: 0s - loss: 0.4246 - categorical_accuracy: 0.8017 90/154 [================>.............] - ETA: 0s - loss: 0.4234 - categorical_accuracy: 0.8017113/154 [=====================>........] - ETA: 0s - loss: 0.4232 - categorical_accuracy: 0.8013135/154 [=========================>....] - ETA: 0s - loss: 0.4242 - categorical_accuracy: 0.8001154/154 [==============================] - 0s 2ms/step - loss: 0.4252 - categorical_accuracy: 0.7991 - val_loss: 0.8308 - val_categorical_accuracy: 0.5353
Epoch 6/100
  1/154 [..............................] - ETA: 0s - loss: 0.3720 - categorical_accuracy: 0.7900 24/154 [===>..........................] - ETA: 0s - loss: 0.3669 - categorical_accuracy: 0.8345 46/154 [=======>......................] - ETA: 0s - loss: 0.3620 - categorical_accuracy: 0.8394 69/154 [============>.................] - ETA: 0s - loss: 0.3596 - categorical_accuracy: 0.8410 91/154 [================>.............] - ETA: 0s - loss: 0.3584 - categorical_accuracy: 0.8419113/154 [=====================>........] - ETA: 0s - loss: 0.3583 - categorical_accuracy: 0.8421135/154 [=========================>....] - ETA: 0s - loss: 0.3591 - categorical_accuracy: 0.8416154/154 [==============================] - 0s 2ms/step - loss: 0.3605 - categorical_accuracy: 0.8407 - val_loss: 0.8726 - val_categorical_accuracy: 0.5311
Epoch 7/100
  1/154 [..............................] - ETA: 0s - loss: 0.2989 - categorical_accuracy: 0.8600 23/154 [===>..........................] - ETA: 0s - loss: 0.3030 - categorical_accuracy: 0.8705 46/154 [=======>......................] - ETA: 0s - loss: 0.3044 - categorical_accuracy: 0.8716 69/154 [============>.................] - ETA: 0s - loss: 0.3068 - categorical_accuracy: 0.8712 91/154 [================>.............] - ETA: 0s - loss: 0.3090 - categorical_accuracy: 0.8700113/154 [=====================>........] - ETA: 0s - loss: 0.3108 - categorical_accuracy: 0.8687135/154 [=========================>....] - ETA: 0s - loss: 0.3122 - categorical_accuracy: 0.8676154/154 [==============================] - 0s 2ms/step - loss: 0.3135 - categorical_accuracy: 0.8666 - val_loss: 1.0355 - val_categorical_accuracy: 0.5447
Epoch 8/100
  1/154 [..............................] - ETA: 0s - loss: 0.1901 - categorical_accuracy: 0.9400 23/154 [===>..........................] - ETA: 0s - loss: 0.2606 - categorical_accuracy: 0.8926 45/154 [=======>......................] - ETA: 0s - loss: 0.2626 - categorical_accuracy: 0.8904 67/154 [============>.................] - ETA: 0s - loss: 0.2640 - categorical_accuracy: 0.8888 90/154 [================>.............] - ETA: 0s - loss: 0.2654 - categorical_accuracy: 0.8874112/154 [====================>.........] - ETA: 0s - loss: 0.2666 - categorical_accuracy: 0.8861134/154 [=========================>....] - ETA: 0s - loss: 0.2675 - categorical_accuracy: 0.8851154/154 [==============================] - 0s 2ms/step - loss: 0.2684 - categorical_accuracy: 0.8843 - val_loss: 1.1106 - val_categorical_accuracy: 0.5464
Epoch 00008: early stopping
Experiment:  113  Set:  bs1 Train Labels:  ncar10 Test Labels:  clean
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.52      0.57     10699
           1       0.40      0.53      0.46      6544

    accuracy                           0.52     17243
   macro avg       0.52      0.52      0.51     17243
weighted avg       0.55      0.52      0.53     17243

Confusion Matrix for this model: 
 [[5527 5172]
 [3091 3453]]
Experiment:  114  Set:  bs1 Train Labels:  ncar10 Test Labels:  ncar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.63      0.52      0.57     10457
           1       0.41      0.52      0.46      6786

    accuracy                           0.52     17243
   macro avg       0.52      0.52      0.51     17243
weighted avg       0.54      0.52      0.52     17243

Confusion Matrix for this model: 
 [[5391 5066]
 [3227 3559]]
Experiment:  115  Set:  bs1 Train Labels:  ncar10 Test Labels:  ncar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.61      0.52      0.56     10234
           1       0.43      0.52      0.47      7009

    accuracy                           0.52     17243
   macro avg       0.52      0.52      0.52     17243
weighted avg       0.54      0.52      0.52     17243

Confusion Matrix for this model: 
 [[5281 4953]
 [3337 3672]]
Experiment:  116  Set:  bs1 Train Labels:  ncar10 Test Labels:  nar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.58      0.52      0.55      9738
           1       0.45      0.52      0.49      7505

    accuracy                           0.52     17243
   macro avg       0.52      0.52      0.52     17243
weighted avg       0.53      0.52      0.52     17243

Confusion Matrix for this model: 
 [[5025 4713]
 [3593 3912]]
Experiment:  117  Set:  bs1 Train Labels:  ncar10 Test Labels:  nar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.53      0.51      0.52      8829
           1       0.50      0.51      0.51      8414

    accuracy                           0.51     17243
   macro avg       0.51      0.51      0.51     17243
weighted avg       0.51      0.51      0.51     17243

Confusion Matrix for this model: 
 [[4531 4298]
 [4087 4327]]
Experiment:  118  Set:  bs1 Train Labels:  ncar10 Test Labels:  nnar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.52      0.57     10699
           1       0.40      0.53      0.46      6544

    accuracy                           0.52     17243
   macro avg       0.52      0.52      0.51     17243
weighted avg       0.55      0.52      0.53     17243

Confusion Matrix for this model: 
 [[5527 5172]
 [3091 3453]]
Experiment:  119  Set:  bs1 Train Labels:  ncar10 Test Labels:  nnar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.52      0.57     10699
           1       0.40      0.53      0.46      6544

    accuracy                           0.52     17243
   macro avg       0.52      0.52      0.51     17243
weighted avg       0.55      0.52      0.53     17243

Confusion Matrix for this model: 
 [[5527 5172]
 [3091 3453]]
Input Shape:  (17020, 1, 1000)
Model: "sequential_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_17 (LSTM)               (None, 32)                132224    
_________________________________________________________________
dropout_17 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_68 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_69 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_70 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_71 (Dense)             (None, 2)                 130       
=================================================================
Total params: 161,346
Trainable params: 161,346
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
  1/154 [..............................] - ETA: 2:35 - loss: 0.6944 - categorical_accuracy: 0.5000 23/154 [===>..........................] - ETA: 0s - loss: 0.6905 - categorical_accuracy: 0.5270   45/154 [=======>......................] - ETA: 0s - loss: 0.6888 - categorical_accuracy: 0.5389 67/154 [============>.................] - ETA: 0s - loss: 0.6877 - categorical_accuracy: 0.5452 89/154 [================>.............] - ETA: 0s - loss: 0.6872 - categorical_accuracy: 0.5483112/154 [====================>.........] - ETA: 0s - loss: 0.6867 - categorical_accuracy: 0.5506135/154 [=========================>....] - ETA: 0s - loss: 0.6864 - categorical_accuracy: 0.5520154/154 [==============================] - 2s 4ms/step - loss: 0.6862 - categorical_accuracy: 0.5529 - val_loss: 0.6827 - val_categorical_accuracy: 0.5617
Epoch 2/100
  1/154 [..............................] - ETA: 0s - loss: 0.7184 - categorical_accuracy: 0.4400 23/154 [===>..........................] - ETA: 0s - loss: 0.6792 - categorical_accuracy: 0.5475 45/154 [=======>......................] - ETA: 0s - loss: 0.6723 - categorical_accuracy: 0.5642 68/154 [============>.................] - ETA: 0s - loss: 0.6689 - categorical_accuracy: 0.5737 89/154 [================>.............] - ETA: 0s - loss: 0.6672 - categorical_accuracy: 0.5787111/154 [====================>.........] - ETA: 0s - loss: 0.6664 - categorical_accuracy: 0.5814133/154 [========================>.....] - ETA: 0s - loss: 0.6659 - categorical_accuracy: 0.5830154/154 [==============================] - 0s 2ms/step - loss: 0.6656 - categorical_accuracy: 0.5842 - val_loss: 0.6841 - val_categorical_accuracy: 0.5670
Epoch 3/100
  1/154 [..............................] - ETA: 0s - loss: 0.6173 - categorical_accuracy: 0.6400 24/154 [===>..........................] - ETA: 0s - loss: 0.6152 - categorical_accuracy: 0.6516 46/154 [=======>......................] - ETA: 0s - loss: 0.6080 - categorical_accuracy: 0.6604 69/154 [============>.................] - ETA: 0s - loss: 0.6051 - categorical_accuracy: 0.6640 92/154 [================>.............] - ETA: 0s - loss: 0.6038 - categorical_accuracy: 0.6655115/154 [=====================>........] - ETA: 0s - loss: 0.6038 - categorical_accuracy: 0.6654138/154 [=========================>....] - ETA: 0s - loss: 0.6043 - categorical_accuracy: 0.6645154/154 [==============================] - 0s 2ms/step - loss: 0.6049 - categorical_accuracy: 0.6637 - val_loss: 0.7072 - val_categorical_accuracy: 0.5329
Epoch 4/100
  1/154 [..............................] - ETA: 0s - loss: 0.5146 - categorical_accuracy: 0.7600 24/154 [===>..........................] - ETA: 0s - loss: 0.5093 - categorical_accuracy: 0.7787 47/154 [========>.....................] - ETA: 0s - loss: 0.5044 - categorical_accuracy: 0.7717 70/154 [============>.................] - ETA: 0s - loss: 0.5037 - categorical_accuracy: 0.7669 93/154 [=================>............] - ETA: 0s - loss: 0.5051 - categorical_accuracy: 0.7630116/154 [=====================>........] - ETA: 0s - loss: 0.5075 - categorical_accuracy: 0.7594139/154 [==========================>...] - ETA: 0s - loss: 0.5099 - categorical_accuracy: 0.7562154/154 [==============================] - 0s 2ms/step - loss: 0.5116 - categorical_accuracy: 0.7543 - val_loss: 0.7732 - val_categorical_accuracy: 0.5458
Epoch 5/100
  1/154 [..............................] - ETA: 0s - loss: 0.4432 - categorical_accuracy: 0.7900 24/154 [===>..........................] - ETA: 0s - loss: 0.4347 - categorical_accuracy: 0.7936 47/154 [========>.....................] - ETA: 0s - loss: 0.4279 - categorical_accuracy: 0.8000 70/154 [============>.................] - ETA: 0s - loss: 0.4252 - categorical_accuracy: 0.8010 93/154 [=================>............] - ETA: 0s - loss: 0.4253 - categorical_accuracy: 0.8002116/154 [=====================>........] - ETA: 0s - loss: 0.4265 - categorical_accuracy: 0.7988139/154 [==========================>...] - ETA: 0s - loss: 0.4281 - categorical_accuracy: 0.7974154/154 [==============================] - 0s 2ms/step - loss: 0.4293 - categorical_accuracy: 0.7965 - val_loss: 0.8541 - val_categorical_accuracy: 0.5435
Epoch 6/100
  1/154 [..............................] - ETA: 0s - loss: 0.3629 - categorical_accuracy: 0.8600 24/154 [===>..........................] - ETA: 0s - loss: 0.3626 - categorical_accuracy: 0.8486 47/154 [========>.....................] - ETA: 0s - loss: 0.3590 - categorical_accuracy: 0.8465 70/154 [============>.................] - ETA: 0s - loss: 0.3577 - categorical_accuracy: 0.8455 93/154 [=================>............] - ETA: 0s - loss: 0.3580 - categorical_accuracy: 0.8443116/154 [=====================>........] - ETA: 0s - loss: 0.3585 - categorical_accuracy: 0.8435139/154 [==========================>...] - ETA: 0s - loss: 0.3600 - categorical_accuracy: 0.8421154/154 [==============================] - 0s 2ms/step - loss: 0.3613 - categorical_accuracy: 0.8410 - val_loss: 0.9487 - val_categorical_accuracy: 0.5370
Epoch 7/100
  1/154 [..............................] - ETA: 0s - loss: 0.2671 - categorical_accuracy: 0.9000 23/154 [===>..........................] - ETA: 0s - loss: 0.2966 - categorical_accuracy: 0.8745 46/154 [=======>......................] - ETA: 0s - loss: 0.2933 - categorical_accuracy: 0.8756 69/154 [============>.................] - ETA: 0s - loss: 0.2969 - categorical_accuracy: 0.8739 92/154 [================>.............] - ETA: 0s - loss: 0.2999 - categorical_accuracy: 0.8724115/154 [=====================>........] - ETA: 0s - loss: 0.3025 - categorical_accuracy: 0.8709138/154 [=========================>....] - ETA: 0s - loss: 0.3054 - categorical_accuracy: 0.8691154/154 [==============================] - 0s 2ms/step - loss: 0.3071 - categorical_accuracy: 0.8680 - val_loss: 1.0657 - val_categorical_accuracy: 0.5370
Epoch 8/100
  1/154 [..............................] - ETA: 0s - loss: 0.2624 - categorical_accuracy: 0.8900 24/154 [===>..........................] - ETA: 0s - loss: 0.2656 - categorical_accuracy: 0.8935 47/154 [========>.....................] - ETA: 0s - loss: 0.2619 - categorical_accuracy: 0.8931 70/154 [============>.................] - ETA: 0s - loss: 0.2646 - categorical_accuracy: 0.8908 92/154 [================>.............] - ETA: 0s - loss: 0.2667 - categorical_accuracy: 0.8890115/154 [=====================>........] - ETA: 0s - loss: 0.2683 - categorical_accuracy: 0.8876138/154 [=========================>....] - ETA: 0s - loss: 0.2698 - categorical_accuracy: 0.8862154/154 [==============================] - 0s 2ms/step - loss: 0.2710 - categorical_accuracy: 0.8852 - val_loss: 1.1198 - val_categorical_accuracy: 0.5317
Epoch 00008: early stopping
Experiment:  120  Set:  bs1 Train Labels:  nar5 Test Labels:  clean
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.51      0.57     10699
           1       0.40      0.53      0.45      6544

    accuracy                           0.52     17243
   macro avg       0.52      0.52      0.51     17243
weighted avg       0.55      0.52      0.52     17243

Confusion Matrix for this model: 
 [[5472 5227]
 [3089 3455]]
Experiment:  121  Set:  bs1 Train Labels:  nar5 Test Labels:  ncar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.62      0.51      0.56     10457
           1       0.41      0.52      0.46      6786

    accuracy                           0.52     17243
   macro avg       0.52      0.52      0.51     17243
weighted avg       0.54      0.52      0.52     17243

Confusion Matrix for this model: 
 [[5330 5127]
 [3231 3555]]
Experiment:  122  Set:  bs1 Train Labels:  nar5 Test Labels:  ncar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.61      0.51      0.55     10234
           1       0.42      0.52      0.46      7009

    accuracy                           0.51     17243
   macro avg       0.51      0.51      0.51     17243
weighted avg       0.53      0.51      0.52     17243

Confusion Matrix for this model: 
 [[5184 5050]
 [3377 3632]]
Experiment:  123  Set:  bs1 Train Labels:  nar5 Test Labels:  nar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.58      0.51      0.54      9738
           1       0.45      0.52      0.48      7505

    accuracy                           0.52     17243
   macro avg       0.52      0.52      0.51     17243
weighted avg       0.53      0.52      0.52     17243

Confusion Matrix for this model: 
 [[4979 4759]
 [3582 3923]]
Experiment:  124  Set:  bs1 Train Labels:  nar5 Test Labels:  nar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.53      0.51      0.52      8829
           1       0.50      0.52      0.51      8414

    accuracy                           0.51     17243
   macro avg       0.51      0.51      0.51     17243
weighted avg       0.51      0.51      0.51     17243

Confusion Matrix for this model: 
 [[4507 4322]
 [4054 4360]]
Experiment:  125  Set:  bs1 Train Labels:  nar5 Test Labels:  nnar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.51      0.57     10699
           1       0.40      0.53      0.45      6544

    accuracy                           0.52     17243
   macro avg       0.52      0.52      0.51     17243
weighted avg       0.55      0.52      0.52     17243

Confusion Matrix for this model: 
 [[5472 5227]
 [3089 3455]]
Experiment:  126  Set:  bs1 Train Labels:  nar5 Test Labels:  nnar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.51      0.57     10699
           1       0.40      0.53      0.45      6544

    accuracy                           0.52     17243
   macro avg       0.52      0.52      0.51     17243
weighted avg       0.55      0.52      0.52     17243

Confusion Matrix for this model: 
 [[5472 5227]
 [3089 3455]]
Input Shape:  (17020, 1, 1000)
Model: "sequential_18"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_18 (LSTM)               (None, 32)                132224    
_________________________________________________________________
dropout_18 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_72 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_73 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_74 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_75 (Dense)             (None, 2)                 130       
=================================================================
Total params: 161,346
Trainable params: 161,346
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
  1/154 [..............................] - ETA: 2:40 - loss: 0.6949 - categorical_accuracy: 0.5200 23/154 [===>..........................] - ETA: 0s - loss: 0.6929 - categorical_accuracy: 0.5218   45/154 [=======>......................] - ETA: 0s - loss: 0.6929 - categorical_accuracy: 0.5181 67/154 [============>.................] - ETA: 0s - loss: 0.6928 - categorical_accuracy: 0.5191 89/154 [================>.............] - ETA: 0s - loss: 0.6927 - categorical_accuracy: 0.5196111/154 [====================>.........] - ETA: 0s - loss: 0.6927 - categorical_accuracy: 0.5187133/154 [========================>.....] - ETA: 0s - loss: 0.6927 - categorical_accuracy: 0.5181154/154 [==============================] - 2s 5ms/step - loss: 0.6927 - categorical_accuracy: 0.5175 - val_loss: 0.6911 - val_categorical_accuracy: 0.5235
Epoch 2/100
  1/154 [..............................] - ETA: 0s - loss: 0.6969 - categorical_accuracy: 0.5100 18/154 [==>...........................] - ETA: 0s - loss: 0.6839 - categorical_accuracy: 0.5591 37/154 [======>.......................] - ETA: 0s - loss: 0.6805 - categorical_accuracy: 0.5641 56/154 [=========>....................] - ETA: 0s - loss: 0.6790 - categorical_accuracy: 0.5664 73/154 [=============>................] - ETA: 0s - loss: 0.6785 - categorical_accuracy: 0.5668 94/154 [=================>............] - ETA: 0s - loss: 0.6786 - categorical_accuracy: 0.5660110/154 [====================>.........] - ETA: 0s - loss: 0.6787 - categorical_accuracy: 0.5656129/154 [========================>.....] - ETA: 0s - loss: 0.6788 - categorical_accuracy: 0.5650147/154 [===========================>..] - ETA: 0s - loss: 0.6790 - categorical_accuracy: 0.5644154/154 [==============================] - 0s 3ms/step - loss: 0.6790 - categorical_accuracy: 0.5642 - val_loss: 0.6976 - val_categorical_accuracy: 0.5229
Epoch 3/100
  1/154 [..............................] - ETA: 0s - loss: 0.6609 - categorical_accuracy: 0.6300 17/154 [==>...........................] - ETA: 0s - loss: 0.6441 - categorical_accuracy: 0.6482 35/154 [=====>........................] - ETA: 0s - loss: 0.6335 - categorical_accuracy: 0.6555 53/154 [=========>....................] - ETA: 0s - loss: 0.6287 - categorical_accuracy: 0.6569 72/154 [=============>................] - ETA: 0s - loss: 0.6275 - categorical_accuracy: 0.6553 93/154 [=================>............] - ETA: 0s - loss: 0.6276 - categorical_accuracy: 0.6535114/154 [=====================>........] - ETA: 0s - loss: 0.6279 - categorical_accuracy: 0.6522134/154 [=========================>....] - ETA: 0s - loss: 0.6281 - categorical_accuracy: 0.6511154/154 [==============================] - 0s 3ms/step - loss: 0.6283 - categorical_accuracy: 0.6498 - val_loss: 0.7322 - val_categorical_accuracy: 0.5212
Epoch 4/100
  1/154 [..............................] - ETA: 0s - loss: 0.4792 - categorical_accuracy: 0.8300 23/154 [===>..........................] - ETA: 0s - loss: 0.5088 - categorical_accuracy: 0.7741 45/154 [=======>......................] - ETA: 0s - loss: 0.5111 - categorical_accuracy: 0.7626 67/154 [============>.................] - ETA: 0s - loss: 0.5148 - categorical_accuracy: 0.7551 89/154 [================>.............] - ETA: 0s - loss: 0.5190 - categorical_accuracy: 0.7491112/154 [====================>.........] - ETA: 0s - loss: 0.5221 - categorical_accuracy: 0.7449133/154 [========================>.....] - ETA: 0s - loss: 0.5245 - categorical_accuracy: 0.7419154/154 [==============================] - 0s 3ms/step - loss: 0.5267 - categorical_accuracy: 0.7391 - val_loss: 0.7778 - val_categorical_accuracy: 0.5311
Epoch 5/100
  1/154 [..............................] - ETA: 0s - loss: 0.4494 - categorical_accuracy: 0.8200 23/154 [===>..........................] - ETA: 0s - loss: 0.4297 - categorical_accuracy: 0.8205 44/154 [=======>......................] - ETA: 0s - loss: 0.4297 - categorical_accuracy: 0.8149 66/154 [===========>..................] - ETA: 0s - loss: 0.4315 - categorical_accuracy: 0.8107 88/154 [================>.............] - ETA: 0s - loss: 0.4320 - categorical_accuracy: 0.8077111/154 [====================>.........] - ETA: 0s - loss: 0.4336 - categorical_accuracy: 0.8046133/154 [========================>.....] - ETA: 0s - loss: 0.4356 - categorical_accuracy: 0.8017154/154 [==============================] - 0s 3ms/step - loss: 0.4375 - categorical_accuracy: 0.7993 - val_loss: 0.8888 - val_categorical_accuracy: 0.5241
Epoch 6/100
  1/154 [..............................] - ETA: 0s - loss: 0.3670 - categorical_accuracy: 0.8100 23/154 [===>..........................] - ETA: 0s - loss: 0.3539 - categorical_accuracy: 0.8429 46/154 [=======>......................] - ETA: 0s - loss: 0.3551 - categorical_accuracy: 0.8430 69/154 [============>.................] - ETA: 0s - loss: 0.3574 - categorical_accuracy: 0.8413 92/154 [================>.............] - ETA: 0s - loss: 0.3606 - categorical_accuracy: 0.8390115/154 [=====================>........] - ETA: 0s - loss: 0.3631 - categorical_accuracy: 0.8374138/154 [=========================>....] - ETA: 0s - loss: 0.3654 - categorical_accuracy: 0.8359154/154 [==============================] - 0s 2ms/step - loss: 0.3671 - categorical_accuracy: 0.8347 - val_loss: 1.0011 - val_categorical_accuracy: 0.5135
Epoch 7/100
  1/154 [..............................] - ETA: 0s - loss: 0.2716 - categorical_accuracy: 0.9000 23/154 [===>..........................] - ETA: 0s - loss: 0.3010 - categorical_accuracy: 0.8757 46/154 [=======>......................] - ETA: 0s - loss: 0.3020 - categorical_accuracy: 0.8734 67/154 [============>.................] - ETA: 0s - loss: 0.3021 - categorical_accuracy: 0.8721 88/154 [================>.............] - ETA: 0s - loss: 0.3040 - categorical_accuracy: 0.8701107/154 [===================>..........] - ETA: 0s - loss: 0.3059 - categorical_accuracy: 0.8683124/154 [=======================>......] - ETA: 0s - loss: 0.3074 - categorical_accuracy: 0.8671143/154 [==========================>...] - ETA: 0s - loss: 0.3089 - categorical_accuracy: 0.8659154/154 [==============================] - 0s 3ms/step - loss: 0.3099 - categorical_accuracy: 0.8651 - val_loss: 1.0817 - val_categorical_accuracy: 0.5223
Epoch 8/100
  1/154 [..............................] - ETA: 0s - loss: 0.2076 - categorical_accuracy: 0.9400 21/154 [===>..........................] - ETA: 0s - loss: 0.2471 - categorical_accuracy: 0.9012 42/154 [=======>......................] - ETA: 0s - loss: 0.2533 - categorical_accuracy: 0.8970 64/154 [===========>..................] - ETA: 0s - loss: 0.2563 - categorical_accuracy: 0.8948 85/154 [===============>..............] - ETA: 0s - loss: 0.2587 - categorical_accuracy: 0.8932107/154 [===================>..........] - ETA: 0s - loss: 0.2608 - categorical_accuracy: 0.8914129/154 [========================>.....] - ETA: 0s - loss: 0.2634 - categorical_accuracy: 0.8896150/154 [============================>.] - ETA: 0s - loss: 0.2658 - categorical_accuracy: 0.8879154/154 [==============================] - 0s 3ms/step - loss: 0.2663 - categorical_accuracy: 0.8875 - val_loss: 1.1528 - val_categorical_accuracy: 0.5165
Epoch 00008: early stopping
Experiment:  127  Set:  bs1 Train Labels:  nar10 Test Labels:  clean
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.50      0.56     10699
           1       0.40      0.53      0.45      6544

    accuracy                           0.51     17243
   macro avg       0.52      0.52      0.51     17243
weighted avg       0.55      0.51      0.52     17243

Confusion Matrix for this model: 
 [[5346 5353]
 [3046 3498]]
Experiment:  128  Set:  bs1 Train Labels:  nar10 Test Labels:  ncar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.62      0.50      0.55     10457
           1       0.41      0.53      0.46      6786

    accuracy                           0.51     17243
   macro avg       0.51      0.52      0.51     17243
weighted avg       0.54      0.51      0.52     17243

Confusion Matrix for this model: 
 [[5213 5244]
 [3179 3607]]
Experiment:  129  Set:  bs1 Train Labels:  nar10 Test Labels:  ncar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.61      0.50      0.55     10234
           1       0.42      0.53      0.47      7009

    accuracy                           0.51     17243
   macro avg       0.51      0.51      0.51     17243
weighted avg       0.53      0.51      0.52     17243

Confusion Matrix for this model: 
 [[5102 5132]
 [3290 3719]]
Experiment:  130  Set:  bs1 Train Labels:  nar10 Test Labels:  nar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.58      0.50      0.54      9738
           1       0.45      0.53      0.49      7505

    accuracy                           0.51     17243
   macro avg       0.51      0.51      0.51     17243
weighted avg       0.52      0.51      0.51     17243

Confusion Matrix for this model: 
 [[4863 4875]
 [3529 3976]]
Experiment:  131  Set:  bs1 Train Labels:  nar10 Test Labels:  nar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.52      0.50      0.51      8829
           1       0.50      0.53      0.51      8414

    accuracy                           0.51     17243
   macro avg       0.51      0.51      0.51     17243
weighted avg       0.51      0.51      0.51     17243

Confusion Matrix for this model: 
 [[4400 4429]
 [3992 4422]]
Experiment:  132  Set:  bs1 Train Labels:  nar10 Test Labels:  nnar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.50      0.56     10699
           1       0.40      0.53      0.45      6544

    accuracy                           0.51     17243
   macro avg       0.52      0.52      0.51     17243
weighted avg       0.55      0.51      0.52     17243

Confusion Matrix for this model: 
 [[5346 5353]
 [3046 3498]]
Experiment:  133  Set:  bs1 Train Labels:  nar10 Test Labels:  nnar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.50      0.56     10699
           1       0.40      0.53      0.45      6544

    accuracy                           0.51     17243
   macro avg       0.52      0.52      0.51     17243
weighted avg       0.55      0.51      0.52     17243

Confusion Matrix for this model: 
 [[5346 5353]
 [3046 3498]]
Input Shape:  (17020, 1, 1000)
Model: "sequential_19"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_19 (LSTM)               (None, 32)                132224    
_________________________________________________________________
dropout_19 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_76 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_77 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_78 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_79 (Dense)             (None, 2)                 130       
=================================================================
Total params: 161,346
Trainable params: 161,346
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
  1/154 [..............................] - ETA: 2:37 - loss: 0.6908 - categorical_accuracy: 0.6000 23/154 [===>..........................] - ETA: 0s - loss: 0.6859 - categorical_accuracy: 0.5705   45/154 [=======>......................] - ETA: 0s - loss: 0.6849 - categorical_accuracy: 0.5724 67/154 [============>.................] - ETA: 0s - loss: 0.6844 - categorical_accuracy: 0.5735 89/154 [================>.............] - ETA: 0s - loss: 0.6839 - categorical_accuracy: 0.5742112/154 [====================>.........] - ETA: 0s - loss: 0.6836 - categorical_accuracy: 0.5739135/154 [=========================>....] - ETA: 0s - loss: 0.6835 - categorical_accuracy: 0.5735154/154 [==============================] - 2s 4ms/step - loss: 0.6834 - categorical_accuracy: 0.5729 - val_loss: 0.6843 - val_categorical_accuracy: 0.5558
Epoch 2/100
  1/154 [..............................] - ETA: 0s - loss: 0.6627 - categorical_accuracy: 0.5800 23/154 [===>..........................] - ETA: 0s - loss: 0.6694 - categorical_accuracy: 0.5678 45/154 [=======>......................] - ETA: 0s - loss: 0.6688 - categorical_accuracy: 0.5658 67/154 [============>.................] - ETA: 0s - loss: 0.6680 - categorical_accuracy: 0.5677 90/154 [================>.............] - ETA: 0s - loss: 0.6664 - categorical_accuracy: 0.5711113/154 [=====================>........] - ETA: 0s - loss: 0.6655 - categorical_accuracy: 0.5736136/154 [=========================>....] - ETA: 0s - loss: 0.6650 - categorical_accuracy: 0.5756154/154 [==============================] - 0s 2ms/step - loss: 0.6647 - categorical_accuracy: 0.5768 - val_loss: 0.6899 - val_categorical_accuracy: 0.5376
Epoch 3/100
  1/154 [..............................] - ETA: 0s - loss: 0.6098 - categorical_accuracy: 0.7000 23/154 [===>..........................] - ETA: 0s - loss: 0.6046 - categorical_accuracy: 0.6831 43/154 [=======>......................] - ETA: 0s - loss: 0.5967 - categorical_accuracy: 0.6862 65/154 [===========>..................] - ETA: 0s - loss: 0.5927 - categorical_accuracy: 0.6867 88/154 [================>.............] - ETA: 0s - loss: 0.5918 - categorical_accuracy: 0.6850111/154 [====================>.........] - ETA: 0s - loss: 0.5922 - categorical_accuracy: 0.6827134/154 [=========================>....] - ETA: 0s - loss: 0.5931 - categorical_accuracy: 0.6805154/154 [==============================] - 0s 2ms/step - loss: 0.5941 - categorical_accuracy: 0.6788 - val_loss: 0.7205 - val_categorical_accuracy: 0.5200
Epoch 4/100
  1/154 [..............................] - ETA: 0s - loss: 0.5004 - categorical_accuracy: 0.8100 24/154 [===>..........................] - ETA: 0s - loss: 0.5120 - categorical_accuracy: 0.7637 47/154 [========>.....................] - ETA: 0s - loss: 0.5052 - categorical_accuracy: 0.7622 69/154 [============>.................] - ETA: 0s - loss: 0.5038 - categorical_accuracy: 0.7603 92/154 [================>.............] - ETA: 0s - loss: 0.5050 - categorical_accuracy: 0.7573115/154 [=====================>........] - ETA: 0s - loss: 0.5077 - categorical_accuracy: 0.7539138/154 [=========================>....] - ETA: 0s - loss: 0.5100 - categorical_accuracy: 0.7511154/154 [==============================] - 0s 2ms/step - loss: 0.5113 - categorical_accuracy: 0.7496 - val_loss: 0.7890 - val_categorical_accuracy: 0.5194
Epoch 5/100
  1/154 [..............................] - ETA: 0s - loss: 0.4446 - categorical_accuracy: 0.8200 24/154 [===>..........................] - ETA: 0s - loss: 0.4215 - categorical_accuracy: 0.8160 46/154 [=======>......................] - ETA: 0s - loss: 0.4212 - categorical_accuracy: 0.8123 69/154 [============>.................] - ETA: 0s - loss: 0.4236 - categorical_accuracy: 0.8089 92/154 [================>.............] - ETA: 0s - loss: 0.4257 - categorical_accuracy: 0.8063114/154 [=====================>........] - ETA: 0s - loss: 0.4281 - categorical_accuracy: 0.8037137/154 [=========================>....] - ETA: 0s - loss: 0.4303 - categorical_accuracy: 0.8015154/154 [==============================] - 0s 2ms/step - loss: 0.4316 - categorical_accuracy: 0.8002 - val_loss: 0.8774 - val_categorical_accuracy: 0.5076
Epoch 6/100
  1/154 [..............................] - ETA: 0s - loss: 0.3171 - categorical_accuracy: 0.8700 24/154 [===>..........................] - ETA: 0s - loss: 0.3512 - categorical_accuracy: 0.8510 47/154 [========>.....................] - ETA: 0s - loss: 0.3493 - categorical_accuracy: 0.8510 70/154 [============>.................] - ETA: 0s - loss: 0.3498 - categorical_accuracy: 0.8497 93/154 [=================>............] - ETA: 0s - loss: 0.3520 - categorical_accuracy: 0.8481116/154 [=====================>........] - ETA: 0s - loss: 0.3556 - categorical_accuracy: 0.8457139/154 [==========================>...] - ETA: 0s - loss: 0.3587 - categorical_accuracy: 0.8436154/154 [==============================] - 0s 2ms/step - loss: 0.3605 - categorical_accuracy: 0.8423 - val_loss: 0.9764 - val_categorical_accuracy: 0.5182
Epoch 7/100
  1/154 [..............................] - ETA: 0s - loss: 0.3310 - categorical_accuracy: 0.8800 24/154 [===>..........................] - ETA: 0s - loss: 0.3070 - categorical_accuracy: 0.8773 47/154 [========>.....................] - ETA: 0s - loss: 0.3102 - categorical_accuracy: 0.8711 70/154 [============>.................] - ETA: 0s - loss: 0.3104 - categorical_accuracy: 0.8690 93/154 [=================>............] - ETA: 0s - loss: 0.3116 - categorical_accuracy: 0.8667116/154 [=====================>........] - ETA: 0s - loss: 0.3130 - categorical_accuracy: 0.8647139/154 [==========================>...] - ETA: 0s - loss: 0.3141 - categorical_accuracy: 0.8631154/154 [==============================] - 0s 2ms/step - loss: 0.3149 - categorical_accuracy: 0.8623 - val_loss: 1.1057 - val_categorical_accuracy: 0.5235
Epoch 8/100
  1/154 [..............................] - ETA: 0s - loss: 0.2638 - categorical_accuracy: 0.8900 24/154 [===>..........................] - ETA: 0s - loss: 0.2626 - categorical_accuracy: 0.8843 47/154 [========>.....................] - ETA: 0s - loss: 0.2651 - categorical_accuracy: 0.8820 70/154 [============>.................] - ETA: 0s - loss: 0.2675 - categorical_accuracy: 0.8810 93/154 [=================>............] - ETA: 0s - loss: 0.2701 - categorical_accuracy: 0.8804116/154 [=====================>........] - ETA: 0s - loss: 0.2718 - categorical_accuracy: 0.8801139/154 [==========================>...] - ETA: 0s - loss: 0.2738 - categorical_accuracy: 0.8795154/154 [==============================] - 0s 2ms/step - loss: 0.2751 - categorical_accuracy: 0.8791 - val_loss: 1.1385 - val_categorical_accuracy: 0.5235
Epoch 00008: early stopping
Experiment:  134  Set:  bs1 Train Labels:  nnar5 Test Labels:  clean
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.41      0.50     10699
           1       0.39      0.62      0.48      6544

    accuracy                           0.49     17243
   macro avg       0.52      0.52      0.49     17243
weighted avg       0.55      0.49      0.49     17243

Confusion Matrix for this model: 
 [[4368 6331]
 [2468 4076]]
Experiment:  135  Set:  bs1 Train Labels:  nnar5 Test Labels:  ncar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.62      0.41      0.49     10457
           1       0.41      0.62      0.49      6786

    accuracy                           0.49     17243
   macro avg       0.52      0.52      0.49     17243
weighted avg       0.54      0.49      0.49     17243

Confusion Matrix for this model: 
 [[4271 6186]
 [2565 4221]]
Experiment:  136  Set:  bs1 Train Labels:  nnar5 Test Labels:  ncar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.61      0.41      0.49     10234
           1       0.42      0.62      0.50      7009

    accuracy                           0.49     17243
   macro avg       0.51      0.51      0.49     17243
weighted avg       0.53      0.49      0.49     17243

Confusion Matrix for this model: 
 [[4180 6054]
 [2656 4353]]
Experiment:  137  Set:  bs1 Train Labels:  nnar5 Test Labels:  nar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.58      0.41      0.48      9738
           1       0.45      0.62      0.52      7505

    accuracy                           0.50     17243
   macro avg       0.51      0.51      0.50     17243
weighted avg       0.52      0.50      0.50     17243

Confusion Matrix for this model: 
 [[3976 5762]
 [2860 4645]]
Experiment:  138  Set:  bs1 Train Labels:  nnar5 Test Labels:  nar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.53      0.41      0.46      8829
           1       0.50      0.61      0.55      8414

    accuracy                           0.51     17243
   macro avg       0.51      0.51      0.50     17243
weighted avg       0.51      0.51      0.50     17243

Confusion Matrix for this model: 
 [[3589 5240]
 [3247 5167]]
Experiment:  139  Set:  bs1 Train Labels:  nnar5 Test Labels:  nnar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.41      0.50     10699
           1       0.39      0.62      0.48      6544

    accuracy                           0.49     17243
   macro avg       0.52      0.52      0.49     17243
weighted avg       0.55      0.49      0.49     17243

Confusion Matrix for this model: 
 [[4368 6331]
 [2468 4076]]
Experiment:  140  Set:  bs1 Train Labels:  nnar5 Test Labels:  nnar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.41      0.50     10699
           1       0.39      0.62      0.48      6544

    accuracy                           0.49     17243
   macro avg       0.52      0.52      0.49     17243
weighted avg       0.55      0.49      0.49     17243

Confusion Matrix for this model: 
 [[4368 6331]
 [2468 4076]]
Input Shape:  (17020, 1, 1000)
Model: "sequential_20"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_20 (LSTM)               (None, 32)                132224    
_________________________________________________________________
dropout_20 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_80 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_81 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_82 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_83 (Dense)             (None, 2)                 130       
=================================================================
Total params: 161,346
Trainable params: 161,346
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
  1/154 [..............................] - ETA: 2:39 - loss: 0.6943 - categorical_accuracy: 0.4600 23/154 [===>..........................] - ETA: 0s - loss: 0.6941 - categorical_accuracy: 0.4820   46/154 [=======>......................] - ETA: 0s - loss: 0.6938 - categorical_accuracy: 0.4953 68/154 [============>.................] - ETA: 0s - loss: 0.6936 - categorical_accuracy: 0.5004 90/154 [================>.............] - ETA: 0s - loss: 0.6935 - categorical_accuracy: 0.5031112/154 [====================>.........] - ETA: 0s - loss: 0.6934 - categorical_accuracy: 0.5050135/154 [=========================>....] - ETA: 0s - loss: 0.6932 - categorical_accuracy: 0.5066154/154 [==============================] - 2s 4ms/step - loss: 0.6932 - categorical_accuracy: 0.5076 - val_loss: 0.6906 - val_categorical_accuracy: 0.5382
Epoch 2/100
  1/154 [..............................] - ETA: 0s - loss: 0.6830 - categorical_accuracy: 0.5800 24/154 [===>..........................] - ETA: 0s - loss: 0.6824 - categorical_accuracy: 0.5456 46/154 [=======>......................] - ETA: 0s - loss: 0.6810 - categorical_accuracy: 0.5513 68/154 [============>.................] - ETA: 0s - loss: 0.6794 - categorical_accuracy: 0.5578 90/154 [================>.............] - ETA: 0s - loss: 0.6786 - categorical_accuracy: 0.5615113/154 [=====================>........] - ETA: 0s - loss: 0.6780 - categorical_accuracy: 0.5643136/154 [=========================>....] - ETA: 0s - loss: 0.6774 - categorical_accuracy: 0.5664154/154 [==============================] - 0s 2ms/step - loss: 0.6770 - categorical_accuracy: 0.5679 - val_loss: 0.6985 - val_categorical_accuracy: 0.5247
Epoch 3/100
  1/154 [..............................] - ETA: 0s - loss: 0.5918 - categorical_accuracy: 0.7300 24/154 [===>..........................] - ETA: 0s - loss: 0.6043 - categorical_accuracy: 0.7002 47/154 [========>.....................] - ETA: 0s - loss: 0.6055 - categorical_accuracy: 0.6910 70/154 [============>.................] - ETA: 0s - loss: 0.6044 - categorical_accuracy: 0.6883 93/154 [=================>............] - ETA: 0s - loss: 0.6045 - categorical_accuracy: 0.6854116/154 [=====================>........] - ETA: 0s - loss: 0.6049 - categorical_accuracy: 0.6831139/154 [==========================>...] - ETA: 0s - loss: 0.6057 - categorical_accuracy: 0.6808154/154 [==============================] - 0s 2ms/step - loss: 0.6062 - categorical_accuracy: 0.6794 - val_loss: 0.7229 - val_categorical_accuracy: 0.5353
Epoch 4/100
  1/154 [..............................] - ETA: 0s - loss: 0.5093 - categorical_accuracy: 0.7900 23/154 [===>..........................] - ETA: 0s - loss: 0.4966 - categorical_accuracy: 0.7773 46/154 [=======>......................] - ETA: 0s - loss: 0.4907 - categorical_accuracy: 0.7741 68/154 [============>.................] - ETA: 0s - loss: 0.4916 - categorical_accuracy: 0.7697 91/154 [================>.............] - ETA: 0s - loss: 0.4942 - categorical_accuracy: 0.7658114/154 [=====================>........] - ETA: 0s - loss: 0.4969 - categorical_accuracy: 0.7624137/154 [=========================>....] - ETA: 0s - loss: 0.4992 - categorical_accuracy: 0.7599154/154 [==============================] - 0s 2ms/step - loss: 0.5010 - categorical_accuracy: 0.7581 - val_loss: 0.7798 - val_categorical_accuracy: 0.5523
Epoch 5/100
  1/154 [..............................] - ETA: 0s - loss: 0.4605 - categorical_accuracy: 0.8000 23/154 [===>..........................] - ETA: 0s - loss: 0.4245 - categorical_accuracy: 0.8237 45/154 [=======>......................] - ETA: 0s - loss: 0.4171 - categorical_accuracy: 0.8212 68/154 [============>.................] - ETA: 0s - loss: 0.4128 - categorical_accuracy: 0.8200 90/154 [================>.............] - ETA: 0s - loss: 0.4118 - categorical_accuracy: 0.8185113/154 [=====================>........] - ETA: 0s - loss: 0.4124 - categorical_accuracy: 0.8162136/154 [=========================>....] - ETA: 0s - loss: 0.4135 - categorical_accuracy: 0.8142154/154 [==============================] - 0s 2ms/step - loss: 0.4149 - categorical_accuracy: 0.8127 - val_loss: 0.8900 - val_categorical_accuracy: 0.5335
Epoch 6/100
  1/154 [..............................] - ETA: 0s - loss: 0.2931 - categorical_accuracy: 0.9000 23/154 [===>..........................] - ETA: 0s - loss: 0.3327 - categorical_accuracy: 0.8658 46/154 [=======>......................] - ETA: 0s - loss: 0.3324 - categorical_accuracy: 0.8617 68/154 [============>.................] - ETA: 0s - loss: 0.3338 - categorical_accuracy: 0.8584 90/154 [================>.............] - ETA: 0s - loss: 0.3360 - categorical_accuracy: 0.8559113/154 [=====================>........] - ETA: 0s - loss: 0.3385 - categorical_accuracy: 0.8537136/154 [=========================>....] - ETA: 0s - loss: 0.3414 - categorical_accuracy: 0.8514154/154 [==============================] - 0s 2ms/step - loss: 0.3437 - categorical_accuracy: 0.8497 - val_loss: 0.9968 - val_categorical_accuracy: 0.5347
Epoch 7/100
  1/154 [..............................] - ETA: 0s - loss: 0.3107 - categorical_accuracy: 0.8400 23/154 [===>..........................] - ETA: 0s - loss: 0.2919 - categorical_accuracy: 0.8658 45/154 [=======>......................] - ETA: 0s - loss: 0.2950 - categorical_accuracy: 0.8670 68/154 [============>.................] - ETA: 0s - loss: 0.2983 - categorical_accuracy: 0.8664 91/154 [================>.............] - ETA: 0s - loss: 0.2985 - categorical_accuracy: 0.8667113/154 [=====================>........] - ETA: 0s - loss: 0.2988 - categorical_accuracy: 0.8669132/154 [========================>.....] - ETA: 0s - loss: 0.2996 - categorical_accuracy: 0.8667153/154 [============================>.] - ETA: 0s - loss: 0.3007 - categorical_accuracy: 0.8663154/154 [==============================] - 0s 3ms/step - loss: 0.3008 - categorical_accuracy: 0.8663 - val_loss: 1.0880 - val_categorical_accuracy: 0.5235
Epoch 8/100
  1/154 [..............................] - ETA: 0s - loss: 0.2440 - categorical_accuracy: 0.9200 23/154 [===>..........................] - ETA: 0s - loss: 0.2245 - categorical_accuracy: 0.9064 45/154 [=======>......................] - ETA: 0s - loss: 0.2297 - categorical_accuracy: 0.9036 68/154 [============>.................] - ETA: 0s - loss: 0.2337 - categorical_accuracy: 0.9015 91/154 [================>.............] - ETA: 0s - loss: 0.2384 - categorical_accuracy: 0.8998114/154 [=====================>........] - ETA: 0s - loss: 0.2428 - categorical_accuracy: 0.8980135/154 [=========================>....] - ETA: 0s - loss: 0.2465 - categorical_accuracy: 0.8964154/154 [==============================] - 0s 3ms/step - loss: 0.2494 - categorical_accuracy: 0.8951 - val_loss: 1.1862 - val_categorical_accuracy: 0.5294
Epoch 00008: early stopping
Experiment:  141  Set:  bs1 Train Labels:  nnar10 Test Labels:  clean
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.50      0.56     10699
           1       0.40      0.53      0.45      6544

    accuracy                           0.51     17243
   macro avg       0.52      0.52      0.51     17243
weighted avg       0.55      0.51      0.52     17243

Confusion Matrix for this model: 
 [[5366 5333]
 [3055 3489]]
Experiment:  142  Set:  bs1 Train Labels:  nnar10 Test Labels:  ncar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.62      0.50      0.56     10457
           1       0.41      0.53      0.46      6786

    accuracy                           0.51     17243
   macro avg       0.52      0.52      0.51     17243
weighted avg       0.54      0.51      0.52     17243

Confusion Matrix for this model: 
 [[5243 5214]
 [3178 3608]]
Experiment:  143  Set:  bs1 Train Labels:  nnar10 Test Labels:  ncar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.61      0.50      0.55     10234
           1       0.42      0.53      0.47      7009

    accuracy                           0.51     17243
   macro avg       0.51      0.51      0.51     17243
weighted avg       0.53      0.51      0.51     17243

Confusion Matrix for this model: 
 [[5107 5127]
 [3314 3695]]
Experiment:  144  Set:  bs1 Train Labels:  nnar10 Test Labels:  nar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.58      0.50      0.54      9738
           1       0.45      0.53      0.49      7505

    accuracy                           0.51     17243
   macro avg       0.51      0.51      0.51     17243
weighted avg       0.52      0.51      0.52     17243

Confusion Matrix for this model: 
 [[4881 4857]
 [3540 3965]]
Experiment:  145  Set:  bs1 Train Labels:  nnar10 Test Labels:  nar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.52      0.50      0.51      8829
           1       0.50      0.52      0.51      8414

    accuracy                           0.51     17243
   macro avg       0.51      0.51      0.51     17243
weighted avg       0.51      0.51      0.51     17243

Confusion Matrix for this model: 
 [[4408 4421]
 [4013 4401]]
Experiment:  146  Set:  bs1 Train Labels:  nnar10 Test Labels:  nnar5
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.50      0.56     10699
           1       0.40      0.53      0.45      6544

    accuracy                           0.51     17243
   macro avg       0.52      0.52      0.51     17243
weighted avg       0.55      0.51      0.52     17243

Confusion Matrix for this model: 
 [[5366 5333]
 [3055 3489]]
Experiment:  147  Set:  bs1 Train Labels:  nnar10 Test Labels:  nnar10
Shape of X_train:  (17020, 1, 1000)
Shape of X_test:  (17243, 1, 1000)
Shape of y_train:  (17020, 2)
Shape of y_test:  (17243, 2)
NUM_INSTANCES is  17020
instances should be  17020
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.50      0.56     10699
           1       0.40      0.53      0.45      6544

    accuracy                           0.51     17243
   macro avg       0.52      0.52      0.51     17243
weighted avg       0.55      0.51      0.52     17243

Confusion Matrix for this model: 
 [[5366 5333]
 [3055 3489]]
Input Shape:  (2467, 2, 1000)
Model: "sequential_21"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_21 (LSTM)               (None, 32)                132224    
_________________________________________________________________
dropout_21 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_84 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_85 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_86 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_87 (Dense)             (None, 2)                 130       
=================================================================
Total params: 161,346
Trainable params: 161,346
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/23 [>.............................] - ETA: 22s - loss: 0.6627 - categorical_accuracy: 0.800017/23 [=====================>........] - ETA: 0s - loss: 0.5983 - categorical_accuracy: 0.7563 23/23 [==============================] - 1s 16ms/step - loss: 0.5929 - categorical_accuracy: 0.7532 - val_loss: 0.6579 - val_categorical_accuracy: 0.6599
Epoch 2/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6571 - categorical_accuracy: 0.680018/23 [======================>.......] - ETA: 0s - loss: 0.5778 - categorical_accuracy: 0.736323/23 [==============================] - 0s 4ms/step - loss: 0.5737 - categorical_accuracy: 0.7391 - val_loss: 0.6380 - val_categorical_accuracy: 0.6599
Epoch 3/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5829 - categorical_accuracy: 0.730018/23 [======================>.......] - ETA: 0s - loss: 0.5522 - categorical_accuracy: 0.752923/23 [==============================] - 0s 4ms/step - loss: 0.5528 - categorical_accuracy: 0.7516 - val_loss: 0.6392 - val_categorical_accuracy: 0.6599
Epoch 4/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5196 - categorical_accuracy: 0.770018/23 [======================>.......] - ETA: 0s - loss: 0.5580 - categorical_accuracy: 0.736423/23 [==============================] - 0s 4ms/step - loss: 0.5551 - categorical_accuracy: 0.7388 - val_loss: 0.6639 - val_categorical_accuracy: 0.6599
Epoch 5/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5866 - categorical_accuracy: 0.700018/23 [======================>.......] - ETA: 0s - loss: 0.5314 - categorical_accuracy: 0.749623/23 [==============================] - 0s 4ms/step - loss: 0.5347 - categorical_accuracy: 0.7486 - val_loss: 0.6347 - val_categorical_accuracy: 0.6599
Epoch 6/100
 1/23 [>.............................] - ETA: 0s - loss: 0.4925 - categorical_accuracy: 0.780019/23 [=======================>......] - ETA: 0s - loss: 0.5302 - categorical_accuracy: 0.751823/23 [==============================] - 0s 4ms/step - loss: 0.5323 - categorical_accuracy: 0.7507 - val_loss: 0.6473 - val_categorical_accuracy: 0.6599
Epoch 7/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5003 - categorical_accuracy: 0.740019/23 [=======================>......] - ETA: 0s - loss: 0.5398 - categorical_accuracy: 0.734223/23 [==============================] - 0s 4ms/step - loss: 0.5382 - categorical_accuracy: 0.7368 - val_loss: 0.6510 - val_categorical_accuracy: 0.6599
Epoch 8/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6203 - categorical_accuracy: 0.650019/23 [=======================>......] - ETA: 0s - loss: 0.5403 - categorical_accuracy: 0.736623/23 [==============================] - 0s 4ms/step - loss: 0.5381 - categorical_accuracy: 0.7391 - val_loss: 0.6308 - val_categorical_accuracy: 0.6599
Epoch 9/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5407 - categorical_accuracy: 0.750018/23 [======================>.......] - ETA: 0s - loss: 0.5209 - categorical_accuracy: 0.760523/23 [==============================] - 0s 4ms/step - loss: 0.5229 - categorical_accuracy: 0.7574 - val_loss: 0.6190 - val_categorical_accuracy: 0.6518
Epoch 10/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5470 - categorical_accuracy: 0.750018/23 [======================>.......] - ETA: 0s - loss: 0.5398 - categorical_accuracy: 0.756723/23 [==============================] - 0s 4ms/step - loss: 0.5401 - categorical_accuracy: 0.7543 - val_loss: 0.6272 - val_categorical_accuracy: 0.6599
Epoch 11/100
 1/23 [>.............................] - ETA: 0s - loss: 0.4861 - categorical_accuracy: 0.820019/23 [=======================>......] - ETA: 0s - loss: 0.5361 - categorical_accuracy: 0.749523/23 [==============================] - 0s 4ms/step - loss: 0.5349 - categorical_accuracy: 0.7486 - val_loss: 0.6875 - val_categorical_accuracy: 0.6599
Epoch 12/100
 1/23 [>.............................] - ETA: 0s - loss: 0.4431 - categorical_accuracy: 0.790019/23 [=======================>......] - ETA: 0s - loss: 0.5052 - categorical_accuracy: 0.767923/23 [==============================] - 0s 4ms/step - loss: 0.5108 - categorical_accuracy: 0.7637 - val_loss: 0.6496 - val_categorical_accuracy: 0.6599
Epoch 13/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6142 - categorical_accuracy: 0.680018/23 [======================>.......] - ETA: 0s - loss: 0.5362 - categorical_accuracy: 0.736423/23 [==============================] - 0s 4ms/step - loss: 0.5331 - categorical_accuracy: 0.7391 - val_loss: 0.6646 - val_categorical_accuracy: 0.6599
Epoch 14/100
 1/23 [>.............................] - ETA: 0s - loss: 0.4727 - categorical_accuracy: 0.780018/23 [======================>.......] - ETA: 0s - loss: 0.5029 - categorical_accuracy: 0.761923/23 [==============================] - 0s 4ms/step - loss: 0.5067 - categorical_accuracy: 0.7586 - val_loss: 0.6340 - val_categorical_accuracy: 0.6599
Epoch 15/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5089 - categorical_accuracy: 0.750018/23 [======================>.......] - ETA: 0s - loss: 0.5096 - categorical_accuracy: 0.755223/23 [==============================] - 0s 4ms/step - loss: 0.5116 - categorical_accuracy: 0.7526 - val_loss: 0.6815 - val_categorical_accuracy: 0.6599
Epoch 16/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5706 - categorical_accuracy: 0.690018/23 [======================>.......] - ETA: 0s - loss: 0.5209 - categorical_accuracy: 0.745823/23 [==============================] - 0s 4ms/step - loss: 0.5196 - categorical_accuracy: 0.7472 - val_loss: 0.6352 - val_categorical_accuracy: 0.6599
Epoch 00016: early stopping
Experiment:  148  Set:  bs2 Train Labels:  clean Test Labels:  clean
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       348
           1       0.55      1.00      0.71       420

    accuracy                           0.55       768
   macro avg       0.27      0.50      0.35       768
weighted avg       0.30      0.55      0.39       768

Confusion Matrix for this model: 
 [[  0 348]
 [  0 420]]
Experiment:  149  Set:  bs2 Train Labels:  clean Test Labels:  ncar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       355
           1       0.54      1.00      0.70       413

    accuracy                           0.54       768
   macro avg       0.27      0.50      0.35       768
weighted avg       0.29      0.54      0.38       768

Confusion Matrix for this model: 
 [[  0 355]
 [  0 413]]
Experiment:  150  Set:  bs2 Train Labels:  clean Test Labels:  ncar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       338
           1       0.56      1.00      0.72       430

    accuracy                           0.56       768
   macro avg       0.28      0.50      0.36       768
weighted avg       0.31      0.56      0.40       768

Confusion Matrix for this model: 
 [[  0 338]
 [  0 430]]
Experiment:  151  Set:  bs2 Train Labels:  clean Test Labels:  nar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       390
           1       0.49      1.00      0.66       378

    accuracy                           0.49       768
   macro avg       0.25      0.50      0.33       768
weighted avg       0.24      0.49      0.32       768

Confusion Matrix for this model: 
 [[  0 390]
 [  0 378]]
Experiment:  152  Set:  bs2 Train Labels:  clean Test Labels:  nar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       432
           1       0.44      1.00      0.61       336

    accuracy                           0.44       768
   macro avg       0.22      0.50      0.30       768
weighted avg       0.19      0.44      0.27       768

Confusion Matrix for this model: 
 [[  0 432]
 [  0 336]]
Experiment:  153  Set:  bs2 Train Labels:  clean Test Labels:  nnar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       372
           1       0.52      1.00      0.68       396

    accuracy                           0.52       768
   macro avg       0.26      0.50      0.34       768
weighted avg       0.27      0.52      0.35       768

Confusion Matrix for this model: 
 [[  0 372]
 [  0 396]]
Experiment:  154  Set:  bs2 Train Labels:  clean Test Labels:  nnar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       421
           1       0.45      1.00      0.62       347

    accuracy                           0.45       768
   macro avg       0.23      0.50      0.31       768
weighted avg       0.20      0.45      0.28       768

Confusion Matrix for this model: 
 [[  0 421]
 [  0 347]]
Input Shape:  (2467, 2, 1000)
Model: "sequential_22"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_22 (LSTM)               (None, 32)                132224    
_________________________________________________________________
dropout_22 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_88 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_89 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_90 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_91 (Dense)             (None, 2)                 130       
=================================================================
Total params: 161,346
Trainable params: 161,346
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/23 [>.............................] - ETA: 23s - loss: 0.6825 - categorical_accuracy: 0.660018/23 [======================>.......] - ETA: 0s - loss: 0.6131 - categorical_accuracy: 0.7136 23/23 [==============================] - 1s 17ms/step - loss: 0.6064 - categorical_accuracy: 0.7185 - val_loss: 0.6499 - val_categorical_accuracy: 0.6559
Epoch 2/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6230 - categorical_accuracy: 0.690018/23 [======================>.......] - ETA: 0s - loss: 0.5747 - categorical_accuracy: 0.740223/23 [==============================] - 0s 4ms/step - loss: 0.5755 - categorical_accuracy: 0.7387 - val_loss: 0.6420 - val_categorical_accuracy: 0.6559
Epoch 3/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6001 - categorical_accuracy: 0.710018/23 [======================>.......] - ETA: 0s - loss: 0.5682 - categorical_accuracy: 0.742223/23 [==============================] - 0s 4ms/step - loss: 0.5691 - categorical_accuracy: 0.7404 - val_loss: 0.6557 - val_categorical_accuracy: 0.6559
Epoch 4/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6098 - categorical_accuracy: 0.700018/23 [======================>.......] - ETA: 0s - loss: 0.5697 - categorical_accuracy: 0.728523/23 [==============================] - 0s 4ms/step - loss: 0.5674 - categorical_accuracy: 0.7300 - val_loss: 0.6447 - val_categorical_accuracy: 0.6559
Epoch 5/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6267 - categorical_accuracy: 0.630017/23 [=====================>........] - ETA: 0s - loss: 0.5666 - categorical_accuracy: 0.716923/23 [==============================] - 0s 4ms/step - loss: 0.5648 - categorical_accuracy: 0.7213 - val_loss: 0.6527 - val_categorical_accuracy: 0.6559
Epoch 6/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5689 - categorical_accuracy: 0.740015/23 [==================>...........] - ETA: 0s - loss: 0.5448 - categorical_accuracy: 0.751323/23 [==============================] - 0s 4ms/step - loss: 0.5489 - categorical_accuracy: 0.7454 - val_loss: 0.6664 - val_categorical_accuracy: 0.6559
Epoch 7/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5225 - categorical_accuracy: 0.770016/23 [===================>..........] - ETA: 0s - loss: 0.5440 - categorical_accuracy: 0.741523/23 [==============================] - 0s 4ms/step - loss: 0.5477 - categorical_accuracy: 0.7397 - val_loss: 0.6244 - val_categorical_accuracy: 0.6559
Epoch 8/100
 1/23 [>.............................] - ETA: 0s - loss: 0.4942 - categorical_accuracy: 0.790017/23 [=====================>........] - ETA: 0s - loss: 0.5330 - categorical_accuracy: 0.739023/23 [==============================] - 0s 4ms/step - loss: 0.5362 - categorical_accuracy: 0.7377 - val_loss: 0.6370 - val_categorical_accuracy: 0.6559
Epoch 9/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5854 - categorical_accuracy: 0.680018/23 [======================>.......] - ETA: 0s - loss: 0.5475 - categorical_accuracy: 0.729023/23 [==============================] - 0s 4ms/step - loss: 0.5480 - categorical_accuracy: 0.7306 - val_loss: 0.6337 - val_categorical_accuracy: 0.6559
Epoch 10/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5945 - categorical_accuracy: 0.740018/23 [======================>.......] - ETA: 0s - loss: 0.5381 - categorical_accuracy: 0.744523/23 [==============================] - 0s 4ms/step - loss: 0.5396 - categorical_accuracy: 0.7425 - val_loss: 0.6240 - val_categorical_accuracy: 0.6559
Epoch 11/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5171 - categorical_accuracy: 0.760018/23 [======================>.......] - ETA: 0s - loss: 0.5357 - categorical_accuracy: 0.739323/23 [==============================] - 0s 4ms/step - loss: 0.5396 - categorical_accuracy: 0.7386 - val_loss: 0.6529 - val_categorical_accuracy: 0.6559
Epoch 12/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5219 - categorical_accuracy: 0.720018/23 [======================>.......] - ETA: 0s - loss: 0.5442 - categorical_accuracy: 0.733423/23 [==============================] - 0s 4ms/step - loss: 0.5446 - categorical_accuracy: 0.7341 - val_loss: 0.6404 - val_categorical_accuracy: 0.6559
Epoch 13/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5506 - categorical_accuracy: 0.690018/23 [======================>.......] - ETA: 0s - loss: 0.5531 - categorical_accuracy: 0.721423/23 [==============================] - 0s 4ms/step - loss: 0.5512 - categorical_accuracy: 0.7249 - val_loss: 0.6348 - val_categorical_accuracy: 0.6559
Epoch 14/100
 1/23 [>.............................] - ETA: 0s - loss: 0.4687 - categorical_accuracy: 0.820018/23 [======================>.......] - ETA: 0s - loss: 0.5354 - categorical_accuracy: 0.750723/23 [==============================] - 0s 4ms/step - loss: 0.5386 - categorical_accuracy: 0.7461 - val_loss: 0.6414 - val_categorical_accuracy: 0.6559
Epoch 15/100
 1/23 [>.............................] - ETA: 0s - loss: 0.4751 - categorical_accuracy: 0.770018/23 [======================>.......] - ETA: 0s - loss: 0.5417 - categorical_accuracy: 0.736223/23 [==============================] - 0s 4ms/step - loss: 0.5429 - categorical_accuracy: 0.7356 - val_loss: 0.6586 - val_categorical_accuracy: 0.6559
Epoch 16/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5787 - categorical_accuracy: 0.710018/23 [======================>.......] - ETA: 0s - loss: 0.5498 - categorical_accuracy: 0.726823/23 [==============================] - 0s 4ms/step - loss: 0.5461 - categorical_accuracy: 0.7290 - val_loss: 0.6521 - val_categorical_accuracy: 0.6559
Epoch 17/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5541 - categorical_accuracy: 0.720019/23 [=======================>......] - ETA: 0s - loss: 0.5476 - categorical_accuracy: 0.727423/23 [==============================] - 0s 4ms/step - loss: 0.5471 - categorical_accuracy: 0.7289 - val_loss: 0.6419 - val_categorical_accuracy: 0.6559
Epoch 00017: early stopping
Experiment:  155  Set:  bs2 Train Labels:  ncar5 Test Labels:  clean
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       348
           1       0.55      1.00      0.71       420

    accuracy                           0.55       768
   macro avg       0.27      0.50      0.35       768
weighted avg       0.30      0.55      0.39       768

Confusion Matrix for this model: 
 [[  0 348]
 [  0 420]]
Experiment:  156  Set:  bs2 Train Labels:  ncar5 Test Labels:  ncar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       355
           1       0.54      1.00      0.70       413

    accuracy                           0.54       768
   macro avg       0.27      0.50      0.35       768
weighted avg       0.29      0.54      0.38       768

Confusion Matrix for this model: 
 [[  0 355]
 [  0 413]]
Experiment:  157  Set:  bs2 Train Labels:  ncar5 Test Labels:  ncar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       338
           1       0.56      1.00      0.72       430

    accuracy                           0.56       768
   macro avg       0.28      0.50      0.36       768
weighted avg       0.31      0.56      0.40       768

Confusion Matrix for this model: 
 [[  0 338]
 [  0 430]]
Experiment:  158  Set:  bs2 Train Labels:  ncar5 Test Labels:  nar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       390
           1       0.49      1.00      0.66       378

    accuracy                           0.49       768
   macro avg       0.25      0.50      0.33       768
weighted avg       0.24      0.49      0.32       768

Confusion Matrix for this model: 
 [[  0 390]
 [  0 378]]
Experiment:  159  Set:  bs2 Train Labels:  ncar5 Test Labels:  nar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       432
           1       0.44      1.00      0.61       336

    accuracy                           0.44       768
   macro avg       0.22      0.50      0.30       768
weighted avg       0.19      0.44      0.27       768

Confusion Matrix for this model: 
 [[  0 432]
 [  0 336]]
Experiment:  160  Set:  bs2 Train Labels:  ncar5 Test Labels:  nnar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       372
           1       0.52      1.00      0.68       396

    accuracy                           0.52       768
   macro avg       0.26      0.50      0.34       768
weighted avg       0.27      0.52      0.35       768

Confusion Matrix for this model: 
 [[  0 372]
 [  0 396]]
Experiment:  161  Set:  bs2 Train Labels:  ncar5 Test Labels:  nnar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       421
           1       0.45      1.00      0.62       347

    accuracy                           0.45       768
   macro avg       0.23      0.50      0.31       768
weighted avg       0.20      0.45      0.28       768

Confusion Matrix for this model: 
 [[  0 421]
 [  0 347]]
Input Shape:  (2467, 2, 1000)
Model: "sequential_23"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_23 (LSTM)               (None, 32)                132224    
_________________________________________________________________
dropout_23 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_92 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_93 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_94 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_95 (Dense)             (None, 2)                 130       
=================================================================
Total params: 161,346
Trainable params: 161,346
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/23 [>.............................] - ETA: 24s - loss: 0.7051 - categorical_accuracy: 0.320018/23 [======================>.......] - ETA: 0s - loss: 0.6504 - categorical_accuracy: 0.6100 23/23 [==============================] - 2s 19ms/step - loss: 0.6436 - categorical_accuracy: 0.6270 - val_loss: 0.6721 - val_categorical_accuracy: 0.6235
Epoch 2/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5788 - categorical_accuracy: 0.730016/23 [===================>..........] - ETA: 0s - loss: 0.6016 - categorical_accuracy: 0.707323/23 [==============================] - 0s 4ms/step - loss: 0.6046 - categorical_accuracy: 0.7045 - val_loss: 0.6571 - val_categorical_accuracy: 0.6235
Epoch 3/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6041 - categorical_accuracy: 0.710017/23 [=====================>........] - ETA: 0s - loss: 0.6114 - categorical_accuracy: 0.693923/23 [==============================] - 0s 4ms/step - loss: 0.6104 - categorical_accuracy: 0.6947 - val_loss: 0.6595 - val_categorical_accuracy: 0.6235
Epoch 4/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5561 - categorical_accuracy: 0.760016/23 [===================>..........] - ETA: 0s - loss: 0.5891 - categorical_accuracy: 0.714623/23 [==============================] - 0s 4ms/step - loss: 0.5931 - categorical_accuracy: 0.7107 - val_loss: 0.6497 - val_categorical_accuracy: 0.6235
Epoch 5/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5919 - categorical_accuracy: 0.690017/23 [=====================>........] - ETA: 0s - loss: 0.5971 - categorical_accuracy: 0.703623/23 [==============================] - 0s 4ms/step - loss: 0.5995 - categorical_accuracy: 0.7023 - val_loss: 0.6480 - val_categorical_accuracy: 0.6235
Epoch 6/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5971 - categorical_accuracy: 0.700017/23 [=====================>........] - ETA: 0s - loss: 0.6014 - categorical_accuracy: 0.695923/23 [==============================] - 0s 4ms/step - loss: 0.6013 - categorical_accuracy: 0.6967 - val_loss: 0.6500 - val_categorical_accuracy: 0.6235
Epoch 7/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6192 - categorical_accuracy: 0.690018/23 [======================>.......] - ETA: 0s - loss: 0.6074 - categorical_accuracy: 0.696223/23 [==============================] - 0s 4ms/step - loss: 0.6064 - categorical_accuracy: 0.6961 - val_loss: 0.6502 - val_categorical_accuracy: 0.6235
Epoch 8/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5718 - categorical_accuracy: 0.710012/23 [==============>...............] - ETA: 0s - loss: 0.6022 - categorical_accuracy: 0.690723/23 [==============================] - 0s 5ms/step - loss: 0.6045 - categorical_accuracy: 0.6906 - val_loss: 0.6942 - val_categorical_accuracy: 0.6235
Epoch 9/100
 1/23 [>.............................] - ETA: 0s - loss: 0.7291 - categorical_accuracy: 0.620015/23 [==================>...........] - ETA: 0s - loss: 0.6421 - categorical_accuracy: 0.667323/23 [==============================] - 0s 4ms/step - loss: 0.6273 - categorical_accuracy: 0.6780 - val_loss: 0.6576 - val_categorical_accuracy: 0.6235
Epoch 10/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6080 - categorical_accuracy: 0.660015/23 [==================>...........] - ETA: 0s - loss: 0.6043 - categorical_accuracy: 0.684623/23 [==============================] - 0s 4ms/step - loss: 0.6017 - categorical_accuracy: 0.6897 - val_loss: 0.6546 - val_categorical_accuracy: 0.6235
Epoch 11/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5759 - categorical_accuracy: 0.690018/23 [======================>.......] - ETA: 0s - loss: 0.5901 - categorical_accuracy: 0.697323/23 [==============================] - 0s 4ms/step - loss: 0.5907 - categorical_accuracy: 0.6976 - val_loss: 0.6604 - val_categorical_accuracy: 0.6235
Epoch 12/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6406 - categorical_accuracy: 0.630015/23 [==================>...........] - ETA: 0s - loss: 0.6036 - categorical_accuracy: 0.685223/23 [==============================] - 0s 4ms/step - loss: 0.5989 - categorical_accuracy: 0.6892 - val_loss: 0.6819 - val_categorical_accuracy: 0.6235
Epoch 00012: early stopping
Experiment:  162  Set:  bs2 Train Labels:  ncar10 Test Labels:  clean
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       348
           1       0.55      1.00      0.71       420

    accuracy                           0.55       768
   macro avg       0.27      0.50      0.35       768
weighted avg       0.30      0.55      0.39       768

Confusion Matrix for this model: 
 [[  0 348]
 [  0 420]]
Experiment:  163  Set:  bs2 Train Labels:  ncar10 Test Labels:  ncar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       355
           1       0.54      1.00      0.70       413

    accuracy                           0.54       768
   macro avg       0.27      0.50      0.35       768
weighted avg       0.29      0.54      0.38       768

Confusion Matrix for this model: 
 [[  0 355]
 [  0 413]]
Experiment:  164  Set:  bs2 Train Labels:  ncar10 Test Labels:  ncar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       338
           1       0.56      1.00      0.72       430

    accuracy                           0.56       768
   macro avg       0.28      0.50      0.36       768
weighted avg       0.31      0.56      0.40       768

Confusion Matrix for this model: 
 [[  0 338]
 [  0 430]]
Experiment:  165  Set:  bs2 Train Labels:  ncar10 Test Labels:  nar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       390
           1       0.49      1.00      0.66       378

    accuracy                           0.49       768
   macro avg       0.25      0.50      0.33       768
weighted avg       0.24      0.49      0.32       768

Confusion Matrix for this model: 
 [[  0 390]
 [  0 378]]
Experiment:  166  Set:  bs2 Train Labels:  ncar10 Test Labels:  nar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       432
           1       0.44      1.00      0.61       336

    accuracy                           0.44       768
   macro avg       0.22      0.50      0.30       768
weighted avg       0.19      0.44      0.27       768

Confusion Matrix for this model: 
 [[  0 432]
 [  0 336]]
Experiment:  167  Set:  bs2 Train Labels:  ncar10 Test Labels:  nnar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       372
           1       0.52      1.00      0.68       396

    accuracy                           0.52       768
   macro avg       0.26      0.50      0.34       768
weighted avg       0.27      0.52      0.35       768

Confusion Matrix for this model: 
 [[  0 372]
 [  0 396]]
Experiment:  168  Set:  bs2 Train Labels:  ncar10 Test Labels:  nnar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       421
           1       0.45      1.00      0.62       347

    accuracy                           0.45       768
   macro avg       0.23      0.50      0.31       768
weighted avg       0.20      0.45      0.28       768

Confusion Matrix for this model: 
 [[  0 421]
 [  0 347]]
Input Shape:  (2467, 2, 1000)
Model: "sequential_24"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_24 (LSTM)               (None, 32)                132224    
_________________________________________________________________
dropout_24 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_96 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_97 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_98 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_99 (Dense)             (None, 2)                 130       
=================================================================
Total params: 161,346
Trainable params: 161,346
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/23 [>.............................] - ETA: 29s - loss: 0.6699 - categorical_accuracy: 0.770017/23 [=====================>........] - ETA: 0s - loss: 0.6275 - categorical_accuracy: 0.7199 23/23 [==============================] - 2s 18ms/step - loss: 0.6275 - categorical_accuracy: 0.7141 - val_loss: 0.7182 - val_categorical_accuracy: 0.5830
Epoch 2/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6255 - categorical_accuracy: 0.690018/23 [======================>.......] - ETA: 0s - loss: 0.6113 - categorical_accuracy: 0.700423/23 [==============================] - 0s 4ms/step - loss: 0.6114 - categorical_accuracy: 0.7001 - val_loss: 0.7013 - val_categorical_accuracy: 0.5830
Epoch 3/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6069 - categorical_accuracy: 0.690017/23 [=====================>........] - ETA: 0s - loss: 0.5998 - categorical_accuracy: 0.703823/23 [==============================] - 0s 4ms/step - loss: 0.6011 - categorical_accuracy: 0.7029 - val_loss: 0.6786 - val_categorical_accuracy: 0.5830
Epoch 4/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6012 - categorical_accuracy: 0.730018/23 [======================>.......] - ETA: 0s - loss: 0.6074 - categorical_accuracy: 0.710123/23 [==============================] - 0s 4ms/step - loss: 0.6088 - categorical_accuracy: 0.7071 - val_loss: 0.6941 - val_categorical_accuracy: 0.5830
Epoch 5/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5773 - categorical_accuracy: 0.730017/23 [=====================>........] - ETA: 0s - loss: 0.5938 - categorical_accuracy: 0.708523/23 [==============================] - 0s 4ms/step - loss: 0.5963 - categorical_accuracy: 0.7048 - val_loss: 0.6921 - val_categorical_accuracy: 0.5830
Epoch 6/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5873 - categorical_accuracy: 0.700018/23 [======================>.......] - ETA: 0s - loss: 0.5898 - categorical_accuracy: 0.712623/23 [==============================] - 0s 4ms/step - loss: 0.5937 - categorical_accuracy: 0.7087 - val_loss: 0.6954 - val_categorical_accuracy: 0.5830
Epoch 7/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5609 - categorical_accuracy: 0.750018/23 [======================>.......] - ETA: 0s - loss: 0.5885 - categorical_accuracy: 0.708623/23 [==============================] - 0s 4ms/step - loss: 0.5910 - categorical_accuracy: 0.7060 - val_loss: 0.6868 - val_categorical_accuracy: 0.5830
Epoch 8/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5823 - categorical_accuracy: 0.700016/23 [===================>..........] - ETA: 0s - loss: 0.5899 - categorical_accuracy: 0.706723/23 [==============================] - 0s 4ms/step - loss: 0.5913 - categorical_accuracy: 0.7047 - val_loss: 0.6909 - val_categorical_accuracy: 0.5830
Epoch 9/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5982 - categorical_accuracy: 0.660017/23 [=====================>........] - ETA: 0s - loss: 0.5977 - categorical_accuracy: 0.688723/23 [==============================] - 0s 4ms/step - loss: 0.5956 - categorical_accuracy: 0.6919 - val_loss: 0.6922 - val_categorical_accuracy: 0.5830
Epoch 10/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6088 - categorical_accuracy: 0.700017/23 [=====================>........] - ETA: 0s - loss: 0.5936 - categorical_accuracy: 0.694423/23 [==============================] - 0s 4ms/step - loss: 0.5914 - categorical_accuracy: 0.6960 - val_loss: 0.6837 - val_categorical_accuracy: 0.5830
Epoch 00010: early stopping
Experiment:  169  Set:  bs2 Train Labels:  nar5 Test Labels:  clean
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       348
           1       0.55      1.00      0.71       420

    accuracy                           0.55       768
   macro avg       0.27      0.50      0.35       768
weighted avg       0.30      0.55      0.39       768

Confusion Matrix for this model: 
 [[  0 348]
 [  0 420]]
Experiment:  170  Set:  bs2 Train Labels:  nar5 Test Labels:  ncar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       355
           1       0.54      1.00      0.70       413

    accuracy                           0.54       768
   macro avg       0.27      0.50      0.35       768
weighted avg       0.29      0.54      0.38       768

Confusion Matrix for this model: 
 [[  0 355]
 [  0 413]]
Experiment:  171  Set:  bs2 Train Labels:  nar5 Test Labels:  ncar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       338
           1       0.56      1.00      0.72       430

    accuracy                           0.56       768
   macro avg       0.28      0.50      0.36       768
weighted avg       0.31      0.56      0.40       768

Confusion Matrix for this model: 
 [[  0 338]
 [  0 430]]
Experiment:  172  Set:  bs2 Train Labels:  nar5 Test Labels:  nar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       390
           1       0.49      1.00      0.66       378

    accuracy                           0.49       768
   macro avg       0.25      0.50      0.33       768
weighted avg       0.24      0.49      0.32       768

Confusion Matrix for this model: 
 [[  0 390]
 [  0 378]]
Experiment:  173  Set:  bs2 Train Labels:  nar5 Test Labels:  nar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       432
           1       0.44      1.00      0.61       336

    accuracy                           0.44       768
   macro avg       0.22      0.50      0.30       768
weighted avg       0.19      0.44      0.27       768

Confusion Matrix for this model: 
 [[  0 432]
 [  0 336]]
Experiment:  174  Set:  bs2 Train Labels:  nar5 Test Labels:  nnar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       372
           1       0.52      1.00      0.68       396

    accuracy                           0.52       768
   macro avg       0.26      0.50      0.34       768
weighted avg       0.27      0.52      0.35       768

Confusion Matrix for this model: 
 [[  0 372]
 [  0 396]]
Experiment:  175  Set:  bs2 Train Labels:  nar5 Test Labels:  nnar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       421
           1       0.45      1.00      0.62       347

    accuracy                           0.45       768
   macro avg       0.23      0.50      0.31       768
weighted avg       0.20      0.45      0.28       768

Confusion Matrix for this model: 
 [[  0 421]
 [  0 347]]
Input Shape:  (2467, 2, 1000)
Model: "sequential_25"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_25 (LSTM)               (None, 32)                132224    
_________________________________________________________________
dropout_25 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_100 (Dense)            (None, 128)               4224      
_________________________________________________________________
dense_101 (Dense)            (None, 128)               16512     
_________________________________________________________________
dense_102 (Dense)            (None, 64)                8256      
_________________________________________________________________
dense_103 (Dense)            (None, 2)                 130       
=================================================================
Total params: 161,346
Trainable params: 161,346
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/23 [>.............................] - ETA: 23s - loss: 0.7131 - categorical_accuracy: 0.390017/23 [=====================>........] - ETA: 0s - loss: 0.6721 - categorical_accuracy: 0.5905 23/23 [==============================] - 1s 17ms/step - loss: 0.6673 - categorical_accuracy: 0.6034 - val_loss: 0.6845 - val_categorical_accuracy: 0.5870
Epoch 2/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6297 - categorical_accuracy: 0.670018/23 [======================>.......] - ETA: 0s - loss: 0.6539 - categorical_accuracy: 0.636423/23 [==============================] - 0s 4ms/step - loss: 0.6528 - categorical_accuracy: 0.6384 - val_loss: 0.6966 - val_categorical_accuracy: 0.5870
Epoch 3/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6424 - categorical_accuracy: 0.650018/23 [======================>.......] - ETA: 0s - loss: 0.6500 - categorical_accuracy: 0.645123/23 [==============================] - 0s 4ms/step - loss: 0.6486 - categorical_accuracy: 0.6455 - val_loss: 0.6801 - val_categorical_accuracy: 0.5870
Epoch 4/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6311 - categorical_accuracy: 0.650018/23 [======================>.......] - ETA: 0s - loss: 0.6433 - categorical_accuracy: 0.630823/23 [==============================] - 0s 4ms/step - loss: 0.6412 - categorical_accuracy: 0.6348 - val_loss: 0.6733 - val_categorical_accuracy: 0.5870
Epoch 5/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6456 - categorical_accuracy: 0.610018/23 [======================>.......] - ETA: 0s - loss: 0.6444 - categorical_accuracy: 0.631523/23 [==============================] - 0s 4ms/step - loss: 0.6437 - categorical_accuracy: 0.6348 - val_loss: 0.6713 - val_categorical_accuracy: 0.5870
Epoch 6/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6328 - categorical_accuracy: 0.620019/23 [=======================>......] - ETA: 0s - loss: 0.6378 - categorical_accuracy: 0.632523/23 [==============================] - 0s 4ms/step - loss: 0.6370 - categorical_accuracy: 0.6350 - val_loss: 0.6881 - val_categorical_accuracy: 0.5870
Epoch 7/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6263 - categorical_accuracy: 0.670019/23 [=======================>......] - ETA: 0s - loss: 0.6303 - categorical_accuracy: 0.650123/23 [==============================] - 0s 4ms/step - loss: 0.6306 - categorical_accuracy: 0.6493 - val_loss: 0.6852 - val_categorical_accuracy: 0.5870
Epoch 8/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6312 - categorical_accuracy: 0.660019/23 [=======================>......] - ETA: 0s - loss: 0.6343 - categorical_accuracy: 0.644923/23 [==============================] - 0s 4ms/step - loss: 0.6347 - categorical_accuracy: 0.6438 - val_loss: 0.6765 - val_categorical_accuracy: 0.5870
Epoch 9/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6061 - categorical_accuracy: 0.650019/23 [=======================>......] - ETA: 0s - loss: 0.6184 - categorical_accuracy: 0.645623/23 [==============================] - 0s 4ms/step - loss: 0.6199 - categorical_accuracy: 0.6445 - val_loss: 0.6801 - val_categorical_accuracy: 0.5992
Epoch 10/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5785 - categorical_accuracy: 0.690018/23 [======================>.......] - ETA: 0s - loss: 0.6159 - categorical_accuracy: 0.662723/23 [==============================] - 0s 4ms/step - loss: 0.6186 - categorical_accuracy: 0.6601 - val_loss: 0.6743 - val_categorical_accuracy: 0.5870
Epoch 11/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6400 - categorical_accuracy: 0.620018/23 [======================>.......] - ETA: 0s - loss: 0.6142 - categorical_accuracy: 0.649323/23 [==============================] - 0s 4ms/step - loss: 0.6161 - categorical_accuracy: 0.6481 - val_loss: 0.6712 - val_categorical_accuracy: 0.5870
Epoch 12/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5969 - categorical_accuracy: 0.670018/23 [======================>.......] - ETA: 0s - loss: 0.6182 - categorical_accuracy: 0.653123/23 [==============================] - 0s 4ms/step - loss: 0.6192 - categorical_accuracy: 0.6527 - val_loss: 0.6764 - val_categorical_accuracy: 0.5951
Epoch 13/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5944 - categorical_accuracy: 0.670019/23 [=======================>......] - ETA: 0s - loss: 0.6132 - categorical_accuracy: 0.665323/23 [==============================] - 0s 4ms/step - loss: 0.6157 - categorical_accuracy: 0.6623 - val_loss: 0.6753 - val_categorical_accuracy: 0.5870
Epoch 14/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6778 - categorical_accuracy: 0.590018/23 [======================>.......] - ETA: 0s - loss: 0.6238 - categorical_accuracy: 0.643923/23 [==============================] - 0s 4ms/step - loss: 0.6234 - categorical_accuracy: 0.6442 - val_loss: 0.6701 - val_categorical_accuracy: 0.5789
Epoch 15/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6672 - categorical_accuracy: 0.620019/23 [=======================>......] - ETA: 0s - loss: 0.6345 - categorical_accuracy: 0.649923/23 [==============================] - 0s 4ms/step - loss: 0.6321 - categorical_accuracy: 0.6509 - val_loss: 0.6789 - val_categorical_accuracy: 0.5830
Epoch 16/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5665 - categorical_accuracy: 0.660018/23 [======================>.......] - ETA: 0s - loss: 0.6026 - categorical_accuracy: 0.654923/23 [==============================] - 0s 4ms/step - loss: 0.6051 - categorical_accuracy: 0.6563 - val_loss: 0.6677 - val_categorical_accuracy: 0.5587
Epoch 17/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6125 - categorical_accuracy: 0.700019/23 [=======================>......] - ETA: 0s - loss: 0.6186 - categorical_accuracy: 0.652023/23 [==============================] - 0s 4ms/step - loss: 0.6168 - categorical_accuracy: 0.6539 - val_loss: 0.7130 - val_categorical_accuracy: 0.5830
Epoch 18/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6606 - categorical_accuracy: 0.600018/23 [======================>.......] - ETA: 0s - loss: 0.6228 - categorical_accuracy: 0.654223/23 [==============================] - 0s 4ms/step - loss: 0.6197 - categorical_accuracy: 0.6582 - val_loss: 0.6921 - val_categorical_accuracy: 0.5911
Epoch 19/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6043 - categorical_accuracy: 0.680019/23 [=======================>......] - ETA: 0s - loss: 0.6080 - categorical_accuracy: 0.661023/23 [==============================] - 0s 4ms/step - loss: 0.6098 - categorical_accuracy: 0.6585 - val_loss: 0.6700 - val_categorical_accuracy: 0.5789
Epoch 20/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6004 - categorical_accuracy: 0.690019/23 [=======================>......] - ETA: 0s - loss: 0.6074 - categorical_accuracy: 0.654323/23 [==============================] - 0s 4ms/step - loss: 0.6080 - categorical_accuracy: 0.6553 - val_loss: 0.7030 - val_categorical_accuracy: 0.5789
Epoch 21/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6545 - categorical_accuracy: 0.570019/23 [=======================>......] - ETA: 0s - loss: 0.6214 - categorical_accuracy: 0.640723/23 [==============================] - 0s 4ms/step - loss: 0.6186 - categorical_accuracy: 0.6451 - val_loss: 0.6874 - val_categorical_accuracy: 0.5830
Epoch 22/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6648 - categorical_accuracy: 0.620019/23 [=======================>......] - ETA: 0s - loss: 0.6117 - categorical_accuracy: 0.666323/23 [==============================] - 0s 4ms/step - loss: 0.6098 - categorical_accuracy: 0.6668 - val_loss: 0.6677 - val_categorical_accuracy: 0.5709
Epoch 23/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5815 - categorical_accuracy: 0.700017/23 [=====================>........] - ETA: 0s - loss: 0.5949 - categorical_accuracy: 0.669623/23 [==============================] - 0s 4ms/step - loss: 0.5953 - categorical_accuracy: 0.6692 - val_loss: 0.6687 - val_categorical_accuracy: 0.5870
Epoch 24/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6042 - categorical_accuracy: 0.590018/23 [======================>.......] - ETA: 0s - loss: 0.6041 - categorical_accuracy: 0.661623/23 [==============================] - 0s 4ms/step - loss: 0.6035 - categorical_accuracy: 0.6631 - val_loss: 0.6793 - val_categorical_accuracy: 0.5992
Epoch 25/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6602 - categorical_accuracy: 0.620018/23 [======================>.......] - ETA: 0s - loss: 0.5972 - categorical_accuracy: 0.663423/23 [==============================] - 0s 4ms/step - loss: 0.5963 - categorical_accuracy: 0.6637 - val_loss: 0.6695 - val_categorical_accuracy: 0.5830
Epoch 26/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5853 - categorical_accuracy: 0.680019/23 [=======================>......] - ETA: 0s - loss: 0.5924 - categorical_accuracy: 0.674423/23 [==============================] - 0s 4ms/step - loss: 0.5911 - categorical_accuracy: 0.6770 - val_loss: 0.6996 - val_categorical_accuracy: 0.5749
Epoch 27/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6472 - categorical_accuracy: 0.640019/23 [=======================>......] - ETA: 0s - loss: 0.5999 - categorical_accuracy: 0.672023/23 [==============================] - 0s 4ms/step - loss: 0.5991 - categorical_accuracy: 0.6707 - val_loss: 0.6680 - val_categorical_accuracy: 0.5668
Epoch 28/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5828 - categorical_accuracy: 0.650017/23 [=====================>........] - ETA: 0s - loss: 0.5948 - categorical_accuracy: 0.664423/23 [==============================] - 0s 4ms/step - loss: 0.5922 - categorical_accuracy: 0.6675 - val_loss: 0.6810 - val_categorical_accuracy: 0.5749
Epoch 29/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5582 - categorical_accuracy: 0.680018/23 [======================>.......] - ETA: 0s - loss: 0.5935 - categorical_accuracy: 0.685623/23 [==============================] - 0s 4ms/step - loss: 0.5925 - categorical_accuracy: 0.6857 - val_loss: 0.6800 - val_categorical_accuracy: 0.5911
Epoch 00029: early stopping
Experiment:  176  Set:  bs2 Train Labels:  nar10 Test Labels:  clean
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.47      0.31      0.37       348
           1       0.55      0.70      0.62       420

    accuracy                           0.53       768
   macro avg       0.51      0.51      0.50       768
weighted avg       0.51      0.53      0.51       768

Confusion Matrix for this model: 
 [[108 240]
 [124 296]]
Experiment:  177  Set:  bs2 Train Labels:  nar10 Test Labels:  ncar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.48      0.32      0.38       355
           1       0.55      0.71      0.62       413

    accuracy                           0.53       768
   macro avg       0.51      0.51      0.50       768
weighted avg       0.52      0.53      0.51       768

Confusion Matrix for this model: 
 [[112 243]
 [120 293]]
Experiment:  178  Set:  bs2 Train Labels:  nar10 Test Labels:  ncar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.49      0.34      0.40       338
           1       0.58      0.73      0.65       430

    accuracy                           0.55       768
   macro avg       0.54      0.53      0.52       768
weighted avg       0.54      0.55      0.54       768

Confusion Matrix for this model: 
 [[114 224]
 [118 312]]
Experiment:  179  Set:  bs2 Train Labels:  nar10 Test Labels:  nar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.51      0.31      0.38       390
           1       0.49      0.70      0.58       378

    accuracy                           0.50       768
   macro avg       0.50      0.50      0.48       768
weighted avg       0.50      0.50      0.48       768

Confusion Matrix for this model: 
 [[119 271]
 [113 265]]
Experiment:  180  Set:  bs2 Train Labels:  nar10 Test Labels:  nar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.58      0.31      0.41       432
           1       0.45      0.71      0.55       336

    accuracy                           0.49       768
   macro avg       0.51      0.51      0.48       768
weighted avg       0.52      0.49      0.47       768

Confusion Matrix for this model: 
 [[135 297]
 [ 97 239]]
Experiment:  181  Set:  bs2 Train Labels:  nar10 Test Labels:  nnar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.51      0.32      0.39       372
           1       0.53      0.71      0.61       396

    accuracy                           0.52       768
   macro avg       0.52      0.51      0.50       768
weighted avg       0.52      0.52      0.50       768

Confusion Matrix for this model: 
 [[118 254]
 [114 282]]
Experiment:  182  Set:  bs2 Train Labels:  nar10 Test Labels:  nnar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.55      0.30      0.39       421
           1       0.45      0.70      0.55       347

    accuracy                           0.48       768
   macro avg       0.50      0.50      0.47       768
weighted avg       0.51      0.48      0.46       768

Confusion Matrix for this model: 
 [[128 293]
 [104 243]]
Input Shape:  (2467, 2, 1000)
Model: "sequential_26"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_26 (LSTM)               (None, 32)                132224    
_________________________________________________________________
dropout_26 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_104 (Dense)            (None, 128)               4224      
_________________________________________________________________
dense_105 (Dense)            (None, 128)               16512     
_________________________________________________________________
dense_106 (Dense)            (None, 64)                8256      
_________________________________________________________________
dense_107 (Dense)            (None, 2)                 130       
=================================================================
Total params: 161,346
Trainable params: 161,346
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/23 [>.............................] - ETA: 22s - loss: 0.6972 - categorical_accuracy: 0.410018/23 [======================>.......] - ETA: 0s - loss: 0.6202 - categorical_accuracy: 0.6721 23/23 [==============================] - 1s 16ms/step - loss: 0.6136 - categorical_accuracy: 0.6838 - val_loss: 0.6703 - val_categorical_accuracy: 0.6478
Epoch 2/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5658 - categorical_accuracy: 0.740018/23 [======================>.......] - ETA: 0s - loss: 0.5609 - categorical_accuracy: 0.749023/23 [==============================] - 0s 4ms/step - loss: 0.5649 - categorical_accuracy: 0.7458 - val_loss: 0.6561 - val_categorical_accuracy: 0.6478
Epoch 3/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6807 - categorical_accuracy: 0.630018/23 [======================>.......] - ETA: 0s - loss: 0.5887 - categorical_accuracy: 0.713623/23 [==============================] - 0s 4ms/step - loss: 0.5837 - categorical_accuracy: 0.7183 - val_loss: 0.6660 - val_categorical_accuracy: 0.6478
Epoch 4/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6264 - categorical_accuracy: 0.680018/23 [======================>.......] - ETA: 0s - loss: 0.5726 - categorical_accuracy: 0.725023/23 [==============================] - 0s 4ms/step - loss: 0.5700 - categorical_accuracy: 0.7275 - val_loss: 0.6382 - val_categorical_accuracy: 0.6478
Epoch 5/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5579 - categorical_accuracy: 0.730018/23 [======================>.......] - ETA: 0s - loss: 0.5595 - categorical_accuracy: 0.729023/23 [==============================] - 0s 4ms/step - loss: 0.5595 - categorical_accuracy: 0.7301 - val_loss: 0.6343 - val_categorical_accuracy: 0.6478
Epoch 6/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5929 - categorical_accuracy: 0.710019/23 [=======================>......] - ETA: 0s - loss: 0.5663 - categorical_accuracy: 0.732023/23 [==============================] - 0s 4ms/step - loss: 0.5641 - categorical_accuracy: 0.7328 - val_loss: 0.6361 - val_categorical_accuracy: 0.6478
Epoch 7/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5260 - categorical_accuracy: 0.750018/23 [======================>.......] - ETA: 0s - loss: 0.5479 - categorical_accuracy: 0.739223/23 [==============================] - 0s 4ms/step - loss: 0.5498 - categorical_accuracy: 0.7377 - val_loss: 0.6307 - val_categorical_accuracy: 0.6478
Epoch 8/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6109 - categorical_accuracy: 0.680019/23 [=======================>......] - ETA: 0s - loss: 0.5603 - categorical_accuracy: 0.719923/23 [==============================] - 0s 4ms/step - loss: 0.5580 - categorical_accuracy: 0.7225 - val_loss: 0.7073 - val_categorical_accuracy: 0.6478
Epoch 9/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5529 - categorical_accuracy: 0.760018/23 [======================>.......] - ETA: 0s - loss: 0.5679 - categorical_accuracy: 0.736523/23 [==============================] - 0s 4ms/step - loss: 0.5661 - categorical_accuracy: 0.7356 - val_loss: 0.6703 - val_categorical_accuracy: 0.6478
Epoch 10/100
 1/23 [>.............................] - ETA: 0s - loss: 0.4663 - categorical_accuracy: 0.800018/23 [======================>.......] - ETA: 0s - loss: 0.5503 - categorical_accuracy: 0.738723/23 [==============================] - 0s 4ms/step - loss: 0.5503 - categorical_accuracy: 0.7374 - val_loss: 0.6344 - val_categorical_accuracy: 0.6478
Epoch 11/100
 1/23 [>.............................] - ETA: 0s - loss: 0.4952 - categorical_accuracy: 0.770019/23 [=======================>......] - ETA: 0s - loss: 0.5436 - categorical_accuracy: 0.732823/23 [==============================] - 0s 4ms/step - loss: 0.5449 - categorical_accuracy: 0.7331 - val_loss: 0.7040 - val_categorical_accuracy: 0.6478
Epoch 12/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5581 - categorical_accuracy: 0.720019/23 [=======================>......] - ETA: 0s - loss: 0.5556 - categorical_accuracy: 0.733423/23 [==============================] - 0s 4ms/step - loss: 0.5527 - categorical_accuracy: 0.7339 - val_loss: 0.6294 - val_categorical_accuracy: 0.6478
Epoch 13/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5544 - categorical_accuracy: 0.730019/23 [=======================>......] - ETA: 0s - loss: 0.5391 - categorical_accuracy: 0.739723/23 [==============================] - 0s 4ms/step - loss: 0.5387 - categorical_accuracy: 0.7384 - val_loss: 0.6240 - val_categorical_accuracy: 0.6478
Epoch 14/100
 1/23 [>.............................] - ETA: 0s - loss: 0.4555 - categorical_accuracy: 0.800019/23 [=======================>......] - ETA: 0s - loss: 0.5254 - categorical_accuracy: 0.740123/23 [==============================] - 0s 4ms/step - loss: 0.5275 - categorical_accuracy: 0.7388 - val_loss: 0.6298 - val_categorical_accuracy: 0.6437
Epoch 15/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5249 - categorical_accuracy: 0.770018/23 [======================>.......] - ETA: 0s - loss: 0.5481 - categorical_accuracy: 0.720023/23 [==============================] - 0s 4ms/step - loss: 0.5437 - categorical_accuracy: 0.7244 - val_loss: 0.6233 - val_categorical_accuracy: 0.6356
Epoch 16/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5114 - categorical_accuracy: 0.760018/23 [======================>.......] - ETA: 0s - loss: 0.5133 - categorical_accuracy: 0.748623/23 [==============================] - 0s 4ms/step - loss: 0.5160 - categorical_accuracy: 0.7453 - val_loss: 0.6157 - val_categorical_accuracy: 0.6559
Epoch 17/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5508 - categorical_accuracy: 0.740018/23 [======================>.......] - ETA: 0s - loss: 0.5273 - categorical_accuracy: 0.740523/23 [==============================] - 0s 4ms/step - loss: 0.5263 - categorical_accuracy: 0.7402 - val_loss: 0.6186 - val_categorical_accuracy: 0.6437
Epoch 18/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5452 - categorical_accuracy: 0.750018/23 [======================>.......] - ETA: 0s - loss: 0.5261 - categorical_accuracy: 0.738023/23 [==============================] - 0s 4ms/step - loss: 0.5253 - categorical_accuracy: 0.7371 - val_loss: 0.6610 - val_categorical_accuracy: 0.6437
Epoch 19/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5067 - categorical_accuracy: 0.760019/23 [=======================>......] - ETA: 0s - loss: 0.5155 - categorical_accuracy: 0.744123/23 [==============================] - 0s 4ms/step - loss: 0.5157 - categorical_accuracy: 0.7436 - val_loss: 0.6187 - val_categorical_accuracy: 0.6680
Epoch 20/100
 1/23 [>.............................] - ETA: 0s - loss: 0.4831 - categorical_accuracy: 0.760019/23 [=======================>......] - ETA: 0s - loss: 0.5058 - categorical_accuracy: 0.746823/23 [==============================] - 0s 4ms/step - loss: 0.5095 - categorical_accuracy: 0.7448 - val_loss: 0.6528 - val_categorical_accuracy: 0.6559
Epoch 21/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5349 - categorical_accuracy: 0.730018/23 [======================>.......] - ETA: 0s - loss: 0.5243 - categorical_accuracy: 0.732123/23 [==============================] - 0s 4ms/step - loss: 0.5219 - categorical_accuracy: 0.7340 - val_loss: 0.6836 - val_categorical_accuracy: 0.6518
Epoch 22/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5044 - categorical_accuracy: 0.750017/23 [=====================>........] - ETA: 0s - loss: 0.4923 - categorical_accuracy: 0.751623/23 [==============================] - 0s 4ms/step - loss: 0.4981 - categorical_accuracy: 0.7495 - val_loss: 0.6469 - val_categorical_accuracy: 0.6437
Epoch 23/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5530 - categorical_accuracy: 0.700019/23 [=======================>......] - ETA: 0s - loss: 0.5237 - categorical_accuracy: 0.726623/23 [==============================] - 0s 4ms/step - loss: 0.5210 - categorical_accuracy: 0.7301 - val_loss: 0.6835 - val_categorical_accuracy: 0.6518
Epoch 00023: early stopping
Experiment:  183  Set:  bs2 Train Labels:  nnar5 Test Labels:  clean
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.44      0.05      0.09       348
           1       0.55      0.95      0.69       420

    accuracy                           0.54       768
   macro avg       0.49      0.50      0.39       768
weighted avg       0.50      0.54      0.42       768

Confusion Matrix for this model: 
 [[ 18 330]
 [ 23 397]]
Experiment:  184  Set:  bs2 Train Labels:  nnar5 Test Labels:  ncar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.49      0.06      0.10       355
           1       0.54      0.95      0.69       413

    accuracy                           0.54       768
   macro avg       0.51      0.50      0.39       768
weighted avg       0.52      0.54      0.42       768

Confusion Matrix for this model: 
 [[ 20 335]
 [ 21 392]]
Experiment:  185  Set:  bs2 Train Labels:  nnar5 Test Labels:  ncar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.37      0.04      0.08       338
           1       0.56      0.94      0.70       430

    accuracy                           0.55       768
   macro avg       0.46      0.49      0.39       768
weighted avg       0.47      0.55      0.43       768

Confusion Matrix for this model: 
 [[ 15 323]
 [ 26 404]]
Experiment:  186  Set:  bs2 Train Labels:  nnar5 Test Labels:  nar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.46      0.05      0.09       390
           1       0.49      0.94      0.64       378

    accuracy                           0.49       768
   macro avg       0.48      0.50      0.37       768
weighted avg       0.48      0.49      0.36       768

Confusion Matrix for this model: 
 [[ 19 371]
 [ 22 356]]
Experiment:  187  Set:  bs2 Train Labels:  nnar5 Test Labels:  nar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.59      0.06      0.10       432
           1       0.44      0.95      0.60       336

    accuracy                           0.45       768
   macro avg       0.51      0.50      0.35       768
weighted avg       0.52      0.45      0.32       768

Confusion Matrix for this model: 
 [[ 24 408]
 [ 17 319]]
Experiment:  188  Set:  bs2 Train Labels:  nnar5 Test Labels:  nnar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.49      0.05      0.10       372
           1       0.52      0.95      0.67       396

    accuracy                           0.51       768
   macro avg       0.50      0.50      0.38       768
weighted avg       0.50      0.51      0.39       768

Confusion Matrix for this model: 
 [[ 20 352]
 [ 21 375]]
Experiment:  189  Set:  bs2 Train Labels:  nnar5 Test Labels:  nnar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.51      0.05      0.09       421
           1       0.45      0.94      0.61       347

    accuracy                           0.45       768
   macro avg       0.48      0.50      0.35       768
weighted avg       0.48      0.45      0.32       768

Confusion Matrix for this model: 
 [[ 21 400]
 [ 20 327]]
Input Shape:  (2467, 2, 1000)
Model: "sequential_27"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_27 (LSTM)               (None, 32)                132224    
_________________________________________________________________
dropout_27 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_108 (Dense)            (None, 128)               4224      
_________________________________________________________________
dense_109 (Dense)            (None, 128)               16512     
_________________________________________________________________
dense_110 (Dense)            (None, 64)                8256      
_________________________________________________________________
dense_111 (Dense)            (None, 2)                 130       
=================================================================
Total params: 161,346
Trainable params: 161,346
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/23 [>.............................] - ETA: 24s - loss: 0.7106 - categorical_accuracy: 0.340017/23 [=====================>........] - ETA: 0s - loss: 0.6642 - categorical_accuracy: 0.5930 23/23 [==============================] - 1s 16ms/step - loss: 0.6614 - categorical_accuracy: 0.6056 - val_loss: 0.6895 - val_categorical_accuracy: 0.5830
Epoch 2/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6440 - categorical_accuracy: 0.650018/23 [======================>.......] - ETA: 0s - loss: 0.6419 - categorical_accuracy: 0.657823/23 [==============================] - 0s 4ms/step - loss: 0.6424 - categorical_accuracy: 0.6572 - val_loss: 0.6832 - val_categorical_accuracy: 0.5830
Epoch 3/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6345 - categorical_accuracy: 0.650018/23 [======================>.......] - ETA: 0s - loss: 0.6308 - categorical_accuracy: 0.668423/23 [==============================] - 0s 4ms/step - loss: 0.6336 - categorical_accuracy: 0.6647 - val_loss: 0.6763 - val_categorical_accuracy: 0.5830
Epoch 4/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5963 - categorical_accuracy: 0.730018/23 [======================>.......] - ETA: 0s - loss: 0.6350 - categorical_accuracy: 0.667023/23 [==============================] - 0s 4ms/step - loss: 0.6358 - categorical_accuracy: 0.6641 - val_loss: 0.6950 - val_categorical_accuracy: 0.5830
Epoch 5/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5970 - categorical_accuracy: 0.690017/23 [=====================>........] - ETA: 0s - loss: 0.6370 - categorical_accuracy: 0.651323/23 [==============================] - 0s 4ms/step - loss: 0.6372 - categorical_accuracy: 0.6524 - val_loss: 0.6729 - val_categorical_accuracy: 0.5830
Epoch 6/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6325 - categorical_accuracy: 0.660018/23 [======================>.......] - ETA: 0s - loss: 0.6430 - categorical_accuracy: 0.641123/23 [==============================] - 0s 4ms/step - loss: 0.6396 - categorical_accuracy: 0.6444 - val_loss: 0.7043 - val_categorical_accuracy: 0.5830
Epoch 7/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5314 - categorical_accuracy: 0.750019/23 [=======================>......] - ETA: 0s - loss: 0.6263 - categorical_accuracy: 0.661723/23 [==============================] - 0s 4ms/step - loss: 0.6282 - categorical_accuracy: 0.6602 - val_loss: 0.6842 - val_categorical_accuracy: 0.5830
Epoch 8/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5583 - categorical_accuracy: 0.750019/23 [=======================>......] - ETA: 0s - loss: 0.6173 - categorical_accuracy: 0.668723/23 [==============================] - 0s 4ms/step - loss: 0.6192 - categorical_accuracy: 0.6658 - val_loss: 0.6830 - val_categorical_accuracy: 0.5830
Epoch 9/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6717 - categorical_accuracy: 0.560019/23 [=======================>......] - ETA: 0s - loss: 0.6276 - categorical_accuracy: 0.637423/23 [==============================] - 0s 4ms/step - loss: 0.6265 - categorical_accuracy: 0.6415 - val_loss: 0.6829 - val_categorical_accuracy: 0.5830
Epoch 10/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6654 - categorical_accuracy: 0.600019/23 [=======================>......] - ETA: 0s - loss: 0.6337 - categorical_accuracy: 0.647123/23 [==============================] - 0s 4ms/step - loss: 0.6330 - categorical_accuracy: 0.6485 - val_loss: 0.6730 - val_categorical_accuracy: 0.5789
Epoch 11/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6122 - categorical_accuracy: 0.680018/23 [======================>.......] - ETA: 0s - loss: 0.6192 - categorical_accuracy: 0.667123/23 [==============================] - 0s 4ms/step - loss: 0.6215 - categorical_accuracy: 0.6644 - val_loss: 0.6715 - val_categorical_accuracy: 0.5911
Epoch 12/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6520 - categorical_accuracy: 0.630018/23 [======================>.......] - ETA: 0s - loss: 0.6152 - categorical_accuracy: 0.659323/23 [==============================] - 0s 4ms/step - loss: 0.6161 - categorical_accuracy: 0.6573 - val_loss: 0.6743 - val_categorical_accuracy: 0.5870
Epoch 13/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6213 - categorical_accuracy: 0.620019/23 [=======================>......] - ETA: 0s - loss: 0.6034 - categorical_accuracy: 0.668223/23 [==============================] - 0s 4ms/step - loss: 0.6062 - categorical_accuracy: 0.6661 - val_loss: 0.6714 - val_categorical_accuracy: 0.5911
Epoch 14/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6032 - categorical_accuracy: 0.670019/23 [=======================>......] - ETA: 0s - loss: 0.6175 - categorical_accuracy: 0.648823/23 [==============================] - 0s 4ms/step - loss: 0.6178 - categorical_accuracy: 0.6502 - val_loss: 0.6729 - val_categorical_accuracy: 0.5870
Epoch 15/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6771 - categorical_accuracy: 0.570018/23 [======================>.......] - ETA: 0s - loss: 0.6222 - categorical_accuracy: 0.648623/23 [==============================] - 0s 4ms/step - loss: 0.6201 - categorical_accuracy: 0.6510 - val_loss: 0.6914 - val_categorical_accuracy: 0.5830
Epoch 16/100
 1/23 [>.............................] - ETA: 0s - loss: 0.5995 - categorical_accuracy: 0.640019/23 [=======================>......] - ETA: 0s - loss: 0.6075 - categorical_accuracy: 0.653923/23 [==============================] - 0s 4ms/step - loss: 0.6094 - categorical_accuracy: 0.6543 - val_loss: 0.6812 - val_categorical_accuracy: 0.5789
Epoch 17/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6205 - categorical_accuracy: 0.600018/23 [======================>.......] - ETA: 0s - loss: 0.5998 - categorical_accuracy: 0.657623/23 [==============================] - 0s 4ms/step - loss: 0.6020 - categorical_accuracy: 0.6592 - val_loss: 0.6781 - val_categorical_accuracy: 0.5709
Epoch 18/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6344 - categorical_accuracy: 0.670018/23 [======================>.......] - ETA: 0s - loss: 0.6225 - categorical_accuracy: 0.658123/23 [==============================] - 0s 4ms/step - loss: 0.6223 - categorical_accuracy: 0.6568 - val_loss: 0.6800 - val_categorical_accuracy: 0.5749
Epoch 19/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6153 - categorical_accuracy: 0.610018/23 [======================>.......] - ETA: 0s - loss: 0.6175 - categorical_accuracy: 0.656123/23 [==============================] - 0s 4ms/step - loss: 0.6168 - categorical_accuracy: 0.6573 - val_loss: 0.7155 - val_categorical_accuracy: 0.5749
Epoch 20/100
 1/23 [>.............................] - ETA: 0s - loss: 0.6054 - categorical_accuracy: 0.650019/23 [=======================>......] - ETA: 0s - loss: 0.6118 - categorical_accuracy: 0.658123/23 [==============================] - 0s 4ms/step - loss: 0.6121 - categorical_accuracy: 0.6585 - val_loss: 0.6907 - val_categorical_accuracy: 0.5911
Epoch 00020: early stopping
Experiment:  190  Set:  bs2 Train Labels:  nnar10 Test Labels:  clean
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.56      0.07      0.13       348
           1       0.55      0.95      0.70       420

    accuracy                           0.55       768
   macro avg       0.55      0.51      0.41       768
weighted avg       0.55      0.55      0.44       768

Confusion Matrix for this model: 
 [[ 25 323]
 [ 20 400]]
Experiment:  191  Set:  bs2 Train Labels:  nnar10 Test Labels:  ncar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.56      0.07      0.12       355
           1       0.54      0.95      0.69       413

    accuracy                           0.54       768
   macro avg       0.55      0.51      0.41       768
weighted avg       0.55      0.54      0.43       768

Confusion Matrix for this model: 
 [[ 25 330]
 [ 20 393]]
Experiment:  192  Set:  bs2 Train Labels:  nnar10 Test Labels:  ncar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.51      0.07      0.12       338
           1       0.56      0.95      0.71       430

    accuracy                           0.56       768
   macro avg       0.54      0.51      0.41       768
weighted avg       0.54      0.56      0.45       768

Confusion Matrix for this model: 
 [[ 23 315]
 [ 22 408]]
Experiment:  193  Set:  bs2 Train Labels:  nnar10 Test Labels:  nar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.58      0.07      0.12       390
           1       0.50      0.95      0.65       378

    accuracy                           0.50       768
   macro avg       0.54      0.51      0.39       768
weighted avg       0.54      0.50      0.38       768

Confusion Matrix for this model: 
 [[ 26 364]
 [ 19 359]]
Experiment:  194  Set:  bs2 Train Labels:  nnar10 Test Labels:  nar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.67      0.07      0.13       432
           1       0.44      0.96      0.61       336

    accuracy                           0.46       768
   macro avg       0.56      0.51      0.37       768
weighted avg       0.57      0.46      0.34       768

Confusion Matrix for this model: 
 [[ 30 402]
 [ 15 321]]
Experiment:  195  Set:  bs2 Train Labels:  nnar10 Test Labels:  nnar5
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.56      0.07      0.12       372
           1       0.52      0.95      0.67       396

    accuracy                           0.52       768
   macro avg       0.54      0.51      0.40       768
weighted avg       0.54      0.52      0.40       768

Confusion Matrix for this model: 
 [[ 25 347]
 [ 20 376]]
Experiment:  196  Set:  bs2 Train Labels:  nnar10 Test Labels:  nnar10
Shape of X_train:  (2467, 2, 1000)
Shape of X_test:  (768, 2, 1000)
Shape of y_train:  (2467, 2)
Shape of y_test:  (768, 2)
NUM_INSTANCES is  4934
instances should be  2467
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.07      0.12       421
           1       0.46      0.95      0.62       347

    accuracy                           0.47       768
   macro avg       0.55      0.51      0.37       768
weighted avg       0.56      0.47      0.35       768

Confusion Matrix for this model: 
 [[ 29 392]
 [ 16 331]]
Input Shape:  (425, 1, 150)
Model: "sequential_28"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_28 (LSTM)               (None, 32)                23424     
_________________________________________________________________
dropout_28 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_112 (Dense)            (None, 128)               4224      
_________________________________________________________________
dense_113 (Dense)            (None, 128)               16512     
_________________________________________________________________
dense_114 (Dense)            (None, 64)                8256      
_________________________________________________________________
dense_115 (Dense)            (None, 7)                 455       
=================================================================
Total params: 52,871
Trainable params: 52,871
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
1/4 [======>.......................] - ETA: 3s - loss: 1.9491 - categorical_accuracy: 0.15004/4 [==============================] - 1s 104ms/step - loss: 1.9456 - categorical_accuracy: 0.1598 - val_loss: 1.9337 - val_categorical_accuracy: 0.2558
Epoch 2/100
1/4 [======>.......................] - ETA: 0s - loss: 1.9237 - categorical_accuracy: 0.26004/4 [==============================] - 0s 6ms/step - loss: 1.9201 - categorical_accuracy: 0.2583 - val_loss: 1.9129 - val_categorical_accuracy: 0.2558
Epoch 3/100
1/4 [======>.......................] - ETA: 0s - loss: 1.8969 - categorical_accuracy: 0.32004/4 [==============================] - 0s 6ms/step - loss: 1.8969 - categorical_accuracy: 0.2888 - val_loss: 1.8884 - val_categorical_accuracy: 0.3023
Epoch 4/100
1/4 [======>.......................] - ETA: 0s - loss: 1.8639 - categorical_accuracy: 0.30004/4 [==============================] - 0s 6ms/step - loss: 1.8638 - categorical_accuracy: 0.3080 - val_loss: 1.8559 - val_categorical_accuracy: 0.3256
Epoch 5/100
1/4 [======>.......................] - ETA: 0s - loss: 1.8350 - categorical_accuracy: 0.29004/4 [==============================] - 0s 6ms/step - loss: 1.8236 - categorical_accuracy: 0.3250 - val_loss: 1.8073 - val_categorical_accuracy: 0.4186
Epoch 6/100
1/4 [======>.......................] - ETA: 0s - loss: 1.7931 - categorical_accuracy: 0.39004/4 [==============================] - 0s 6ms/step - loss: 1.7762 - categorical_accuracy: 0.4152 - val_loss: 1.7412 - val_categorical_accuracy: 0.3953
Epoch 7/100
1/4 [======>.......................] - ETA: 0s - loss: 1.7013 - categorical_accuracy: 0.56004/4 [==============================] - 0s 6ms/step - loss: 1.6893 - categorical_accuracy: 0.5193 - val_loss: 1.6582 - val_categorical_accuracy: 0.3953
Epoch 8/100
1/4 [======>.......................] - ETA: 0s - loss: 1.6447 - categorical_accuracy: 0.49004/4 [==============================] - 0s 6ms/step - loss: 1.6143 - categorical_accuracy: 0.4895 - val_loss: 1.5515 - val_categorical_accuracy: 0.4186
Epoch 9/100
1/4 [======>.......................] - ETA: 0s - loss: 1.4648 - categorical_accuracy: 0.52004/4 [==============================] - 0s 6ms/step - loss: 1.4586 - categorical_accuracy: 0.5060 - val_loss: 1.4314 - val_categorical_accuracy: 0.3953
Epoch 10/100
1/4 [======>.......................] - ETA: 0s - loss: 1.3201 - categorical_accuracy: 0.52004/4 [==============================] - 0s 6ms/step - loss: 1.3397 - categorical_accuracy: 0.4787 - val_loss: 1.3115 - val_categorical_accuracy: 0.4419
Epoch 11/100
1/4 [======>.......................] - ETA: 0s - loss: 1.2084 - categorical_accuracy: 0.55004/4 [==============================] - 0s 6ms/step - loss: 1.2242 - categorical_accuracy: 0.5343 - val_loss: 1.1928 - val_categorical_accuracy: 0.4651
Epoch 12/100
1/4 [======>.......................] - ETA: 0s - loss: 1.2360 - categorical_accuracy: 0.47004/4 [==============================] - 0s 7ms/step - loss: 1.1418 - categorical_accuracy: 0.5620 - val_loss: 1.1000 - val_categorical_accuracy: 0.5116
Epoch 13/100
1/4 [======>.......................] - ETA: 0s - loss: 1.0029 - categorical_accuracy: 0.62004/4 [==============================] - 0s 6ms/step - loss: 1.0071 - categorical_accuracy: 0.5981 - val_loss: 1.0073 - val_categorical_accuracy: 0.5814
Epoch 14/100
1/4 [======>.......................] - ETA: 0s - loss: 0.9611 - categorical_accuracy: 0.63004/4 [==============================] - 0s 6ms/step - loss: 0.9279 - categorical_accuracy: 0.6527 - val_loss: 0.9278 - val_categorical_accuracy: 0.6279
Epoch 15/100
1/4 [======>.......................] - ETA: 0s - loss: 0.8869 - categorical_accuracy: 0.68004/4 [==============================] - 0s 6ms/step - loss: 0.8359 - categorical_accuracy: 0.7008 - val_loss: 0.8617 - val_categorical_accuracy: 0.6279
Epoch 16/100
1/4 [======>.......................] - ETA: 0s - loss: 0.8474 - categorical_accuracy: 0.64004/4 [==============================] - 0s 6ms/step - loss: 0.7740 - categorical_accuracy: 0.6807 - val_loss: 0.8060 - val_categorical_accuracy: 0.6744
Epoch 17/100
1/4 [======>.......................] - ETA: 0s - loss: 0.7159 - categorical_accuracy: 0.70004/4 [==============================] - 0s 6ms/step - loss: 0.6954 - categorical_accuracy: 0.7246 - val_loss: 0.7471 - val_categorical_accuracy: 0.7209
Epoch 18/100
1/4 [======>.......................] - ETA: 0s - loss: 0.6933 - categorical_accuracy: 0.76004/4 [==============================] - 0s 6ms/step - loss: 0.6252 - categorical_accuracy: 0.7833 - val_loss: 0.6980 - val_categorical_accuracy: 0.7442
Epoch 19/100
1/4 [======>.......................] - ETA: 0s - loss: 0.5297 - categorical_accuracy: 0.85004/4 [==============================] - 0s 6ms/step - loss: 0.5475 - categorical_accuracy: 0.8128 - val_loss: 0.6618 - val_categorical_accuracy: 0.7209
Epoch 20/100
1/4 [======>.......................] - ETA: 0s - loss: 0.5619 - categorical_accuracy: 0.79004/4 [==============================] - 0s 6ms/step - loss: 0.5244 - categorical_accuracy: 0.8183 - val_loss: 0.6370 - val_categorical_accuracy: 0.7442
Epoch 21/100
1/4 [======>.......................] - ETA: 0s - loss: 0.4351 - categorical_accuracy: 0.88004/4 [==============================] - 0s 6ms/step - loss: 0.4381 - categorical_accuracy: 0.8568 - val_loss: 0.6540 - val_categorical_accuracy: 0.7209
Epoch 22/100
1/4 [======>.......................] - ETA: 0s - loss: 0.4017 - categorical_accuracy: 0.85004/4 [==============================] - 0s 7ms/step - loss: 0.4218 - categorical_accuracy: 0.8412 - val_loss: 0.6606 - val_categorical_accuracy: 0.7442
Epoch 23/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3584 - categorical_accuracy: 0.87004/4 [==============================] - 0s 6ms/step - loss: 0.3698 - categorical_accuracy: 0.8611 - val_loss: 0.6202 - val_categorical_accuracy: 0.7674
Epoch 24/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3899 - categorical_accuracy: 0.87004/4 [==============================] - 0s 6ms/step - loss: 0.3799 - categorical_accuracy: 0.8586 - val_loss: 0.6394 - val_categorical_accuracy: 0.7674
Epoch 25/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3333 - categorical_accuracy: 0.87004/4 [==============================] - 0s 6ms/step - loss: 0.3412 - categorical_accuracy: 0.8686 - val_loss: 0.6869 - val_categorical_accuracy: 0.7442
Epoch 26/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3327 - categorical_accuracy: 0.88004/4 [==============================] - 0s 6ms/step - loss: 0.3299 - categorical_accuracy: 0.8791 - val_loss: 0.6435 - val_categorical_accuracy: 0.7442
Epoch 27/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3409 - categorical_accuracy: 0.91004/4 [==============================] - 0s 6ms/step - loss: 0.3131 - categorical_accuracy: 0.9097 - val_loss: 0.6439 - val_categorical_accuracy: 0.7674
Epoch 28/100
1/4 [======>.......................] - ETA: 0s - loss: 0.2913 - categorical_accuracy: 0.89004/4 [==============================] - 0s 6ms/step - loss: 0.2686 - categorical_accuracy: 0.9077 - val_loss: 0.7107 - val_categorical_accuracy: 0.7674
Epoch 29/100
1/4 [======>.......................] - ETA: 0s - loss: 0.2438 - categorical_accuracy: 0.92004/4 [==============================] - 0s 6ms/step - loss: 0.2514 - categorical_accuracy: 0.9038 - val_loss: 0.6558 - val_categorical_accuracy: 0.7674
Epoch 30/100
1/4 [======>.......................] - ETA: 0s - loss: 0.2773 - categorical_accuracy: 0.86004/4 [==============================] - 0s 6ms/step - loss: 0.2670 - categorical_accuracy: 0.8862 - val_loss: 0.6401 - val_categorical_accuracy: 0.7674
Epoch 00030: early stopping
Experiment:  197  Set:  har1 Train Labels:  clean Test Labels:  clean
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.52      0.79      0.63        28
           1       0.95      1.00      0.97        35
           3       0.59      0.42      0.49        38
           4       0.32      0.23      0.27        35
           5       0.52      0.47      0.49        30
           6       0.78      0.95      0.85        37

    accuracy                           0.64       203
   macro avg       0.61      0.64      0.62       203
weighted avg       0.62      0.64      0.62       203

Confusion Matrix for this model: 
 [[22  0  0  1  5  0]
 [ 0 35  0  0  0  0]
 [ 5  0 16 16  1  0]
 [ 9  2 11  8  5  0]
 [ 6  0  0  0 14 10]
 [ 0  0  0  0  2 35]]
Experiment:  198  Set:  har1 Train Labels:  clean Test Labels:  ncar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.50      0.81      0.62        26
           1       0.89      0.92      0.90        36
           2       0.00      0.00      0.00         1
           3       0.56      0.38      0.45        39
           4       0.24      0.18      0.21        33
           5       0.52      0.44      0.47        32
           6       0.76      0.94      0.84        36

    accuracy                           0.61       203
   macro avg       0.49      0.52      0.50       203
weighted avg       0.58      0.61      0.58       203

Confusion Matrix for this model: 
 [[21  0  0  0  1  4  0]
 [ 1 33  0  1  0  1  0]
 [ 0  0  0  0  1  0  0]
 [ 4  0  0 15 17  2  1]
 [ 9  2  0 11  6  5  0]
 [ 7  1  0  0  0 14 10]
 [ 0  1  0  0  0  1 34]]
Experiment:  199  Set:  har1 Train Labels:  clean Test Labels:  ncar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.52      0.71      0.60        31
           1       0.86      0.94      0.90        34
           2       0.00      0.00      0.00         3
           3       0.59      0.42      0.49        38
           4       0.32      0.21      0.25        38
           5       0.44      0.48      0.46        25
           6       0.71      0.94      0.81        34

    accuracy                           0.60       203
   macro avg       0.49      0.53      0.50       203
weighted avg       0.57      0.60      0.58       203

Confusion Matrix for this model: 
 [[22  1  0  0  1  5  2]
 [ 1 32  0  0  0  1  0]
 [ 1  0  0  1  0  0  1]
 [ 5  0  0 16 16  1  0]
 [ 9  4  0  9  8  7  1]
 [ 4  0  0  0  0 12  9]
 [ 0  0  0  1  0  1 32]]
Experiment:  200  Set:  har1 Train Labels:  clean Test Labels:  nar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.52      0.79      0.63        28
           1       0.95      1.00      0.97        35
           2       0.00      0.00      0.00         7
           3       0.48      0.42      0.45        31
           4       0.32      0.23      0.27        35
           5       0.52      0.47      0.49        30
           6       0.78      0.95      0.85        37

    accuracy                           0.63       203
   macro avg       0.51      0.55      0.52       203
weighted avg       0.58      0.63      0.60       203

Confusion Matrix for this model: 
 [[22  0  0  0  1  5  0]
 [ 0 35  0  0  0  0  0]
 [ 0  0  0  3  4  0  0]
 [ 5  0  0 13 12  1  0]
 [ 9  2  0 11  8  5  0]
 [ 6  0  0  0  0 14 10]
 [ 0  0  0  0  0  2 35]]
Experiment:  201  Set:  har1 Train Labels:  clean Test Labels:  nar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.52      0.79      0.63        28
           1       0.95      1.00      0.97        35
           2       0.00      0.00      0.00        23
           3       0.22      0.40      0.29        15
           4       0.32      0.23      0.27        35
           5       0.52      0.47      0.49        30
           6       0.78      0.95      0.85        37

    accuracy                           0.59       203
   macro avg       0.47      0.55      0.50       203
weighted avg       0.53      0.59      0.55       203

Confusion Matrix for this model: 
 [[22  0  0  0  1  5  0]
 [ 0 35  0  0  0  0  0]
 [ 2  0  0 10 10  1  0]
 [ 3  0  0  6  6  0  0]
 [ 9  2  0 11  8  5  0]
 [ 6  0  0  0  0 14 10]
 [ 0  0  0  0  0  2 35]]
Experiment:  202  Set:  har1 Train Labels:  clean Test Labels:  nnar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.52      0.79      0.63        28
           1       0.95      1.00      0.97        35
           3       0.44      0.40      0.42        30
           4       0.48      0.28      0.35        43
           5       0.52      0.47      0.49        30
           6       0.78      0.95      0.85        37

    accuracy                           0.64       203
   macro avg       0.62      0.65      0.62       203
weighted avg       0.62      0.64      0.62       203

Confusion Matrix for this model: 
 [[22  0  0  1  5  0]
 [ 0 35  0  0  0  0]
 [ 5  0 12 12  1  0]
 [ 9  2 15 12  5  0]
 [ 6  0  0  0 14 10]
 [ 0  0  0  0  2 35]]
Experiment:  203  Set:  har1 Train Labels:  clean Test Labels:  nnar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.52      0.79      0.63        28
           1       0.95      1.00      0.97        35
           3       0.44      0.40      0.42        30
           4       0.48      0.28      0.35        43
           5       0.52      0.47      0.49        30
           6       0.78      0.95      0.85        37

    accuracy                           0.64       203
   macro avg       0.62      0.65      0.62       203
weighted avg       0.62      0.64      0.62       203

Confusion Matrix for this model: 
 [[22  0  0  1  5  0]
 [ 0 35  0  0  0  0]
 [ 5  0 12 12  1  0]
 [ 9  2 15 12  5  0]
 [ 6  0  0  0 14 10]
 [ 0  0  0  0  2 35]]
Input Shape:  (425, 1, 150)
Model: "sequential_29"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_29 (LSTM)               (None, 32)                23424     
_________________________________________________________________
dropout_29 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_116 (Dense)            (None, 128)               4224      
_________________________________________________________________
dense_117 (Dense)            (None, 128)               16512     
_________________________________________________________________
dense_118 (Dense)            (None, 64)                8256      
_________________________________________________________________
dense_119 (Dense)            (None, 7)                 455       
=================================================================
Total params: 52,871
Trainable params: 52,871
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
1/4 [======>.......................] - ETA: 3s - loss: 1.9572 - categorical_accuracy: 0.06004/4 [==============================] - 1s 99ms/step - loss: 1.9515 - categorical_accuracy: 0.0916 - val_loss: 1.9304 - val_categorical_accuracy: 0.1163
Epoch 2/100
1/4 [======>.......................] - ETA: 0s - loss: 1.9302 - categorical_accuracy: 0.24004/4 [==============================] - 0s 7ms/step - loss: 1.9244 - categorical_accuracy: 0.2584 - val_loss: 1.9140 - val_categorical_accuracy: 0.1628
Epoch 3/100
1/4 [======>.......................] - ETA: 0s - loss: 1.9054 - categorical_accuracy: 0.29004/4 [==============================] - 0s 6ms/step - loss: 1.8996 - categorical_accuracy: 0.2982 - val_loss: 1.8905 - val_categorical_accuracy: 0.2326
Epoch 4/100
1/4 [======>.......................] - ETA: 0s - loss: 1.8796 - categorical_accuracy: 0.29004/4 [==============================] - 0s 6ms/step - loss: 1.8722 - categorical_accuracy: 0.2872 - val_loss: 1.8588 - val_categorical_accuracy: 0.2791
Epoch 5/100
1/4 [======>.......................] - ETA: 0s - loss: 1.8551 - categorical_accuracy: 0.32004/4 [==============================] - 0s 6ms/step - loss: 1.8274 - categorical_accuracy: 0.3486 - val_loss: 1.8159 - val_categorical_accuracy: 0.2791
Epoch 6/100
1/4 [======>.......................] - ETA: 0s - loss: 1.8053 - categorical_accuracy: 0.35004/4 [==============================] - 0s 6ms/step - loss: 1.7791 - categorical_accuracy: 0.3755 - val_loss: 1.7646 - val_categorical_accuracy: 0.3488
Epoch 7/100
1/4 [======>.......................] - ETA: 0s - loss: 1.7224 - categorical_accuracy: 0.38004/4 [==============================] - 0s 6ms/step - loss: 1.7116 - categorical_accuracy: 0.3738 - val_loss: 1.7018 - val_categorical_accuracy: 0.3953
Epoch 8/100
1/4 [======>.......................] - ETA: 0s - loss: 1.6613 - categorical_accuracy: 0.38004/4 [==============================] - 0s 6ms/step - loss: 1.6406 - categorical_accuracy: 0.4045 - val_loss: 1.6261 - val_categorical_accuracy: 0.4884
Epoch 9/100
1/4 [======>.......................] - ETA: 0s - loss: 1.5328 - categorical_accuracy: 0.54004/4 [==============================] - 0s 6ms/step - loss: 1.5435 - categorical_accuracy: 0.4962 - val_loss: 1.5419 - val_categorical_accuracy: 0.4419
Epoch 10/100
1/4 [======>.......................] - ETA: 0s - loss: 1.4833 - categorical_accuracy: 0.55004/4 [==============================] - 0s 6ms/step - loss: 1.4438 - categorical_accuracy: 0.5490 - val_loss: 1.4567 - val_categorical_accuracy: 0.4651
Epoch 11/100
1/4 [======>.......................] - ETA: 0s - loss: 1.3928 - categorical_accuracy: 0.49004/4 [==============================] - 0s 6ms/step - loss: 1.3537 - categorical_accuracy: 0.5588 - val_loss: 1.3732 - val_categorical_accuracy: 0.4419
Epoch 12/100
1/4 [======>.......................] - ETA: 0s - loss: 1.2384 - categorical_accuracy: 0.60004/4 [==============================] - 0s 6ms/step - loss: 1.2449 - categorical_accuracy: 0.5880 - val_loss: 1.3103 - val_categorical_accuracy: 0.5116
Epoch 13/100
1/4 [======>.......................] - ETA: 0s - loss: 1.1466 - categorical_accuracy: 0.62004/4 [==============================] - 0s 6ms/step - loss: 1.1406 - categorical_accuracy: 0.6349 - val_loss: 1.2729 - val_categorical_accuracy: 0.5116
Epoch 14/100
1/4 [======>.......................] - ETA: 0s - loss: 1.1223 - categorical_accuracy: 0.68004/4 [==============================] - 0s 6ms/step - loss: 1.0664 - categorical_accuracy: 0.6902 - val_loss: 1.2232 - val_categorical_accuracy: 0.5116
Epoch 15/100
1/4 [======>.......................] - ETA: 0s - loss: 1.0119 - categorical_accuracy: 0.74004/4 [==============================] - 0s 6ms/step - loss: 1.0030 - categorical_accuracy: 0.6783 - val_loss: 1.1999 - val_categorical_accuracy: 0.5116
Epoch 16/100
1/4 [======>.......................] - ETA: 0s - loss: 0.7737 - categorical_accuracy: 0.72004/4 [==============================] - 0s 6ms/step - loss: 0.8764 - categorical_accuracy: 0.7130 - val_loss: 1.1956 - val_categorical_accuracy: 0.5581
Epoch 17/100
1/4 [======>.......................] - ETA: 0s - loss: 0.8738 - categorical_accuracy: 0.70004/4 [==============================] - 0s 6ms/step - loss: 0.8421 - categorical_accuracy: 0.7195 - val_loss: 1.1759 - val_categorical_accuracy: 0.5814
Epoch 18/100
1/4 [======>.......................] - ETA: 0s - loss: 0.9853 - categorical_accuracy: 0.65004/4 [==============================] - 0s 6ms/step - loss: 0.8540 - categorical_accuracy: 0.7054 - val_loss: 1.1926 - val_categorical_accuracy: 0.5581
Epoch 19/100
1/4 [======>.......................] - ETA: 0s - loss: 0.8260 - categorical_accuracy: 0.74004/4 [==============================] - 0s 6ms/step - loss: 0.7703 - categorical_accuracy: 0.7455 - val_loss: 1.2098 - val_categorical_accuracy: 0.5814
Epoch 20/100
1/4 [======>.......................] - ETA: 0s - loss: 0.7967 - categorical_accuracy: 0.72004/4 [==============================] - 0s 6ms/step - loss: 0.7062 - categorical_accuracy: 0.7569 - val_loss: 1.1642 - val_categorical_accuracy: 0.5814
Epoch 21/100
1/4 [======>.......................] - ETA: 0s - loss: 0.6124 - categorical_accuracy: 0.82004/4 [==============================] - 0s 6ms/step - loss: 0.6191 - categorical_accuracy: 0.7965 - val_loss: 1.1597 - val_categorical_accuracy: 0.5581
Epoch 22/100
1/4 [======>.......................] - ETA: 0s - loss: 0.6275 - categorical_accuracy: 0.78004/4 [==============================] - 0s 6ms/step - loss: 0.6114 - categorical_accuracy: 0.7991 - val_loss: 1.1942 - val_categorical_accuracy: 0.5814
Epoch 23/100
1/4 [======>.......................] - ETA: 0s - loss: 0.6655 - categorical_accuracy: 0.75004/4 [==============================] - 0s 6ms/step - loss: 0.6121 - categorical_accuracy: 0.7860 - val_loss: 1.1756 - val_categorical_accuracy: 0.5581
Epoch 24/100
1/4 [======>.......................] - ETA: 0s - loss: 0.4703 - categorical_accuracy: 0.85004/4 [==============================] - 0s 6ms/step - loss: 0.5106 - categorical_accuracy: 0.8310 - val_loss: 1.1548 - val_categorical_accuracy: 0.5814
Epoch 25/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3568 - categorical_accuracy: 0.85004/4 [==============================] - 0s 6ms/step - loss: 0.4403 - categorical_accuracy: 0.8324 - val_loss: 1.1738 - val_categorical_accuracy: 0.6047
Epoch 26/100
1/4 [======>.......................] - ETA: 0s - loss: 0.4309 - categorical_accuracy: 0.86004/4 [==============================] - 0s 6ms/step - loss: 0.4755 - categorical_accuracy: 0.8441 - val_loss: 1.2071 - val_categorical_accuracy: 0.6279
Epoch 27/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3940 - categorical_accuracy: 0.90004/4 [==============================] - 0s 6ms/step - loss: 0.4298 - categorical_accuracy: 0.8765 - val_loss: 1.2121 - val_categorical_accuracy: 0.6279
Epoch 28/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3960 - categorical_accuracy: 0.87004/4 [==============================] - 0s 6ms/step - loss: 0.3905 - categorical_accuracy: 0.8715 - val_loss: 1.1923 - val_categorical_accuracy: 0.6512
Epoch 29/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3578 - categorical_accuracy: 0.88004/4 [==============================] - 0s 6ms/step - loss: 0.4141 - categorical_accuracy: 0.8642 - val_loss: 1.2491 - val_categorical_accuracy: 0.6512
Epoch 30/100
1/4 [======>.......................] - ETA: 0s - loss: 0.4240 - categorical_accuracy: 0.82004/4 [==============================] - 0s 6ms/step - loss: 0.4050 - categorical_accuracy: 0.8438 - val_loss: 1.2645 - val_categorical_accuracy: 0.6512
Epoch 31/100
1/4 [======>.......................] - ETA: 0s - loss: 0.4056 - categorical_accuracy: 0.86004/4 [==============================] - 0s 7ms/step - loss: 0.3640 - categorical_accuracy: 0.8706 - val_loss: 1.3208 - val_categorical_accuracy: 0.6279
Epoch 00031: early stopping
Experiment:  204  Set:  har1 Train Labels:  ncar5 Test Labels:  clean
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.82      0.81        28
           1       0.92      1.00      0.96        35
           2       0.00      0.00      0.00         0
           3       0.74      0.45      0.56        38
           4       0.55      0.63      0.59        35
           5       0.71      0.57      0.63        30
           6       0.75      0.97      0.85        37

    accuracy                           0.74       203
   macro avg       0.64      0.63      0.63       203
weighted avg       0.74      0.74      0.73       203

Confusion Matrix for this model: 
 [[23  0  1  0  0  4  0]
 [ 0 35  0  0  0  0  0]
 [ 0  0  0  0  0  0  0]
 [ 1  1  0 17 18  0  1]
 [ 2  2  0  6 22  2  1]
 [ 3  0  0  0  0 17 10]
 [ 0  0  0  0  0  1 36]]
Experiment:  205  Set:  har1 Train Labels:  ncar5 Test Labels:  ncar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.72      0.81      0.76        26
           1       0.89      0.94      0.92        36
           2       0.00      0.00      0.00         1
           3       0.70      0.41      0.52        39
           4       0.50      0.61      0.55        33
           5       0.71      0.53      0.61        32
           6       0.71      0.94      0.81        36

    accuracy                           0.70       203
   macro avg       0.60      0.61      0.59       203
weighted avg       0.70      0.70      0.69       203

Confusion Matrix for this model: 
 [[21  0  1  1  0  3  0]
 [ 1 34  0  0  0  1  0]
 [ 0  0  0  0  1  0  0]
 [ 2  0  0 16 19  0  2]
 [ 2  2  0  6 20  2  1]
 [ 3  1  0  0  0 17 11]
 [ 0  1  0  0  0  1 34]]
Experiment:  206  Set:  har1 Train Labels:  ncar5 Test Labels:  ncar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.74      0.77        31
           1       0.84      0.94      0.89        34
           2       0.00      0.00      0.00         3
           3       0.74      0.45      0.56        38
           4       0.50      0.53      0.51        38
           5       0.50      0.48      0.49        25
           6       0.67      0.94      0.78        34

    accuracy                           0.67       203
   macro avg       0.58      0.58      0.57       203
weighted avg       0.67      0.67      0.66       203

Confusion Matrix for this model: 
 [[23  1  1  0  0  5  1]
 [ 0 32  0  0  0  2  0]
 [ 0  1  0  0  1  0  1]
 [ 1  1  0 17 18  0  1]
 [ 2  3  0  6 20  4  3]
 [ 3  0  0  0  0 12 10]
 [ 0  0  0  0  1  1 32]]
Experiment:  207  Set:  har1 Train Labels:  ncar5 Test Labels:  nar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.82      0.81        28
           1       0.92      1.00      0.96        35
           2       0.00      0.00      0.00         7
           3       0.57      0.42      0.48        31
           4       0.55      0.63      0.59        35
           5       0.71      0.57      0.63        30
           6       0.75      0.97      0.85        37

    accuracy                           0.72       203
   macro avg       0.61      0.63      0.62       203
weighted avg       0.69      0.72      0.70       203

Confusion Matrix for this model: 
 [[23  0  1  0  0  4  0]
 [ 0 35  0  0  0  0  0]
 [ 0  0  0  4  3  0  0]
 [ 1  1  0 13 15  0  1]
 [ 2  2  0  6 22  2  1]
 [ 3  0  0  0  0 17 10]
 [ 0  0  0  0  0  1 36]]
Experiment:  208  Set:  har1 Train Labels:  ncar5 Test Labels:  nar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.82      0.81        28
           1       0.92      1.00      0.96        35
           2       0.00      0.00      0.00        23
           3       0.39      0.60      0.47        15
           4       0.55      0.63      0.59        35
           5       0.71      0.57      0.63        30
           6       0.75      0.97      0.85        37

    accuracy                           0.70       203
   macro avg       0.59      0.66      0.61       203
weighted avg       0.63      0.70      0.66       203

Confusion Matrix for this model: 
 [[23  0  1  0  0  4  0]
 [ 0 35  0  0  0  0  0]
 [ 0  1  0  8 13  0  1]
 [ 1  0  0  9  5  0  0]
 [ 2  2  0  6 22  2  1]
 [ 3  0  0  0  0 17 10]
 [ 0  0  0  0  0  1 36]]
Experiment:  209  Set:  har1 Train Labels:  ncar5 Test Labels:  nnar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.82      0.81        28
           1       0.92      1.00      0.96        35
           2       0.00      0.00      0.00         0
           3       0.57      0.43      0.49        30
           4       0.62      0.58      0.60        43
           5       0.71      0.57      0.63        30
           6       0.75      0.97      0.85        37

    accuracy                           0.73       203
   macro avg       0.62      0.63      0.62       203
weighted avg       0.73      0.73      0.72       203

Confusion Matrix for this model: 
 [[23  0  1  0  0  4  0]
 [ 0 35  0  0  0  0  0]
 [ 0  0  0  0  0  0  0]
 [ 1  0  0 13 15  0  1]
 [ 2  3  0 10 25  2  1]
 [ 3  0  0  0  0 17 10]
 [ 0  0  0  0  0  1 36]]
Experiment:  210  Set:  har1 Train Labels:  ncar5 Test Labels:  nnar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.82      0.81        28
           1       0.92      1.00      0.96        35
           2       0.00      0.00      0.00         0
           3       0.57      0.43      0.49        30
           4       0.62      0.58      0.60        43
           5       0.71      0.57      0.63        30
           6       0.75      0.97      0.85        37

    accuracy                           0.73       203
   macro avg       0.62      0.63      0.62       203
weighted avg       0.73      0.73      0.72       203

Confusion Matrix for this model: 
 [[23  0  1  0  0  4  0]
 [ 0 35  0  0  0  0  0]
 [ 0  0  0  0  0  0  0]
 [ 1  0  0 13 15  0  1]
 [ 2  3  0 10 25  2  1]
 [ 3  0  0  0  0 17 10]
 [ 0  0  0  0  0  1 36]]
Input Shape:  (425, 1, 150)
Model: "sequential_30"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_30 (LSTM)               (None, 32)                23424     
_________________________________________________________________
dropout_30 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_120 (Dense)            (None, 128)               4224      
_________________________________________________________________
dense_121 (Dense)            (None, 128)               16512     
_________________________________________________________________
dense_122 (Dense)            (None, 64)                8256      
_________________________________________________________________
dense_123 (Dense)            (None, 7)                 455       
=================================================================
Total params: 52,871
Trainable params: 52,871
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
1/4 [======>.......................] - ETA: 3s - loss: 1.9590 - categorical_accuracy: 0.09004/4 [==============================] - 1s 98ms/step - loss: 1.9501 - categorical_accuracy: 0.1556 - val_loss: 1.9329 - val_categorical_accuracy: 0.2093
Epoch 2/100
1/4 [======>.......................] - ETA: 0s - loss: 1.9252 - categorical_accuracy: 0.31004/4 [==============================] - 0s 6ms/step - loss: 1.9226 - categorical_accuracy: 0.2698 - val_loss: 1.9167 - val_categorical_accuracy: 0.3023
Epoch 3/100
1/4 [======>.......................] - ETA: 0s - loss: 1.9109 - categorical_accuracy: 0.25004/4 [==============================] - 0s 6ms/step - loss: 1.9016 - categorical_accuracy: 0.2870 - val_loss: 1.8991 - val_categorical_accuracy: 0.2558
Epoch 4/100
1/4 [======>.......................] - ETA: 0s - loss: 1.8798 - categorical_accuracy: 0.33004/4 [==============================] - 0s 6ms/step - loss: 1.8737 - categorical_accuracy: 0.3026 - val_loss: 1.8795 - val_categorical_accuracy: 0.2558
Epoch 5/100
1/4 [======>.......................] - ETA: 0s - loss: 1.8487 - categorical_accuracy: 0.31004/4 [==============================] - 0s 6ms/step - loss: 1.8347 - categorical_accuracy: 0.3020 - val_loss: 1.8552 - val_categorical_accuracy: 0.2558
Epoch 6/100
1/4 [======>.......................] - ETA: 0s - loss: 1.8029 - categorical_accuracy: 0.31004/4 [==============================] - 0s 6ms/step - loss: 1.7956 - categorical_accuracy: 0.3067 - val_loss: 1.8300 - val_categorical_accuracy: 0.2326
Epoch 7/100
1/4 [======>.......................] - ETA: 0s - loss: 1.7320 - categorical_accuracy: 0.41004/4 [==============================] - 0s 6ms/step - loss: 1.7285 - categorical_accuracy: 0.3612 - val_loss: 1.8084 - val_categorical_accuracy: 0.2558
Epoch 8/100
1/4 [======>.......................] - ETA: 0s - loss: 1.7195 - categorical_accuracy: 0.32004/4 [==============================] - 0s 6ms/step - loss: 1.6649 - categorical_accuracy: 0.3954 - val_loss: 1.7836 - val_categorical_accuracy: 0.2791
Epoch 9/100
1/4 [======>.......................] - ETA: 0s - loss: 1.5941 - categorical_accuracy: 0.46004/4 [==============================] - 0s 6ms/step - loss: 1.5720 - categorical_accuracy: 0.4602 - val_loss: 1.7583 - val_categorical_accuracy: 0.2791
Epoch 10/100
1/4 [======>.......................] - ETA: 0s - loss: 1.5125 - categorical_accuracy: 0.50004/4 [==============================] - 0s 6ms/step - loss: 1.5103 - categorical_accuracy: 0.4699 - val_loss: 1.7303 - val_categorical_accuracy: 0.2558
Epoch 11/100
1/4 [======>.......................] - ETA: 0s - loss: 1.4097 - categorical_accuracy: 0.52004/4 [==============================] - 0s 6ms/step - loss: 1.4181 - categorical_accuracy: 0.4940 - val_loss: 1.7020 - val_categorical_accuracy: 0.3488
Epoch 12/100
1/4 [======>.......................] - ETA: 0s - loss: 1.2990 - categorical_accuracy: 0.53004/4 [==============================] - 0s 6ms/step - loss: 1.2901 - categorical_accuracy: 0.5366 - val_loss: 1.6950 - val_categorical_accuracy: 0.3953
Epoch 13/100
1/4 [======>.......................] - ETA: 0s - loss: 1.2666 - categorical_accuracy: 0.60004/4 [==============================] - 0s 6ms/step - loss: 1.2575 - categorical_accuracy: 0.5907 - val_loss: 1.7117 - val_categorical_accuracy: 0.3721
Epoch 14/100
1/4 [======>.......................] - ETA: 0s - loss: 1.1916 - categorical_accuracy: 0.59004/4 [==============================] - 0s 6ms/step - loss: 1.1762 - categorical_accuracy: 0.6042 - val_loss: 1.7163 - val_categorical_accuracy: 0.3721
Epoch 15/100
1/4 [======>.......................] - ETA: 0s - loss: 1.0445 - categorical_accuracy: 0.60004/4 [==============================] - 0s 6ms/step - loss: 1.0723 - categorical_accuracy: 0.6207 - val_loss: 1.7356 - val_categorical_accuracy: 0.3953
Epoch 16/100
1/4 [======>.......................] - ETA: 0s - loss: 1.0206 - categorical_accuracy: 0.63004/4 [==============================] - 0s 6ms/step - loss: 1.0367 - categorical_accuracy: 0.6531 - val_loss: 1.7648 - val_categorical_accuracy: 0.4419
Epoch 17/100
1/4 [======>.......................] - ETA: 0s - loss: 1.0199 - categorical_accuracy: 0.69004/4 [==============================] - 0s 6ms/step - loss: 0.9910 - categorical_accuracy: 0.6833 - val_loss: 1.7809 - val_categorical_accuracy: 0.4419
Epoch 18/100
1/4 [======>.......................] - ETA: 0s - loss: 1.0850 - categorical_accuracy: 0.68004/4 [==============================] - 0s 6ms/step - loss: 0.9441 - categorical_accuracy: 0.7201 - val_loss: 1.7457 - val_categorical_accuracy: 0.4651
Epoch 19/100
1/4 [======>.......................] - ETA: 0s - loss: 0.8752 - categorical_accuracy: 0.73004/4 [==============================] - 0s 6ms/step - loss: 0.8617 - categorical_accuracy: 0.7448 - val_loss: 1.7377 - val_categorical_accuracy: 0.5116
Epoch 00019: early stopping
Experiment:  211  Set:  har1 Train Labels:  ncar10 Test Labels:  clean
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.76      0.89      0.82        28
           1       0.97      0.94      0.96        35
           3       0.39      0.32      0.35        38
           4       0.34      0.40      0.37        35
           5       0.70      0.23      0.35        30
           6       0.69      1.00      0.81        37

    accuracy                           0.63       203
   macro avg       0.64      0.63      0.61       203
weighted avg       0.63      0.63      0.61       203

Confusion Matrix for this model: 
 [[25  0  1  0  2  0]
 [ 0 33  1  1  0  0]
 [ 2  1 12 23  0  0]
 [ 2  0 17 14  1  1]
 [ 4  0  0  3  7 16]
 [ 0  0  0  0  0 37]]
Experiment:  212  Set:  har1 Train Labels:  ncar10 Test Labels:  ncar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.67      0.85      0.75        26
           1       0.91      0.86      0.89        36
           2       0.00      0.00      0.00         1
           3       0.32      0.26      0.29        39
           4       0.29      0.36      0.32        33
           5       0.60      0.19      0.29        32
           6       0.65      0.97      0.78        36

    accuracy                           0.57       203
   macro avg       0.49      0.50      0.47       203
weighted avg       0.57      0.57      0.54       203

Confusion Matrix for this model: 
 [[22  0  0  2  0  2  0]
 [ 1 31  0  2  1  1  0]
 [ 0  0  0  0  1  0  0]
 [ 3  1  0 10 24  0  1]
 [ 2  0  0 17 12  1  1]
 [ 5  1  0  0  3  6 17]
 [ 0  1  0  0  0  0 35]]
Experiment:  213  Set:  har1 Train Labels:  ncar10 Test Labels:  ncar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.76      0.81      0.78        31
           1       0.88      0.88      0.88        34
           2       0.00      0.00      0.00         3
           3       0.39      0.32      0.35        38
           4       0.32      0.34      0.33        38
           5       0.60      0.24      0.34        25
           6       0.61      0.97      0.75        34

    accuracy                           0.59       203
   macro avg       0.51      0.51      0.49       203
weighted avg       0.57      0.59      0.56       203

Confusion Matrix for this model: 
 [[25  1  0  1  0  2  2]
 [ 0 30  0  1  2  0  1]
 [ 0  0  0  1  1  0  1]
 [ 2  1  0 12 23  0  0]
 [ 3  2  0 15 13  2  3]
 [ 3  0  0  0  2  6 14]
 [ 0  0  0  1  0  0 33]]
Experiment:  214  Set:  har1 Train Labels:  ncar10 Test Labels:  nar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.76      0.89      0.82        28
           1       0.97      0.94      0.96        35
           2       0.00      0.00      0.00         7
           3       0.39      0.39      0.39        31
           4       0.34      0.40      0.37        35
           5       0.70      0.23      0.35        30
           6       0.69      1.00      0.81        37

    accuracy                           0.63       203
   macro avg       0.55      0.55      0.53       203
weighted avg       0.62      0.63      0.60       203

Confusion Matrix for this model: 
 [[25  0  0  1  0  2  0]
 [ 0 33  0  1  1  0  0]
 [ 1  0  0  0  6  0  0]
 [ 1  1  0 12 17  0  0]
 [ 2  0  0 17 14  1  1]
 [ 4  0  0  0  3  7 16]
 [ 0  0  0  0  0  0 37]]
Experiment:  215  Set:  har1 Train Labels:  ncar10 Test Labels:  nar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.76      0.89      0.82        28
           1       0.97      0.94      0.96        35
           2       0.00      0.00      0.00        23
           3       0.19      0.40      0.26        15
           4       0.34      0.40      0.37        35
           5       0.70      0.23      0.35        30
           6       0.69      1.00      0.81        37

    accuracy                           0.60       203
   macro avg       0.52      0.55      0.51       203
weighted avg       0.57      0.60      0.56       203

Confusion Matrix for this model: 
 [[25  0  0  1  0  2  0]
 [ 0 33  0  1  1  0  0]
 [ 1  0  0  6 16  0  0]
 [ 1  1  0  6  7  0  0]
 [ 2  0  0 17 14  1  1]
 [ 4  0  0  0  3  7 16]
 [ 0  0  0  0  0  0 37]]
Experiment:  216  Set:  har1 Train Labels:  ncar10 Test Labels:  nnar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.76      0.89      0.82        28
           1       0.97      0.94      0.96        35
           3       0.32      0.33      0.33        30
           4       0.46      0.44      0.45        43
           5       0.70      0.23      0.35        30
           6       0.69      1.00      0.81        37

    accuracy                           0.65       203
   macro avg       0.65      0.64      0.62       203
weighted avg       0.65      0.65      0.62       203

Confusion Matrix for this model: 
 [[25  0  1  0  2  0]
 [ 0 33  1  1  0  0]
 [ 2  0 10 18  0  0]
 [ 2  1 19 19  1  1]
 [ 4  0  0  3  7 16]
 [ 0  0  0  0  0 37]]
Experiment:  217  Set:  har1 Train Labels:  ncar10 Test Labels:  nnar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.76      0.89      0.82        28
           1       0.97      0.94      0.96        35
           3       0.32      0.33      0.33        30
           4       0.46      0.44      0.45        43
           5       0.70      0.23      0.35        30
           6       0.69      1.00      0.81        37

    accuracy                           0.65       203
   macro avg       0.65      0.64      0.62       203
weighted avg       0.65      0.65      0.62       203

Confusion Matrix for this model: 
 [[25  0  1  0  2  0]
 [ 0 33  1  1  0  0]
 [ 2  0 10 18  0  0]
 [ 2  1 19 19  1  1]
 [ 4  0  0  3  7 16]
 [ 0  0  0  0  0 37]]
Input Shape:  (425, 1, 150)
Model: "sequential_31"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_31 (LSTM)               (None, 32)                23424     
_________________________________________________________________
dropout_31 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_124 (Dense)            (None, 128)               4224      
_________________________________________________________________
dense_125 (Dense)            (None, 128)               16512     
_________________________________________________________________
dense_126 (Dense)            (None, 64)                8256      
_________________________________________________________________
dense_127 (Dense)            (None, 7)                 455       
=================================================================
Total params: 52,871
Trainable params: 52,871
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
1/4 [======>.......................] - ETA: 3s - loss: 1.9554 - categorical_accuracy: 0.05004/4 [==============================] - 1s 95ms/step - loss: 1.9502 - categorical_accuracy: 0.0835 - val_loss: 1.9336 - val_categorical_accuracy: 0.1860
Epoch 2/100
1/4 [======>.......................] - ETA: 0s - loss: 1.9321 - categorical_accuracy: 0.18004/4 [==============================] - 0s 6ms/step - loss: 1.9261 - categorical_accuracy: 0.2280 - val_loss: 1.9231 - val_categorical_accuracy: 0.2791
Epoch 3/100
1/4 [======>.......................] - ETA: 0s - loss: 1.9064 - categorical_accuracy: 0.36004/4 [==============================] - 0s 6ms/step - loss: 1.9072 - categorical_accuracy: 0.3069 - val_loss: 1.9076 - val_categorical_accuracy: 0.3721
Epoch 4/100
1/4 [======>.......................] - ETA: 0s - loss: 1.8957 - categorical_accuracy: 0.36004/4 [==============================] - 0s 6ms/step - loss: 1.8854 - categorical_accuracy: 0.3507 - val_loss: 1.8842 - val_categorical_accuracy: 0.3256
Epoch 5/100
1/4 [======>.......................] - ETA: 0s - loss: 1.8392 - categorical_accuracy: 0.40004/4 [==============================] - 0s 6ms/step - loss: 1.8458 - categorical_accuracy: 0.3634 - val_loss: 1.8506 - val_categorical_accuracy: 0.3488
Epoch 6/100
1/4 [======>.......................] - ETA: 0s - loss: 1.8200 - categorical_accuracy: 0.37004/4 [==============================] - 0s 6ms/step - loss: 1.7993 - categorical_accuracy: 0.4057 - val_loss: 1.8044 - val_categorical_accuracy: 0.3721
Epoch 7/100
1/4 [======>.......................] - ETA: 0s - loss: 1.7652 - categorical_accuracy: 0.38004/4 [==============================] - 0s 6ms/step - loss: 1.7413 - categorical_accuracy: 0.3966 - val_loss: 1.7419 - val_categorical_accuracy: 0.4186
Epoch 8/100
1/4 [======>.......................] - ETA: 0s - loss: 1.6761 - categorical_accuracy: 0.36004/4 [==============================] - 0s 6ms/step - loss: 1.6425 - categorical_accuracy: 0.4279 - val_loss: 1.6639 - val_categorical_accuracy: 0.4186
Epoch 9/100
1/4 [======>.......................] - ETA: 0s - loss: 1.4815 - categorical_accuracy: 0.49004/4 [==============================] - 0s 6ms/step - loss: 1.5237 - categorical_accuracy: 0.4570 - val_loss: 1.5787 - val_categorical_accuracy: 0.4186
Epoch 10/100
1/4 [======>.......................] - ETA: 0s - loss: 1.4658 - categorical_accuracy: 0.47004/4 [==============================] - 0s 6ms/step - loss: 1.4441 - categorical_accuracy: 0.4917 - val_loss: 1.4831 - val_categorical_accuracy: 0.5349
Epoch 11/100
1/4 [======>.......................] - ETA: 0s - loss: 1.3410 - categorical_accuracy: 0.53004/4 [==============================] - 0s 6ms/step - loss: 1.3197 - categorical_accuracy: 0.5386 - val_loss: 1.3900 - val_categorical_accuracy: 0.5349
Epoch 12/100
1/4 [======>.......................] - ETA: 0s - loss: 1.3215 - categorical_accuracy: 0.56004/4 [==============================] - 0s 6ms/step - loss: 1.2441 - categorical_accuracy: 0.5721 - val_loss: 1.3100 - val_categorical_accuracy: 0.6047
Epoch 13/100
1/4 [======>.......................] - ETA: 0s - loss: 1.1121 - categorical_accuracy: 0.67004/4 [==============================] - 0s 6ms/step - loss: 1.0827 - categorical_accuracy: 0.6590 - val_loss: 1.2194 - val_categorical_accuracy: 0.6279
Epoch 14/100
1/4 [======>.......................] - ETA: 0s - loss: 0.9917 - categorical_accuracy: 0.67004/4 [==============================] - 0s 6ms/step - loss: 0.9875 - categorical_accuracy: 0.6610 - val_loss: 1.1039 - val_categorical_accuracy: 0.6512
Epoch 15/100
1/4 [======>.......................] - ETA: 0s - loss: 0.9140 - categorical_accuracy: 0.75004/4 [==============================] - 0s 6ms/step - loss: 0.8951 - categorical_accuracy: 0.7416 - val_loss: 1.0064 - val_categorical_accuracy: 0.6744
Epoch 16/100
1/4 [======>.......................] - ETA: 0s - loss: 0.7900 - categorical_accuracy: 0.74004/4 [==============================] - 0s 6ms/step - loss: 0.7828 - categorical_accuracy: 0.7387 - val_loss: 0.9681 - val_categorical_accuracy: 0.6744
Epoch 17/100
1/4 [======>.......................] - ETA: 0s - loss: 0.6095 - categorical_accuracy: 0.84004/4 [==============================] - 0s 6ms/step - loss: 0.6519 - categorical_accuracy: 0.8037 - val_loss: 0.9328 - val_categorical_accuracy: 0.6512
Epoch 18/100
1/4 [======>.......................] - ETA: 0s - loss: 0.6250 - categorical_accuracy: 0.80004/4 [==============================] - 0s 6ms/step - loss: 0.6250 - categorical_accuracy: 0.7984 - val_loss: 0.8824 - val_categorical_accuracy: 0.6512
Epoch 19/100
1/4 [======>.......................] - ETA: 0s - loss: 0.8091 - categorical_accuracy: 0.68004/4 [==============================] - 0s 6ms/step - loss: 0.6586 - categorical_accuracy: 0.7640 - val_loss: 0.8457 - val_categorical_accuracy: 0.6512
Epoch 20/100
1/4 [======>.......................] - ETA: 0s - loss: 0.5362 - categorical_accuracy: 0.81004/4 [==============================] - 0s 6ms/step - loss: 0.5643 - categorical_accuracy: 0.8001 - val_loss: 0.8222 - val_categorical_accuracy: 0.6512
Epoch 21/100
1/4 [======>.......................] - ETA: 0s - loss: 0.6113 - categorical_accuracy: 0.74004/4 [==============================] - 0s 6ms/step - loss: 0.5618 - categorical_accuracy: 0.7824 - val_loss: 0.8021 - val_categorical_accuracy: 0.6279
Epoch 22/100
1/4 [======>.......................] - ETA: 0s - loss: 0.5721 - categorical_accuracy: 0.78004/4 [==============================] - 0s 6ms/step - loss: 0.5118 - categorical_accuracy: 0.7992 - val_loss: 0.7567 - val_categorical_accuracy: 0.6977
Epoch 23/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3803 - categorical_accuracy: 0.87004/4 [==============================] - 0s 6ms/step - loss: 0.4356 - categorical_accuracy: 0.8549 - val_loss: 0.7473 - val_categorical_accuracy: 0.6744
Epoch 24/100
1/4 [======>.......................] - ETA: 0s - loss: 0.4539 - categorical_accuracy: 0.86004/4 [==============================] - 0s 6ms/step - loss: 0.4149 - categorical_accuracy: 0.8715 - val_loss: 0.7391 - val_categorical_accuracy: 0.6744
Epoch 25/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3651 - categorical_accuracy: 0.89004/4 [==============================] - 0s 6ms/step - loss: 0.3800 - categorical_accuracy: 0.8729 - val_loss: 0.7784 - val_categorical_accuracy: 0.6512
Epoch 26/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3383 - categorical_accuracy: 0.88004/4 [==============================] - 0s 6ms/step - loss: 0.3857 - categorical_accuracy: 0.8503 - val_loss: 0.7380 - val_categorical_accuracy: 0.6744
Epoch 27/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3828 - categorical_accuracy: 0.83004/4 [==============================] - 0s 6ms/step - loss: 0.3683 - categorical_accuracy: 0.8517 - val_loss: 0.7295 - val_categorical_accuracy: 0.6977
Epoch 28/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3398 - categorical_accuracy: 0.87004/4 [==============================] - 0s 6ms/step - loss: 0.3562 - categorical_accuracy: 0.8758 - val_loss: 0.7172 - val_categorical_accuracy: 0.6744
Epoch 29/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3242 - categorical_accuracy: 0.91004/4 [==============================] - 0s 6ms/step - loss: 0.3164 - categorical_accuracy: 0.8961 - val_loss: 0.7024 - val_categorical_accuracy: 0.6744
Epoch 30/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3746 - categorical_accuracy: 0.90004/4 [==============================] - 0s 6ms/step - loss: 0.3385 - categorical_accuracy: 0.8924 - val_loss: 0.6874 - val_categorical_accuracy: 0.7209
Epoch 31/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3310 - categorical_accuracy: 0.88004/4 [==============================] - 0s 6ms/step - loss: 0.3232 - categorical_accuracy: 0.8817 - val_loss: 0.6732 - val_categorical_accuracy: 0.7209
Epoch 32/100
1/4 [======>.......................] - ETA: 0s - loss: 0.2473 - categorical_accuracy: 0.94004/4 [==============================] - 0s 6ms/step - loss: 0.2710 - categorical_accuracy: 0.9269 - val_loss: 0.6694 - val_categorical_accuracy: 0.7442
Epoch 33/100
1/4 [======>.......................] - ETA: 0s - loss: 0.2614 - categorical_accuracy: 0.90004/4 [==============================] - 0s 6ms/step - loss: 0.2641 - categorical_accuracy: 0.8992 - val_loss: 0.6544 - val_categorical_accuracy: 0.6977
Epoch 34/100
1/4 [======>.......................] - ETA: 0s - loss: 0.2284 - categorical_accuracy: 0.91004/4 [==============================] - 0s 6ms/step - loss: 0.2287 - categorical_accuracy: 0.9159 - val_loss: 0.6462 - val_categorical_accuracy: 0.7209
Epoch 35/100
1/4 [======>.......................] - ETA: 0s - loss: 0.2149 - categorical_accuracy: 0.95004/4 [==============================] - 0s 6ms/step - loss: 0.2176 - categorical_accuracy: 0.9486 - val_loss: 0.6741 - val_categorical_accuracy: 0.7442
Epoch 36/100
1/4 [======>.......................] - ETA: 0s - loss: 0.1683 - categorical_accuracy: 0.95004/4 [==============================] - 0s 6ms/step - loss: 0.2086 - categorical_accuracy: 0.9299 - val_loss: 0.6964 - val_categorical_accuracy: 0.7209
Epoch 37/100
1/4 [======>.......................] - ETA: 0s - loss: 0.2564 - categorical_accuracy: 0.89004/4 [==============================] - 0s 6ms/step - loss: 0.2483 - categorical_accuracy: 0.9006 - val_loss: 0.6813 - val_categorical_accuracy: 0.7209
Epoch 38/100
1/4 [======>.......................] - ETA: 0s - loss: 0.2047 - categorical_accuracy: 0.92004/4 [==============================] - 0s 6ms/step - loss: 0.2328 - categorical_accuracy: 0.9124 - val_loss: 0.6815 - val_categorical_accuracy: 0.6977
Epoch 39/100
1/4 [======>.......................] - ETA: 0s - loss: 0.2324 - categorical_accuracy: 0.91004/4 [==============================] - 0s 6ms/step - loss: 0.2045 - categorical_accuracy: 0.9285 - val_loss: 0.6980 - val_categorical_accuracy: 0.7209
Epoch 40/100
1/4 [======>.......................] - ETA: 0s - loss: 0.1628 - categorical_accuracy: 0.97004/4 [==============================] - 0s 6ms/step - loss: 0.1680 - categorical_accuracy: 0.9558 - val_loss: 0.7507 - val_categorical_accuracy: 0.7209
Epoch 41/100
1/4 [======>.......................] - ETA: 0s - loss: 0.2317 - categorical_accuracy: 0.91004/4 [==============================] - 0s 6ms/step - loss: 0.1912 - categorical_accuracy: 0.9312 - val_loss: 0.7746 - val_categorical_accuracy: 0.7209
Epoch 00041: early stopping
Experiment:  218  Set:  har1 Train Labels:  nar5 Test Labels:  clean
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.74      0.93      0.83        28
           1       0.92      1.00      0.96        35
           2       0.00      0.00      0.00         0
           3       0.76      0.50      0.60        38
           4       0.57      0.46      0.51        35
           5       0.52      0.47      0.49        30
           6       0.77      1.00      0.87        37

    accuracy                           0.72       203
   macro avg       0.61      0.62      0.61       203
weighted avg       0.72      0.72      0.71       203

Confusion Matrix for this model: 
 [[26  0  0  0  0  2  0]
 [ 0 35  0  0  0  0  0]
 [ 0  0  0  0  0  0  0]
 [ 2  2  0 19 11  3  1]
 [ 3  1  1  6 16  8  0]
 [ 4  0  1  0  1 14 10]
 [ 0  0  0  0  0  0 37]]
Experiment:  219  Set:  har1 Train Labels:  nar5 Test Labels:  ncar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.69      0.92      0.79        26
           1       0.89      0.94      0.92        36
           2       0.00      0.00      0.00         1
           3       0.72      0.46      0.56        39
           4       0.50      0.42      0.46        33
           5       0.52      0.44      0.47        32
           6       0.73      0.97      0.83        36

    accuracy                           0.68       203
   macro avg       0.58      0.59      0.58       203
weighted avg       0.68      0.68      0.67       203

Confusion Matrix for this model: 
 [[24  0  0  1  0  1  0]
 [ 1 34  0  0  0  1  0]
 [ 0  0  0  0  1  0  0]
 [ 3  1  0 18 12  3  2]
 [ 3  1  1  6 14  8  0]
 [ 4  1  1  0  1 14 11]
 [ 0  1  0  0  0  0 35]]
Experiment:  220  Set:  har1 Train Labels:  nar5 Test Labels:  ncar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.74      0.84      0.79        31
           1       0.84      0.94      0.89        34
           2       0.00      0.00      0.00         3
           3       0.76      0.50      0.60        38
           4       0.54      0.39      0.45        38
           5       0.41      0.44      0.42        25
           6       0.69      0.97      0.80        34

    accuracy                           0.67       203
   macro avg       0.57      0.58      0.57       203
weighted avg       0.66      0.67      0.65       203

Confusion Matrix for this model: 
 [[26  1  0  0  0  2  2]
 [ 0 32  0  0  0  2  0]
 [ 0  0  0  0  0  2  1]
 [ 2  2  0 19 12  3  0]
 [ 4  3  1  6 15  6  3]
 [ 3  0  1  0  1 11  9]
 [ 0  0  0  0  0  1 33]]
Experiment:  221  Set:  har1 Train Labels:  nar5 Test Labels:  nar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.74      0.93      0.83        28
           1       0.92      1.00      0.96        35
           2       0.00      0.00      0.00         7
           3       0.60      0.48      0.54        31
           4       0.57      0.46      0.51        35
           5       0.52      0.47      0.49        30
           6       0.77      1.00      0.87        37

    accuracy                           0.70       203
   macro avg       0.59      0.62      0.60       203
weighted avg       0.67      0.70      0.68       203

Confusion Matrix for this model: 
 [[26  0  0  0  0  2  0]
 [ 0 35  0  0  0  0  0]
 [ 0  0  0  4  3  0  0]
 [ 2  2  0 15  8  3  1]
 [ 3  1  1  6 16  8  0]
 [ 4  0  1  0  1 14 10]
 [ 0  0  0  0  0  0 37]]
Experiment:  222  Set:  har1 Train Labels:  nar5 Test Labels:  nar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.74      0.93      0.83        28
           1       0.92      1.00      0.96        35
           2       0.00      0.00      0.00        23
           3       0.36      0.60      0.45        15
           4       0.57      0.46      0.51        35
           5       0.52      0.47      0.49        30
           6       0.77      1.00      0.87        37

    accuracy                           0.67       203
   macro avg       0.55      0.64      0.59       203
weighted avg       0.60      0.67      0.63       203

Confusion Matrix for this model: 
 [[26  0  0  0  0  2  0]
 [ 0 35  0  0  0  0  0]
 [ 2  1  0 10  8  1  1]
 [ 0  1  0  9  3  2  0]
 [ 3  1  1  6 16  8  0]
 [ 4  0  1  0  1 14 10]
 [ 0  0  0  0  0  0 37]]
Experiment:  223  Set:  har1 Train Labels:  nar5 Test Labels:  nnar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.74      0.93      0.83        28
           1       0.92      1.00      0.96        35
           2       0.00      0.00      0.00         0
           3       0.64      0.53      0.58        30
           4       0.68      0.44      0.54        43
           5       0.52      0.47      0.49        30
           6       0.77      1.00      0.87        37

    accuracy                           0.72       203
   macro avg       0.61      0.62      0.61       203
weighted avg       0.72      0.72      0.71       203

Confusion Matrix for this model: 
 [[26  0  0  0  0  2  0]
 [ 0 35  0  0  0  0  0]
 [ 0  0  0  0  0  0  0]
 [ 2  0  0 16  8  3  1]
 [ 3  3  1  9 19  8  0]
 [ 4  0  1  0  1 14 10]
 [ 0  0  0  0  0  0 37]]
Experiment:  224  Set:  har1 Train Labels:  nar5 Test Labels:  nnar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.74      0.93      0.83        28
           1       0.92      1.00      0.96        35
           2       0.00      0.00      0.00         0
           3       0.64      0.53      0.58        30
           4       0.68      0.44      0.54        43
           5       0.52      0.47      0.49        30
           6       0.77      1.00      0.87        37

    accuracy                           0.72       203
   macro avg       0.61      0.62      0.61       203
weighted avg       0.72      0.72      0.71       203

Confusion Matrix for this model: 
 [[26  0  0  0  0  2  0]
 [ 0 35  0  0  0  0  0]
 [ 0  0  0  0  0  0  0]
 [ 2  0  0 16  8  3  1]
 [ 3  3  1  9 19  8  0]
 [ 4  0  1  0  1 14 10]
 [ 0  0  0  0  0  0 37]]
Input Shape:  (425, 1, 150)
Model: "sequential_32"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_32 (LSTM)               (None, 32)                23424     
_________________________________________________________________
dropout_32 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_128 (Dense)            (None, 128)               4224      
_________________________________________________________________
dense_129 (Dense)            (None, 128)               16512     
_________________________________________________________________
dense_130 (Dense)            (None, 64)                8256      
_________________________________________________________________
dense_131 (Dense)            (None, 7)                 455       
=================================================================
Total params: 52,871
Trainable params: 52,871
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
1/4 [======>.......................] - ETA: 3s - loss: 1.9392 - categorical_accuracy: 0.20004/4 [==============================] - 1s 96ms/step - loss: 1.9356 - categorical_accuracy: 0.1816 - val_loss: 1.9184 - val_categorical_accuracy: 0.3256
Epoch 2/100
1/4 [======>.......................] - ETA: 0s - loss: 1.9210 - categorical_accuracy: 0.23004/4 [==============================] - 0s 6ms/step - loss: 1.9138 - categorical_accuracy: 0.2519 - val_loss: 1.8975 - val_categorical_accuracy: 0.3256
Epoch 3/100
1/4 [======>.......................] - ETA: 0s - loss: 1.8853 - categorical_accuracy: 0.29004/4 [==============================] - 0s 6ms/step - loss: 1.8826 - categorical_accuracy: 0.2842 - val_loss: 1.8732 - val_categorical_accuracy: 0.3256
Epoch 4/100
1/4 [======>.......................] - ETA: 0s - loss: 1.8475 - categorical_accuracy: 0.34004/4 [==============================] - 0s 6ms/step - loss: 1.8444 - categorical_accuracy: 0.3227 - val_loss: 1.8420 - val_categorical_accuracy: 0.3721
Epoch 5/100
1/4 [======>.......................] - ETA: 0s - loss: 1.7916 - categorical_accuracy: 0.35004/4 [==============================] - 0s 6ms/step - loss: 1.8072 - categorical_accuracy: 0.3449 - val_loss: 1.8021 - val_categorical_accuracy: 0.3953
Epoch 6/100
1/4 [======>.......................] - ETA: 0s - loss: 1.7532 - categorical_accuracy: 0.42004/4 [==============================] - 0s 6ms/step - loss: 1.7409 - categorical_accuracy: 0.4354 - val_loss: 1.7483 - val_categorical_accuracy: 0.3721
Epoch 7/100
1/4 [======>.......................] - ETA: 0s - loss: 1.7389 - categorical_accuracy: 0.47004/4 [==============================] - 0s 6ms/step - loss: 1.6857 - categorical_accuracy: 0.4743 - val_loss: 1.6775 - val_categorical_accuracy: 0.4651
Epoch 8/100
1/4 [======>.......................] - ETA: 0s - loss: 1.5600 - categorical_accuracy: 0.55004/4 [==============================] - 0s 6ms/step - loss: 1.5838 - categorical_accuracy: 0.5220 - val_loss: 1.5903 - val_categorical_accuracy: 0.4651
Epoch 9/100
1/4 [======>.......................] - ETA: 0s - loss: 1.5010 - categorical_accuracy: 0.51004/4 [==============================] - 0s 6ms/step - loss: 1.5026 - categorical_accuracy: 0.5170 - val_loss: 1.5017 - val_categorical_accuracy: 0.4651
Epoch 10/100
1/4 [======>.......................] - ETA: 0s - loss: 1.4704 - categorical_accuracy: 0.53004/4 [==============================] - 0s 6ms/step - loss: 1.4120 - categorical_accuracy: 0.5304 - val_loss: 1.4077 - val_categorical_accuracy: 0.5349
Epoch 11/100
1/4 [======>.......................] - ETA: 0s - loss: 1.3441 - categorical_accuracy: 0.56004/4 [==============================] - 0s 6ms/step - loss: 1.2865 - categorical_accuracy: 0.5822 - val_loss: 1.3154 - val_categorical_accuracy: 0.5349
Epoch 12/100
1/4 [======>.......................] - ETA: 0s - loss: 1.0462 - categorical_accuracy: 0.63004/4 [==============================] - 0s 6ms/step - loss: 1.1392 - categorical_accuracy: 0.5900 - val_loss: 1.2177 - val_categorical_accuracy: 0.5349
Epoch 13/100
1/4 [======>.......................] - ETA: 0s - loss: 1.0857 - categorical_accuracy: 0.62004/4 [==============================] - 0s 6ms/step - loss: 1.0915 - categorical_accuracy: 0.6175 - val_loss: 1.1301 - val_categorical_accuracy: 0.5581
Epoch 14/100
1/4 [======>.......................] - ETA: 0s - loss: 0.9998 - categorical_accuracy: 0.66004/4 [==============================] - 0s 6ms/step - loss: 0.9990 - categorical_accuracy: 0.6657 - val_loss: 1.0683 - val_categorical_accuracy: 0.5581
Epoch 15/100
1/4 [======>.......................] - ETA: 0s - loss: 0.8585 - categorical_accuracy: 0.75004/4 [==============================] - 0s 6ms/step - loss: 0.8695 - categorical_accuracy: 0.7319 - val_loss: 1.0178 - val_categorical_accuracy: 0.5814
Epoch 16/100
1/4 [======>.......................] - ETA: 0s - loss: 0.8898 - categorical_accuracy: 0.68004/4 [==============================] - 0s 6ms/step - loss: 0.8495 - categorical_accuracy: 0.6980 - val_loss: 0.9369 - val_categorical_accuracy: 0.6047
Epoch 17/100
1/4 [======>.......................] - ETA: 0s - loss: 0.8008 - categorical_accuracy: 0.72004/4 [==============================] - 0s 6ms/step - loss: 0.7657 - categorical_accuracy: 0.7255 - val_loss: 0.9093 - val_categorical_accuracy: 0.6047
Epoch 18/100
1/4 [======>.......................] - ETA: 0s - loss: 0.7054 - categorical_accuracy: 0.74004/4 [==============================] - 0s 6ms/step - loss: 0.6802 - categorical_accuracy: 0.7547 - val_loss: 0.8898 - val_categorical_accuracy: 0.6279
Epoch 19/100
1/4 [======>.......................] - ETA: 0s - loss: 0.5973 - categorical_accuracy: 0.79004/4 [==============================] - 0s 6ms/step - loss: 0.6016 - categorical_accuracy: 0.7964 - val_loss: 0.8759 - val_categorical_accuracy: 0.6047
Epoch 20/100
1/4 [======>.......................] - ETA: 0s - loss: 0.5842 - categorical_accuracy: 0.82004/4 [==============================] - 0s 6ms/step - loss: 0.5932 - categorical_accuracy: 0.7845 - val_loss: 0.8657 - val_categorical_accuracy: 0.6047
Epoch 21/100
1/4 [======>.......................] - ETA: 0s - loss: 0.5639 - categorical_accuracy: 0.76004/4 [==============================] - 0s 6ms/step - loss: 0.5592 - categorical_accuracy: 0.7833 - val_loss: 0.8104 - val_categorical_accuracy: 0.6279
Epoch 22/100
1/4 [======>.......................] - ETA: 0s - loss: 0.5621 - categorical_accuracy: 0.78004/4 [==============================] - 0s 6ms/step - loss: 0.5418 - categorical_accuracy: 0.7919 - val_loss: 0.8129 - val_categorical_accuracy: 0.6512
Epoch 23/100
1/4 [======>.......................] - ETA: 0s - loss: 0.4675 - categorical_accuracy: 0.84004/4 [==============================] - 0s 6ms/step - loss: 0.4972 - categorical_accuracy: 0.8167 - val_loss: 0.8125 - val_categorical_accuracy: 0.6512
Epoch 24/100
1/4 [======>.......................] - ETA: 0s - loss: 0.4494 - categorical_accuracy: 0.79004/4 [==============================] - 0s 6ms/step - loss: 0.4451 - categorical_accuracy: 0.8092 - val_loss: 0.7502 - val_categorical_accuracy: 0.6977
Epoch 25/100
1/4 [======>.......................] - ETA: 0s - loss: 0.4811 - categorical_accuracy: 0.80004/4 [==============================] - 0s 6ms/step - loss: 0.4715 - categorical_accuracy: 0.8067 - val_loss: 0.7354 - val_categorical_accuracy: 0.7209
Epoch 26/100
1/4 [======>.......................] - ETA: 0s - loss: 0.4714 - categorical_accuracy: 0.82004/4 [==============================] - 0s 6ms/step - loss: 0.4273 - categorical_accuracy: 0.8457 - val_loss: 0.7840 - val_categorical_accuracy: 0.6977
Epoch 27/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3893 - categorical_accuracy: 0.89004/4 [==============================] - 0s 6ms/step - loss: 0.3949 - categorical_accuracy: 0.8699 - val_loss: 0.7356 - val_categorical_accuracy: 0.7209
Epoch 28/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3292 - categorical_accuracy: 0.90004/4 [==============================] - 0s 6ms/step - loss: 0.3666 - categorical_accuracy: 0.8653 - val_loss: 0.7056 - val_categorical_accuracy: 0.6977
Epoch 29/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3515 - categorical_accuracy: 0.89004/4 [==============================] - 0s 6ms/step - loss: 0.3626 - categorical_accuracy: 0.8911 - val_loss: 0.7213 - val_categorical_accuracy: 0.7209
Epoch 30/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3915 - categorical_accuracy: 0.83004/4 [==============================] - 0s 6ms/step - loss: 0.3597 - categorical_accuracy: 0.8526 - val_loss: 0.7752 - val_categorical_accuracy: 0.6977
Epoch 31/100
1/4 [======>.......................] - ETA: 0s - loss: 0.2952 - categorical_accuracy: 0.88004/4 [==============================] - 0s 6ms/step - loss: 0.3376 - categorical_accuracy: 0.8669 - val_loss: 0.7949 - val_categorical_accuracy: 0.7442
Epoch 32/100
1/4 [======>.......................] - ETA: 0s - loss: 0.4190 - categorical_accuracy: 0.83004/4 [==============================] - 0s 6ms/step - loss: 0.3428 - categorical_accuracy: 0.8696 - val_loss: 0.8263 - val_categorical_accuracy: 0.7209
Epoch 33/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3147 - categorical_accuracy: 0.89004/4 [==============================] - 0s 6ms/step - loss: 0.3179 - categorical_accuracy: 0.8859 - val_loss: 0.8154 - val_categorical_accuracy: 0.6977
Epoch 34/100
1/4 [======>.......................] - ETA: 0s - loss: 0.1835 - categorical_accuracy: 0.94004/4 [==============================] - 0s 6ms/step - loss: 0.2501 - categorical_accuracy: 0.9014 - val_loss: 0.8013 - val_categorical_accuracy: 0.7209
Epoch 35/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3352 - categorical_accuracy: 0.88004/4 [==============================] - 0s 6ms/step - loss: 0.3035 - categorical_accuracy: 0.8931 - val_loss: 0.8529 - val_categorical_accuracy: 0.6977
Epoch 00035: early stopping
Experiment:  225  Set:  har1 Train Labels:  nar10 Test Labels:  clean
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.69      0.89      0.78        28
           1       0.92      1.00      0.96        35
           2       0.00      0.00      0.00         0
           3       0.62      0.42      0.50        38
           4       0.48      0.46      0.47        35
           5       0.75      0.20      0.32        30
           6       0.71      0.97      0.82        37

    accuracy                           0.66       203
   macro avg       0.60      0.56      0.55       203
weighted avg       0.69      0.66      0.64       203

Confusion Matrix for this model: 
 [[25  0  3  0  0  0  0]
 [ 0 35  0  0  0  0  0]
 [ 0  0  0  0  0  0  0]
 [ 4  2  0 16 16  0  0]
 [ 3  1  4 10 16  1  0]
 [ 4  0  4  0  1  6 15]
 [ 0  0  0  0  0  1 36]]
Experiment:  226  Set:  har1 Train Labels:  nar10 Test Labels:  ncar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.61      0.85      0.71        26
           1       0.89      0.94      0.92        36
           2       0.00      0.00      0.00         1
           3       0.58      0.38      0.46        39
           4       0.42      0.42      0.42        33
           5       0.62      0.16      0.25        32
           6       0.67      0.94      0.78        36

    accuracy                           0.61       203
   macro avg       0.54      0.53      0.51       203
weighted avg       0.63      0.61      0.59       203

Confusion Matrix for this model: 
 [[22  0  3  1  0  0  0]
 [ 1 34  0  0  0  1  0]
 [ 0  0  0  0  1  0  0]
 [ 5  1  0 15 17  0  1]
 [ 3  1  4 10 14  1  0]
 [ 5  1  4  0  1  5 16]
 [ 0  1  0  0  0  1 34]]
Experiment:  227  Set:  har1 Train Labels:  nar10 Test Labels:  ncar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.69      0.81      0.75        31
           1       0.84      0.94      0.89        34
           2       0.00      0.00      0.00         3
           3       0.62      0.42      0.50        38
           4       0.45      0.39      0.42        38
           5       0.62      0.20      0.30        25
           6       0.63      0.94      0.75        34

    accuracy                           0.62       203
   macro avg       0.55      0.53      0.52       203
weighted avg       0.63      0.62      0.60       203

Confusion Matrix for this model: 
 [[25  1  3  0  0  0  2]
 [ 0 32  1  0  0  0  1]
 [ 0  0  0  1  1  0  1]
 [ 4  2  0 16 16  0  0]
 [ 3  3  4  9 15  2  2]
 [ 3  0  3  0  1  5 13]
 [ 1  0  0  0  0  1 32]]
Experiment:  228  Set:  har1 Train Labels:  nar10 Test Labels:  nar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.69      0.89      0.78        28
           1       0.92      1.00      0.96        35
           2       0.00      0.00      0.00         7
           3       0.50      0.42      0.46        31
           4       0.48      0.46      0.47        35
           5       0.75      0.20      0.32        30
           6       0.71      0.97      0.82        37

    accuracy                           0.65       203
   macro avg       0.58      0.56      0.54       203
weighted avg       0.65      0.65      0.62       203

Confusion Matrix for this model: 
 [[25  0  3  0  0  0  0]
 [ 0 35  0  0  0  0  0]
 [ 0  0  0  3  4  0  0]
 [ 4  2  0 13 12  0  0]
 [ 3  1  4 10 16  1  0]
 [ 4  0  4  0  1  6 15]
 [ 0  0  0  0  0  1 36]]
Experiment:  229  Set:  har1 Train Labels:  nar10 Test Labels:  nar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.69      0.89      0.78        28
           1       0.92      1.00      0.96        35
           2       0.00      0.00      0.00        23
           3       0.35      0.60      0.44        15
           4       0.48      0.46      0.47        35
           5       0.75      0.20      0.32        30
           6       0.71      0.97      0.82        37

    accuracy                           0.63       203
   macro avg       0.56      0.59      0.54       203
weighted avg       0.60      0.63      0.58       203

Confusion Matrix for this model: 
 [[25  0  3  0  0  0  0]
 [ 0 35  0  0  0  0  0]
 [ 3  1  0  7 12  0  0]
 [ 1  1  0  9  4  0  0]
 [ 3  1  4 10 16  1  0]
 [ 4  0  4  0  1  6 15]
 [ 0  0  0  0  0  1 36]]
Experiment:  230  Set:  har1 Train Labels:  nar10 Test Labels:  nnar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.69      0.89      0.78        28
           1       0.92      1.00      0.96        35
           2       0.00      0.00      0.00         0
           3       0.50      0.43      0.46        30
           4       0.61      0.47      0.53        43
           5       0.75      0.20      0.32        30
           6       0.71      0.97      0.82        37

    accuracy                           0.67       203
   macro avg       0.60      0.57      0.55       203
weighted avg       0.70      0.67      0.65       203

Confusion Matrix for this model: 
 [[25  0  3  0  0  0  0]
 [ 0 35  0  0  0  0  0]
 [ 0  0  0  0  0  0  0]
 [ 4  1  0 13 12  0  0]
 [ 3  2  4 13 20  1  0]
 [ 4  0  4  0  1  6 15]
 [ 0  0  0  0  0  1 36]]
Experiment:  231  Set:  har1 Train Labels:  nar10 Test Labels:  nnar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.69      0.89      0.78        28
           1       0.92      1.00      0.96        35
           2       0.00      0.00      0.00         0
           3       0.50      0.43      0.46        30
           4       0.61      0.47      0.53        43
           5       0.75      0.20      0.32        30
           6       0.71      0.97      0.82        37

    accuracy                           0.67       203
   macro avg       0.60      0.57      0.55       203
weighted avg       0.70      0.67      0.65       203

Confusion Matrix for this model: 
 [[25  0  3  0  0  0  0]
 [ 0 35  0  0  0  0  0]
 [ 0  0  0  0  0  0  0]
 [ 4  1  0 13 12  0  0]
 [ 3  2  4 13 20  1  0]
 [ 4  0  4  0  1  6 15]
 [ 0  0  0  0  0  1 36]]
Input Shape:  (425, 1, 150)
Model: "sequential_33"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_33 (LSTM)               (None, 32)                23424     
_________________________________________________________________
dropout_33 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_132 (Dense)            (None, 128)               4224      
_________________________________________________________________
dense_133 (Dense)            (None, 128)               16512     
_________________________________________________________________
dense_134 (Dense)            (None, 64)                8256      
_________________________________________________________________
dense_135 (Dense)            (None, 7)                 455       
=================================================================
Total params: 52,871
Trainable params: 52,871
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
1/4 [======>.......................] - ETA: 3s - loss: 1.9369 - categorical_accuracy: 0.17004/4 [==============================] - 1s 97ms/step - loss: 1.9310 - categorical_accuracy: 0.1868 - val_loss: 1.9154 - val_categorical_accuracy: 0.2093
Epoch 2/100
1/4 [======>.......................] - ETA: 0s - loss: 1.9055 - categorical_accuracy: 0.29004/4 [==============================] - 0s 6ms/step - loss: 1.9004 - categorical_accuracy: 0.2776 - val_loss: 1.8854 - val_categorical_accuracy: 0.2093
Epoch 3/100
1/4 [======>.......................] - ETA: 0s - loss: 1.8690 - categorical_accuracy: 0.31004/4 [==============================] - 0s 6ms/step - loss: 1.8613 - categorical_accuracy: 0.2959 - val_loss: 1.8477 - val_categorical_accuracy: 0.2326
Epoch 4/100
1/4 [======>.......................] - ETA: 0s - loss: 1.8344 - categorical_accuracy: 0.24004/4 [==============================] - 0s 6ms/step - loss: 1.8187 - categorical_accuracy: 0.2864 - val_loss: 1.7996 - val_categorical_accuracy: 0.2093
Epoch 5/100
1/4 [======>.......................] - ETA: 0s - loss: 1.7895 - categorical_accuracy: 0.31004/4 [==============================] - 0s 6ms/step - loss: 1.7691 - categorical_accuracy: 0.3013 - val_loss: 1.7410 - val_categorical_accuracy: 0.2558
Epoch 6/100
1/4 [======>.......................] - ETA: 0s - loss: 1.7103 - categorical_accuracy: 0.31004/4 [==============================] - 0s 6ms/step - loss: 1.6950 - categorical_accuracy: 0.3140 - val_loss: 1.6712 - val_categorical_accuracy: 0.2791
Epoch 7/100
1/4 [======>.......................] - ETA: 0s - loss: 1.6026 - categorical_accuracy: 0.38004/4 [==============================] - 0s 6ms/step - loss: 1.6072 - categorical_accuracy: 0.3750 - val_loss: 1.5912 - val_categorical_accuracy: 0.3721
Epoch 8/100
1/4 [======>.......................] - ETA: 0s - loss: 1.4890 - categorical_accuracy: 0.48004/4 [==============================] - 0s 6ms/step - loss: 1.5047 - categorical_accuracy: 0.4502 - val_loss: 1.4999 - val_categorical_accuracy: 0.3721
Epoch 9/100
1/4 [======>.......................] - ETA: 0s - loss: 1.4521 - categorical_accuracy: 0.41004/4 [==============================] - 0s 6ms/step - loss: 1.4211 - categorical_accuracy: 0.4511 - val_loss: 1.4013 - val_categorical_accuracy: 0.3953
Epoch 10/100
1/4 [======>.......................] - ETA: 0s - loss: 1.3228 - categorical_accuracy: 0.58004/4 [==============================] - 0s 6ms/step - loss: 1.3016 - categorical_accuracy: 0.5728 - val_loss: 1.2979 - val_categorical_accuracy: 0.4651
Epoch 11/100
1/4 [======>.......................] - ETA: 0s - loss: 1.2246 - categorical_accuracy: 0.59004/4 [==============================] - 0s 6ms/step - loss: 1.1928 - categorical_accuracy: 0.6224 - val_loss: 1.1880 - val_categorical_accuracy: 0.4651
Epoch 12/100
1/4 [======>.......................] - ETA: 0s - loss: 1.0237 - categorical_accuracy: 0.67004/4 [==============================] - 0s 6ms/step - loss: 1.0587 - categorical_accuracy: 0.6613 - val_loss: 1.0848 - val_categorical_accuracy: 0.5116
Epoch 13/100
1/4 [======>.......................] - ETA: 0s - loss: 0.9613 - categorical_accuracy: 0.77004/4 [==============================] - 0s 6ms/step - loss: 0.9533 - categorical_accuracy: 0.7427 - val_loss: 1.0180 - val_categorical_accuracy: 0.5581
Epoch 14/100
1/4 [======>.......................] - ETA: 0s - loss: 0.9390 - categorical_accuracy: 0.68004/4 [==============================] - 0s 6ms/step - loss: 0.8790 - categorical_accuracy: 0.7210 - val_loss: 0.9517 - val_categorical_accuracy: 0.6047
Epoch 15/100
1/4 [======>.......................] - ETA: 0s - loss: 0.8253 - categorical_accuracy: 0.79004/4 [==============================] - 0s 6ms/step - loss: 0.7937 - categorical_accuracy: 0.7765 - val_loss: 0.8991 - val_categorical_accuracy: 0.6047
Epoch 16/100
1/4 [======>.......................] - ETA: 0s - loss: 0.7527 - categorical_accuracy: 0.77004/4 [==============================] - 0s 6ms/step - loss: 0.7186 - categorical_accuracy: 0.7726 - val_loss: 0.8310 - val_categorical_accuracy: 0.6279
Epoch 17/100
1/4 [======>.......................] - ETA: 0s - loss: 0.5536 - categorical_accuracy: 0.89004/4 [==============================] - 0s 6ms/step - loss: 0.5751 - categorical_accuracy: 0.8336 - val_loss: 0.7713 - val_categorical_accuracy: 0.6512
Epoch 18/100
1/4 [======>.......................] - ETA: 0s - loss: 0.5332 - categorical_accuracy: 0.85004/4 [==============================] - 0s 6ms/step - loss: 0.5457 - categorical_accuracy: 0.8288 - val_loss: 0.7746 - val_categorical_accuracy: 0.6512
Epoch 19/100
1/4 [======>.......................] - ETA: 0s - loss: 0.6308 - categorical_accuracy: 0.74004/4 [==============================] - 0s 6ms/step - loss: 0.5515 - categorical_accuracy: 0.7923 - val_loss: 0.7715 - val_categorical_accuracy: 0.6512
Epoch 20/100
1/4 [======>.......................] - ETA: 0s - loss: 0.5546 - categorical_accuracy: 0.81004/4 [==============================] - 0s 6ms/step - loss: 0.4908 - categorical_accuracy: 0.8286 - val_loss: 0.7482 - val_categorical_accuracy: 0.6977
Epoch 21/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3444 - categorical_accuracy: 0.89004/4 [==============================] - 0s 6ms/step - loss: 0.3902 - categorical_accuracy: 0.8613 - val_loss: 0.7086 - val_categorical_accuracy: 0.7674
Epoch 22/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3685 - categorical_accuracy: 0.87004/4 [==============================] - 0s 6ms/step - loss: 0.3817 - categorical_accuracy: 0.8629 - val_loss: 0.7097 - val_categorical_accuracy: 0.7442
Epoch 23/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3493 - categorical_accuracy: 0.85004/4 [==============================] - 0s 6ms/step - loss: 0.3541 - categorical_accuracy: 0.8655 - val_loss: 0.7243 - val_categorical_accuracy: 0.7442
Epoch 24/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3369 - categorical_accuracy: 0.88004/4 [==============================] - 0s 6ms/step - loss: 0.3268 - categorical_accuracy: 0.8745 - val_loss: 0.7230 - val_categorical_accuracy: 0.7674
Epoch 25/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3351 - categorical_accuracy: 0.87004/4 [==============================] - 0s 6ms/step - loss: 0.3264 - categorical_accuracy: 0.8837 - val_loss: 0.7102 - val_categorical_accuracy: 0.8140
Epoch 26/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3141 - categorical_accuracy: 0.87004/4 [==============================] - 0s 6ms/step - loss: 0.3041 - categorical_accuracy: 0.8905 - val_loss: 0.7277 - val_categorical_accuracy: 0.7907
Epoch 27/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3060 - categorical_accuracy: 0.84004/4 [==============================] - 0s 6ms/step - loss: 0.2874 - categorical_accuracy: 0.8730 - val_loss: 0.7371 - val_categorical_accuracy: 0.7907
Epoch 28/100
1/4 [======>.......................] - ETA: 0s - loss: 0.2209 - categorical_accuracy: 0.92004/4 [==============================] - 0s 6ms/step - loss: 0.2687 - categorical_accuracy: 0.8824 - val_loss: 0.7593 - val_categorical_accuracy: 0.7907
Epoch 00028: early stopping
Experiment:  232  Set:  har1 Train Labels:  nnar5 Test Labels:  clean
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.57      0.86      0.69        28
           1       0.92      1.00      0.96        35
           3       0.75      0.32      0.44        38
           4       0.46      0.51      0.49        35
           5       0.67      0.40      0.50        30
           6       0.72      0.97      0.83        37

    accuracy                           0.67       203
   macro avg       0.68      0.68      0.65       203
weighted avg       0.69      0.67      0.65       203

Confusion Matrix for this model: 
 [[24  0  0  2  2  0]
 [ 0 35  0  0  0  0]
 [ 3  3 12 18  1  1]
 [11  0  4 18  2  0]
 [ 4  0  0  1 12 13]
 [ 0  0  0  0  1 36]]
Experiment:  233  Set:  har1 Train Labels:  nnar5 Test Labels:  ncar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.50      0.81      0.62        26
           1       0.87      0.92      0.89        36
           2       0.00      0.00      0.00         1
           3       0.69      0.28      0.40        39
           4       0.41      0.48      0.44        33
           5       0.61      0.34      0.44        32
           6       0.68      0.94      0.79        36

    accuracy                           0.62       203
   macro avg       0.54      0.54      0.51       203
weighted avg       0.63      0.62      0.60       203

Confusion Matrix for this model: 
 [[21  0  0  0  3  2  0]
 [ 1 33  0  1  0  1  0]
 [ 0  0  0  0  1  0  0]
 [ 4  3  0 11 18  1  2]
 [11  0  0  4 16  2  0]
 [ 5  1  0  0  1 11 14]
 [ 0  1  0  0  0  1 34]]
Experiment:  234  Set:  har1 Train Labels:  nnar5 Test Labels:  ncar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.57      0.77      0.66        31
           1       0.84      0.94      0.89        34
           2       0.00      0.00      0.00         3
           3       0.75      0.32      0.44        38
           4       0.41      0.42      0.42        38
           5       0.56      0.40      0.47        25
           6       0.64      0.94      0.76        34

    accuracy                           0.62       203
   macro avg       0.54      0.54      0.52       203
weighted avg       0.62      0.62      0.60       203

Confusion Matrix for this model: 
 [[24  1  0  0  2  2  2]
 [ 0 32  0  0  0  2  0]
 [ 0  0  0  0  2  0  1]
 [ 3  3  0 12 18  1  1]
 [12  2  0  4 16  2  2]
 [ 3  0  0  0  0 10 12]
 [ 0  0  0  0  1  1 32]]
Experiment:  235  Set:  har1 Train Labels:  nnar5 Test Labels:  nar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.57      0.86      0.69        28
           1       0.92      1.00      0.96        35
           2       0.00      0.00      0.00         7
           3       0.50      0.26      0.34        31
           4       0.46      0.51      0.49        35
           5       0.67      0.40      0.50        30
           6       0.72      0.97      0.83        37

    accuracy                           0.66       203
   macro avg       0.55      0.57      0.54       203
weighted avg       0.62      0.66      0.62       203

Confusion Matrix for this model: 
 [[24  0  0  0  2  2  0]
 [ 0 35  0  0  0  0  0]
 [ 0  1  0  4  2  0  0]
 [ 3  2  0  8 16  1  1]
 [11  0  0  4 18  2  0]
 [ 4  0  0  0  1 12 13]
 [ 0  0  0  0  0  1 36]]
Experiment:  236  Set:  har1 Train Labels:  nnar5 Test Labels:  nar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.57      0.86      0.69        28
           1       0.92      1.00      0.96        35
           2       0.00      0.00      0.00        23
           3       0.38      0.40      0.39        15
           4       0.46      0.51      0.49        35
           5       0.67      0.40      0.50        30
           6       0.72      0.97      0.83        37

    accuracy                           0.65       203
   macro avg       0.53      0.59      0.55       203
weighted avg       0.57      0.65      0.60       203

Confusion Matrix for this model: 
 [[24  0  0  0  2  2  0]
 [ 0 35  0  0  0  0  0]
 [ 1  1  0  6 14  1  0]
 [ 2  2  0  6  4  0  1]
 [11  0  0  4 18  2  0]
 [ 4  0  0  0  1 12 13]
 [ 0  0  0  0  0  1 36]]
Experiment:  237  Set:  har1 Train Labels:  nnar5 Test Labels:  nnar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.57      0.86      0.69        28
           1       0.92      1.00      0.96        35
           3       0.44      0.23      0.30        30
           4       0.51      0.47      0.49        43
           5       0.67      0.40      0.50        30
           6       0.72      0.97      0.83        37

    accuracy                           0.66       203
   macro avg       0.64      0.65      0.63       203
weighted avg       0.64      0.66      0.63       203

Confusion Matrix for this model: 
 [[24  0  0  2  2  0]
 [ 0 35  0  0  0  0]
 [ 3  2  7 16  1  1]
 [11  1  9 20  2  0]
 [ 4  0  0  1 12 13]
 [ 0  0  0  0  1 36]]
Experiment:  238  Set:  har1 Train Labels:  nnar5 Test Labels:  nnar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.57      0.86      0.69        28
           1       0.92      1.00      0.96        35
           3       0.44      0.23      0.30        30
           4       0.51      0.47      0.49        43
           5       0.67      0.40      0.50        30
           6       0.72      0.97      0.83        37

    accuracy                           0.66       203
   macro avg       0.64      0.65      0.63       203
weighted avg       0.64      0.66      0.63       203

Confusion Matrix for this model: 
 [[24  0  0  2  2  0]
 [ 0 35  0  0  0  0]
 [ 3  2  7 16  1  1]
 [11  1  9 20  2  0]
 [ 4  0  0  1 12 13]
 [ 0  0  0  0  1 36]]
Input Shape:  (425, 1, 150)
Model: "sequential_34"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_34 (LSTM)               (None, 32)                23424     
_________________________________________________________________
dropout_34 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_136 (Dense)            (None, 128)               4224      
_________________________________________________________________
dense_137 (Dense)            (None, 128)               16512     
_________________________________________________________________
dense_138 (Dense)            (None, 64)                8256      
_________________________________________________________________
dense_139 (Dense)            (None, 7)                 455       
=================================================================
Total params: 52,871
Trainable params: 52,871
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
1/4 [======>.......................] - ETA: 3s - loss: 1.9452 - categorical_accuracy: 0.11004/4 [==============================] - 1s 96ms/step - loss: 1.9386 - categorical_accuracy: 0.1733 - val_loss: 1.9190 - val_categorical_accuracy: 0.1628
Epoch 2/100
1/4 [======>.......................] - ETA: 0s - loss: 1.9065 - categorical_accuracy: 0.31004/4 [==============================] - 0s 6ms/step - loss: 1.9019 - categorical_accuracy: 0.3068 - val_loss: 1.8874 - val_categorical_accuracy: 0.2326
Epoch 3/100
1/4 [======>.......................] - ETA: 0s - loss: 1.8757 - categorical_accuracy: 0.33004/4 [==============================] - 0s 6ms/step - loss: 1.8614 - categorical_accuracy: 0.3449 - val_loss: 1.8475 - val_categorical_accuracy: 0.3721
Epoch 4/100
1/4 [======>.......................] - ETA: 0s - loss: 1.8322 - categorical_accuracy: 0.35004/4 [==============================] - 0s 6ms/step - loss: 1.8150 - categorical_accuracy: 0.3625 - val_loss: 1.7949 - val_categorical_accuracy: 0.4186
Epoch 5/100
1/4 [======>.......................] - ETA: 0s - loss: 1.7893 - categorical_accuracy: 0.37004/4 [==============================] - 0s 6ms/step - loss: 1.7552 - categorical_accuracy: 0.3928 - val_loss: 1.7317 - val_categorical_accuracy: 0.3953
Epoch 6/100
1/4 [======>.......................] - ETA: 0s - loss: 1.7347 - categorical_accuracy: 0.33004/4 [==============================] - 0s 6ms/step - loss: 1.6905 - categorical_accuracy: 0.3781 - val_loss: 1.6574 - val_categorical_accuracy: 0.4186
Epoch 7/100
1/4 [======>.......................] - ETA: 0s - loss: 1.6042 - categorical_accuracy: 0.41004/4 [==============================] - 0s 6ms/step - loss: 1.5969 - categorical_accuracy: 0.4019 - val_loss: 1.5664 - val_categorical_accuracy: 0.4186
Epoch 8/100
1/4 [======>.......................] - ETA: 0s - loss: 1.4500 - categorical_accuracy: 0.45004/4 [==============================] - 0s 6ms/step - loss: 1.4732 - categorical_accuracy: 0.4348 - val_loss: 1.4701 - val_categorical_accuracy: 0.4651
Epoch 9/100
1/4 [======>.......................] - ETA: 0s - loss: 1.4479 - categorical_accuracy: 0.41004/4 [==============================] - 0s 6ms/step - loss: 1.3974 - categorical_accuracy: 0.4374 - val_loss: 1.3677 - val_categorical_accuracy: 0.4884
Epoch 10/100
1/4 [======>.......................] - ETA: 0s - loss: 1.2639 - categorical_accuracy: 0.56004/4 [==============================] - 0s 6ms/step - loss: 1.2687 - categorical_accuracy: 0.5646 - val_loss: 1.2755 - val_categorical_accuracy: 0.5814
Epoch 11/100
1/4 [======>.......................] - ETA: 0s - loss: 1.2007 - categorical_accuracy: 0.63004/4 [==============================] - 0s 6ms/step - loss: 1.1738 - categorical_accuracy: 0.6251 - val_loss: 1.1754 - val_categorical_accuracy: 0.5814
Epoch 12/100
1/4 [======>.......................] - ETA: 0s - loss: 1.0570 - categorical_accuracy: 0.65004/4 [==============================] - 0s 6ms/step - loss: 1.0548 - categorical_accuracy: 0.6561 - val_loss: 1.0918 - val_categorical_accuracy: 0.5814
Epoch 13/100
1/4 [======>.......................] - ETA: 0s - loss: 1.0584 - categorical_accuracy: 0.62004/4 [==============================] - 0s 6ms/step - loss: 0.9834 - categorical_accuracy: 0.6732 - val_loss: 1.0136 - val_categorical_accuracy: 0.6047
Epoch 14/100
1/4 [======>.......................] - ETA: 0s - loss: 0.9647 - categorical_accuracy: 0.65004/4 [==============================] - 0s 6ms/step - loss: 0.8901 - categorical_accuracy: 0.7163 - val_loss: 0.9740 - val_categorical_accuracy: 0.6279
Epoch 15/100
1/4 [======>.......................] - ETA: 0s - loss: 0.7844 - categorical_accuracy: 0.76004/4 [==============================] - 0s 6ms/step - loss: 0.7734 - categorical_accuracy: 0.7485 - val_loss: 0.9018 - val_categorical_accuracy: 0.6512
Epoch 16/100
1/4 [======>.......................] - ETA: 0s - loss: 0.6973 - categorical_accuracy: 0.77004/4 [==============================] - 0s 6ms/step - loss: 0.6957 - categorical_accuracy: 0.7794 - val_loss: 0.8413 - val_categorical_accuracy: 0.6744
Epoch 17/100
1/4 [======>.......................] - ETA: 0s - loss: 0.6815 - categorical_accuracy: 0.77004/4 [==============================] - 0s 6ms/step - loss: 0.6424 - categorical_accuracy: 0.7818 - val_loss: 0.8182 - val_categorical_accuracy: 0.6977
Epoch 18/100
1/4 [======>.......................] - ETA: 0s - loss: 0.5473 - categorical_accuracy: 0.82004/4 [==============================] - 0s 6ms/step - loss: 0.5629 - categorical_accuracy: 0.8155 - val_loss: 0.7402 - val_categorical_accuracy: 0.7209
Epoch 19/100
1/4 [======>.......................] - ETA: 0s - loss: 0.4653 - categorical_accuracy: 0.86004/4 [==============================] - 0s 6ms/step - loss: 0.4918 - categorical_accuracy: 0.8435 - val_loss: 0.7165 - val_categorical_accuracy: 0.6977
Epoch 20/100
1/4 [======>.......................] - ETA: 0s - loss: 0.5001 - categorical_accuracy: 0.85004/4 [==============================] - 0s 6ms/step - loss: 0.4660 - categorical_accuracy: 0.8540 - val_loss: 0.7076 - val_categorical_accuracy: 0.6977
Epoch 21/100
1/4 [======>.......................] - ETA: 0s - loss: 0.4365 - categorical_accuracy: 0.85004/4 [==============================] - 0s 6ms/step - loss: 0.4270 - categorical_accuracy: 0.8541 - val_loss: 0.6786 - val_categorical_accuracy: 0.7209
Epoch 22/100
1/4 [======>.......................] - ETA: 0s - loss: 0.5070 - categorical_accuracy: 0.82004/4 [==============================] - 0s 6ms/step - loss: 0.4396 - categorical_accuracy: 0.8474 - val_loss: 0.7110 - val_categorical_accuracy: 0.7442
Epoch 23/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3518 - categorical_accuracy: 0.85004/4 [==============================] - 0s 6ms/step - loss: 0.3570 - categorical_accuracy: 0.8734 - val_loss: 0.6722 - val_categorical_accuracy: 0.7209
Epoch 24/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3355 - categorical_accuracy: 0.86004/4 [==============================] - 0s 6ms/step - loss: 0.3274 - categorical_accuracy: 0.8878 - val_loss: 0.6357 - val_categorical_accuracy: 0.7674
Epoch 25/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3736 - categorical_accuracy: 0.89004/4 [==============================] - 0s 6ms/step - loss: 0.3320 - categorical_accuracy: 0.8955 - val_loss: 0.6578 - val_categorical_accuracy: 0.7209
Epoch 26/100
1/4 [======>.......................] - ETA: 0s - loss: 0.3578 - categorical_accuracy: 0.88004/4 [==============================] - 0s 6ms/step - loss: 0.2986 - categorical_accuracy: 0.8948 - val_loss: 0.6602 - val_categorical_accuracy: 0.7907
Epoch 27/100
1/4 [======>.......................] - ETA: 0s - loss: 0.2135 - categorical_accuracy: 0.93004/4 [==============================] - 0s 6ms/step - loss: 0.2706 - categorical_accuracy: 0.9075 - val_loss: 0.7109 - val_categorical_accuracy: 0.7907
Epoch 28/100
1/4 [======>.......................] - ETA: 0s - loss: 0.2887 - categorical_accuracy: 0.91004/4 [==============================] - 0s 6ms/step - loss: 0.2782 - categorical_accuracy: 0.9033 - val_loss: 0.6911 - val_categorical_accuracy: 0.7674
Epoch 29/100
1/4 [======>.......................] - ETA: 0s - loss: 0.2854 - categorical_accuracy: 0.88004/4 [==============================] - 0s 6ms/step - loss: 0.2856 - categorical_accuracy: 0.8909 - val_loss: 0.6359 - val_categorical_accuracy: 0.7674
Epoch 30/100
1/4 [======>.......................] - ETA: 0s - loss: 0.2308 - categorical_accuracy: 0.93004/4 [==============================] - 0s 6ms/step - loss: 0.2459 - categorical_accuracy: 0.9150 - val_loss: 0.6498 - val_categorical_accuracy: 0.8140
Epoch 31/100
1/4 [======>.......................] - ETA: 0s - loss: 0.1436 - categorical_accuracy: 0.99004/4 [==============================] - 0s 6ms/step - loss: 0.1859 - categorical_accuracy: 0.9573 - val_loss: 0.7421 - val_categorical_accuracy: 0.7674
Epoch 00031: early stopping
Experiment:  239  Set:  har1 Train Labels:  nnar10 Test Labels:  clean
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.67      0.86      0.75        28
           1       1.00      1.00      1.00        35
           3       0.60      0.32      0.41        38
           4       0.45      0.54      0.49        35
           5       0.68      0.57      0.62        30
           6       0.80      0.97      0.88        37

    accuracy                           0.70       203
   macro avg       0.70      0.71      0.69       203
weighted avg       0.70      0.70      0.69       203

Confusion Matrix for this model: 
 [[24  0  0  0  4  0]
 [ 0 35  0  0  0  0]
 [ 3  0 12 23  0  0]
 [ 5  0  8 19  3  0]
 [ 4  0  0  0 17  9]
 [ 0  0  0  0  1 36]]
Experiment:  240  Set:  har1 Train Labels:  nnar10 Test Labels:  ncar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.61      0.85      0.71        26
           1       0.94      0.92      0.93        36
           2       0.00      0.00      0.00         1
           3       0.55      0.28      0.37        39
           4       0.40      0.52      0.45        33
           5       0.68      0.53      0.60        32
           6       0.76      0.94      0.84        36

    accuracy                           0.66       203
   macro avg       0.56      0.58      0.56       203
weighted avg       0.66      0.66      0.64       203

Confusion Matrix for this model: 
 [[22  0  0  0  1  3  0]
 [ 1 33  0  1  0  1  0]
 [ 0  0  0  0  1  0  0]
 [ 4  0  0 11 23  0  1]
 [ 5  0  0  8 17  3  0]
 [ 4  1  0  0  0 17 10]
 [ 0  1  0  0  0  1 34]]
Experiment:  241  Set:  har1 Train Labels:  nnar10 Test Labels:  ncar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.67      0.77      0.72        31
           1       0.91      0.94      0.93        34
           2       0.00      0.00      0.00         3
           3       0.60      0.32      0.41        38
           4       0.43      0.47      0.45        38
           5       0.56      0.56      0.56        25
           6       0.71      0.94      0.81        34

    accuracy                           0.65       203
   macro avg       0.55      0.57      0.55       203
weighted avg       0.64      0.65      0.63       203

Confusion Matrix for this model: 
 [[24  1  0  0  0  4  2]
 [ 0 32  0  0  0  2  0]
 [ 1  0  0  1  0  0  1]
 [ 3  0  0 12 23  0  0]
 [ 5  2  0  7 18  4  2]
 [ 3  0  0  0  0 14  8]
 [ 0  0  0  0  1  1 32]]
Experiment:  242  Set:  har1 Train Labels:  nnar10 Test Labels:  nar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.67      0.86      0.75        28
           1       1.00      1.00      1.00        35
           2       0.00      0.00      0.00         7
           3       0.55      0.35      0.43        31
           4       0.45      0.54      0.49        35
           5       0.68      0.57      0.62        30
           6       0.80      0.97      0.88        37

    accuracy                           0.70       203
   macro avg       0.59      0.61      0.60       203
weighted avg       0.67      0.70      0.68       203

Confusion Matrix for this model: 
 [[24  0  0  0  0  4  0]
 [ 0 35  0  0  0  0  0]
 [ 0  0  0  1  6  0  0]
 [ 3  0  0 11 17  0  0]
 [ 5  0  0  8 19  3  0]
 [ 4  0  0  0  0 17  9]
 [ 0  0  0  0  0  1 36]]
Experiment:  243  Set:  har1 Train Labels:  nnar10 Test Labels:  nar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.67      0.86      0.75        28
           1       1.00      1.00      1.00        35
           2       0.00      0.00      0.00        23
           3       0.25      0.33      0.29        15
           4       0.45      0.54      0.49        35
           5       0.68      0.57      0.62        30
           6       0.80      0.97      0.88        37

    accuracy                           0.67       203
   macro avg       0.55      0.61      0.58       203
weighted avg       0.61      0.67      0.63       203

Confusion Matrix for this model: 
 [[24  0  0  0  0  4  0]
 [ 0 35  0  0  0  0  0]
 [ 2  0  0  7 14  0  0]
 [ 1  0  0  5  9  0  0]
 [ 5  0  0  8 19  3  0]
 [ 4  0  0  0  0 17  9]
 [ 0  0  0  0  0  1 36]]
Experiment:  244  Set:  har1 Train Labels:  nnar10 Test Labels:  nnar5
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.67      0.86      0.75        28
           1       1.00      1.00      1.00        35
           3       0.45      0.30      0.36        30
           4       0.57      0.56      0.56        43
           5       0.68      0.57      0.62        30
           6       0.80      0.97      0.88        37

    accuracy                           0.71       203
   macro avg       0.69      0.71      0.70       203
weighted avg       0.70      0.71      0.70       203

Confusion Matrix for this model: 
 [[24  0  0  0  4  0]
 [ 0 35  0  0  0  0]
 [ 3  0  9 18  0  0]
 [ 5  0 11 24  3  0]
 [ 4  0  0  0 17  9]
 [ 0  0  0  0  1 36]]
Experiment:  245  Set:  har1 Train Labels:  nnar10 Test Labels:  nnar10
Shape of X_train:  (425, 1, 150)
Shape of X_test:  (203, 1, 150)
Shape of y_train:  (425, 7)
Shape of y_test:  (203, 7)
NUM_INSTANCES is  425
instances should be  425
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.67      0.86      0.75        28
           1       1.00      1.00      1.00        35
           3       0.45      0.30      0.36        30
           4       0.57      0.56      0.56        43
           5       0.68      0.57      0.62        30
           6       0.80      0.97      0.88        37

    accuracy                           0.71       203
   macro avg       0.69      0.71      0.70       203
weighted avg       0.70      0.71      0.70       203

Confusion Matrix for this model: 
 [[24  0  0  0  4  0]
 [ 0 35  0  0  0  0]
 [ 3  0  9 18  0  0]
 [ 5  0 11 24  3  0]
 [ 4  0  0  0 17  9]
 [ 0  0  0  0  1 36]]
Input Shape:  (7352, 3, 128)
Model: "sequential_35"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_35 (LSTM)               (None, 32)                20608     
_________________________________________________________________
dropout_35 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_140 (Dense)            (None, 128)               4224      
_________________________________________________________________
dense_141 (Dense)            (None, 128)               16512     
_________________________________________________________________
dense_142 (Dense)            (None, 64)                8256      
_________________________________________________________________
dense_143 (Dense)            (None, 6)                 390       
=================================================================
Total params: 49,990
Trainable params: 49,990
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/67 [..............................] - ETA: 1:09 - loss: 1.8050 - categorical_accuracy: 0.100021/67 [========>.....................] - ETA: 0s - loss: 1.7119 - categorical_accuracy: 0.2315  42/67 [=================>............] - ETA: 0s - loss: 1.6296 - categorical_accuracy: 0.264264/67 [===========================>..] - ETA: 0s - loss: 1.5503 - categorical_accuracy: 0.299367/67 [==============================] - 2s 7ms/step - loss: 1.5369 - categorical_accuracy: 0.3051 - val_loss: 0.9221 - val_categorical_accuracy: 0.5462
Epoch 2/100
 1/67 [..............................] - ETA: 0s - loss: 0.9328 - categorical_accuracy: 0.590022/67 [========>.....................] - ETA: 0s - loss: 0.9483 - categorical_accuracy: 0.550344/67 [==================>...........] - ETA: 0s - loss: 0.9235 - categorical_accuracy: 0.561866/67 [============================>.] - ETA: 0s - loss: 0.9066 - categorical_accuracy: 0.570467/67 [==============================] - 0s 3ms/step - loss: 0.9052 - categorical_accuracy: 0.5712 - val_loss: 0.7274 - val_categorical_accuracy: 0.6603
Epoch 3/100
 1/67 [..............................] - ETA: 0s - loss: 0.7404 - categorical_accuracy: 0.690023/67 [=========>....................] - ETA: 0s - loss: 0.7754 - categorical_accuracy: 0.648745/67 [===================>..........] - ETA: 0s - loss: 0.7694 - categorical_accuracy: 0.645867/67 [==============================] - 0s 3ms/step - loss: 0.7613 - categorical_accuracy: 0.6475 - val_loss: 0.6436 - val_categorical_accuracy: 0.7174
Epoch 4/100
 1/67 [..............................] - ETA: 0s - loss: 0.7116 - categorical_accuracy: 0.670024/67 [=========>....................] - ETA: 0s - loss: 0.7028 - categorical_accuracy: 0.665446/67 [===================>..........] - ETA: 0s - loss: 0.6981 - categorical_accuracy: 0.668467/67 [==============================] - 0s 3ms/step - loss: 0.6946 - categorical_accuracy: 0.6704 - val_loss: 0.6118 - val_categorical_accuracy: 0.6875
Epoch 5/100
 1/67 [..............................] - ETA: 0s - loss: 0.6058 - categorical_accuracy: 0.740023/67 [=========>....................] - ETA: 0s - loss: 0.6407 - categorical_accuracy: 0.698646/67 [===================>..........] - ETA: 0s - loss: 0.6404 - categorical_accuracy: 0.700967/67 [==============================] - 0s 3ms/step - loss: 0.6388 - categorical_accuracy: 0.7018 - val_loss: 0.5729 - val_categorical_accuracy: 0.7242
Epoch 6/100
 1/67 [..............................] - ETA: 0s - loss: 0.6709 - categorical_accuracy: 0.650024/67 [=========>....................] - ETA: 0s - loss: 0.6282 - categorical_accuracy: 0.697146/67 [===================>..........] - ETA: 0s - loss: 0.6169 - categorical_accuracy: 0.705067/67 [==============================] - 0s 3ms/step - loss: 0.6107 - categorical_accuracy: 0.7095 - val_loss: 0.5429 - val_categorical_accuracy: 0.7011
Epoch 7/100
 1/67 [..............................] - ETA: 0s - loss: 0.5443 - categorical_accuracy: 0.720024/67 [=========>....................] - ETA: 0s - loss: 0.5664 - categorical_accuracy: 0.725447/67 [====================>.........] - ETA: 0s - loss: 0.5727 - categorical_accuracy: 0.726267/67 [==============================] - 0s 3ms/step - loss: 0.5717 - categorical_accuracy: 0.7275 - val_loss: 0.4847 - val_categorical_accuracy: 0.7976
Epoch 8/100
 1/67 [..............................] - ETA: 0s - loss: 0.6039 - categorical_accuracy: 0.760024/67 [=========>....................] - ETA: 0s - loss: 0.5189 - categorical_accuracy: 0.773747/67 [====================>.........] - ETA: 0s - loss: 0.5270 - categorical_accuracy: 0.765067/67 [==============================] - 0s 3ms/step - loss: 0.5282 - categorical_accuracy: 0.7615 - val_loss: 0.4479 - val_categorical_accuracy: 0.7812
Epoch 9/100
 1/67 [..............................] - ETA: 0s - loss: 0.5736 - categorical_accuracy: 0.760024/67 [=========>....................] - ETA: 0s - loss: 0.5301 - categorical_accuracy: 0.754947/67 [====================>.........] - ETA: 0s - loss: 0.5209 - categorical_accuracy: 0.758167/67 [==============================] - 0s 3ms/step - loss: 0.5174 - categorical_accuracy: 0.7592 - val_loss: 0.4582 - val_categorical_accuracy: 0.7486
Epoch 10/100
 1/67 [..............................] - ETA: 0s - loss: 0.3217 - categorical_accuracy: 0.880024/67 [=========>....................] - ETA: 0s - loss: 0.4694 - categorical_accuracy: 0.790546/67 [===================>..........] - ETA: 0s - loss: 0.4745 - categorical_accuracy: 0.788367/67 [==============================] - 0s 3ms/step - loss: 0.4751 - categorical_accuracy: 0.7887 - val_loss: 0.4215 - val_categorical_accuracy: 0.8030
Epoch 11/100
 1/67 [..............................] - ETA: 0s - loss: 0.5569 - categorical_accuracy: 0.760023/67 [=========>....................] - ETA: 0s - loss: 0.4408 - categorical_accuracy: 0.805446/67 [===================>..........] - ETA: 0s - loss: 0.4468 - categorical_accuracy: 0.799467/67 [==============================] - 0s 3ms/step - loss: 0.4485 - categorical_accuracy: 0.7975 - val_loss: 0.4137 - val_categorical_accuracy: 0.8071
Epoch 12/100
 1/67 [..............................] - ETA: 0s - loss: 0.5181 - categorical_accuracy: 0.760024/67 [=========>....................] - ETA: 0s - loss: 0.4722 - categorical_accuracy: 0.778246/67 [===================>..........] - ETA: 0s - loss: 0.4572 - categorical_accuracy: 0.787867/67 [==============================] - 0s 3ms/step - loss: 0.4488 - categorical_accuracy: 0.7941 - val_loss: 0.3934 - val_categorical_accuracy: 0.8071
Epoch 13/100
 1/67 [..............................] - ETA: 0s - loss: 0.5073 - categorical_accuracy: 0.790024/67 [=========>....................] - ETA: 0s - loss: 0.4199 - categorical_accuracy: 0.798846/67 [===================>..........] - ETA: 0s - loss: 0.4130 - categorical_accuracy: 0.804667/67 [==============================] - 0s 3ms/step - loss: 0.4114 - categorical_accuracy: 0.8081 - val_loss: 0.3677 - val_categorical_accuracy: 0.8166
Epoch 14/100
 1/67 [..............................] - ETA: 0s - loss: 0.4367 - categorical_accuracy: 0.830024/67 [=========>....................] - ETA: 0s - loss: 0.4626 - categorical_accuracy: 0.793847/67 [====================>.........] - ETA: 0s - loss: 0.4471 - categorical_accuracy: 0.801967/67 [==============================] - 0s 3ms/step - loss: 0.4345 - categorical_accuracy: 0.8088 - val_loss: 0.3702 - val_categorical_accuracy: 0.8207
Epoch 15/100
 1/67 [..............................] - ETA: 0s - loss: 0.4598 - categorical_accuracy: 0.790024/67 [=========>....................] - ETA: 0s - loss: 0.4052 - categorical_accuracy: 0.820147/67 [====================>.........] - ETA: 0s - loss: 0.3985 - categorical_accuracy: 0.824967/67 [==============================] - 0s 3ms/step - loss: 0.3953 - categorical_accuracy: 0.8260 - val_loss: 0.3251 - val_categorical_accuracy: 0.8465
Epoch 16/100
 1/67 [..............................] - ETA: 0s - loss: 0.3255 - categorical_accuracy: 0.870024/67 [=========>....................] - ETA: 0s - loss: 0.3642 - categorical_accuracy: 0.839647/67 [====================>.........] - ETA: 0s - loss: 0.3649 - categorical_accuracy: 0.841867/67 [==============================] - 0s 3ms/step - loss: 0.3671 - categorical_accuracy: 0.8414 - val_loss: 0.3688 - val_categorical_accuracy: 0.8152
Epoch 17/100
 1/67 [..............................] - ETA: 0s - loss: 0.3683 - categorical_accuracy: 0.850024/67 [=========>....................] - ETA: 0s - loss: 0.3775 - categorical_accuracy: 0.823446/67 [===================>..........] - ETA: 0s - loss: 0.3687 - categorical_accuracy: 0.830067/67 [==============================] - 0s 3ms/step - loss: 0.3655 - categorical_accuracy: 0.8332 - val_loss: 0.2946 - val_categorical_accuracy: 0.8709
Epoch 18/100
 1/67 [..............................] - ETA: 0s - loss: 0.3218 - categorical_accuracy: 0.850023/67 [=========>....................] - ETA: 0s - loss: 0.3428 - categorical_accuracy: 0.852946/67 [===================>..........] - ETA: 0s - loss: 0.3488 - categorical_accuracy: 0.850067/67 [==============================] - 0s 3ms/step - loss: 0.3483 - categorical_accuracy: 0.8497 - val_loss: 0.3409 - val_categorical_accuracy: 0.8261
Epoch 19/100
 1/67 [..............................] - ETA: 0s - loss: 0.4103 - categorical_accuracy: 0.800024/67 [=========>....................] - ETA: 0s - loss: 0.3805 - categorical_accuracy: 0.827447/67 [====================>.........] - ETA: 0s - loss: 0.3823 - categorical_accuracy: 0.825367/67 [==============================] - 0s 3ms/step - loss: 0.3794 - categorical_accuracy: 0.8261 - val_loss: 0.3029 - val_categorical_accuracy: 0.8682
Epoch 20/100
 1/67 [..............................] - ETA: 0s - loss: 0.3279 - categorical_accuracy: 0.840024/67 [=========>....................] - ETA: 0s - loss: 0.3204 - categorical_accuracy: 0.869246/67 [===================>..........] - ETA: 0s - loss: 0.3253 - categorical_accuracy: 0.864167/67 [==============================] - 0s 3ms/step - loss: 0.3264 - categorical_accuracy: 0.8624 - val_loss: 0.4309 - val_categorical_accuracy: 0.8166
Epoch 21/100
 1/67 [..............................] - ETA: 0s - loss: 0.3946 - categorical_accuracy: 0.830023/67 [=========>....................] - ETA: 0s - loss: 0.3963 - categorical_accuracy: 0.822446/67 [===================>..........] - ETA: 0s - loss: 0.3725 - categorical_accuracy: 0.831567/67 [==============================] - 0s 3ms/step - loss: 0.3606 - categorical_accuracy: 0.8371 - val_loss: 0.2822 - val_categorical_accuracy: 0.8845
Epoch 22/100
 1/67 [..............................] - ETA: 0s - loss: 0.3425 - categorical_accuracy: 0.830024/67 [=========>....................] - ETA: 0s - loss: 0.3250 - categorical_accuracy: 0.857447/67 [====================>.........] - ETA: 0s - loss: 0.3247 - categorical_accuracy: 0.858367/67 [==============================] - 0s 3ms/step - loss: 0.3267 - categorical_accuracy: 0.8573 - val_loss: 0.2945 - val_categorical_accuracy: 0.8859
Epoch 23/100
 1/67 [..............................] - ETA: 0s - loss: 0.3092 - categorical_accuracy: 0.830024/67 [=========>....................] - ETA: 0s - loss: 0.3165 - categorical_accuracy: 0.852146/67 [===================>..........] - ETA: 0s - loss: 0.3177 - categorical_accuracy: 0.852067/67 [==============================] - 0s 3ms/step - loss: 0.3175 - categorical_accuracy: 0.8533 - val_loss: 0.3725 - val_categorical_accuracy: 0.8220
Epoch 24/100
 1/67 [..............................] - ETA: 0s - loss: 0.3871 - categorical_accuracy: 0.820024/67 [=========>....................] - ETA: 0s - loss: 0.3639 - categorical_accuracy: 0.836246/67 [===================>..........] - ETA: 0s - loss: 0.3603 - categorical_accuracy: 0.839667/67 [==============================] - 0s 3ms/step - loss: 0.3534 - categorical_accuracy: 0.8425 - val_loss: 0.2933 - val_categorical_accuracy: 0.8777
Epoch 25/100
 1/67 [..............................] - ETA: 0s - loss: 0.2151 - categorical_accuracy: 0.930023/67 [=========>....................] - ETA: 0s - loss: 0.3051 - categorical_accuracy: 0.874346/67 [===================>..........] - ETA: 0s - loss: 0.3053 - categorical_accuracy: 0.869767/67 [==============================] - 0s 3ms/step - loss: 0.3039 - categorical_accuracy: 0.8687 - val_loss: 0.2699 - val_categorical_accuracy: 0.8872
Epoch 26/100
 1/67 [..............................] - ETA: 0s - loss: 0.2708 - categorical_accuracy: 0.880024/67 [=========>....................] - ETA: 0s - loss: 0.3145 - categorical_accuracy: 0.862847/67 [====================>.........] - ETA: 0s - loss: 0.3129 - categorical_accuracy: 0.862967/67 [==============================] - 0s 3ms/step - loss: 0.3130 - categorical_accuracy: 0.8618 - val_loss: 0.3328 - val_categorical_accuracy: 0.8302
Epoch 27/100
 1/67 [..............................] - ETA: 0s - loss: 0.3293 - categorical_accuracy: 0.830024/67 [=========>....................] - ETA: 0s - loss: 0.3039 - categorical_accuracy: 0.866547/67 [====================>.........] - ETA: 0s - loss: 0.2977 - categorical_accuracy: 0.868767/67 [==============================] - 0s 3ms/step - loss: 0.2960 - categorical_accuracy: 0.8690 - val_loss: 0.2752 - val_categorical_accuracy: 0.8736
Epoch 28/100
 1/67 [..............................] - ETA: 0s - loss: 0.2434 - categorical_accuracy: 0.910024/67 [=========>....................] - ETA: 0s - loss: 0.2826 - categorical_accuracy: 0.881047/67 [====================>.........] - ETA: 0s - loss: 0.2876 - categorical_accuracy: 0.876967/67 [==============================] - 0s 3ms/step - loss: 0.2906 - categorical_accuracy: 0.8744 - val_loss: 0.2833 - val_categorical_accuracy: 0.8587
Epoch 29/100
 1/67 [..............................] - ETA: 0s - loss: 0.3219 - categorical_accuracy: 0.840023/67 [=========>....................] - ETA: 0s - loss: 0.3078 - categorical_accuracy: 0.859346/67 [===================>..........] - ETA: 0s - loss: 0.3017 - categorical_accuracy: 0.866467/67 [==============================] - 0s 3ms/step - loss: 0.2980 - categorical_accuracy: 0.8700 - val_loss: 0.2638 - val_categorical_accuracy: 0.8709
Epoch 30/100
 1/67 [..............................] - ETA: 0s - loss: 0.3057 - categorical_accuracy: 0.850024/67 [=========>....................] - ETA: 0s - loss: 0.2806 - categorical_accuracy: 0.875446/67 [===================>..........] - ETA: 0s - loss: 0.2800 - categorical_accuracy: 0.877067/67 [==============================] - 0s 3ms/step - loss: 0.2807 - categorical_accuracy: 0.8772 - val_loss: 0.3099 - val_categorical_accuracy: 0.8546
Epoch 31/100
 1/67 [..............................] - ETA: 0s - loss: 0.3531 - categorical_accuracy: 0.830024/67 [=========>....................] - ETA: 0s - loss: 0.3055 - categorical_accuracy: 0.854247/67 [====================>.........] - ETA: 0s - loss: 0.2917 - categorical_accuracy: 0.866167/67 [==============================] - 0s 3ms/step - loss: 0.2868 - categorical_accuracy: 0.8711 - val_loss: 0.3200 - val_categorical_accuracy: 0.8546
Epoch 32/100
 1/67 [..............................] - ETA: 0s - loss: 0.2741 - categorical_accuracy: 0.840024/67 [=========>....................] - ETA: 0s - loss: 0.3239 - categorical_accuracy: 0.845047/67 [====================>.........] - ETA: 0s - loss: 0.3177 - categorical_accuracy: 0.850767/67 [==============================] - 0s 3ms/step - loss: 0.3084 - categorical_accuracy: 0.8564 - val_loss: 0.4289 - val_categorical_accuracy: 0.8356
Epoch 33/100
 1/67 [..............................] - ETA: 0s - loss: 0.3619 - categorical_accuracy: 0.850024/67 [=========>....................] - ETA: 0s - loss: 0.3086 - categorical_accuracy: 0.867746/67 [===================>..........] - ETA: 0s - loss: 0.3011 - categorical_accuracy: 0.871267/67 [==============================] - 0s 3ms/step - loss: 0.2965 - categorical_accuracy: 0.8725 - val_loss: 0.2701 - val_categorical_accuracy: 0.8967
Epoch 34/100
 1/67 [..............................] - ETA: 0s - loss: 0.3543 - categorical_accuracy: 0.870023/67 [=========>....................] - ETA: 0s - loss: 0.2844 - categorical_accuracy: 0.882145/67 [===================>..........] - ETA: 0s - loss: 0.2811 - categorical_accuracy: 0.881667/67 [==============================] - ETA: 0s - loss: 0.2783 - categorical_accuracy: 0.882367/67 [==============================] - 0s 3ms/step - loss: 0.2782 - categorical_accuracy: 0.8823 - val_loss: 0.2620 - val_categorical_accuracy: 0.8995
Epoch 35/100
 1/67 [..............................] - ETA: 0s - loss: 0.3335 - categorical_accuracy: 0.810024/67 [=========>....................] - ETA: 0s - loss: 0.2658 - categorical_accuracy: 0.878247/67 [====================>.........] - ETA: 0s - loss: 0.2647 - categorical_accuracy: 0.880667/67 [==============================] - 0s 3ms/step - loss: 0.2707 - categorical_accuracy: 0.8786 - val_loss: 0.2860 - val_categorical_accuracy: 0.8818
Epoch 36/100
 1/67 [..............................] - ETA: 0s - loss: 0.2286 - categorical_accuracy: 0.920024/67 [=========>....................] - ETA: 0s - loss: 0.2880 - categorical_accuracy: 0.875947/67 [====================>.........] - ETA: 0s - loss: 0.2852 - categorical_accuracy: 0.875367/67 [==============================] - 0s 3ms/step - loss: 0.2830 - categorical_accuracy: 0.8763 - val_loss: 0.2640 - val_categorical_accuracy: 0.8967
Epoch 37/100
 1/67 [..............................] - ETA: 0s - loss: 0.3830 - categorical_accuracy: 0.830023/67 [=========>....................] - ETA: 0s - loss: 0.2772 - categorical_accuracy: 0.878246/67 [===================>..........] - ETA: 0s - loss: 0.2646 - categorical_accuracy: 0.887067/67 [==============================] - 0s 3ms/step - loss: 0.2603 - categorical_accuracy: 0.8890 - val_loss: 0.2675 - val_categorical_accuracy: 0.8764
Epoch 38/100
 1/67 [..............................] - ETA: 0s - loss: 0.2390 - categorical_accuracy: 0.900024/67 [=========>....................] - ETA: 0s - loss: 0.2731 - categorical_accuracy: 0.881347/67 [====================>.........] - ETA: 0s - loss: 0.2761 - categorical_accuracy: 0.881567/67 [==============================] - 0s 3ms/step - loss: 0.2743 - categorical_accuracy: 0.8830 - val_loss: 0.2546 - val_categorical_accuracy: 0.8859
Epoch 39/100
 1/67 [..............................] - ETA: 0s - loss: 0.3415 - categorical_accuracy: 0.820023/67 [=========>....................] - ETA: 0s - loss: 0.2755 - categorical_accuracy: 0.876946/67 [===================>..........] - ETA: 0s - loss: 0.2661 - categorical_accuracy: 0.883867/67 [==============================] - 0s 3ms/step - loss: 0.2619 - categorical_accuracy: 0.8862 - val_loss: 0.2709 - val_categorical_accuracy: 0.8682
Epoch 40/100
 1/67 [..............................] - ETA: 0s - loss: 0.2827 - categorical_accuracy: 0.870024/67 [=========>....................] - ETA: 0s - loss: 0.2764 - categorical_accuracy: 0.878247/67 [====================>.........] - ETA: 0s - loss: 0.2675 - categorical_accuracy: 0.882167/67 [==============================] - 0s 3ms/step - loss: 0.2669 - categorical_accuracy: 0.8816 - val_loss: 0.2642 - val_categorical_accuracy: 0.9049
Epoch 41/100
 1/67 [..............................] - ETA: 0s - loss: 0.2365 - categorical_accuracy: 0.930024/67 [=========>....................] - ETA: 0s - loss: 0.2491 - categorical_accuracy: 0.896946/67 [===================>..........] - ETA: 0s - loss: 0.2494 - categorical_accuracy: 0.896367/67 [==============================] - 0s 3ms/step - loss: 0.2475 - categorical_accuracy: 0.8974 - val_loss: 0.3149 - val_categorical_accuracy: 0.8587
Epoch 42/100
 1/67 [..............................] - ETA: 0s - loss: 0.2572 - categorical_accuracy: 0.900024/67 [=========>....................] - ETA: 0s - loss: 0.2888 - categorical_accuracy: 0.878347/67 [====================>.........] - ETA: 0s - loss: 0.2803 - categorical_accuracy: 0.881767/67 [==============================] - 0s 3ms/step - loss: 0.2752 - categorical_accuracy: 0.8841 - val_loss: 0.2505 - val_categorical_accuracy: 0.8804
Epoch 43/100
 1/67 [..............................] - ETA: 0s - loss: 0.3002 - categorical_accuracy: 0.880024/67 [=========>....................] - ETA: 0s - loss: 0.2865 - categorical_accuracy: 0.868146/67 [===================>..........] - ETA: 0s - loss: 0.2758 - categorical_accuracy: 0.873867/67 [==============================] - 0s 3ms/step - loss: 0.2684 - categorical_accuracy: 0.8781 - val_loss: 0.2510 - val_categorical_accuracy: 0.8954
Epoch 44/100
 1/67 [..............................] - ETA: 0s - loss: 0.2026 - categorical_accuracy: 0.910024/67 [=========>....................] - ETA: 0s - loss: 0.2311 - categorical_accuracy: 0.903046/67 [===================>..........] - ETA: 0s - loss: 0.2336 - categorical_accuracy: 0.900067/67 [==============================] - 0s 3ms/step - loss: 0.2351 - categorical_accuracy: 0.8986 - val_loss: 0.2954 - val_categorical_accuracy: 0.8723
Epoch 45/100
 1/67 [..............................] - ETA: 0s - loss: 0.3623 - categorical_accuracy: 0.850024/67 [=========>....................] - ETA: 0s - loss: 0.2818 - categorical_accuracy: 0.874946/67 [===================>..........] - ETA: 0s - loss: 0.2690 - categorical_accuracy: 0.879267/67 [==============================] - 0s 3ms/step - loss: 0.2638 - categorical_accuracy: 0.8818 - val_loss: 0.2712 - val_categorical_accuracy: 0.9035
Epoch 46/100
 1/67 [..............................] - ETA: 0s - loss: 0.1804 - categorical_accuracy: 0.940024/67 [=========>....................] - ETA: 0s - loss: 0.2126 - categorical_accuracy: 0.914547/67 [====================>.........] - ETA: 0s - loss: 0.2237 - categorical_accuracy: 0.907367/67 [==============================] - 0s 3ms/step - loss: 0.2323 - categorical_accuracy: 0.9021 - val_loss: 0.2805 - val_categorical_accuracy: 0.8886
Epoch 47/100
 1/67 [..............................] - ETA: 0s - loss: 0.2576 - categorical_accuracy: 0.890024/67 [=========>....................] - ETA: 0s - loss: 0.2416 - categorical_accuracy: 0.887546/67 [===================>..........] - ETA: 0s - loss: 0.2518 - categorical_accuracy: 0.883767/67 [==============================] - 0s 3ms/step - loss: 0.2565 - categorical_accuracy: 0.8822 - val_loss: 0.2642 - val_categorical_accuracy: 0.8995
Epoch 48/100
 1/67 [..............................] - ETA: 0s - loss: 0.1964 - categorical_accuracy: 0.940024/67 [=========>....................] - ETA: 0s - loss: 0.2233 - categorical_accuracy: 0.908546/67 [===================>..........] - ETA: 0s - loss: 0.2301 - categorical_accuracy: 0.904367/67 [==============================] - 0s 3ms/step - loss: 0.2321 - categorical_accuracy: 0.9030 - val_loss: 0.2468 - val_categorical_accuracy: 0.8981
Epoch 49/100
 1/67 [..............................] - ETA: 0s - loss: 0.2015 - categorical_accuracy: 0.900024/67 [=========>....................] - ETA: 0s - loss: 0.2171 - categorical_accuracy: 0.907847/67 [====================>.........] - ETA: 0s - loss: 0.2260 - categorical_accuracy: 0.904767/67 [==============================] - 0s 3ms/step - loss: 0.2274 - categorical_accuracy: 0.9044 - val_loss: 0.2565 - val_categorical_accuracy: 0.8995
Epoch 50/100
 1/67 [..............................] - ETA: 0s - loss: 0.1785 - categorical_accuracy: 0.940024/67 [=========>....................] - ETA: 0s - loss: 0.2141 - categorical_accuracy: 0.907646/67 [===================>..........] - ETA: 0s - loss: 0.2163 - categorical_accuracy: 0.908267/67 [==============================] - 0s 3ms/step - loss: 0.2198 - categorical_accuracy: 0.9069 - val_loss: 0.2934 - val_categorical_accuracy: 0.8682
Epoch 51/100
 1/67 [..............................] - ETA: 0s - loss: 0.2733 - categorical_accuracy: 0.880024/67 [=========>....................] - ETA: 0s - loss: 0.2284 - categorical_accuracy: 0.902447/67 [====================>.........] - ETA: 0s - loss: 0.2280 - categorical_accuracy: 0.902867/67 [==============================] - 0s 3ms/step - loss: 0.2287 - categorical_accuracy: 0.9023 - val_loss: 0.2543 - val_categorical_accuracy: 0.8804
Epoch 52/100
 1/67 [..............................] - ETA: 0s - loss: 0.2579 - categorical_accuracy: 0.850022/67 [========>.....................] - ETA: 0s - loss: 0.2422 - categorical_accuracy: 0.887444/67 [==================>...........] - ETA: 0s - loss: 0.2327 - categorical_accuracy: 0.896265/67 [============================>.] - ETA: 0s - loss: 0.2291 - categorical_accuracy: 0.899867/67 [==============================] - 0s 3ms/step - loss: 0.2286 - categorical_accuracy: 0.9003 - val_loss: 0.3670 - val_categorical_accuracy: 0.8492
Epoch 53/100
 1/67 [..............................] - ETA: 0s - loss: 0.3564 - categorical_accuracy: 0.840023/67 [=========>....................] - ETA: 0s - loss: 0.2785 - categorical_accuracy: 0.886645/67 [===================>..........] - ETA: 0s - loss: 0.2590 - categorical_accuracy: 0.893867/67 [==============================] - ETA: 0s - loss: 0.2500 - categorical_accuracy: 0.896367/67 [==============================] - 0s 3ms/step - loss: 0.2498 - categorical_accuracy: 0.8964 - val_loss: 0.2865 - val_categorical_accuracy: 0.8804
Epoch 54/100
 1/67 [..............................] - ETA: 0s - loss: 0.1949 - categorical_accuracy: 0.930024/67 [=========>....................] - ETA: 0s - loss: 0.2536 - categorical_accuracy: 0.890446/67 [===================>..........] - ETA: 0s - loss: 0.2461 - categorical_accuracy: 0.894367/67 [==============================] - 0s 3ms/step - loss: 0.2412 - categorical_accuracy: 0.8977 - val_loss: 0.2263 - val_categorical_accuracy: 0.9062
Epoch 55/100
 1/67 [..............................] - ETA: 0s - loss: 0.2140 - categorical_accuracy: 0.910024/67 [=========>....................] - ETA: 0s - loss: 0.2163 - categorical_accuracy: 0.908346/67 [===================>..........] - ETA: 0s - loss: 0.2116 - categorical_accuracy: 0.912367/67 [==============================] - 0s 3ms/step - loss: 0.2100 - categorical_accuracy: 0.9135 - val_loss: 0.2307 - val_categorical_accuracy: 0.9049
Epoch 56/100
 1/67 [..............................] - ETA: 0s - loss: 0.1831 - categorical_accuracy: 0.920024/67 [=========>....................] - ETA: 0s - loss: 0.2021 - categorical_accuracy: 0.910747/67 [====================>.........] - ETA: 0s - loss: 0.2109 - categorical_accuracy: 0.908567/67 [==============================] - 0s 3ms/step - loss: 0.2140 - categorical_accuracy: 0.9077 - val_loss: 0.2445 - val_categorical_accuracy: 0.8995
Epoch 57/100
 1/67 [..............................] - ETA: 0s - loss: 0.2119 - categorical_accuracy: 0.930024/67 [=========>....................] - ETA: 0s - loss: 0.1994 - categorical_accuracy: 0.920847/67 [====================>.........] - ETA: 0s - loss: 0.2101 - categorical_accuracy: 0.913467/67 [==============================] - 0s 3ms/step - loss: 0.2127 - categorical_accuracy: 0.9113 - val_loss: 0.2517 - val_categorical_accuracy: 0.9022
Epoch 58/100
 1/67 [..............................] - ETA: 0s - loss: 0.2191 - categorical_accuracy: 0.900024/67 [=========>....................] - ETA: 0s - loss: 0.2491 - categorical_accuracy: 0.898047/67 [====================>.........] - ETA: 0s - loss: 0.2404 - categorical_accuracy: 0.900167/67 [==============================] - 0s 3ms/step - loss: 0.2363 - categorical_accuracy: 0.9003 - val_loss: 0.2392 - val_categorical_accuracy: 0.9022
Epoch 59/100
 1/67 [..............................] - ETA: 0s - loss: 0.2203 - categorical_accuracy: 0.900024/67 [=========>....................] - ETA: 0s - loss: 0.2206 - categorical_accuracy: 0.909047/67 [====================>.........] - ETA: 0s - loss: 0.2209 - categorical_accuracy: 0.908367/67 [==============================] - 0s 3ms/step - loss: 0.2190 - categorical_accuracy: 0.9085 - val_loss: 0.2567 - val_categorical_accuracy: 0.8954
Epoch 60/100
 1/67 [..............................] - ETA: 0s - loss: 0.2818 - categorical_accuracy: 0.920024/67 [=========>....................] - ETA: 0s - loss: 0.2159 - categorical_accuracy: 0.913847/67 [====================>.........] - ETA: 0s - loss: 0.2267 - categorical_accuracy: 0.907567/67 [==============================] - 0s 3ms/step - loss: 0.2293 - categorical_accuracy: 0.9054 - val_loss: 0.2544 - val_categorical_accuracy: 0.9062
Epoch 61/100
 1/67 [..............................] - ETA: 0s - loss: 0.2690 - categorical_accuracy: 0.870024/67 [=========>....................] - ETA: 0s - loss: 0.2644 - categorical_accuracy: 0.883546/67 [===================>..........] - ETA: 0s - loss: 0.2500 - categorical_accuracy: 0.890667/67 [==============================] - 0s 3ms/step - loss: 0.2414 - categorical_accuracy: 0.8952 - val_loss: 0.2715 - val_categorical_accuracy: 0.8777
Epoch 00061: early stopping
Experiment:  246  Set:  har2 Train Labels:  clean Test Labels:  clean
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.78      0.79       496
           1       0.78      0.76      0.77       471
           2       0.85      0.86      0.85       420
           3       0.71      0.78      0.74       491
           4       0.79      0.86      0.83       532
           5       1.00      0.85      0.92       537

    accuracy                           0.82      2947
   macro avg       0.82      0.82      0.82      2947
weighted avg       0.82      0.82      0.82      2947

Confusion Matrix for this model: 
 [[386  60  38   2  10   0]
 [ 85 359  27   0   0   0]
 [ 14  44 362   0   0   0]
 [  0   0   0 384 107   0]
 [  0   0   0  75 457   0]
 [  0   0   0  79   1 457]]
Experiment:  247  Set:  har2 Train Labels:  clean Test Labels:  ncar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.77      0.74      0.75       506
           1       0.74      0.73      0.74       468
           2       0.78      0.81      0.80       413
           3       0.67      0.74      0.71       489
           4       0.75      0.82      0.79       523
           5       0.97      0.81      0.88       548

    accuracy                           0.78      2947
   macro avg       0.78      0.78      0.78      2947
weighted avg       0.79      0.78      0.78      2947

Confusion Matrix for this model: 
 [[373  58  49  10  14   2]
 [ 82 343  29   7   5   2]
 [ 21  44 335   3   7   3]
 [  2   4   5 364 109   5]
 [  5   6   4  76 431   1]
 [  2   8   5  80   9 444]]
Experiment:  248  Set:  har2 Train Labels:  clean Test Labels:  ncar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.72      0.71      0.72       491
           1       0.71      0.67      0.69       489
           2       0.77      0.77      0.77       426
           3       0.66      0.70      0.68       504
           4       0.70      0.79      0.74       512
           5       0.90      0.78      0.84       525

    accuracy                           0.74      2947
   macro avg       0.74      0.74      0.74      2947
weighted avg       0.74      0.74      0.74      2947

Confusion Matrix for this model: 
 [[350  60  40   6  27   8]
 [ 86 330  35  10  14  14]
 [ 19  45 327  15  13   7]
 [  9   9  14 355 109   8]
 [  6   7   9  77 404   9]
 [ 15  12   2  77   8 411]]
Experiment:  249  Set:  har2 Train Labels:  clean Test Labels:  nar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.78      0.79       496
           1       0.78      0.76      0.77       471
           2       0.85      0.63      0.72       572
           3       0.71      0.78      0.74       491
           4       0.79      0.86      0.83       532
           5       0.71      0.85      0.77       385

    accuracy                           0.77      2947
   macro avg       0.77      0.78      0.77      2947
weighted avg       0.78      0.77      0.77      2947

Confusion Matrix for this model: 
 [[386  60  38   2  10   0]
 [ 85 359  27   0   0   0]
 [ 14  44 362  21   0 131]
 [  0   0   0 384 107   0]
 [  0   0   0  75 457   0]
 [  0   0   0  58   1 326]]
Experiment:  250  Set:  har2 Train Labels:  clean Test Labels:  nar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.78      0.79       496
           1       0.78      0.76      0.77       471
           2       0.85      0.50      0.63       720
           3       0.71      0.78      0.74       491
           4       0.79      0.86      0.83       532
           5       0.45      0.86      0.59       237

    accuracy                           0.73      2947
   macro avg       0.73      0.76      0.72      2947
weighted avg       0.76      0.73      0.73      2947

Confusion Matrix for this model: 
 [[386  60  38   2  10   0]
 [ 85 359  27   0   0   0]
 [ 14  44 362  47   1 252]
 [  0   0   0 384 107   0]
 [  0   0   0  75 457   0]
 [  0   0   0  32   0 205]]
Experiment:  251  Set:  har2 Train Labels:  clean Test Labels:  nnar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.75      0.77       512
           1       0.78      0.75      0.76       476
           2       0.85      0.80      0.82       453
           3       0.72      0.75      0.73       514
           4       0.79      0.79      0.79       582
           5       0.75      0.84      0.79       410

    accuracy                           0.78      2947
   macro avg       0.78      0.78      0.78      2947
weighted avg       0.78      0.78      0.78      2947

Confusion Matrix for this model: 
 [[386  60  38   2  10  16]
 [ 85 359  27   1   0   4]
 [ 14  44 362   5   0  28]
 [  0   0   0 387 107  20]
 [  0   0   0  79 457  46]
 [  0   0   0  66   1 343]]
Experiment:  252  Set:  har2 Train Labels:  clean Test Labels:  nnar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.78      0.79       496
           1       0.78      0.76      0.77       471
           2       0.85      0.86      0.85       420
           3       0.75      0.61      0.67       666
           4       0.79      0.82      0.81       555
           5       0.61      0.83      0.71       339

    accuracy                           0.76      2947
   macro avg       0.76      0.78      0.77      2947
weighted avg       0.77      0.76      0.76      2947

Confusion Matrix for this model: 
 [[386  60  38   2  10   0]
 [ 85 359  27   0   0   0]
 [ 14  44 362   0   0   0]
 [  0   0   0 405 108 153]
 [  0   0   0  75 457  23]
 [  0   0   0  58   0 281]]
Input Shape:  (7352, 3, 128)
Model: "sequential_36"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_36 (LSTM)               (None, 32)                20608     
_________________________________________________________________
dropout_36 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_144 (Dense)            (None, 128)               4224      
_________________________________________________________________
dense_145 (Dense)            (None, 128)               16512     
_________________________________________________________________
dense_146 (Dense)            (None, 64)                8256      
_________________________________________________________________
dense_147 (Dense)            (None, 6)                 390       
=================================================================
Total params: 49,990
Trainable params: 49,990
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/67 [..............................] - ETA: 1:13 - loss: 1.7619 - categorical_accuracy: 0.260022/67 [========>.....................] - ETA: 0s - loss: 1.6784 - categorical_accuracy: 0.2256  43/67 [==================>...........] - ETA: 0s - loss: 1.6143 - categorical_accuracy: 0.260765/67 [============================>.] - ETA: 0s - loss: 1.5596 - categorical_accuracy: 0.296767/67 [==============================] - 2s 7ms/step - loss: 1.5525 - categorical_accuracy: 0.3011 - val_loss: 1.1186 - val_categorical_accuracy: 0.5353
Epoch 2/100
 1/67 [..............................] - ETA: 0s - loss: 1.0034 - categorical_accuracy: 0.560020/67 [=======>......................] - ETA: 0s - loss: 1.0415 - categorical_accuracy: 0.556341/67 [=================>............] - ETA: 0s - loss: 1.0288 - categorical_accuracy: 0.557862/67 [==========================>...] - ETA: 0s - loss: 1.0212 - categorical_accuracy: 0.562267/67 [==============================] - 0s 3ms/step - loss: 1.0199 - categorical_accuracy: 0.5636 - val_loss: 0.9554 - val_categorical_accuracy: 0.6168
Epoch 3/100
 1/67 [..............................] - ETA: 0s - loss: 0.8853 - categorical_accuracy: 0.670022/67 [========>.....................] - ETA: 0s - loss: 0.9226 - categorical_accuracy: 0.623544/67 [==================>...........] - ETA: 0s - loss: 0.9303 - categorical_accuracy: 0.623166/67 [============================>.] - ETA: 0s - loss: 0.9286 - categorical_accuracy: 0.623467/67 [==============================] - 0s 3ms/step - loss: 0.9283 - categorical_accuracy: 0.6235 - val_loss: 0.9193 - val_categorical_accuracy: 0.6359
Epoch 4/100
 1/67 [..............................] - ETA: 0s - loss: 0.8721 - categorical_accuracy: 0.620022/67 [========>.....................] - ETA: 0s - loss: 0.8602 - categorical_accuracy: 0.639844/67 [==================>...........] - ETA: 0s - loss: 0.8660 - categorical_accuracy: 0.637966/67 [============================>.] - ETA: 0s - loss: 0.8674 - categorical_accuracy: 0.639467/67 [==============================] - 0s 3ms/step - loss: 0.8673 - categorical_accuracy: 0.6396 - val_loss: 0.8474 - val_categorical_accuracy: 0.6671
Epoch 5/100
 1/67 [..............................] - ETA: 0s - loss: 0.7164 - categorical_accuracy: 0.730024/67 [=========>....................] - ETA: 0s - loss: 0.7813 - categorical_accuracy: 0.691244/67 [==================>...........] - ETA: 0s - loss: 0.7953 - categorical_accuracy: 0.684360/67 [=========================>....] - ETA: 0s - loss: 0.8019 - categorical_accuracy: 0.682267/67 [==============================] - 0s 3ms/step - loss: 0.8054 - categorical_accuracy: 0.6811 - val_loss: 0.8169 - val_categorical_accuracy: 0.6658
Epoch 6/100
 1/67 [..............................] - ETA: 0s - loss: 0.8236 - categorical_accuracy: 0.630023/67 [=========>....................] - ETA: 0s - loss: 0.8079 - categorical_accuracy: 0.678944/67 [==================>...........] - ETA: 0s - loss: 0.8062 - categorical_accuracy: 0.683367/67 [==============================] - ETA: 0s - loss: 0.8026 - categorical_accuracy: 0.686667/67 [==============================] - 0s 3ms/step - loss: 0.8025 - categorical_accuracy: 0.6867 - val_loss: 0.7587 - val_categorical_accuracy: 0.7038
Epoch 7/100
 1/67 [..............................] - ETA: 0s - loss: 0.8143 - categorical_accuracy: 0.690023/67 [=========>....................] - ETA: 0s - loss: 0.7922 - categorical_accuracy: 0.688939/67 [================>.............] - ETA: 0s - loss: 0.7832 - categorical_accuracy: 0.692758/67 [========================>.....] - ETA: 0s - loss: 0.7744 - categorical_accuracy: 0.697867/67 [==============================] - 0s 3ms/step - loss: 0.7714 - categorical_accuracy: 0.6999 - val_loss: 0.7273 - val_categorical_accuracy: 0.7296
Epoch 8/100
 1/67 [..............................] - ETA: 0s - loss: 0.7749 - categorical_accuracy: 0.680021/67 [========>.....................] - ETA: 0s - loss: 0.7276 - categorical_accuracy: 0.728142/67 [=================>............] - ETA: 0s - loss: 0.7317 - categorical_accuracy: 0.727860/67 [=========================>....] - ETA: 0s - loss: 0.7338 - categorical_accuracy: 0.727667/67 [==============================] - 0s 3ms/step - loss: 0.7335 - categorical_accuracy: 0.7280 - val_loss: 0.7391 - val_categorical_accuracy: 0.7106
Epoch 9/100
 1/67 [..............................] - ETA: 0s - loss: 0.7679 - categorical_accuracy: 0.600019/67 [=======>......................] - ETA: 0s - loss: 0.7277 - categorical_accuracy: 0.722835/67 [==============>...............] - ETA: 0s - loss: 0.7226 - categorical_accuracy: 0.731752/67 [======================>.......] - ETA: 0s - loss: 0.7163 - categorical_accuracy: 0.737067/67 [==============================] - 0s 3ms/step - loss: 0.7124 - categorical_accuracy: 0.7396 - val_loss: 0.7516 - val_categorical_accuracy: 0.7120
Epoch 10/100
 1/67 [..............................] - ETA: 0s - loss: 0.6073 - categorical_accuracy: 0.770019/67 [=======>......................] - ETA: 0s - loss: 0.6898 - categorical_accuracy: 0.753437/67 [===============>..............] - ETA: 0s - loss: 0.6953 - categorical_accuracy: 0.746158/67 [========================>.....] - ETA: 0s - loss: 0.6947 - categorical_accuracy: 0.745767/67 [==============================] - 0s 3ms/step - loss: 0.6952 - categorical_accuracy: 0.7452 - val_loss: 0.6606 - val_categorical_accuracy: 0.7649
Epoch 11/100
 1/67 [..............................] - ETA: 0s - loss: 0.7306 - categorical_accuracy: 0.720022/67 [========>.....................] - ETA: 0s - loss: 0.7117 - categorical_accuracy: 0.745144/67 [==================>...........] - ETA: 0s - loss: 0.6919 - categorical_accuracy: 0.754266/67 [============================>.] - ETA: 0s - loss: 0.6839 - categorical_accuracy: 0.756967/67 [==============================] - 0s 3ms/step - loss: 0.6835 - categorical_accuracy: 0.7570 - val_loss: 0.6615 - val_categorical_accuracy: 0.7446
Epoch 12/100
 1/67 [..............................] - ETA: 0s - loss: 0.6307 - categorical_accuracy: 0.750023/67 [=========>....................] - ETA: 0s - loss: 0.6329 - categorical_accuracy: 0.759643/67 [==================>...........] - ETA: 0s - loss: 0.6395 - categorical_accuracy: 0.760161/67 [==========================>...] - ETA: 0s - loss: 0.6406 - categorical_accuracy: 0.762367/67 [==============================] - 0s 3ms/step - loss: 0.6412 - categorical_accuracy: 0.7629 - val_loss: 0.6342 - val_categorical_accuracy: 0.7785
Epoch 13/100
 1/67 [..............................] - ETA: 0s - loss: 0.4420 - categorical_accuracy: 0.860020/67 [=======>......................] - ETA: 0s - loss: 0.6631 - categorical_accuracy: 0.775239/67 [================>.............] - ETA: 0s - loss: 0.6697 - categorical_accuracy: 0.770560/67 [=========================>....] - ETA: 0s - loss: 0.6651 - categorical_accuracy: 0.771067/67 [==============================] - 0s 3ms/step - loss: 0.6632 - categorical_accuracy: 0.7716 - val_loss: 0.6201 - val_categorical_accuracy: 0.7880
Epoch 14/100
 1/67 [..............................] - ETA: 0s - loss: 0.6672 - categorical_accuracy: 0.730023/67 [=========>....................] - ETA: 0s - loss: 0.6446 - categorical_accuracy: 0.776545/67 [===================>..........] - ETA: 0s - loss: 0.6330 - categorical_accuracy: 0.782367/67 [==============================] - ETA: 0s - loss: 0.6261 - categorical_accuracy: 0.786167/67 [==============================] - 0s 3ms/step - loss: 0.6259 - categorical_accuracy: 0.7861 - val_loss: 0.7376 - val_categorical_accuracy: 0.7323
Epoch 15/100
 1/67 [..............................] - ETA: 0s - loss: 0.7552 - categorical_accuracy: 0.740022/67 [========>.....................] - ETA: 0s - loss: 0.7281 - categorical_accuracy: 0.745744/67 [==================>...........] - ETA: 0s - loss: 0.6918 - categorical_accuracy: 0.757666/67 [============================>.] - ETA: 0s - loss: 0.6758 - categorical_accuracy: 0.763667/67 [==============================] - 0s 3ms/step - loss: 0.6745 - categorical_accuracy: 0.7641 - val_loss: 0.6096 - val_categorical_accuracy: 0.7867
Epoch 16/100
 1/67 [..............................] - ETA: 0s - loss: 0.5476 - categorical_accuracy: 0.800022/67 [========>.....................] - ETA: 0s - loss: 0.5865 - categorical_accuracy: 0.788844/67 [==================>...........] - ETA: 0s - loss: 0.5972 - categorical_accuracy: 0.788266/67 [============================>.] - ETA: 0s - loss: 0.5981 - categorical_accuracy: 0.789467/67 [==============================] - 0s 3ms/step - loss: 0.5983 - categorical_accuracy: 0.7895 - val_loss: 0.5853 - val_categorical_accuracy: 0.7935
Epoch 17/100
 1/67 [..............................] - ETA: 0s - loss: 0.5950 - categorical_accuracy: 0.790024/67 [=========>....................] - ETA: 0s - loss: 0.5917 - categorical_accuracy: 0.802646/67 [===================>..........] - ETA: 0s - loss: 0.5908 - categorical_accuracy: 0.800067/67 [==============================] - 0s 3ms/step - loss: 0.5933 - categorical_accuracy: 0.7974 - val_loss: 0.6249 - val_categorical_accuracy: 0.7758
Epoch 18/100
 1/67 [..............................] - ETA: 0s - loss: 0.5210 - categorical_accuracy: 0.810024/67 [=========>....................] - ETA: 0s - loss: 0.5578 - categorical_accuracy: 0.801343/67 [==================>...........] - ETA: 0s - loss: 0.5683 - categorical_accuracy: 0.798365/67 [============================>.] - ETA: 0s - loss: 0.5734 - categorical_accuracy: 0.797267/67 [==============================] - 0s 3ms/step - loss: 0.5740 - categorical_accuracy: 0.7971 - val_loss: 0.5731 - val_categorical_accuracy: 0.8397
Epoch 19/100
 1/67 [..............................] - ETA: 0s - loss: 0.4919 - categorical_accuracy: 0.850023/67 [=========>....................] - ETA: 0s - loss: 0.6082 - categorical_accuracy: 0.794946/67 [===================>..........] - ETA: 0s - loss: 0.5945 - categorical_accuracy: 0.797367/67 [==============================] - 0s 3ms/step - loss: 0.5914 - categorical_accuracy: 0.7970 - val_loss: 0.6465 - val_categorical_accuracy: 0.7799
Epoch 20/100
 1/67 [..............................] - ETA: 0s - loss: 0.7086 - categorical_accuracy: 0.760024/67 [=========>....................] - ETA: 0s - loss: 0.6541 - categorical_accuracy: 0.771247/67 [====================>.........] - ETA: 0s - loss: 0.6326 - categorical_accuracy: 0.779467/67 [==============================] - 0s 3ms/step - loss: 0.6246 - categorical_accuracy: 0.7824 - val_loss: 0.5917 - val_categorical_accuracy: 0.8125
Epoch 21/100
 1/67 [..............................] - ETA: 0s - loss: 0.5438 - categorical_accuracy: 0.800024/67 [=========>....................] - ETA: 0s - loss: 0.5858 - categorical_accuracy: 0.801743/67 [==================>...........] - ETA: 0s - loss: 0.5854 - categorical_accuracy: 0.802158/67 [========================>.....] - ETA: 0s - loss: 0.5818 - categorical_accuracy: 0.803367/67 [==============================] - 0s 3ms/step - loss: 0.5801 - categorical_accuracy: 0.8043 - val_loss: 0.6126 - val_categorical_accuracy: 0.7840
Epoch 22/100
 1/67 [..............................] - ETA: 0s - loss: 0.5133 - categorical_accuracy: 0.850023/67 [=========>....................] - ETA: 0s - loss: 0.5765 - categorical_accuracy: 0.800839/67 [================>.............] - ETA: 0s - loss: 0.5752 - categorical_accuracy: 0.802456/67 [========================>.....] - ETA: 0s - loss: 0.5731 - categorical_accuracy: 0.804667/67 [==============================] - 0s 3ms/step - loss: 0.5706 - categorical_accuracy: 0.8066 - val_loss: 0.5728 - val_categorical_accuracy: 0.8030
Epoch 23/100
 1/67 [..............................] - ETA: 0s - loss: 0.5360 - categorical_accuracy: 0.770017/67 [======>.......................] - ETA: 0s - loss: 0.5275 - categorical_accuracy: 0.813735/67 [==============>...............] - ETA: 0s - loss: 0.5246 - categorical_accuracy: 0.817954/67 [=======================>......] - ETA: 0s - loss: 0.5340 - categorical_accuracy: 0.817067/67 [==============================] - 0s 3ms/step - loss: 0.5383 - categorical_accuracy: 0.8164 - val_loss: 0.5971 - val_categorical_accuracy: 0.7962
Epoch 24/100
 1/67 [..............................] - ETA: 0s - loss: 0.8269 - categorical_accuracy: 0.680018/67 [=======>......................] - ETA: 0s - loss: 0.6145 - categorical_accuracy: 0.778333/67 [=============>................] - ETA: 0s - loss: 0.5968 - categorical_accuracy: 0.790746/67 [===================>..........] - ETA: 0s - loss: 0.5839 - categorical_accuracy: 0.798363/67 [===========================>..] - ETA: 0s - loss: 0.5710 - categorical_accuracy: 0.804967/67 [==============================] - 0s 4ms/step - loss: 0.5687 - categorical_accuracy: 0.8061 - val_loss: 0.6532 - val_categorical_accuracy: 0.7867
Epoch 25/100
 1/67 [..............................] - ETA: 0s - loss: 0.5589 - categorical_accuracy: 0.780019/67 [=======>......................] - ETA: 0s - loss: 0.5589 - categorical_accuracy: 0.807138/67 [================>.............] - ETA: 0s - loss: 0.5713 - categorical_accuracy: 0.803456/67 [========================>.....] - ETA: 0s - loss: 0.5722 - categorical_accuracy: 0.803067/67 [==============================] - 0s 3ms/step - loss: 0.5714 - categorical_accuracy: 0.8038 - val_loss: 0.5634 - val_categorical_accuracy: 0.8397
Epoch 26/100
 1/67 [..............................] - ETA: 0s - loss: 0.5643 - categorical_accuracy: 0.820021/67 [========>.....................] - ETA: 0s - loss: 0.5368 - categorical_accuracy: 0.829743/67 [==================>...........] - ETA: 0s - loss: 0.5382 - categorical_accuracy: 0.824364/67 [===========================>..] - ETA: 0s - loss: 0.5380 - categorical_accuracy: 0.820867/67 [==============================] - 0s 3ms/step - loss: 0.5381 - categorical_accuracy: 0.8202 - val_loss: 0.5655 - val_categorical_accuracy: 0.8030
Epoch 27/100
 1/67 [..............................] - ETA: 0s - loss: 0.4882 - categorical_accuracy: 0.780023/67 [=========>....................] - ETA: 0s - loss: 0.5068 - categorical_accuracy: 0.818845/67 [===================>..........] - ETA: 0s - loss: 0.5164 - categorical_accuracy: 0.822267/67 [==============================] - ETA: 0s - loss: 0.5192 - categorical_accuracy: 0.824167/67 [==============================] - 0s 3ms/step - loss: 0.5192 - categorical_accuracy: 0.8242 - val_loss: 0.5626 - val_categorical_accuracy: 0.8179
Epoch 28/100
 1/67 [..............................] - ETA: 0s - loss: 0.4448 - categorical_accuracy: 0.890022/67 [========>.....................] - ETA: 0s - loss: 0.4705 - categorical_accuracy: 0.854544/67 [==================>...........] - ETA: 0s - loss: 0.4949 - categorical_accuracy: 0.841866/67 [============================>.] - ETA: 0s - loss: 0.5062 - categorical_accuracy: 0.836867/67 [==============================] - 0s 3ms/step - loss: 0.5069 - categorical_accuracy: 0.8364 - val_loss: 0.5583 - val_categorical_accuracy: 0.8424
Epoch 29/100
 1/67 [..............................] - ETA: 0s - loss: 0.4728 - categorical_accuracy: 0.860022/67 [========>.....................] - ETA: 0s - loss: 0.5032 - categorical_accuracy: 0.833744/67 [==================>...........] - ETA: 0s - loss: 0.5107 - categorical_accuracy: 0.833066/67 [============================>.] - ETA: 0s - loss: 0.5097 - categorical_accuracy: 0.834367/67 [==============================] - 0s 3ms/step - loss: 0.5097 - categorical_accuracy: 0.8343 - val_loss: 0.6091 - val_categorical_accuracy: 0.8016
Epoch 30/100
 1/67 [..............................] - ETA: 0s - loss: 0.5036 - categorical_accuracy: 0.850023/67 [=========>....................] - ETA: 0s - loss: 0.5841 - categorical_accuracy: 0.805245/67 [===================>..........] - ETA: 0s - loss: 0.5653 - categorical_accuracy: 0.810367/67 [==============================] - 0s 3ms/step - loss: 0.5516 - categorical_accuracy: 0.8147 - val_loss: 0.5322 - val_categorical_accuracy: 0.8478
Epoch 31/100
 1/67 [..............................] - ETA: 0s - loss: 0.4862 - categorical_accuracy: 0.830024/67 [=========>....................] - ETA: 0s - loss: 0.5055 - categorical_accuracy: 0.826846/67 [===================>..........] - ETA: 0s - loss: 0.5071 - categorical_accuracy: 0.830367/67 [==============================] - 0s 3ms/step - loss: 0.5066 - categorical_accuracy: 0.8317 - val_loss: 0.6323 - val_categorical_accuracy: 0.7867
Epoch 32/100
 1/67 [..............................] - ETA: 0s - loss: 0.5020 - categorical_accuracy: 0.810023/67 [=========>....................] - ETA: 0s - loss: 0.5882 - categorical_accuracy: 0.794745/67 [===================>..........] - ETA: 0s - loss: 0.5687 - categorical_accuracy: 0.799967/67 [==============================] - ETA: 0s - loss: 0.5571 - categorical_accuracy: 0.804267/67 [==============================] - 0s 3ms/step - loss: 0.5568 - categorical_accuracy: 0.8044 - val_loss: 0.5521 - val_categorical_accuracy: 0.8288
Epoch 33/100
 1/67 [..............................] - ETA: 0s - loss: 0.4772 - categorical_accuracy: 0.860023/67 [=========>....................] - ETA: 0s - loss: 0.4911 - categorical_accuracy: 0.839545/67 [===================>..........] - ETA: 0s - loss: 0.4850 - categorical_accuracy: 0.840867/67 [==============================] - 0s 3ms/step - loss: 0.4865 - categorical_accuracy: 0.8401 - val_loss: 0.5872 - val_categorical_accuracy: 0.8179
Epoch 34/100
 1/67 [..............................] - ETA: 0s - loss: 0.4869 - categorical_accuracy: 0.840024/67 [=========>....................] - ETA: 0s - loss: 0.4742 - categorical_accuracy: 0.840246/67 [===================>..........] - ETA: 0s - loss: 0.4743 - categorical_accuracy: 0.843267/67 [==============================] - 0s 3ms/step - loss: 0.4778 - categorical_accuracy: 0.8431 - val_loss: 0.5490 - val_categorical_accuracy: 0.8166
Epoch 35/100
 1/67 [..............................] - ETA: 0s - loss: 0.4485 - categorical_accuracy: 0.850018/67 [=======>......................] - ETA: 0s - loss: 0.4513 - categorical_accuracy: 0.856636/67 [===============>..............] - ETA: 0s - loss: 0.4559 - categorical_accuracy: 0.857055/67 [=======================>......] - ETA: 0s - loss: 0.4615 - categorical_accuracy: 0.855367/67 [==============================] - 0s 3ms/step - loss: 0.4662 - categorical_accuracy: 0.8530 - val_loss: 0.5557 - val_categorical_accuracy: 0.8302
Epoch 36/100
 1/67 [..............................] - ETA: 0s - loss: 0.3967 - categorical_accuracy: 0.870021/67 [========>.....................] - ETA: 0s - loss: 0.4859 - categorical_accuracy: 0.842642/67 [=================>............] - ETA: 0s - loss: 0.4846 - categorical_accuracy: 0.843864/67 [===========================>..] - ETA: 0s - loss: 0.4869 - categorical_accuracy: 0.841767/67 [==============================] - 0s 3ms/step - loss: 0.4875 - categorical_accuracy: 0.8412 - val_loss: 0.5841 - val_categorical_accuracy: 0.8016
Epoch 37/100
 1/67 [..............................] - ETA: 0s - loss: 0.4589 - categorical_accuracy: 0.870023/67 [=========>....................] - ETA: 0s - loss: 0.4725 - categorical_accuracy: 0.844744/67 [==================>...........] - ETA: 0s - loss: 0.4772 - categorical_accuracy: 0.844766/67 [============================>.] - ETA: 0s - loss: 0.4779 - categorical_accuracy: 0.845267/67 [==============================] - 0s 3ms/step - loss: 0.4780 - categorical_accuracy: 0.8453 - val_loss: 0.5377 - val_categorical_accuracy: 0.8356
Epoch 00037: early stopping
Experiment:  253  Set:  har2 Train Labels:  ncar5 Test Labels:  clean
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.69      0.73       496
           1       0.73      0.78      0.75       471
           2       0.79      0.83      0.81       420
           3       0.84      0.72      0.77       491
           4       0.77      0.89      0.83       532
           5       0.97      0.98      0.98       537

    accuracy                           0.82      2947
   macro avg       0.82      0.81      0.81      2947
weighted avg       0.82      0.82      0.82      2947

Confusion Matrix for this model: 
 [[340  85  58   1  12   0]
 [ 70 368  32   1   0   0]
 [ 22  51 347   0   0   0]
 [  0   0   0 352 126  13]
 [  0   0   0  58 473   1]
 [  0   0   0   9   2 526]]
Experiment:  254  Set:  har2 Train Labels:  ncar5 Test Labels:  ncar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.76      0.65      0.70       506
           1       0.70      0.75      0.72       468
           2       0.73      0.78      0.76       413
           3       0.79      0.68      0.73       489
           4       0.73      0.85      0.79       523
           5       0.94      0.93      0.94       548

    accuracy                           0.78      2947
   macro avg       0.78      0.77      0.77      2947
weighted avg       0.78      0.78      0.78      2947

Confusion Matrix for this model: 
 [[328  83  68   8  16   3]
 [ 69 352  32   6   6   3]
 [ 25  54 321   2   7   4]
 [  2   5   4 333 128  17]
 [  5   4   6  58 446   4]
 [  3   6   6  14  10 509]]
Experiment:  255  Set:  har2 Train Labels:  ncar5 Test Labels:  ncar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.71      0.62      0.66       491
           1       0.67      0.69      0.68       489
           2       0.71      0.73      0.72       426
           3       0.76      0.63      0.69       504
           4       0.68      0.82      0.74       512
           5       0.87      0.90      0.88       525

    accuracy                           0.73      2947
   macro avg       0.73      0.73      0.73      2947
weighted avg       0.74      0.73      0.73      2947

Confusion Matrix for this model: 
 [[306  84  59   5  29   8]
 [ 75 336  39   9  14  16]
 [ 26  53 312  12  14   9]
 [  7  10  15 320 128  24]
 [  5   6  11  59 419  12]
 [ 13  15   1  16   9 471]]
Experiment:  256  Set:  har2 Train Labels:  ncar5 Test Labels:  nar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.69      0.73       496
           1       0.73      0.78      0.75       471
           2       0.79      0.61      0.69       572
           3       0.84      0.72      0.77       491
           4       0.77      0.89      0.83       532
           5       0.70      0.98      0.82       385

    accuracy                           0.77      2947
   macro avg       0.77      0.78      0.77      2947
weighted avg       0.77      0.77      0.76      2947

Confusion Matrix for this model: 
 [[340  85  58   1  12   0]
 [ 70 368  32   1   0   0]
 [ 22  51 347   3   1 148]
 [  0   0   0 352 126  13]
 [  0   0   0  58 473   1]
 [  0   0   0   6   1 378]]
Experiment:  257  Set:  har2 Train Labels:  ncar5 Test Labels:  nar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.69      0.73       496
           1       0.73      0.78      0.75       471
           2       0.79      0.48      0.60       720
           3       0.84      0.72      0.77       491
           4       0.77      0.89      0.83       532
           5       0.43      0.99      0.60       237

    accuracy                           0.72      2947
   macro avg       0.73      0.76      0.71      2947
weighted avg       0.76      0.72      0.72      2947

Confusion Matrix for this model: 
 [[340  85  58   1  12   0]
 [ 70 368  32   1   0   0]
 [ 22  51 347   6   2 292]
 [  0   0   0 352 126  13]
 [  0   0   0  58 473   1]
 [  0   0   0   3   0 234]]
Experiment:  258  Set:  har2 Train Labels:  ncar5 Test Labels:  nnar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.66      0.72       512
           1       0.73      0.77      0.75       476
           2       0.79      0.77      0.78       453
           3       0.84      0.68      0.75       514
           4       0.77      0.81      0.79       582
           5       0.74      0.98      0.84       410

    accuracy                           0.77      2947
   macro avg       0.78      0.78      0.77      2947
weighted avg       0.78      0.77      0.77      2947

Confusion Matrix for this model: 
 [[340  85  58   1  12  16]
 [ 70 368  32   1   0   5]
 [ 22  51 347   0   0  33]
 [  0   0   0 352 126  36]
 [  0   0   0  59 473  50]
 [  0   0   0   8   2 400]]
Experiment:  259  Set:  har2 Train Labels:  ncar5 Test Labels:  nnar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.69      0.73       496
           1       0.73      0.78      0.75       471
           2       0.79      0.83      0.81       420
           3       0.85      0.53      0.66       666
           4       0.77      0.85      0.81       555
           5       0.62      0.99      0.76       339

    accuracy                           0.75      2947
   macro avg       0.76      0.78      0.75      2947
weighted avg       0.77      0.75      0.75      2947

Confusion Matrix for this model: 
 [[340  85  58   1  12   0]
 [ 70 368  32   1   0   0]
 [ 22  51 347   0   0   0]
 [  0   0   0 356 127 183]
 [  0   0   0  58 474  23]
 [  0   0   0   5   0 334]]
Input Shape:  (7352, 3, 128)
Model: "sequential_37"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_37 (LSTM)               (None, 32)                20608     
_________________________________________________________________
dropout_37 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_148 (Dense)            (None, 128)               4224      
_________________________________________________________________
dense_149 (Dense)            (None, 128)               16512     
_________________________________________________________________
dense_150 (Dense)            (None, 64)                8256      
_________________________________________________________________
dense_151 (Dense)            (None, 6)                 390       
=================================================================
Total params: 49,990
Trainable params: 49,990
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/67 [..............................] - ETA: 1:09 - loss: 1.7958 - categorical_accuracy: 0.140022/67 [========>.....................] - ETA: 0s - loss: 1.6945 - categorical_accuracy: 0.2566  43/67 [==================>...........] - ETA: 0s - loss: 1.6269 - categorical_accuracy: 0.288165/67 [============================>.] - ETA: 0s - loss: 1.5761 - categorical_accuracy: 0.316967/67 [==============================] - 2s 7ms/step - loss: 1.5697 - categorical_accuracy: 0.3203 - val_loss: 1.1908 - val_categorical_accuracy: 0.5340
Epoch 2/100
 1/67 [..............................] - ETA: 0s - loss: 1.2054 - categorical_accuracy: 0.570021/67 [========>.....................] - ETA: 0s - loss: 1.1859 - categorical_accuracy: 0.541741/67 [=================>............] - ETA: 0s - loss: 1.1812 - categorical_accuracy: 0.534761/67 [==========================>...] - ETA: 0s - loss: 1.1718 - categorical_accuracy: 0.536367/67 [==============================] - 0s 3ms/step - loss: 1.1690 - categorical_accuracy: 0.5373 - val_loss: 1.0783 - val_categorical_accuracy: 0.6277
Epoch 3/100
 1/67 [..............................] - ETA: 0s - loss: 1.1091 - categorical_accuracy: 0.540022/67 [========>.....................] - ETA: 0s - loss: 1.0748 - categorical_accuracy: 0.557642/67 [=================>............] - ETA: 0s - loss: 1.0708 - categorical_accuracy: 0.564162/67 [==========================>...] - ETA: 0s - loss: 1.0664 - categorical_accuracy: 0.570267/67 [==============================] - 0s 3ms/step - loss: 1.0654 - categorical_accuracy: 0.5716 - val_loss: 1.0763 - val_categorical_accuracy: 0.6073
Epoch 4/100
 1/67 [..............................] - ETA: 0s - loss: 1.1106 - categorical_accuracy: 0.590022/67 [========>.....................] - ETA: 0s - loss: 1.0467 - categorical_accuracy: 0.609643/67 [==================>...........] - ETA: 0s - loss: 1.0268 - categorical_accuracy: 0.614764/67 [===========================>..] - ETA: 0s - loss: 1.0172 - categorical_accuracy: 0.616767/67 [==============================] - 0s 3ms/step - loss: 1.0160 - categorical_accuracy: 0.6171 - val_loss: 1.0036 - val_categorical_accuracy: 0.6264
Epoch 5/100
 1/67 [..............................] - ETA: 0s - loss: 1.0922 - categorical_accuracy: 0.610023/67 [=========>....................] - ETA: 0s - loss: 1.0268 - categorical_accuracy: 0.614646/67 [===================>..........] - ETA: 0s - loss: 1.0201 - categorical_accuracy: 0.614167/67 [==============================] - 0s 3ms/step - loss: 1.0080 - categorical_accuracy: 0.6179 - val_loss: 0.9690 - val_categorical_accuracy: 0.6685
Epoch 6/100
 1/67 [..............................] - ETA: 0s - loss: 0.9008 - categorical_accuracy: 0.700023/67 [=========>....................] - ETA: 0s - loss: 0.9865 - categorical_accuracy: 0.638145/67 [===================>..........] - ETA: 0s - loss: 0.9712 - categorical_accuracy: 0.644267/67 [==============================] - 0s 3ms/step - loss: 0.9614 - categorical_accuracy: 0.6489 - val_loss: 0.9808 - val_categorical_accuracy: 0.6522
Epoch 7/100
 1/67 [..............................] - ETA: 0s - loss: 0.9879 - categorical_accuracy: 0.640023/67 [=========>....................] - ETA: 0s - loss: 0.9508 - categorical_accuracy: 0.639346/67 [===================>..........] - ETA: 0s - loss: 0.9366 - categorical_accuracy: 0.650867/67 [==============================] - 0s 3ms/step - loss: 0.9274 - categorical_accuracy: 0.6571 - val_loss: 0.9485 - val_categorical_accuracy: 0.6427
Epoch 8/100
 1/67 [..............................] - ETA: 0s - loss: 1.0224 - categorical_accuracy: 0.580024/67 [=========>....................] - ETA: 0s - loss: 0.9434 - categorical_accuracy: 0.649146/67 [===================>..........] - ETA: 0s - loss: 0.9289 - categorical_accuracy: 0.659467/67 [==============================] - 0s 3ms/step - loss: 0.9220 - categorical_accuracy: 0.6651 - val_loss: 0.9122 - val_categorical_accuracy: 0.6957
Epoch 9/100
 1/67 [..............................] - ETA: 0s - loss: 0.9871 - categorical_accuracy: 0.640023/67 [=========>....................] - ETA: 0s - loss: 0.8806 - categorical_accuracy: 0.682445/67 [===================>..........] - ETA: 0s - loss: 0.8735 - categorical_accuracy: 0.688267/67 [==============================] - ETA: 0s - loss: 0.8710 - categorical_accuracy: 0.690867/67 [==============================] - 0s 3ms/step - loss: 0.8709 - categorical_accuracy: 0.6909 - val_loss: 0.8756 - val_categorical_accuracy: 0.6916
Epoch 10/100
 1/67 [..............................] - ETA: 0s - loss: 0.7590 - categorical_accuracy: 0.720023/67 [=========>....................] - ETA: 0s - loss: 0.8194 - categorical_accuracy: 0.708846/67 [===================>..........] - ETA: 0s - loss: 0.8308 - categorical_accuracy: 0.707967/67 [==============================] - 0s 3ms/step - loss: 0.8342 - categorical_accuracy: 0.7083 - val_loss: 0.9044 - val_categorical_accuracy: 0.6984
Epoch 11/100
 1/67 [..............................] - ETA: 0s - loss: 0.8095 - categorical_accuracy: 0.700024/67 [=========>....................] - ETA: 0s - loss: 0.8539 - categorical_accuracy: 0.697247/67 [====================>.........] - ETA: 0s - loss: 0.8458 - categorical_accuracy: 0.705667/67 [==============================] - 0s 3ms/step - loss: 0.8435 - categorical_accuracy: 0.7076 - val_loss: 0.8707 - val_categorical_accuracy: 0.7296
Epoch 12/100
 1/67 [..............................] - ETA: 0s - loss: 0.6811 - categorical_accuracy: 0.740024/67 [=========>....................] - ETA: 0s - loss: 0.7976 - categorical_accuracy: 0.716246/67 [===================>..........] - ETA: 0s - loss: 0.8128 - categorical_accuracy: 0.713767/67 [==============================] - 0s 3ms/step - loss: 0.8170 - categorical_accuracy: 0.7143 - val_loss: 0.8320 - val_categorical_accuracy: 0.7188
Epoch 13/100
 1/67 [..............................] - ETA: 0s - loss: 0.8198 - categorical_accuracy: 0.750023/67 [=========>....................] - ETA: 0s - loss: 0.7951 - categorical_accuracy: 0.728445/67 [===================>..........] - ETA: 0s - loss: 0.8018 - categorical_accuracy: 0.725267/67 [==============================] - 0s 3ms/step - loss: 0.8052 - categorical_accuracy: 0.7251 - val_loss: 0.8219 - val_categorical_accuracy: 0.7459
Epoch 14/100
 1/67 [..............................] - ETA: 0s - loss: 0.7856 - categorical_accuracy: 0.760024/67 [=========>....................] - ETA: 0s - loss: 0.7775 - categorical_accuracy: 0.733847/67 [====================>.........] - ETA: 0s - loss: 0.7852 - categorical_accuracy: 0.732267/67 [==============================] - 0s 3ms/step - loss: 0.7898 - categorical_accuracy: 0.7318 - val_loss: 0.8265 - val_categorical_accuracy: 0.7283
Epoch 15/100
 1/67 [..............................] - ETA: 0s - loss: 0.7551 - categorical_accuracy: 0.750024/67 [=========>....................] - ETA: 0s - loss: 0.8034 - categorical_accuracy: 0.744645/67 [===================>..........] - ETA: 0s - loss: 0.7886 - categorical_accuracy: 0.746166/67 [============================>.] - ETA: 0s - loss: 0.7860 - categorical_accuracy: 0.745767/67 [==============================] - 0s 3ms/step - loss: 0.7859 - categorical_accuracy: 0.7457 - val_loss: 0.8435 - val_categorical_accuracy: 0.7052
Epoch 16/100
 1/67 [..............................] - ETA: 0s - loss: 0.7653 - categorical_accuracy: 0.750023/67 [=========>....................] - ETA: 0s - loss: 0.8237 - categorical_accuracy: 0.721646/67 [===================>..........] - ETA: 0s - loss: 0.8028 - categorical_accuracy: 0.730067/67 [==============================] - 0s 3ms/step - loss: 0.7968 - categorical_accuracy: 0.7330 - val_loss: 0.8246 - val_categorical_accuracy: 0.7283
Epoch 17/100
 1/67 [..............................] - ETA: 0s - loss: 0.8436 - categorical_accuracy: 0.740023/67 [=========>....................] - ETA: 0s - loss: 0.7816 - categorical_accuracy: 0.738646/67 [===================>..........] - ETA: 0s - loss: 0.7734 - categorical_accuracy: 0.738167/67 [==============================] - 0s 3ms/step - loss: 0.7749 - categorical_accuracy: 0.7392 - val_loss: 0.8004 - val_categorical_accuracy: 0.7677
Epoch 18/100
 1/67 [..............................] - ETA: 0s - loss: 0.5769 - categorical_accuracy: 0.860024/67 [=========>....................] - ETA: 0s - loss: 0.7490 - categorical_accuracy: 0.752647/67 [====================>.........] - ETA: 0s - loss: 0.7658 - categorical_accuracy: 0.745367/67 [==============================] - 0s 3ms/step - loss: 0.7704 - categorical_accuracy: 0.7430 - val_loss: 0.8262 - val_categorical_accuracy: 0.7337
Epoch 19/100
 1/67 [..............................] - ETA: 0s - loss: 0.7343 - categorical_accuracy: 0.810024/67 [=========>....................] - ETA: 0s - loss: 0.7656 - categorical_accuracy: 0.767146/67 [===================>..........] - ETA: 0s - loss: 0.7578 - categorical_accuracy: 0.762467/67 [==============================] - 0s 3ms/step - loss: 0.7562 - categorical_accuracy: 0.7610 - val_loss: 0.7860 - val_categorical_accuracy: 0.7840
Epoch 20/100
 1/67 [..............................] - ETA: 0s - loss: 0.9222 - categorical_accuracy: 0.690023/67 [=========>....................] - ETA: 0s - loss: 0.7584 - categorical_accuracy: 0.749545/67 [===================>..........] - ETA: 0s - loss: 0.7597 - categorical_accuracy: 0.749267/67 [==============================] - 0s 3ms/step - loss: 0.7598 - categorical_accuracy: 0.7495 - val_loss: 0.7832 - val_categorical_accuracy: 0.7853
Epoch 21/100
 1/67 [..............................] - ETA: 0s - loss: 0.8686 - categorical_accuracy: 0.700023/67 [=========>....................] - ETA: 0s - loss: 0.7340 - categorical_accuracy: 0.763646/67 [===================>..........] - ETA: 0s - loss: 0.7331 - categorical_accuracy: 0.764867/67 [==============================] - 0s 3ms/step - loss: 0.7345 - categorical_accuracy: 0.7646 - val_loss: 0.8307 - val_categorical_accuracy: 0.7283
Epoch 22/100
 1/67 [..............................] - ETA: 0s - loss: 0.6219 - categorical_accuracy: 0.760024/67 [=========>....................] - ETA: 0s - loss: 0.7253 - categorical_accuracy: 0.752547/67 [====================>.........] - ETA: 0s - loss: 0.7453 - categorical_accuracy: 0.747767/67 [==============================] - 0s 3ms/step - loss: 0.7489 - categorical_accuracy: 0.7469 - val_loss: 0.8147 - val_categorical_accuracy: 0.7323
Epoch 23/100
 1/67 [..............................] - ETA: 0s - loss: 0.6858 - categorical_accuracy: 0.730023/67 [=========>....................] - ETA: 0s - loss: 0.6991 - categorical_accuracy: 0.769745/67 [===================>..........] - ETA: 0s - loss: 0.6978 - categorical_accuracy: 0.773267/67 [==============================] - 0s 3ms/step - loss: 0.7058 - categorical_accuracy: 0.7724 - val_loss: 0.7867 - val_categorical_accuracy: 0.7826
Epoch 24/100
 1/67 [..............................] - ETA: 0s - loss: 0.7429 - categorical_accuracy: 0.790024/67 [=========>....................] - ETA: 0s - loss: 0.7094 - categorical_accuracy: 0.778847/67 [====================>.........] - ETA: 0s - loss: 0.7182 - categorical_accuracy: 0.770867/67 [==============================] - 0s 3ms/step - loss: 0.7213 - categorical_accuracy: 0.7690 - val_loss: 0.7992 - val_categorical_accuracy: 0.7622
Epoch 25/100
 1/67 [..............................] - ETA: 0s - loss: 0.7351 - categorical_accuracy: 0.760024/67 [=========>....................] - ETA: 0s - loss: 0.6978 - categorical_accuracy: 0.770146/67 [===================>..........] - ETA: 0s - loss: 0.6980 - categorical_accuracy: 0.770067/67 [==============================] - 0s 3ms/step - loss: 0.7028 - categorical_accuracy: 0.7691 - val_loss: 0.7662 - val_categorical_accuracy: 0.7880
Epoch 26/100
 1/67 [..............................] - ETA: 0s - loss: 0.5417 - categorical_accuracy: 0.860024/67 [=========>....................] - ETA: 0s - loss: 0.6842 - categorical_accuracy: 0.794446/67 [===================>..........] - ETA: 0s - loss: 0.6967 - categorical_accuracy: 0.785367/67 [==============================] - 0s 3ms/step - loss: 0.6995 - categorical_accuracy: 0.7836 - val_loss: 0.7862 - val_categorical_accuracy: 0.7785
Epoch 27/100
 1/67 [..............................] - ETA: 0s - loss: 0.7467 - categorical_accuracy: 0.760023/67 [=========>....................] - ETA: 0s - loss: 0.7057 - categorical_accuracy: 0.787346/67 [===================>..........] - ETA: 0s - loss: 0.7133 - categorical_accuracy: 0.778767/67 [==============================] - 0s 3ms/step - loss: 0.7160 - categorical_accuracy: 0.7755 - val_loss: 0.8252 - val_categorical_accuracy: 0.7337
Epoch 28/100
 1/67 [..............................] - ETA: 0s - loss: 0.8455 - categorical_accuracy: 0.710021/67 [========>.....................] - ETA: 0s - loss: 0.7455 - categorical_accuracy: 0.745342/67 [=================>............] - ETA: 0s - loss: 0.7264 - categorical_accuracy: 0.757462/67 [==========================>...] - ETA: 0s - loss: 0.7184 - categorical_accuracy: 0.762567/67 [==============================] - 0s 3ms/step - loss: 0.7164 - categorical_accuracy: 0.7636 - val_loss: 0.7709 - val_categorical_accuracy: 0.7622
Epoch 29/100
 1/67 [..............................] - ETA: 0s - loss: 0.9067 - categorical_accuracy: 0.760023/67 [=========>....................] - ETA: 0s - loss: 0.7124 - categorical_accuracy: 0.763745/67 [===================>..........] - ETA: 0s - loss: 0.7061 - categorical_accuracy: 0.767566/67 [============================>.] - ETA: 0s - loss: 0.7045 - categorical_accuracy: 0.769767/67 [==============================] - 0s 3ms/step - loss: 0.7042 - categorical_accuracy: 0.7700 - val_loss: 0.7854 - val_categorical_accuracy: 0.7582
Epoch 30/100
 1/67 [..............................] - ETA: 0s - loss: 0.5801 - categorical_accuracy: 0.810024/67 [=========>....................] - ETA: 0s - loss: 0.6823 - categorical_accuracy: 0.772046/67 [===================>..........] - ETA: 0s - loss: 0.6847 - categorical_accuracy: 0.774767/67 [==============================] - 0s 3ms/step - loss: 0.6844 - categorical_accuracy: 0.7771 - val_loss: 0.7660 - val_categorical_accuracy: 0.7826
Epoch 31/100
 1/67 [..............................] - ETA: 0s - loss: 0.6233 - categorical_accuracy: 0.770024/67 [=========>....................] - ETA: 0s - loss: 0.7137 - categorical_accuracy: 0.759747/67 [====================>.........] - ETA: 0s - loss: 0.6984 - categorical_accuracy: 0.768967/67 [==============================] - 0s 3ms/step - loss: 0.6998 - categorical_accuracy: 0.7704 - val_loss: 0.8118 - val_categorical_accuracy: 0.7378
Epoch 32/100
 1/67 [..............................] - ETA: 0s - loss: 0.7276 - categorical_accuracy: 0.780024/67 [=========>....................] - ETA: 0s - loss: 0.6930 - categorical_accuracy: 0.769547/67 [====================>.........] - ETA: 0s - loss: 0.6940 - categorical_accuracy: 0.770967/67 [==============================] - 0s 3ms/step - loss: 0.6961 - categorical_accuracy: 0.7718 - val_loss: 0.7881 - val_categorical_accuracy: 0.7582
Epoch 33/100
 1/67 [..............................] - ETA: 0s - loss: 0.7202 - categorical_accuracy: 0.760024/67 [=========>....................] - ETA: 0s - loss: 0.7108 - categorical_accuracy: 0.776847/67 [====================>.........] - ETA: 0s - loss: 0.7020 - categorical_accuracy: 0.779667/67 [==============================] - 0s 3ms/step - loss: 0.6960 - categorical_accuracy: 0.7815 - val_loss: 0.7993 - val_categorical_accuracy: 0.7812
Epoch 34/100
 1/67 [..............................] - ETA: 0s - loss: 0.8007 - categorical_accuracy: 0.780022/67 [========>.....................] - ETA: 0s - loss: 0.7208 - categorical_accuracy: 0.781044/67 [==================>...........] - ETA: 0s - loss: 0.7163 - categorical_accuracy: 0.777867/67 [==============================] - ETA: 0s - loss: 0.7086 - categorical_accuracy: 0.778067/67 [==============================] - 0s 3ms/step - loss: 0.7082 - categorical_accuracy: 0.7781 - val_loss: 0.7881 - val_categorical_accuracy: 0.7908
Epoch 35/100
 1/67 [..............................] - ETA: 0s - loss: 0.7886 - categorical_accuracy: 0.750023/67 [=========>....................] - ETA: 0s - loss: 0.6832 - categorical_accuracy: 0.787146/67 [===================>..........] - ETA: 0s - loss: 0.6849 - categorical_accuracy: 0.783866/67 [============================>.] - ETA: 0s - loss: 0.6825 - categorical_accuracy: 0.785267/67 [==============================] - 0s 3ms/step - loss: 0.6820 - categorical_accuracy: 0.7855 - val_loss: 0.7875 - val_categorical_accuracy: 0.7663
Epoch 36/100
 1/67 [..............................] - ETA: 0s - loss: 0.6314 - categorical_accuracy: 0.790023/67 [=========>....................] - ETA: 0s - loss: 0.6591 - categorical_accuracy: 0.784646/67 [===================>..........] - ETA: 0s - loss: 0.6684 - categorical_accuracy: 0.782167/67 [==============================] - 0s 3ms/step - loss: 0.6724 - categorical_accuracy: 0.7816 - val_loss: 0.7691 - val_categorical_accuracy: 0.7731
Epoch 37/100
 1/67 [..............................] - ETA: 0s - loss: 0.4009 - categorical_accuracy: 0.880024/67 [=========>....................] - ETA: 0s - loss: 0.6055 - categorical_accuracy: 0.813646/67 [===================>..........] - ETA: 0s - loss: 0.6300 - categorical_accuracy: 0.806867/67 [==============================] - 0s 3ms/step - loss: 0.6388 - categorical_accuracy: 0.8041 - val_loss: 0.7800 - val_categorical_accuracy: 0.7880
Epoch 00037: early stopping
Experiment:  260  Set:  har2 Train Labels:  ncar10 Test Labels:  clean
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.70      0.82      0.75       496
           1       0.77      0.69      0.72       471
           2       0.85      0.77      0.81       420
           3       0.70      0.76      0.73       491
           4       0.79      0.85      0.82       532
           5       1.00      0.86      0.93       537

    accuracy                           0.80      2947
   macro avg       0.80      0.79      0.79      2947
weighted avg       0.80      0.80      0.80      2947

Confusion Matrix for this model: 
 [[405  52  35   2   2   0]
 [122 323  22   4   0   0]
 [ 50  46 324   0   0   0]
 [  0   0   0 374 117   0]
 [  0   0   0  78 454   0]
 [  0   0   0  73   1 463]]
Experiment:  261  Set:  har2 Train Labels:  ncar10 Test Labels:  ncar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.68      0.78      0.73       506
           1       0.73      0.66      0.69       468
           2       0.79      0.73      0.76       413
           3       0.67      0.73      0.70       489
           4       0.75      0.82      0.78       523
           5       0.97      0.82      0.89       548

    accuracy                           0.76      2947
   macro avg       0.76      0.75      0.76      2947
weighted avg       0.77      0.76      0.76      2947

Confusion Matrix for this model: 
 [[395  50  43  10   6   2]
 [120 307  23   9   6   3]
 [ 51  48 301   3   7   3]
 [  2   4   5 355 118   5]
 [  5   6   4  79 428   1]
 [  4   6   5  75   9 449]]
Experiment:  262  Set:  har2 Train Labels:  ncar10 Test Labels:  ncar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.75      0.69       491
           1       0.71      0.61      0.65       489
           2       0.77      0.69      0.73       426
           3       0.65      0.68      0.66       504
           4       0.70      0.78      0.73       512
           5       0.89      0.79      0.84       525

    accuracy                           0.72      2947
   macro avg       0.73      0.72      0.72      2947
weighted avg       0.73      0.72      0.72      2947

Confusion Matrix for this model: 
 [[369  53  36   6  19   8]
 [119 298  30  13  14  15]
 [ 49  48 294  12  15   8]
 [ 14   9   9 343 120   9]
 [  8   4  10  81 399  10]
 [ 18   9   2  76   7 413]]
Experiment:  263  Set:  har2 Train Labels:  ncar10 Test Labels:  nar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.70      0.82      0.75       496
           1       0.77      0.69      0.72       471
           2       0.85      0.57      0.68       572
           3       0.70      0.76      0.73       491
           4       0.79      0.85      0.82       532
           5       0.71      0.85      0.78       385

    accuracy                           0.75      2947
   macro avg       0.75      0.76      0.75      2947
weighted avg       0.76      0.75      0.75      2947

Confusion Matrix for this model: 
 [[405  52  35   2   2   0]
 [122 323  22   4   0   0]
 [ 50  46 324  18   0 134]
 [  0   0   0 374 117   0]
 [  0   0   0  78 454   0]
 [  0   0   0  55   1 329]]
Experiment:  264  Set:  har2 Train Labels:  ncar10 Test Labels:  nar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.70      0.82      0.75       496
           1       0.77      0.69      0.72       471
           2       0.85      0.45      0.59       720
           3       0.70      0.76      0.73       491
           4       0.79      0.85      0.82       532
           5       0.44      0.85      0.58       237

    accuracy                           0.71      2947
   macro avg       0.71      0.74      0.70      2947
weighted avg       0.74      0.71      0.70      2947

Confusion Matrix for this model: 
 [[405  52  35   2   2   0]
 [122 323  22   4   0   0]
 [ 50  46 324  38   1 261]
 [  0   0   0 374 117   0]
 [  0   0   0  78 454   0]
 [  0   0   0  35   0 202]]
Experiment:  265  Set:  har2 Train Labels:  ncar10 Test Labels:  nnar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.70      0.79      0.74       512
           1       0.77      0.68      0.72       476
           2       0.85      0.72      0.78       453
           3       0.71      0.74      0.72       514
           4       0.79      0.78      0.79       582
           5       0.76      0.86      0.81       410

    accuracy                           0.76      2947
   macro avg       0.76      0.76      0.76      2947
weighted avg       0.76      0.76      0.76      2947

Confusion Matrix for this model: 
 [[405  52  35   3   2  15]
 [122 323  22   4   0   5]
 [ 50  46 324   5   0  28]
 [  0   0   0 378 117  19]
 [  0   0   0  84 454  44]
 [  0   0   0  57   1 352]]
Experiment:  266  Set:  har2 Train Labels:  ncar10 Test Labels:  nnar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.70      0.82      0.75       496
           1       0.77      0.69      0.72       471
           2       0.85      0.77      0.81       420
           3       0.75      0.60      0.66       666
           4       0.79      0.82      0.80       555
           5       0.63      0.86      0.73       339

    accuracy                           0.75      2947
   macro avg       0.75      0.76      0.75      2947
weighted avg       0.75      0.75      0.74      2947

Confusion Matrix for this model: 
 [[405  52  35   2   2   0]
 [122 323  22   4   0   0]
 [ 50  46 324   0   0   0]
 [  0   0   0 398 118 150]
 [  0   0   0  81 454  20]
 [  0   0   0  46   0 293]]
Input Shape:  (7352, 3, 128)
Model: "sequential_38"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_38 (LSTM)               (None, 32)                20608     
_________________________________________________________________
dropout_38 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_152 (Dense)            (None, 128)               4224      
_________________________________________________________________
dense_153 (Dense)            (None, 128)               16512     
_________________________________________________________________
dense_154 (Dense)            (None, 64)                8256      
_________________________________________________________________
dense_155 (Dense)            (None, 6)                 390       
=================================================================
Total params: 49,990
Trainable params: 49,990
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/67 [..............................] - ETA: 1:09 - loss: 1.8259 - categorical_accuracy: 0.160021/67 [========>.....................] - ETA: 0s - loss: 1.7386 - categorical_accuracy: 0.2403  42/67 [=================>............] - ETA: 0s - loss: 1.6618 - categorical_accuracy: 0.272664/67 [===========================>..] - ETA: 0s - loss: 1.5881 - categorical_accuracy: 0.309267/67 [==============================] - 2s 7ms/step - loss: 1.5759 - categorical_accuracy: 0.3149 - val_loss: 1.0195 - val_categorical_accuracy: 0.5204
Epoch 2/100
 1/67 [..............................] - ETA: 0s - loss: 1.1019 - categorical_accuracy: 0.450023/67 [=========>....................] - ETA: 0s - loss: 1.0485 - categorical_accuracy: 0.526945/67 [===================>..........] - ETA: 0s - loss: 1.0214 - categorical_accuracy: 0.543267/67 [==============================] - ETA: 0s - loss: 1.0064 - categorical_accuracy: 0.552067/67 [==============================] - 0s 3ms/step - loss: 1.0058 - categorical_accuracy: 0.5523 - val_loss: 0.8758 - val_categorical_accuracy: 0.6087
Epoch 3/100
 1/67 [..............................] - ETA: 0s - loss: 0.8619 - categorical_accuracy: 0.560023/67 [=========>....................] - ETA: 0s - loss: 0.9058 - categorical_accuracy: 0.589945/67 [===================>..........] - ETA: 0s - loss: 0.8971 - categorical_accuracy: 0.594667/67 [==============================] - 0s 3ms/step - loss: 0.8883 - categorical_accuracy: 0.5996 - val_loss: 0.7965 - val_categorical_accuracy: 0.6291
Epoch 4/100
 1/67 [..............................] - ETA: 0s - loss: 0.7948 - categorical_accuracy: 0.650023/67 [=========>....................] - ETA: 0s - loss: 0.8578 - categorical_accuracy: 0.624945/67 [===================>..........] - ETA: 0s - loss: 0.8456 - categorical_accuracy: 0.628667/67 [==============================] - 0s 3ms/step - loss: 0.8338 - categorical_accuracy: 0.6338 - val_loss: 0.7420 - val_categorical_accuracy: 0.6807
Epoch 5/100
 1/67 [..............................] - ETA: 0s - loss: 0.7179 - categorical_accuracy: 0.730024/67 [=========>....................] - ETA: 0s - loss: 0.7742 - categorical_accuracy: 0.674846/67 [===================>..........] - ETA: 0s - loss: 0.7720 - categorical_accuracy: 0.671967/67 [==============================] - 0s 3ms/step - loss: 0.7664 - categorical_accuracy: 0.6727 - val_loss: 0.6972 - val_categorical_accuracy: 0.6916
Epoch 6/100
 1/67 [..............................] - ETA: 0s - loss: 0.6775 - categorical_accuracy: 0.690024/67 [=========>....................] - ETA: 0s - loss: 0.7293 - categorical_accuracy: 0.670546/67 [===================>..........] - ETA: 0s - loss: 0.7360 - categorical_accuracy: 0.667967/67 [==============================] - 0s 3ms/step - loss: 0.7356 - categorical_accuracy: 0.6686 - val_loss: 0.6586 - val_categorical_accuracy: 0.7011
Epoch 7/100
 1/67 [..............................] - ETA: 0s - loss: 0.7166 - categorical_accuracy: 0.700023/67 [=========>....................] - ETA: 0s - loss: 0.6959 - categorical_accuracy: 0.704146/67 [===================>..........] - ETA: 0s - loss: 0.6940 - categorical_accuracy: 0.702467/67 [==============================] - 0s 3ms/step - loss: 0.6921 - categorical_accuracy: 0.7011 - val_loss: 0.6191 - val_categorical_accuracy: 0.7432
Epoch 8/100
 1/67 [..............................] - ETA: 0s - loss: 0.6193 - categorical_accuracy: 0.730023/67 [=========>....................] - ETA: 0s - loss: 0.6677 - categorical_accuracy: 0.705545/67 [===================>..........] - ETA: 0s - loss: 0.6715 - categorical_accuracy: 0.705767/67 [==============================] - 0s 3ms/step - loss: 0.6715 - categorical_accuracy: 0.7067 - val_loss: 0.5722 - val_categorical_accuracy: 0.7663
Epoch 9/100
 1/67 [..............................] - ETA: 0s - loss: 0.6075 - categorical_accuracy: 0.720024/67 [=========>....................] - ETA: 0s - loss: 0.6466 - categorical_accuracy: 0.720246/67 [===================>..........] - ETA: 0s - loss: 0.6390 - categorical_accuracy: 0.724167/67 [==============================] - 0s 3ms/step - loss: 0.6345 - categorical_accuracy: 0.7257 - val_loss: 0.5784 - val_categorical_accuracy: 0.7541
Epoch 10/100
 1/67 [..............................] - ETA: 0s - loss: 0.5427 - categorical_accuracy: 0.770024/67 [=========>....................] - ETA: 0s - loss: 0.6239 - categorical_accuracy: 0.734947/67 [====================>.........] - ETA: 0s - loss: 0.6113 - categorical_accuracy: 0.738767/67 [==============================] - 0s 3ms/step - loss: 0.6031 - categorical_accuracy: 0.7415 - val_loss: 0.5480 - val_categorical_accuracy: 0.7663
Epoch 11/100
 1/67 [..............................] - ETA: 0s - loss: 0.5267 - categorical_accuracy: 0.770024/67 [=========>....................] - ETA: 0s - loss: 0.5328 - categorical_accuracy: 0.768247/67 [====================>.........] - ETA: 0s - loss: 0.5393 - categorical_accuracy: 0.768667/67 [==============================] - 0s 3ms/step - loss: 0.5446 - categorical_accuracy: 0.7678 - val_loss: 0.5254 - val_categorical_accuracy: 0.7649
Epoch 12/100
 1/67 [..............................] - ETA: 0s - loss: 0.4847 - categorical_accuracy: 0.820021/67 [========>.....................] - ETA: 0s - loss: 0.5667 - categorical_accuracy: 0.768543/67 [==================>...........] - ETA: 0s - loss: 0.5685 - categorical_accuracy: 0.761866/67 [============================>.] - ETA: 0s - loss: 0.5635 - categorical_accuracy: 0.762867/67 [==============================] - 0s 3ms/step - loss: 0.5634 - categorical_accuracy: 0.7628 - val_loss: 0.5117 - val_categorical_accuracy: 0.7704
Epoch 13/100
 1/67 [..............................] - ETA: 0s - loss: 0.5831 - categorical_accuracy: 0.730024/67 [=========>....................] - ETA: 0s - loss: 0.5750 - categorical_accuracy: 0.755947/67 [====================>.........] - ETA: 0s - loss: 0.5552 - categorical_accuracy: 0.765167/67 [==============================] - 0s 3ms/step - loss: 0.5496 - categorical_accuracy: 0.7663 - val_loss: 0.5398 - val_categorical_accuracy: 0.7704
Epoch 14/100
 1/67 [..............................] - ETA: 0s - loss: 0.6222 - categorical_accuracy: 0.720023/67 [=========>....................] - ETA: 0s - loss: 0.5381 - categorical_accuracy: 0.760546/67 [===================>..........] - ETA: 0s - loss: 0.5351 - categorical_accuracy: 0.765467/67 [==============================] - 0s 3ms/step - loss: 0.5308 - categorical_accuracy: 0.7687 - val_loss: 0.4940 - val_categorical_accuracy: 0.7772
Epoch 15/100
 1/67 [..............................] - ETA: 0s - loss: 0.4800 - categorical_accuracy: 0.800024/67 [=========>....................] - ETA: 0s - loss: 0.5638 - categorical_accuracy: 0.755647/67 [====================>.........] - ETA: 0s - loss: 0.5646 - categorical_accuracy: 0.755567/67 [==============================] - 0s 3ms/step - loss: 0.5590 - categorical_accuracy: 0.7569 - val_loss: 0.5096 - val_categorical_accuracy: 0.7799
Epoch 16/100
 1/67 [..............................] - ETA: 0s - loss: 0.4671 - categorical_accuracy: 0.800024/67 [=========>....................] - ETA: 0s - loss: 0.5755 - categorical_accuracy: 0.745546/67 [===================>..........] - ETA: 0s - loss: 0.5693 - categorical_accuracy: 0.749567/67 [==============================] - 0s 3ms/step - loss: 0.5624 - categorical_accuracy: 0.7534 - val_loss: 0.4876 - val_categorical_accuracy: 0.8111
Epoch 17/100
 1/67 [..............................] - ETA: 0s - loss: 0.4975 - categorical_accuracy: 0.790023/67 [=========>....................] - ETA: 0s - loss: 0.5196 - categorical_accuracy: 0.784446/67 [===================>..........] - ETA: 0s - loss: 0.5202 - categorical_accuracy: 0.782467/67 [==============================] - 0s 3ms/step - loss: 0.5159 - categorical_accuracy: 0.7842 - val_loss: 0.4746 - val_categorical_accuracy: 0.7785
Epoch 18/100
 1/67 [..............................] - ETA: 0s - loss: 0.4514 - categorical_accuracy: 0.780024/67 [=========>....................] - ETA: 0s - loss: 0.4748 - categorical_accuracy: 0.795747/67 [====================>.........] - ETA: 0s - loss: 0.4808 - categorical_accuracy: 0.795567/67 [==============================] - 0s 3ms/step - loss: 0.4844 - categorical_accuracy: 0.7936 - val_loss: 0.4505 - val_categorical_accuracy: 0.7976
Epoch 19/100
 1/67 [..............................] - ETA: 0s - loss: 0.4104 - categorical_accuracy: 0.850023/67 [=========>....................] - ETA: 0s - loss: 0.4425 - categorical_accuracy: 0.818145/67 [===================>..........] - ETA: 0s - loss: 0.4469 - categorical_accuracy: 0.814767/67 [==============================] - 0s 3ms/step - loss: 0.4514 - categorical_accuracy: 0.8119 - val_loss: 0.4462 - val_categorical_accuracy: 0.7962
Epoch 20/100
 1/67 [..............................] - ETA: 0s - loss: 0.4580 - categorical_accuracy: 0.830024/67 [=========>....................] - ETA: 0s - loss: 0.4625 - categorical_accuracy: 0.811946/67 [===================>..........] - ETA: 0s - loss: 0.4660 - categorical_accuracy: 0.807967/67 [==============================] - 0s 3ms/step - loss: 0.4709 - categorical_accuracy: 0.8043 - val_loss: 0.4802 - val_categorical_accuracy: 0.7867
Epoch 21/100
 1/67 [..............................] - ETA: 0s - loss: 0.4576 - categorical_accuracy: 0.830024/67 [=========>....................] - ETA: 0s - loss: 0.4583 - categorical_accuracy: 0.810647/67 [====================>.........] - ETA: 0s - loss: 0.4566 - categorical_accuracy: 0.811367/67 [==============================] - 0s 3ms/step - loss: 0.4562 - categorical_accuracy: 0.8109 - val_loss: 0.4932 - val_categorical_accuracy: 0.7976
Epoch 22/100
 1/67 [..............................] - ETA: 0s - loss: 0.3761 - categorical_accuracy: 0.840024/67 [=========>....................] - ETA: 0s - loss: 0.4675 - categorical_accuracy: 0.791847/67 [====================>.........] - ETA: 0s - loss: 0.4639 - categorical_accuracy: 0.796867/67 [==============================] - 0s 3ms/step - loss: 0.4622 - categorical_accuracy: 0.7994 - val_loss: 0.4635 - val_categorical_accuracy: 0.7908
Epoch 23/100
 1/67 [..............................] - ETA: 0s - loss: 0.3997 - categorical_accuracy: 0.840024/67 [=========>....................] - ETA: 0s - loss: 0.4589 - categorical_accuracy: 0.807546/67 [===================>..........] - ETA: 0s - loss: 0.4578 - categorical_accuracy: 0.804867/67 [==============================] - 0s 3ms/step - loss: 0.4553 - categorical_accuracy: 0.8057 - val_loss: 0.4560 - val_categorical_accuracy: 0.8234
Epoch 24/100
 1/67 [..............................] - ETA: 0s - loss: 0.4655 - categorical_accuracy: 0.820023/67 [=========>....................] - ETA: 0s - loss: 0.4823 - categorical_accuracy: 0.796846/67 [===================>..........] - ETA: 0s - loss: 0.4780 - categorical_accuracy: 0.798667/67 [==============================] - 0s 3ms/step - loss: 0.4731 - categorical_accuracy: 0.8010 - val_loss: 0.4739 - val_categorical_accuracy: 0.8139
Epoch 25/100
 1/67 [..............................] - ETA: 0s - loss: 0.3684 - categorical_accuracy: 0.880023/67 [=========>....................] - ETA: 0s - loss: 0.4470 - categorical_accuracy: 0.814546/67 [===================>..........] - ETA: 0s - loss: 0.4428 - categorical_accuracy: 0.816767/67 [==============================] - 0s 3ms/step - loss: 0.4398 - categorical_accuracy: 0.8179 - val_loss: 0.4341 - val_categorical_accuracy: 0.8084
Epoch 26/100
 1/67 [..............................] - ETA: 0s - loss: 0.3580 - categorical_accuracy: 0.880024/67 [=========>....................] - ETA: 0s - loss: 0.4380 - categorical_accuracy: 0.823146/67 [===================>..........] - ETA: 0s - loss: 0.4487 - categorical_accuracy: 0.816067/67 [==============================] - 0s 3ms/step - loss: 0.4519 - categorical_accuracy: 0.8123 - val_loss: 0.4155 - val_categorical_accuracy: 0.8125
Epoch 27/100
 1/67 [..............................] - ETA: 0s - loss: 0.4132 - categorical_accuracy: 0.840023/67 [=========>....................] - ETA: 0s - loss: 0.4186 - categorical_accuracy: 0.823946/67 [===================>..........] - ETA: 0s - loss: 0.4145 - categorical_accuracy: 0.827467/67 [==============================] - 0s 3ms/step - loss: 0.4141 - categorical_accuracy: 0.8278 - val_loss: 0.4705 - val_categorical_accuracy: 0.7976
Epoch 28/100
 1/67 [..............................] - ETA: 0s - loss: 0.3571 - categorical_accuracy: 0.850024/67 [=========>....................] - ETA: 0s - loss: 0.4481 - categorical_accuracy: 0.804147/67 [====================>.........] - ETA: 0s - loss: 0.4427 - categorical_accuracy: 0.808267/67 [==============================] - 0s 3ms/step - loss: 0.4364 - categorical_accuracy: 0.8116 - val_loss: 0.3796 - val_categorical_accuracy: 0.8465
Epoch 29/100
 1/67 [..............................] - ETA: 0s - loss: 0.4083 - categorical_accuracy: 0.870024/67 [=========>....................] - ETA: 0s - loss: 0.4255 - categorical_accuracy: 0.826747/67 [====================>.........] - ETA: 0s - loss: 0.4212 - categorical_accuracy: 0.826367/67 [==============================] - 0s 3ms/step - loss: 0.4188 - categorical_accuracy: 0.8261 - val_loss: 0.4117 - val_categorical_accuracy: 0.8288
Epoch 30/100
 1/67 [..............................] - ETA: 0s - loss: 0.3587 - categorical_accuracy: 0.870024/67 [=========>....................] - ETA: 0s - loss: 0.3939 - categorical_accuracy: 0.828246/67 [===================>..........] - ETA: 0s - loss: 0.4000 - categorical_accuracy: 0.828367/67 [==============================] - 0s 3ms/step - loss: 0.4046 - categorical_accuracy: 0.8270 - val_loss: 0.4289 - val_categorical_accuracy: 0.8125
Epoch 31/100
 1/67 [..............................] - ETA: 0s - loss: 0.5746 - categorical_accuracy: 0.780024/67 [=========>....................] - ETA: 0s - loss: 0.4472 - categorical_accuracy: 0.808147/67 [====================>.........] - ETA: 0s - loss: 0.4284 - categorical_accuracy: 0.817567/67 [==============================] - 0s 3ms/step - loss: 0.4210 - categorical_accuracy: 0.8215 - val_loss: 0.3870 - val_categorical_accuracy: 0.8397
Epoch 32/100
 1/67 [..............................] - ETA: 0s - loss: 0.3431 - categorical_accuracy: 0.880024/67 [=========>....................] - ETA: 0s - loss: 0.3850 - categorical_accuracy: 0.839746/67 [===================>..........] - ETA: 0s - loss: 0.3829 - categorical_accuracy: 0.838767/67 [==============================] - 0s 3ms/step - loss: 0.3871 - categorical_accuracy: 0.8363 - val_loss: 0.4169 - val_categorical_accuracy: 0.8342
Epoch 33/100
 1/67 [..............................] - ETA: 0s - loss: 0.4012 - categorical_accuracy: 0.860024/67 [=========>....................] - ETA: 0s - loss: 0.4151 - categorical_accuracy: 0.827747/67 [====================>.........] - ETA: 0s - loss: 0.4122 - categorical_accuracy: 0.827667/67 [==============================] - 0s 3ms/step - loss: 0.4076 - categorical_accuracy: 0.8289 - val_loss: 0.3817 - val_categorical_accuracy: 0.8533
Epoch 34/100
 1/67 [..............................] - ETA: 0s - loss: 0.3329 - categorical_accuracy: 0.880024/67 [=========>....................] - ETA: 0s - loss: 0.3602 - categorical_accuracy: 0.853647/67 [====================>.........] - ETA: 0s - loss: 0.3701 - categorical_accuracy: 0.847367/67 [==============================] - 0s 3ms/step - loss: 0.3771 - categorical_accuracy: 0.8434 - val_loss: 0.4238 - val_categorical_accuracy: 0.8220
Epoch 35/100
 1/67 [..............................] - ETA: 0s - loss: 0.4222 - categorical_accuracy: 0.830024/67 [=========>....................] - ETA: 0s - loss: 0.4945 - categorical_accuracy: 0.800547/67 [====================>.........] - ETA: 0s - loss: 0.4650 - categorical_accuracy: 0.810767/67 [==============================] - 0s 3ms/step - loss: 0.4492 - categorical_accuracy: 0.8164 - val_loss: 0.4195 - val_categorical_accuracy: 0.8193
Epoch 00035: early stopping
Experiment:  267  Set:  har2 Train Labels:  nar5 Test Labels:  clean
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.72      0.79      0.75       496
           1       0.81      0.70      0.75       471
           2       0.83      0.86      0.85       420
           3       0.63      0.73      0.67       491
           4       0.77      0.85      0.81       532
           5       1.00      0.75      0.86       537

    accuracy                           0.78      2947
   macro avg       0.79      0.78      0.78      2947
weighted avg       0.79      0.78      0.78      2947

Confusion Matrix for this model: 
 [[391  58  45   0   2   0]
 [112 329  29   1   0   0]
 [ 38  19 363   0   0   0]
 [  0   0   0 356 134   1]
 [  1   0   0  80 451   0]
 [  0   0   0 131   1 405]]
Experiment:  268  Set:  har2 Train Labels:  nar5 Test Labels:  ncar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.70      0.75      0.73       506
           1       0.77      0.67      0.71       468
           2       0.77      0.82      0.79       413
           3       0.60      0.69      0.64       489
           4       0.72      0.81      0.77       523
           5       0.97      0.72      0.83       548

    accuracy                           0.74      2947
   macro avg       0.76      0.74      0.74      2947
weighted avg       0.76      0.74      0.75      2947

Confusion Matrix for this model: 
 [[382  57  51   8   6   2]
 [109 312  32   9   5   1]
 [ 39  24 337   2   8   3]
 [  2   4   5 338 135   5]
 [  7   4   5  81 425   1]
 [  3   5   7 130   9 394]]
Experiment:  269  Set:  har2 Train Labels:  nar5 Test Labels:  ncar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.65      0.72      0.68       491
           1       0.74      0.61      0.67       489
           2       0.75      0.77      0.76       426
           3       0.58      0.65      0.61       504
           4       0.68      0.78      0.72       512
           5       0.89      0.69      0.77       525

    accuracy                           0.70      2947
   macro avg       0.71      0.70      0.70      2947
weighted avg       0.71      0.70      0.70      2947

Confusion Matrix for this model: 
 [[352  61  47   4  19   8]
 [116 299  36  11  13  14]
 [ 40  24 327  15  14   6]
 [ 10   7  15 327 136   9]
 [  9   4   9  83 398   9]
 [ 15  11   3 128   8 360]]
Experiment:  270  Set:  har2 Train Labels:  nar5 Test Labels:  nar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.72      0.79      0.75       496
           1       0.81      0.70      0.75       471
           2       0.83      0.63      0.72       572
           3       0.63      0.73      0.67       491
           4       0.77      0.85      0.81       532
           5       0.71      0.75      0.73       385

    accuracy                           0.74      2947
   macro avg       0.74      0.74      0.74      2947
weighted avg       0.75      0.74      0.74      2947

Confusion Matrix for this model: 
 [[391  58  45   0   2   0]
 [112 329  29   1   0   0]
 [ 38  19 363  35   0 117]
 [  0   0   0 356 134   1]
 [  1   0   0  80 451   0]
 [  0   0   0  96   1 288]]
Experiment:  271  Set:  har2 Train Labels:  nar5 Test Labels:  nar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.72      0.79      0.75       496
           1       0.81      0.70      0.75       471
           2       0.83      0.50      0.63       720
           3       0.63      0.73      0.67       491
           4       0.77      0.85      0.81       532
           5       0.44      0.76      0.56       237

    accuracy                           0.70      2947
   macro avg       0.70      0.72      0.69      2947
weighted avg       0.73      0.70      0.70      2947

Confusion Matrix for this model: 
 [[391  58  45   0   2   0]
 [112 329  29   1   0   0]
 [ 38  19 363  74   1 225]
 [  0   0   0 356 134   1]
 [  1   0   0  80 451   0]
 [  0   0   0  57   0 180]]
Experiment:  272  Set:  har2 Train Labels:  nar5 Test Labels:  nnar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.72      0.76      0.74       512
           1       0.81      0.69      0.75       476
           2       0.83      0.80      0.82       453
           3       0.64      0.71      0.67       514
           4       0.77      0.77      0.77       582
           5       0.75      0.74      0.74       410

    accuracy                           0.75      2947
   macro avg       0.75      0.75      0.75      2947
weighted avg       0.75      0.75      0.75      2947

Confusion Matrix for this model: 
 [[391  58  45   1   2  15]
 [112 329  29   2   0   4]
 [ 38  19 363   7   0  26]
 [  0   0   0 363 134  17]
 [  1   0   0  89 451  41]
 [  0   0   0 106   1 303]]
Experiment:  273  Set:  har2 Train Labels:  nar5 Test Labels:  nnar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.72      0.79      0.75       496
           1       0.81      0.70      0.75       471
           2       0.83      0.86      0.85       420
           3       0.70      0.60      0.65       666
           4       0.77      0.81      0.79       555
           5       0.62      0.74      0.68       339

    accuracy                           0.74      2947
   macro avg       0.74      0.75      0.74      2947
weighted avg       0.74      0.74      0.74      2947

Confusion Matrix for this model: 
 [[391  58  45   0   2   0]
 [112 329  29   1   0   0]
 [ 38  19 363   0   0   0]
 [  0   0   0 400 135 131]
 [  1   0   0  80 451  23]
 [  0   0   0  87   0 252]]
Input Shape:  (7352, 3, 128)
Model: "sequential_39"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_39 (LSTM)               (None, 32)                20608     
_________________________________________________________________
dropout_39 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_156 (Dense)            (None, 128)               4224      
_________________________________________________________________
dense_157 (Dense)            (None, 128)               16512     
_________________________________________________________________
dense_158 (Dense)            (None, 64)                8256      
_________________________________________________________________
dense_159 (Dense)            (None, 6)                 390       
=================================================================
Total params: 49,990
Trainable params: 49,990
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/67 [..............................] - ETA: 1:08 - loss: 1.7949 - categorical_accuracy: 0.160022/67 [========>.....................] - ETA: 0s - loss: 1.7065 - categorical_accuracy: 0.2471  43/67 [==================>...........] - ETA: 0s - loss: 1.6359 - categorical_accuracy: 0.286865/67 [============================>.] - ETA: 0s - loss: 1.5696 - categorical_accuracy: 0.321567/67 [==============================] - 1s 7ms/step - loss: 1.5612 - categorical_accuracy: 0.3254 - val_loss: 1.0660 - val_categorical_accuracy: 0.5095
Epoch 2/100
 1/67 [..............................] - ETA: 0s - loss: 1.0480 - categorical_accuracy: 0.590022/67 [========>.....................] - ETA: 0s - loss: 1.0717 - categorical_accuracy: 0.514544/67 [==================>...........] - ETA: 0s - loss: 1.0473 - categorical_accuracy: 0.527666/67 [============================>.] - ETA: 0s - loss: 1.0285 - categorical_accuracy: 0.537167/67 [==============================] - 0s 3ms/step - loss: 1.0273 - categorical_accuracy: 0.5378 - val_loss: 0.8765 - val_categorical_accuracy: 0.5897
Epoch 3/100
 1/67 [..............................] - ETA: 0s - loss: 1.0179 - categorical_accuracy: 0.500023/67 [=========>....................] - ETA: 0s - loss: 0.9361 - categorical_accuracy: 0.586445/67 [===================>..........] - ETA: 0s - loss: 0.9148 - categorical_accuracy: 0.592567/67 [==============================] - 0s 3ms/step - loss: 0.9084 - categorical_accuracy: 0.5942 - val_loss: 0.8803 - val_categorical_accuracy: 0.5856
Epoch 4/100
 1/67 [..............................] - ETA: 0s - loss: 0.8235 - categorical_accuracy: 0.670024/67 [=========>....................] - ETA: 0s - loss: 0.8357 - categorical_accuracy: 0.628447/67 [====================>.........] - ETA: 0s - loss: 0.8270 - categorical_accuracy: 0.632567/67 [==============================] - 0s 3ms/step - loss: 0.8231 - categorical_accuracy: 0.6325 - val_loss: 0.7571 - val_categorical_accuracy: 0.6440
Epoch 5/100
 1/67 [..............................] - ETA: 0s - loss: 0.8229 - categorical_accuracy: 0.580023/67 [=========>....................] - ETA: 0s - loss: 0.7969 - categorical_accuracy: 0.617246/67 [===================>..........] - ETA: 0s - loss: 0.7960 - categorical_accuracy: 0.621867/67 [==============================] - 0s 3ms/step - loss: 0.7920 - categorical_accuracy: 0.6263 - val_loss: 0.7213 - val_categorical_accuracy: 0.6644
Epoch 6/100
 1/67 [..............................] - ETA: 0s - loss: 0.8273 - categorical_accuracy: 0.610023/67 [=========>....................] - ETA: 0s - loss: 0.7648 - categorical_accuracy: 0.641446/67 [===================>..........] - ETA: 0s - loss: 0.7538 - categorical_accuracy: 0.645367/67 [==============================] - 0s 3ms/step - loss: 0.7492 - categorical_accuracy: 0.6482 - val_loss: 0.6920 - val_categorical_accuracy: 0.6562
Epoch 7/100
 1/67 [..............................] - ETA: 0s - loss: 0.6735 - categorical_accuracy: 0.700024/67 [=========>....................] - ETA: 0s - loss: 0.7286 - categorical_accuracy: 0.669646/67 [===================>..........] - ETA: 0s - loss: 0.7153 - categorical_accuracy: 0.675967/67 [==============================] - 0s 3ms/step - loss: 0.7079 - categorical_accuracy: 0.6781 - val_loss: 0.6550 - val_categorical_accuracy: 0.6929
Epoch 8/100
 1/67 [..............................] - ETA: 0s - loss: 0.6750 - categorical_accuracy: 0.690024/67 [=========>....................] - ETA: 0s - loss: 0.6732 - categorical_accuracy: 0.689746/67 [===================>..........] - ETA: 0s - loss: 0.6628 - categorical_accuracy: 0.694967/67 [==============================] - 0s 3ms/step - loss: 0.6592 - categorical_accuracy: 0.6955 - val_loss: 0.5760 - val_categorical_accuracy: 0.7337
Epoch 9/100
 1/67 [..............................] - ETA: 0s - loss: 0.5879 - categorical_accuracy: 0.710023/67 [=========>....................] - ETA: 0s - loss: 0.5755 - categorical_accuracy: 0.726046/67 [===================>..........] - ETA: 0s - loss: 0.5905 - categorical_accuracy: 0.720967/67 [==============================] - 0s 3ms/step - loss: 0.5977 - categorical_accuracy: 0.7179 - val_loss: 0.5807 - val_categorical_accuracy: 0.7092
Epoch 10/100
 1/67 [..............................] - ETA: 0s - loss: 0.6574 - categorical_accuracy: 0.710024/67 [=========>....................] - ETA: 0s - loss: 0.5857 - categorical_accuracy: 0.745644/67 [==================>...........] - ETA: 0s - loss: 0.5845 - categorical_accuracy: 0.742866/67 [============================>.] - ETA: 0s - loss: 0.5845 - categorical_accuracy: 0.739167/67 [==============================] - 0s 3ms/step - loss: 0.5845 - categorical_accuracy: 0.7389 - val_loss: 0.5734 - val_categorical_accuracy: 0.7092
Epoch 11/100
 1/67 [..............................] - ETA: 0s - loss: 0.5910 - categorical_accuracy: 0.670024/67 [=========>....................] - ETA: 0s - loss: 0.6259 - categorical_accuracy: 0.700246/67 [===================>..........] - ETA: 0s - loss: 0.6225 - categorical_accuracy: 0.704367/67 [==============================] - 0s 3ms/step - loss: 0.6153 - categorical_accuracy: 0.7092 - val_loss: 0.5139 - val_categorical_accuracy: 0.7582
Epoch 12/100
 1/67 [..............................] - ETA: 0s - loss: 0.5594 - categorical_accuracy: 0.730024/67 [=========>....................] - ETA: 0s - loss: 0.5423 - categorical_accuracy: 0.735847/67 [====================>.........] - ETA: 0s - loss: 0.5414 - categorical_accuracy: 0.740767/67 [==============================] - 0s 3ms/step - loss: 0.5436 - categorical_accuracy: 0.7411 - val_loss: 0.5449 - val_categorical_accuracy: 0.7255
Epoch 13/100
 1/67 [..............................] - ETA: 0s - loss: 0.5544 - categorical_accuracy: 0.740023/67 [=========>....................] - ETA: 0s - loss: 0.5790 - categorical_accuracy: 0.721946/67 [===================>..........] - ETA: 0s - loss: 0.5692 - categorical_accuracy: 0.729367/67 [==============================] - 0s 3ms/step - loss: 0.5612 - categorical_accuracy: 0.7335 - val_loss: 0.5590 - val_categorical_accuracy: 0.7215
Epoch 14/100
 1/67 [..............................] - ETA: 0s - loss: 0.4893 - categorical_accuracy: 0.790024/67 [=========>....................] - ETA: 0s - loss: 0.5547 - categorical_accuracy: 0.736146/67 [===================>..........] - ETA: 0s - loss: 0.5459 - categorical_accuracy: 0.740867/67 [==============================] - 0s 3ms/step - loss: 0.5409 - categorical_accuracy: 0.7444 - val_loss: 0.4812 - val_categorical_accuracy: 0.7514
Epoch 15/100
 1/67 [..............................] - ETA: 0s - loss: 0.5104 - categorical_accuracy: 0.750024/67 [=========>....................] - ETA: 0s - loss: 0.5058 - categorical_accuracy: 0.756647/67 [====================>.........] - ETA: 0s - loss: 0.5104 - categorical_accuracy: 0.755167/67 [==============================] - 0s 3ms/step - loss: 0.5100 - categorical_accuracy: 0.7556 - val_loss: 0.4983 - val_categorical_accuracy: 0.7636
Epoch 16/100
 1/67 [..............................] - ETA: 0s - loss: 0.5358 - categorical_accuracy: 0.770023/67 [=========>....................] - ETA: 0s - loss: 0.5164 - categorical_accuracy: 0.758146/67 [===================>..........] - ETA: 0s - loss: 0.5264 - categorical_accuracy: 0.751667/67 [==============================] - 0s 3ms/step - loss: 0.5263 - categorical_accuracy: 0.7507 - val_loss: 0.4882 - val_categorical_accuracy: 0.7595
Epoch 17/100
 1/67 [..............................] - ETA: 0s - loss: 0.4582 - categorical_accuracy: 0.800024/67 [=========>....................] - ETA: 0s - loss: 0.5247 - categorical_accuracy: 0.743847/67 [====================>.........] - ETA: 0s - loss: 0.5199 - categorical_accuracy: 0.747067/67 [==============================] - 0s 3ms/step - loss: 0.5148 - categorical_accuracy: 0.7501 - val_loss: 0.4623 - val_categorical_accuracy: 0.7731
Epoch 18/100
 1/67 [..............................] - ETA: 0s - loss: 0.4307 - categorical_accuracy: 0.810023/67 [=========>....................] - ETA: 0s - loss: 0.4802 - categorical_accuracy: 0.772145/67 [===================>..........] - ETA: 0s - loss: 0.4770 - categorical_accuracy: 0.772767/67 [==============================] - 0s 3ms/step - loss: 0.4782 - categorical_accuracy: 0.7712 - val_loss: 0.5092 - val_categorical_accuracy: 0.7391
Epoch 19/100
 1/67 [..............................] - ETA: 0s - loss: 0.6221 - categorical_accuracy: 0.680024/67 [=========>....................] - ETA: 0s - loss: 0.5417 - categorical_accuracy: 0.747847/67 [====================>.........] - ETA: 0s - loss: 0.5309 - categorical_accuracy: 0.752467/67 [==============================] - 0s 3ms/step - loss: 0.5237 - categorical_accuracy: 0.7555 - val_loss: 0.4758 - val_categorical_accuracy: 0.7500
Epoch 20/100
 1/67 [..............................] - ETA: 0s - loss: 0.5749 - categorical_accuracy: 0.730023/67 [=========>....................] - ETA: 0s - loss: 0.4876 - categorical_accuracy: 0.768846/67 [===================>..........] - ETA: 0s - loss: 0.4773 - categorical_accuracy: 0.772967/67 [==============================] - 0s 3ms/step - loss: 0.4774 - categorical_accuracy: 0.7733 - val_loss: 0.4539 - val_categorical_accuracy: 0.7758
Epoch 21/100
 1/67 [..............................] - ETA: 0s - loss: 0.4197 - categorical_accuracy: 0.790024/67 [=========>....................] - ETA: 0s - loss: 0.4706 - categorical_accuracy: 0.776547/67 [====================>.........] - ETA: 0s - loss: 0.4662 - categorical_accuracy: 0.778867/67 [==============================] - 0s 3ms/step - loss: 0.4639 - categorical_accuracy: 0.7799 - val_loss: 0.4472 - val_categorical_accuracy: 0.7595
Epoch 22/100
 1/67 [..............................] - ETA: 0s - loss: 0.4199 - categorical_accuracy: 0.810024/67 [=========>....................] - ETA: 0s - loss: 0.4253 - categorical_accuracy: 0.802447/67 [====================>.........] - ETA: 0s - loss: 0.4431 - categorical_accuracy: 0.792267/67 [==============================] - 0s 3ms/step - loss: 0.4571 - categorical_accuracy: 0.7851 - val_loss: 0.4540 - val_categorical_accuracy: 0.7636
Epoch 23/100
 1/67 [..............................] - ETA: 0s - loss: 0.3965 - categorical_accuracy: 0.840023/67 [=========>....................] - ETA: 0s - loss: 0.4756 - categorical_accuracy: 0.776246/67 [===================>..........] - ETA: 0s - loss: 0.4732 - categorical_accuracy: 0.773667/67 [==============================] - 0s 3ms/step - loss: 0.4699 - categorical_accuracy: 0.7744 - val_loss: 0.4852 - val_categorical_accuracy: 0.7473
Epoch 24/100
 1/67 [..............................] - ETA: 0s - loss: 0.5450 - categorical_accuracy: 0.740023/67 [=========>....................] - ETA: 0s - loss: 0.4911 - categorical_accuracy: 0.760745/67 [===================>..........] - ETA: 0s - loss: 0.4807 - categorical_accuracy: 0.764367/67 [==============================] - ETA: 0s - loss: 0.4734 - categorical_accuracy: 0.768867/67 [==============================] - 0s 3ms/step - loss: 0.4732 - categorical_accuracy: 0.7690 - val_loss: 0.4302 - val_categorical_accuracy: 0.7812
Epoch 25/100
 1/67 [..............................] - ETA: 0s - loss: 0.4330 - categorical_accuracy: 0.740024/67 [=========>....................] - ETA: 0s - loss: 0.4306 - categorical_accuracy: 0.779946/67 [===================>..........] - ETA: 0s - loss: 0.4379 - categorical_accuracy: 0.779167/67 [==============================] - 0s 3ms/step - loss: 0.4422 - categorical_accuracy: 0.7779 - val_loss: 0.4143 - val_categorical_accuracy: 0.7908
Epoch 26/100
 1/67 [..............................] - ETA: 0s - loss: 0.3831 - categorical_accuracy: 0.820023/67 [=========>....................] - ETA: 0s - loss: 0.4093 - categorical_accuracy: 0.805146/67 [===================>..........] - ETA: 0s - loss: 0.4185 - categorical_accuracy: 0.799167/67 [==============================] - 0s 3ms/step - loss: 0.4256 - categorical_accuracy: 0.7950 - val_loss: 0.4451 - val_categorical_accuracy: 0.7595
Epoch 27/100
 1/67 [..............................] - ETA: 0s - loss: 0.4964 - categorical_accuracy: 0.770024/67 [=========>....................] - ETA: 0s - loss: 0.4425 - categorical_accuracy: 0.786047/67 [====================>.........] - ETA: 0s - loss: 0.4394 - categorical_accuracy: 0.787267/67 [==============================] - 0s 3ms/step - loss: 0.4355 - categorical_accuracy: 0.7886 - val_loss: 0.4373 - val_categorical_accuracy: 0.7785
Epoch 28/100
 1/67 [..............................] - ETA: 0s - loss: 0.3767 - categorical_accuracy: 0.790024/67 [=========>....................] - ETA: 0s - loss: 0.4404 - categorical_accuracy: 0.789747/67 [====================>.........] - ETA: 0s - loss: 0.4503 - categorical_accuracy: 0.779067/67 [==============================] - 0s 3ms/step - loss: 0.4499 - categorical_accuracy: 0.7780 - val_loss: 0.4174 - val_categorical_accuracy: 0.7880
Epoch 29/100
 1/67 [..............................] - ETA: 0s - loss: 0.4320 - categorical_accuracy: 0.770023/67 [=========>....................] - ETA: 0s - loss: 0.4381 - categorical_accuracy: 0.781246/67 [===================>..........] - ETA: 0s - loss: 0.4319 - categorical_accuracy: 0.787767/67 [==============================] - 0s 3ms/step - loss: 0.4308 - categorical_accuracy: 0.7888 - val_loss: 0.4104 - val_categorical_accuracy: 0.7921
Epoch 30/100
 1/67 [..............................] - ETA: 0s - loss: 0.3926 - categorical_accuracy: 0.780024/67 [=========>....................] - ETA: 0s - loss: 0.4129 - categorical_accuracy: 0.794447/67 [====================>.........] - ETA: 0s - loss: 0.4196 - categorical_accuracy: 0.794267/67 [==============================] - 0s 3ms/step - loss: 0.4315 - categorical_accuracy: 0.7915 - val_loss: 0.4849 - val_categorical_accuracy: 0.7473
Epoch 31/100
 1/67 [..............................] - ETA: 0s - loss: 0.5842 - categorical_accuracy: 0.750024/67 [=========>....................] - ETA: 0s - loss: 0.4910 - categorical_accuracy: 0.765147/67 [====================>.........] - ETA: 0s - loss: 0.4682 - categorical_accuracy: 0.774667/67 [==============================] - 0s 3ms/step - loss: 0.4570 - categorical_accuracy: 0.7796 - val_loss: 0.4811 - val_categorical_accuracy: 0.7595
Epoch 32/100
 1/67 [..............................] - ETA: 0s - loss: 0.4336 - categorical_accuracy: 0.780023/67 [=========>....................] - ETA: 0s - loss: 0.4400 - categorical_accuracy: 0.797345/67 [===================>..........] - ETA: 0s - loss: 0.4384 - categorical_accuracy: 0.796666/67 [============================>.] - ETA: 0s - loss: 0.4342 - categorical_accuracy: 0.797067/67 [==============================] - 0s 3ms/step - loss: 0.4337 - categorical_accuracy: 0.7971 - val_loss: 0.4290 - val_categorical_accuracy: 0.7976
Epoch 33/100
 1/67 [..............................] - ETA: 0s - loss: 0.4598 - categorical_accuracy: 0.800024/67 [=========>....................] - ETA: 0s - loss: 0.4342 - categorical_accuracy: 0.794947/67 [====================>.........] - ETA: 0s - loss: 0.4255 - categorical_accuracy: 0.796867/67 [==============================] - 0s 3ms/step - loss: 0.4204 - categorical_accuracy: 0.7986 - val_loss: 0.4088 - val_categorical_accuracy: 0.7948
Epoch 34/100
 1/67 [..............................] - ETA: 0s - loss: 0.3397 - categorical_accuracy: 0.820024/67 [=========>....................] - ETA: 0s - loss: 0.4096 - categorical_accuracy: 0.793446/67 [===================>..........] - ETA: 0s - loss: 0.4063 - categorical_accuracy: 0.795867/67 [==============================] - 0s 3ms/step - loss: 0.4042 - categorical_accuracy: 0.7980 - val_loss: 0.7243 - val_categorical_accuracy: 0.7133
Epoch 35/100
 1/67 [..............................] - ETA: 0s - loss: 1.0325 - categorical_accuracy: 0.660024/67 [=========>....................] - ETA: 0s - loss: 0.6268 - categorical_accuracy: 0.733646/67 [===================>..........] - ETA: 0s - loss: 0.5498 - categorical_accuracy: 0.757667/67 [==============================] - 0s 3ms/step - loss: 0.5156 - categorical_accuracy: 0.7677 - val_loss: 0.4131 - val_categorical_accuracy: 0.7785
Epoch 36/100
 1/67 [..............................] - ETA: 0s - loss: 0.4313 - categorical_accuracy: 0.770024/67 [=========>....................] - ETA: 0s - loss: 0.4349 - categorical_accuracy: 0.783247/67 [====================>.........] - ETA: 0s - loss: 0.4201 - categorical_accuracy: 0.791767/67 [==============================] - 0s 3ms/step - loss: 0.4150 - categorical_accuracy: 0.7951 - val_loss: 0.3996 - val_categorical_accuracy: 0.7826
Epoch 37/100
 1/67 [..............................] - ETA: 0s - loss: 0.3824 - categorical_accuracy: 0.820024/67 [=========>....................] - ETA: 0s - loss: 0.4031 - categorical_accuracy: 0.795646/67 [===================>..........] - ETA: 0s - loss: 0.4048 - categorical_accuracy: 0.797167/67 [==============================] - 0s 3ms/step - loss: 0.4057 - categorical_accuracy: 0.7974 - val_loss: 0.4150 - val_categorical_accuracy: 0.7894
Epoch 38/100
 1/67 [..............................] - ETA: 0s - loss: 0.4099 - categorical_accuracy: 0.740024/67 [=========>....................] - ETA: 0s - loss: 0.4455 - categorical_accuracy: 0.774247/67 [====================>.........] - ETA: 0s - loss: 0.4378 - categorical_accuracy: 0.779967/67 [==============================] - 0s 3ms/step - loss: 0.4346 - categorical_accuracy: 0.7819 - val_loss: 0.4575 - val_categorical_accuracy: 0.7731
Epoch 39/100
 1/67 [..............................] - ETA: 0s - loss: 0.4774 - categorical_accuracy: 0.770024/67 [=========>....................] - ETA: 0s - loss: 0.4399 - categorical_accuracy: 0.796446/67 [===================>..........] - ETA: 0s - loss: 0.4260 - categorical_accuracy: 0.802167/67 [==============================] - 0s 3ms/step - loss: 0.4194 - categorical_accuracy: 0.8031 - val_loss: 0.4026 - val_categorical_accuracy: 0.7921
Epoch 40/100
 1/67 [..............................] - ETA: 0s - loss: 0.4208 - categorical_accuracy: 0.790024/67 [=========>....................] - ETA: 0s - loss: 0.4302 - categorical_accuracy: 0.788147/67 [====================>.........] - ETA: 0s - loss: 0.4287 - categorical_accuracy: 0.789667/67 [==============================] - 0s 3ms/step - loss: 0.4229 - categorical_accuracy: 0.7925 - val_loss: 0.4908 - val_categorical_accuracy: 0.7554
Epoch 41/100
 1/67 [..............................] - ETA: 0s - loss: 0.4739 - categorical_accuracy: 0.780024/67 [=========>....................] - ETA: 0s - loss: 0.4787 - categorical_accuracy: 0.770746/67 [===================>..........] - ETA: 0s - loss: 0.4569 - categorical_accuracy: 0.780567/67 [==============================] - 0s 3ms/step - loss: 0.4427 - categorical_accuracy: 0.7874 - val_loss: 0.4459 - val_categorical_accuracy: 0.7717
Epoch 42/100
 1/67 [..............................] - ETA: 0s - loss: 0.5161 - categorical_accuracy: 0.720024/67 [=========>....................] - ETA: 0s - loss: 0.4321 - categorical_accuracy: 0.780547/67 [====================>.........] - ETA: 0s - loss: 0.4194 - categorical_accuracy: 0.788067/67 [==============================] - 0s 3ms/step - loss: 0.4128 - categorical_accuracy: 0.7919 - val_loss: 0.4145 - val_categorical_accuracy: 0.8003
Epoch 43/100
 1/67 [..............................] - ETA: 0s - loss: 0.3397 - categorical_accuracy: 0.820024/67 [=========>....................] - ETA: 0s - loss: 0.3890 - categorical_accuracy: 0.808147/67 [====================>.........] - ETA: 0s - loss: 0.3912 - categorical_accuracy: 0.806067/67 [==============================] - 0s 3ms/step - loss: 0.3936 - categorical_accuracy: 0.8051 - val_loss: 0.4038 - val_categorical_accuracy: 0.7976
Epoch 00043: early stopping
Experiment:  274  Set:  har2 Train Labels:  nar10 Test Labels:  clean
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.81      0.69      0.74       496
           1       0.71      0.81      0.76       471
           2       0.49      0.85      0.62       420
           3       0.82      0.70      0.76       491
           4       0.73      0.90      0.81       532
           5       1.00      0.34      0.51       537

    accuracy                           0.71      2947
   macro avg       0.76      0.72      0.70      2947
weighted avg       0.77      0.71      0.70      2947

Confusion Matrix for this model: 
 [[342 113  41   0   0   0]
 [ 59 383  26   1   2   0]
 [ 22  42 356   0   0   0]
 [  0   0   1 346 144   0]
 [  0   0   0  54 478   0]
 [  0   0 305  20  27 185]]
Experiment:  275  Set:  har2 Train Labels:  nar10 Test Labels:  ncar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.78      0.65      0.71       506
           1       0.68      0.78      0.73       468
           2       0.46      0.80      0.58       413
           3       0.77      0.67      0.72       489
           4       0.69      0.86      0.77       523
           5       0.95      0.32      0.48       548

    accuracy                           0.67      2947
   macro avg       0.72      0.68      0.66      2947
weighted avg       0.73      0.67      0.66      2947

Confusion Matrix for this model: 
 [[330 111  53   7   4   1]
 [ 58 366  29   6   7   2]
 [ 27  42 332   2   8   2]
 [  1   5   8 326 146   3]
 [  5   6   5  55 451   1]
 [  2   8 302  25  35 176]]
Experiment:  276  Set:  har2 Train Labels:  nar10 Test Labels:  ncar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.74      0.64      0.68       491
           1       0.66      0.72      0.69       489
           2       0.45      0.77      0.57       426
           3       0.74      0.62      0.68       504
           4       0.65      0.83      0.73       512
           5       0.91      0.32      0.47       525

    accuracy                           0.65      2947
   macro avg       0.69      0.65      0.64      2947
weighted avg       0.70      0.65      0.64      2947

Confusion Matrix for this model: 
 [[313 107  48   4  17   2]
 [ 60 354  44   9  17   5]
 [ 22  46 329  12  14   3]
 [  7  11  21 313 146   6]
 [  7   5  19  56 424   1]
 [ 14  15 268  27  33 168]]
Experiment:  277  Set:  har2 Train Labels:  nar10 Test Labels:  nar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.81      0.69      0.74       496
           1       0.71      0.81      0.76       471
           2       0.61      0.78      0.69       572
           3       0.82      0.70      0.76       491
           4       0.73      0.90      0.81       532
           5       0.73      0.35      0.47       385

    accuracy                           0.72      2947
   macro avg       0.74      0.71      0.70      2947
weighted avg       0.73      0.72      0.71      2947

Confusion Matrix for this model: 
 [[342 113  41   0   0   0]
 [ 59 383  26   1   2   0]
 [ 22  42 446   6   6  50]
 [  0   0   1 346 144   0]
 [  0   0   0  54 478   0]
 [  0   0 215  14  21 135]]
Experiment:  278  Set:  har2 Train Labels:  nar10 Test Labels:  nar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.81      0.69      0.74       496
           1       0.71      0.81      0.76       471
           2       0.72      0.73      0.72       720
           3       0.82      0.70      0.76       491
           4       0.73      0.90      0.81       532
           5       0.43      0.34      0.38       237

    accuracy                           0.73      2947
   macro avg       0.70      0.70      0.70      2947
weighted avg       0.73      0.73      0.73      2947

Confusion Matrix for this model: 
 [[342 113  41   0   0   0]
 [ 59 383  26   1   2   0]
 [ 22  42 524  15  12 105]
 [  0   0   1 346 144   0]
 [  0   0   0  54 478   0]
 [  0   0 137   5  15  80]]
Experiment:  279  Set:  har2 Train Labels:  nar10 Test Labels:  nnar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.81      0.67      0.73       512
           1       0.71      0.80      0.76       476
           2       0.51      0.82      0.63       453
           3       0.82      0.67      0.74       514
           4       0.74      0.83      0.78       582
           5       0.76      0.34      0.47       410

    accuracy                           0.70      2947
   macro avg       0.72      0.69      0.68      2947
weighted avg       0.73      0.70      0.69      2947

Confusion Matrix for this model: 
 [[342 113  51   0   1   5]
 [ 59 383  29   1   2   2]
 [ 22  42 371   0   1  17]
 [  0   0  12 346 146  10]
 [  0   0  34  55 482  11]
 [  0   0 232  19  19 140]]
Experiment:  280  Set:  har2 Train Labels:  nar10 Test Labels:  nnar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.81      0.69      0.74       496
           1       0.71      0.81      0.76       471
           2       0.49      0.85      0.62       420
           3       0.83      0.53      0.65       666
           4       0.74      0.86      0.80       555
           5       0.64      0.35      0.45       339

    accuracy                           0.69      2947
   macro avg       0.70      0.68      0.67      2947
weighted avg       0.72      0.69      0.68      2947

Confusion Matrix for this model: 
 [[342 113  41   0   0   0]
 [ 59 383  26   1   2   0]
 [ 22  42 356   0   0   0]
 [  0   0  93 351 156  66]
 [  0   0  20  55 480   0]
 [  0   0 193  14  13 119]]
Input Shape:  (7352, 3, 128)
Model: "sequential_40"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_40 (LSTM)               (None, 32)                20608     
_________________________________________________________________
dropout_40 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_160 (Dense)            (None, 128)               4224      
_________________________________________________________________
dense_161 (Dense)            (None, 128)               16512     
_________________________________________________________________
dense_162 (Dense)            (None, 64)                8256      
_________________________________________________________________
dense_163 (Dense)            (None, 6)                 390       
=================================================================
Total params: 49,990
Trainable params: 49,990
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/67 [..............................] - ETA: 1:08 - loss: 1.7772 - categorical_accuracy: 0.240022/67 [========>.....................] - ETA: 0s - loss: 1.7004 - categorical_accuracy: 0.2755  42/67 [=================>............] - ETA: 0s - loss: 1.6314 - categorical_accuracy: 0.298864/67 [===========================>..] - ETA: 0s - loss: 1.5677 - categorical_accuracy: 0.326267/67 [==============================] - 1s 7ms/step - loss: 1.5567 - categorical_accuracy: 0.3306 - val_loss: 1.0605 - val_categorical_accuracy: 0.5245
Epoch 2/100
 1/67 [..............................] - ETA: 0s - loss: 1.1568 - categorical_accuracy: 0.570023/67 [=========>....................] - ETA: 0s - loss: 1.0668 - categorical_accuracy: 0.514745/67 [===================>..........] - ETA: 0s - loss: 1.0394 - categorical_accuracy: 0.526466/67 [============================>.] - ETA: 0s - loss: 1.0227 - categorical_accuracy: 0.535667/67 [==============================] - 0s 3ms/step - loss: 1.0212 - categorical_accuracy: 0.5365 - val_loss: 0.9045 - val_categorical_accuracy: 0.6168
Epoch 3/100
 1/67 [..............................] - ETA: 0s - loss: 0.8538 - categorical_accuracy: 0.650023/67 [=========>....................] - ETA: 0s - loss: 0.8858 - categorical_accuracy: 0.622745/67 [===================>..........] - ETA: 0s - loss: 0.8769 - categorical_accuracy: 0.622467/67 [==============================] - ETA: 0s - loss: 0.8704 - categorical_accuracy: 0.623467/67 [==============================] - 0s 3ms/step - loss: 0.8701 - categorical_accuracy: 0.6235 - val_loss: 0.8136 - val_categorical_accuracy: 0.6440
Epoch 4/100
 1/67 [..............................] - ETA: 0s - loss: 0.8538 - categorical_accuracy: 0.640023/67 [=========>....................] - ETA: 0s - loss: 0.7984 - categorical_accuracy: 0.666445/67 [===================>..........] - ETA: 0s - loss: 0.7984 - categorical_accuracy: 0.662267/67 [==============================] - 0s 3ms/step - loss: 0.7967 - categorical_accuracy: 0.6601 - val_loss: 0.7633 - val_categorical_accuracy: 0.7052
Epoch 5/100
 1/67 [..............................] - ETA: 0s - loss: 0.7388 - categorical_accuracy: 0.690023/67 [=========>....................] - ETA: 0s - loss: 0.7531 - categorical_accuracy: 0.677546/67 [===================>..........] - ETA: 0s - loss: 0.7430 - categorical_accuracy: 0.681567/67 [==============================] - 0s 3ms/step - loss: 0.7412 - categorical_accuracy: 0.6824 - val_loss: 0.7259 - val_categorical_accuracy: 0.6712
Epoch 6/100
 1/67 [..............................] - ETA: 0s - loss: 0.6369 - categorical_accuracy: 0.740023/67 [=========>....................] - ETA: 0s - loss: 0.6934 - categorical_accuracy: 0.697046/67 [===================>..........] - ETA: 0s - loss: 0.6945 - categorical_accuracy: 0.702967/67 [==============================] - 0s 3ms/step - loss: 0.6964 - categorical_accuracy: 0.7039 - val_loss: 0.7053 - val_categorical_accuracy: 0.6943
Epoch 7/100
 1/67 [..............................] - ETA: 0s - loss: 0.8219 - categorical_accuracy: 0.650023/67 [=========>....................] - ETA: 0s - loss: 0.6596 - categorical_accuracy: 0.721145/67 [===================>..........] - ETA: 0s - loss: 0.6656 - categorical_accuracy: 0.719167/67 [==============================] - 0s 3ms/step - loss: 0.6671 - categorical_accuracy: 0.7188 - val_loss: 0.6741 - val_categorical_accuracy: 0.7079
Epoch 8/100
 1/67 [..............................] - ETA: 0s - loss: 0.5627 - categorical_accuracy: 0.760024/67 [=========>....................] - ETA: 0s - loss: 0.6564 - categorical_accuracy: 0.718247/67 [====================>.........] - ETA: 0s - loss: 0.6556 - categorical_accuracy: 0.717967/67 [==============================] - 0s 3ms/step - loss: 0.6518 - categorical_accuracy: 0.7212 - val_loss: 0.6442 - val_categorical_accuracy: 0.7446
Epoch 9/100
 1/67 [..............................] - ETA: 0s - loss: 0.8493 - categorical_accuracy: 0.650024/67 [=========>....................] - ETA: 0s - loss: 0.6572 - categorical_accuracy: 0.735346/67 [===================>..........] - ETA: 0s - loss: 0.6355 - categorical_accuracy: 0.741467/67 [==============================] - 0s 3ms/step - loss: 0.6296 - categorical_accuracy: 0.7425 - val_loss: 0.6555 - val_categorical_accuracy: 0.7024
Epoch 10/100
 1/67 [..............................] - ETA: 0s - loss: 0.5676 - categorical_accuracy: 0.740023/67 [=========>....................] - ETA: 0s - loss: 0.6059 - categorical_accuracy: 0.745646/67 [===================>..........] - ETA: 0s - loss: 0.6068 - categorical_accuracy: 0.743567/67 [==============================] - 0s 3ms/step - loss: 0.6068 - categorical_accuracy: 0.7425 - val_loss: 0.5999 - val_categorical_accuracy: 0.7378
Epoch 11/100
 1/67 [..............................] - ETA: 0s - loss: 0.7175 - categorical_accuracy: 0.710024/67 [=========>....................] - ETA: 0s - loss: 0.6119 - categorical_accuracy: 0.742147/67 [====================>.........] - ETA: 0s - loss: 0.5977 - categorical_accuracy: 0.746867/67 [==============================] - 0s 3ms/step - loss: 0.5951 - categorical_accuracy: 0.7479 - val_loss: 0.5859 - val_categorical_accuracy: 0.7554
Epoch 12/100
 1/67 [..............................] - ETA: 0s - loss: 0.4734 - categorical_accuracy: 0.810024/67 [=========>....................] - ETA: 0s - loss: 0.5370 - categorical_accuracy: 0.779746/67 [===================>..........] - ETA: 0s - loss: 0.5558 - categorical_accuracy: 0.770667/67 [==============================] - 0s 3ms/step - loss: 0.5619 - categorical_accuracy: 0.7666 - val_loss: 0.5656 - val_categorical_accuracy: 0.7677
Epoch 13/100
 1/67 [..............................] - ETA: 0s - loss: 0.4235 - categorical_accuracy: 0.800023/67 [=========>....................] - ETA: 0s - loss: 0.5187 - categorical_accuracy: 0.771246/67 [===================>..........] - ETA: 0s - loss: 0.5359 - categorical_accuracy: 0.765867/67 [==============================] - 0s 3ms/step - loss: 0.5459 - categorical_accuracy: 0.7635 - val_loss: 0.5861 - val_categorical_accuracy: 0.7622
Epoch 14/100
 1/67 [..............................] - ETA: 0s - loss: 0.6805 - categorical_accuracy: 0.680023/67 [=========>....................] - ETA: 0s - loss: 0.5947 - categorical_accuracy: 0.759245/67 [===================>..........] - ETA: 0s - loss: 0.5787 - categorical_accuracy: 0.765067/67 [==============================] - 0s 3ms/step - loss: 0.5711 - categorical_accuracy: 0.7675 - val_loss: 0.5873 - val_categorical_accuracy: 0.7391
Epoch 15/100
 1/67 [..............................] - ETA: 0s - loss: 0.5520 - categorical_accuracy: 0.780024/67 [=========>....................] - ETA: 0s - loss: 0.5298 - categorical_accuracy: 0.780046/67 [===================>..........] - ETA: 0s - loss: 0.5375 - categorical_accuracy: 0.778267/67 [==============================] - 0s 3ms/step - loss: 0.5398 - categorical_accuracy: 0.7768 - val_loss: 0.5529 - val_categorical_accuracy: 0.7826
Epoch 16/100
 1/67 [..............................] - ETA: 0s - loss: 0.6038 - categorical_accuracy: 0.780024/67 [=========>....................] - ETA: 0s - loss: 0.5281 - categorical_accuracy: 0.792646/67 [===================>..........] - ETA: 0s - loss: 0.5244 - categorical_accuracy: 0.789267/67 [==============================] - 0s 3ms/step - loss: 0.5238 - categorical_accuracy: 0.7874 - val_loss: 0.5496 - val_categorical_accuracy: 0.8057
Epoch 17/100
 1/67 [..............................] - ETA: 0s - loss: 0.5321 - categorical_accuracy: 0.820024/67 [=========>....................] - ETA: 0s - loss: 0.5148 - categorical_accuracy: 0.810546/67 [===================>..........] - ETA: 0s - loss: 0.5180 - categorical_accuracy: 0.804967/67 [==============================] - 0s 3ms/step - loss: 0.5184 - categorical_accuracy: 0.8031 - val_loss: 0.5501 - val_categorical_accuracy: 0.7840
Epoch 18/100
 1/67 [..............................] - ETA: 0s - loss: 0.4220 - categorical_accuracy: 0.820024/67 [=========>....................] - ETA: 0s - loss: 0.5495 - categorical_accuracy: 0.757346/67 [===================>..........] - ETA: 0s - loss: 0.5465 - categorical_accuracy: 0.765067/67 [==============================] - 0s 3ms/step - loss: 0.5426 - categorical_accuracy: 0.7697 - val_loss: 0.5190 - val_categorical_accuracy: 0.8071
Epoch 19/100
 1/67 [..............................] - ETA: 0s - loss: 0.4980 - categorical_accuracy: 0.820024/67 [=========>....................] - ETA: 0s - loss: 0.5091 - categorical_accuracy: 0.799246/67 [===================>..........] - ETA: 0s - loss: 0.5069 - categorical_accuracy: 0.797867/67 [==============================] - 0s 3ms/step - loss: 0.5074 - categorical_accuracy: 0.7960 - val_loss: 0.5411 - val_categorical_accuracy: 0.7663
Epoch 20/100
 1/67 [..............................] - ETA: 0s - loss: 0.5809 - categorical_accuracy: 0.770023/67 [=========>....................] - ETA: 0s - loss: 0.4930 - categorical_accuracy: 0.792246/67 [===================>..........] - ETA: 0s - loss: 0.4920 - categorical_accuracy: 0.794867/67 [==============================] - 0s 3ms/step - loss: 0.4948 - categorical_accuracy: 0.7949 - val_loss: 0.5634 - val_categorical_accuracy: 0.7595
Epoch 21/100
 1/67 [..............................] - ETA: 0s - loss: 0.4957 - categorical_accuracy: 0.780024/67 [=========>....................] - ETA: 0s - loss: 0.5058 - categorical_accuracy: 0.787746/67 [===================>..........] - ETA: 0s - loss: 0.5053 - categorical_accuracy: 0.791267/67 [==============================] - 0s 3ms/step - loss: 0.5027 - categorical_accuracy: 0.7943 - val_loss: 0.4961 - val_categorical_accuracy: 0.8043
Epoch 22/100
 1/67 [..............................] - ETA: 0s - loss: 0.4656 - categorical_accuracy: 0.800024/67 [=========>....................] - ETA: 0s - loss: 0.4803 - categorical_accuracy: 0.806946/67 [===================>..........] - ETA: 0s - loss: 0.4855 - categorical_accuracy: 0.804867/67 [==============================] - 0s 3ms/step - loss: 0.4880 - categorical_accuracy: 0.8040 - val_loss: 0.5186 - val_categorical_accuracy: 0.7785
Epoch 23/100
 1/67 [..............................] - ETA: 0s - loss: 0.4660 - categorical_accuracy: 0.820024/67 [=========>....................] - ETA: 0s - loss: 0.5053 - categorical_accuracy: 0.793346/67 [===================>..........] - ETA: 0s - loss: 0.4999 - categorical_accuracy: 0.794967/67 [==============================] - 0s 3ms/step - loss: 0.4995 - categorical_accuracy: 0.7948 - val_loss: 0.4958 - val_categorical_accuracy: 0.7867
Epoch 24/100
 1/67 [..............................] - ETA: 0s - loss: 0.5777 - categorical_accuracy: 0.790024/67 [=========>....................] - ETA: 0s - loss: 0.4814 - categorical_accuracy: 0.805947/67 [====================>.........] - ETA: 0s - loss: 0.4779 - categorical_accuracy: 0.806967/67 [==============================] - 0s 3ms/step - loss: 0.4783 - categorical_accuracy: 0.8076 - val_loss: 0.5464 - val_categorical_accuracy: 0.7772
Epoch 25/100
 1/67 [..............................] - ETA: 0s - loss: 0.4404 - categorical_accuracy: 0.800023/67 [=========>....................] - ETA: 0s - loss: 0.4615 - categorical_accuracy: 0.817045/67 [===================>..........] - ETA: 0s - loss: 0.4645 - categorical_accuracy: 0.818167/67 [==============================] - 0s 3ms/step - loss: 0.4677 - categorical_accuracy: 0.8175 - val_loss: 0.4963 - val_categorical_accuracy: 0.7935
Epoch 26/100
 1/67 [..............................] - ETA: 0s - loss: 0.4902 - categorical_accuracy: 0.790024/67 [=========>....................] - ETA: 0s - loss: 0.4718 - categorical_accuracy: 0.813746/67 [===================>..........] - ETA: 0s - loss: 0.4704 - categorical_accuracy: 0.812167/67 [==============================] - 0s 3ms/step - loss: 0.4714 - categorical_accuracy: 0.8111 - val_loss: 0.4833 - val_categorical_accuracy: 0.8016
Epoch 27/100
 1/67 [..............................] - ETA: 0s - loss: 0.3488 - categorical_accuracy: 0.900024/67 [=========>....................] - ETA: 0s - loss: 0.4402 - categorical_accuracy: 0.838447/67 [====================>.........] - ETA: 0s - loss: 0.4581 - categorical_accuracy: 0.828167/67 [==============================] - 0s 3ms/step - loss: 0.4645 - categorical_accuracy: 0.8239 - val_loss: 0.4805 - val_categorical_accuracy: 0.7962
Epoch 28/100
 1/67 [..............................] - ETA: 0s - loss: 0.3895 - categorical_accuracy: 0.840024/67 [=========>....................] - ETA: 0s - loss: 0.4879 - categorical_accuracy: 0.804747/67 [====================>.........] - ETA: 0s - loss: 0.4836 - categorical_accuracy: 0.808067/67 [==============================] - 0s 3ms/step - loss: 0.4830 - categorical_accuracy: 0.8081 - val_loss: 0.5279 - val_categorical_accuracy: 0.7785
Epoch 29/100
 1/67 [..............................] - ETA: 0s - loss: 0.5096 - categorical_accuracy: 0.780024/67 [=========>....................] - ETA: 0s - loss: 0.5090 - categorical_accuracy: 0.802646/67 [===================>..........] - ETA: 0s - loss: 0.4916 - categorical_accuracy: 0.811067/67 [==============================] - 0s 3ms/step - loss: 0.4827 - categorical_accuracy: 0.8148 - val_loss: 0.5103 - val_categorical_accuracy: 0.7880
Epoch 30/100
 1/67 [..............................] - ETA: 0s - loss: 0.5297 - categorical_accuracy: 0.810023/67 [=========>....................] - ETA: 0s - loss: 0.4752 - categorical_accuracy: 0.817246/67 [===================>..........] - ETA: 0s - loss: 0.4679 - categorical_accuracy: 0.817967/67 [==============================] - 0s 3ms/step - loss: 0.4643 - categorical_accuracy: 0.8186 - val_loss: 0.5066 - val_categorical_accuracy: 0.8071
Epoch 31/100
 1/67 [..............................] - ETA: 0s - loss: 0.4586 - categorical_accuracy: 0.770023/67 [=========>....................] - ETA: 0s - loss: 0.4815 - categorical_accuracy: 0.801046/67 [===================>..........] - ETA: 0s - loss: 0.4740 - categorical_accuracy: 0.806767/67 [==============================] - 0s 3ms/step - loss: 0.4690 - categorical_accuracy: 0.8110 - val_loss: 0.4725 - val_categorical_accuracy: 0.8207
Epoch 32/100
 1/67 [..............................] - ETA: 0s - loss: 0.4260 - categorical_accuracy: 0.830024/67 [=========>....................] - ETA: 0s - loss: 0.4665 - categorical_accuracy: 0.824546/67 [===================>..........] - ETA: 0s - loss: 0.4590 - categorical_accuracy: 0.827367/67 [==============================] - 0s 3ms/step - loss: 0.4548 - categorical_accuracy: 0.8292 - val_loss: 0.4683 - val_categorical_accuracy: 0.8043
Epoch 33/100
 1/67 [..............................] - ETA: 0s - loss: 0.4605 - categorical_accuracy: 0.770022/67 [========>.....................] - ETA: 0s - loss: 0.4904 - categorical_accuracy: 0.788845/67 [===================>..........] - ETA: 0s - loss: 0.4722 - categorical_accuracy: 0.804667/67 [==============================] - 0s 3ms/step - loss: 0.4627 - categorical_accuracy: 0.8127 - val_loss: 0.4511 - val_categorical_accuracy: 0.8179
Epoch 34/100
 1/67 [..............................] - ETA: 0s - loss: 0.3329 - categorical_accuracy: 0.900023/67 [=========>....................] - ETA: 0s - loss: 0.4201 - categorical_accuracy: 0.831346/67 [===================>..........] - ETA: 0s - loss: 0.4221 - categorical_accuracy: 0.831567/67 [==============================] - 0s 3ms/step - loss: 0.4244 - categorical_accuracy: 0.8316 - val_loss: 0.4421 - val_categorical_accuracy: 0.8478
Epoch 35/100
 1/67 [..............................] - ETA: 0s - loss: 0.3041 - categorical_accuracy: 0.900023/67 [=========>....................] - ETA: 0s - loss: 0.4199 - categorical_accuracy: 0.841646/67 [===================>..........] - ETA: 0s - loss: 0.4236 - categorical_accuracy: 0.840467/67 [==============================] - 0s 3ms/step - loss: 0.4242 - categorical_accuracy: 0.8398 - val_loss: 0.4567 - val_categorical_accuracy: 0.8383
Epoch 36/100
 1/67 [..............................] - ETA: 0s - loss: 0.3157 - categorical_accuracy: 0.900024/67 [=========>....................] - ETA: 0s - loss: 0.3976 - categorical_accuracy: 0.854646/67 [===================>..........] - ETA: 0s - loss: 0.4113 - categorical_accuracy: 0.846767/67 [==============================] - 0s 3ms/step - loss: 0.4151 - categorical_accuracy: 0.8448 - val_loss: 0.4439 - val_categorical_accuracy: 0.8234
Epoch 37/100
 1/67 [..............................] - ETA: 0s - loss: 0.4207 - categorical_accuracy: 0.830023/67 [=========>....................] - ETA: 0s - loss: 0.4257 - categorical_accuracy: 0.826146/67 [===================>..........] - ETA: 0s - loss: 0.4238 - categorical_accuracy: 0.829667/67 [==============================] - 0s 3ms/step - loss: 0.4238 - categorical_accuracy: 0.8314 - val_loss: 0.4561 - val_categorical_accuracy: 0.8234
Epoch 38/100
 1/67 [..............................] - ETA: 0s - loss: 0.4561 - categorical_accuracy: 0.830024/67 [=========>....................] - ETA: 0s - loss: 0.4732 - categorical_accuracy: 0.827146/67 [===================>..........] - ETA: 0s - loss: 0.4563 - categorical_accuracy: 0.830167/67 [==============================] - 0s 3ms/step - loss: 0.4492 - categorical_accuracy: 0.8312 - val_loss: 0.4445 - val_categorical_accuracy: 0.8573
Epoch 39/100
 1/67 [..............................] - ETA: 0s - loss: 0.2718 - categorical_accuracy: 0.910024/67 [=========>....................] - ETA: 0s - loss: 0.3727 - categorical_accuracy: 0.862346/67 [===================>..........] - ETA: 0s - loss: 0.3904 - categorical_accuracy: 0.851467/67 [==============================] - 0s 3ms/step - loss: 0.3982 - categorical_accuracy: 0.8485 - val_loss: 0.4607 - val_categorical_accuracy: 0.8329
Epoch 40/100
 1/67 [..............................] - ETA: 0s - loss: 0.4568 - categorical_accuracy: 0.850024/67 [=========>....................] - ETA: 0s - loss: 0.4244 - categorical_accuracy: 0.845846/67 [===================>..........] - ETA: 0s - loss: 0.4153 - categorical_accuracy: 0.849167/67 [==============================] - 0s 3ms/step - loss: 0.4110 - categorical_accuracy: 0.8507 - val_loss: 0.4636 - val_categorical_accuracy: 0.8438
Epoch 41/100
 1/67 [..............................] - ETA: 0s - loss: 0.4714 - categorical_accuracy: 0.820023/67 [=========>....................] - ETA: 0s - loss: 0.4138 - categorical_accuracy: 0.833646/67 [===================>..........] - ETA: 0s - loss: 0.4085 - categorical_accuracy: 0.840367/67 [==============================] - ETA: 0s - loss: 0.4118 - categorical_accuracy: 0.840167/67 [==============================] - 0s 3ms/step - loss: 0.4121 - categorical_accuracy: 0.8401 - val_loss: 0.4636 - val_categorical_accuracy: 0.8152
Epoch 00041: early stopping
Experiment:  281  Set:  har2 Train Labels:  nnar5 Test Labels:  clean
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.86      0.77      0.81       496
           1       0.82      0.83      0.82       471
           2       0.83      0.92      0.87       420
           3       0.78      0.49      0.60       491
           4       0.78      0.87      0.82       532
           5       0.81      0.99      0.89       537

    accuracy                           0.81      2947
   macro avg       0.81      0.81      0.80      2947
weighted avg       0.81      0.81      0.80      2947

Confusion Matrix for this model: 
 [[383  62  51   0   0   0]
 [ 52 389  29   0   1   0]
 [ 11  23 386   0   0   0]
 [  1   0   0 242 130 118]
 [  0   0   0  67 461   4]
 [  0   0   0   3   2 532]]
Experiment:  282  Set:  har2 Train Labels:  nnar5 Test Labels:  ncar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.83      0.73      0.78       506
           1       0.78      0.79      0.79       468
           2       0.76      0.86      0.81       413
           3       0.73      0.47      0.57       489
           4       0.73      0.83      0.78       523
           5       0.79      0.94      0.86       548

    accuracy                           0.77      2947
   macro avg       0.77      0.77      0.76      2947
weighted avg       0.77      0.77      0.76      2947

Confusion Matrix for this model: 
 [[370  61  61   5   4   5]
 [ 51 371  31   5   6   4]
 [ 17  27 356   1   7   5]
 [  3   4   5 229 132 116]
 [  4   5   6  64 435   9]
 [  2   6   7   8  10 515]]
Experiment:  283  Set:  har2 Train Labels:  nnar5 Test Labels:  ncar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.78      0.71      0.74       491
           1       0.75      0.73      0.74       489
           2       0.75      0.82      0.78       426
           3       0.70      0.43      0.53       504
           4       0.68      0.79      0.73       512
           5       0.73      0.91      0.81       525

    accuracy                           0.73      2947
   macro avg       0.73      0.73      0.72      2947
weighted avg       0.73      0.73      0.72      2947

Confusion Matrix for this model: 
 [[348  63  51   4  17   8]
 [ 55 357  38   8  15  16]
 [ 15  27 349   9  14  12]
 [ 10   8  15 217 132 122]
 [  6   6  10  68 406  16]
 [ 13  13   3   6  10 480]]
Experiment:  284  Set:  har2 Train Labels:  nnar5 Test Labels:  nar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.86      0.77      0.81       496
           1       0.82      0.83      0.82       471
           2       0.83      0.67      0.74       572
           3       0.78      0.49      0.60       491
           4       0.78      0.87      0.82       532
           5       0.58      0.99      0.74       385

    accuracy                           0.76      2947
   macro avg       0.77      0.77      0.76      2947
weighted avg       0.78      0.76      0.76      2947

Confusion Matrix for this model: 
 [[383  62  51   0   0   0]
 [ 52 389  29   0   1   0]
 [ 11  23 386   1   1 150]
 [  1   0   0 242 130 118]
 [  0   0   0  67 461   4]
 [  0   0   0   2   1 382]]
Experiment:  285  Set:  har2 Train Labels:  nnar5 Test Labels:  nar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.86      0.77      0.81       496
           1       0.82      0.83      0.82       471
           2       0.83      0.54      0.65       720
           3       0.78      0.49      0.60       491
           4       0.78      0.87      0.82       532
           5       0.36      1.00      0.53       237

    accuracy                           0.71      2947
   macro avg       0.74      0.75      0.71      2947
weighted avg       0.78      0.71      0.72      2947

Confusion Matrix for this model: 
 [[383  62  51   0   0   0]
 [ 52 389  29   0   1   0]
 [ 11  23 386   2   2 296]
 [  1   0   0 242 130 118]
 [  0   0   0  67 461   4]
 [  0   0   0   1   0 236]]
Experiment:  286  Set:  har2 Train Labels:  nnar5 Test Labels:  nnar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.86      0.75      0.80       512
           1       0.82      0.82      0.82       476
           2       0.83      0.85      0.84       453
           3       0.78      0.47      0.59       514
           4       0.78      0.79      0.78       582
           5       0.62      0.99      0.76       410

    accuracy                           0.77      2947
   macro avg       0.78      0.78      0.76      2947
weighted avg       0.78      0.77      0.76      2947

Confusion Matrix for this model: 
 [[383  62  51   0   0  16]
 [ 52 389  29   0   1   5]
 [ 11  23 386   0   0  33]
 [  1   0   0 242 130 141]
 [  0   0   0  67 461  54]
 [  0   0   0   3   2 405]]
Experiment:  287  Set:  har2 Train Labels:  nnar5 Test Labels:  nnar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.86      0.77      0.81       496
           1       0.82      0.83      0.82       471
           2       0.83      0.92      0.87       420
           3       0.78      0.36      0.50       666
           4       0.78      0.83      0.80       555
           5       0.52      0.99      0.68       339

    accuracy                           0.75      2947
   macro avg       0.76      0.78      0.75      2947
weighted avg       0.78      0.75      0.73      2947

Confusion Matrix for this model: 
 [[383  62  51   0   0   0]
 [ 52 389  29   0   1   0]
 [ 11  23 386   0   0   0]
 [  1   0   0 243 131 291]
 [  0   0   0  67 462  26]
 [  0   0   0   2   0 337]]
Input Shape:  (7352, 3, 128)
Model: "sequential_41"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_41 (LSTM)               (None, 32)                20608     
_________________________________________________________________
dropout_41 (Dropout)         (None, 32)                0         
_________________________________________________________________
dense_164 (Dense)            (None, 128)               4224      
_________________________________________________________________
dense_165 (Dense)            (None, 128)               16512     
_________________________________________________________________
dense_166 (Dense)            (None, 64)                8256      
_________________________________________________________________
dense_167 (Dense)            (None, 6)                 390       
=================================================================
Total params: 49,990
Trainable params: 49,990
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 1/67 [..............................] - ETA: 1:09 - loss: 1.7671 - categorical_accuracy: 0.320021/67 [========>.....................] - ETA: 0s - loss: 1.6347 - categorical_accuracy: 0.3128  42/67 [=================>............] - ETA: 0s - loss: 1.5572 - categorical_accuracy: 0.330964/67 [===========================>..] - ETA: 0s - loss: 1.4901 - categorical_accuracy: 0.357467/67 [==============================] - 2s 7ms/step - loss: 1.4785 - categorical_accuracy: 0.3618 - val_loss: 0.9439 - val_categorical_accuracy: 0.5625
Epoch 2/100
 1/67 [..............................] - ETA: 0s - loss: 1.0065 - categorical_accuracy: 0.610023/67 [=========>....................] - ETA: 0s - loss: 0.9544 - categorical_accuracy: 0.577645/67 [===================>..........] - ETA: 0s - loss: 0.9332 - categorical_accuracy: 0.577467/67 [==============================] - ETA: 0s - loss: 0.9167 - categorical_accuracy: 0.581767/67 [==============================] - 0s 3ms/step - loss: 0.9161 - categorical_accuracy: 0.5819 - val_loss: 0.7783 - val_categorical_accuracy: 0.6141
Epoch 3/100
 1/67 [..............................] - ETA: 0s - loss: 0.7994 - categorical_accuracy: 0.680023/67 [=========>....................] - ETA: 0s - loss: 0.7946 - categorical_accuracy: 0.657945/67 [===================>..........] - ETA: 0s - loss: 0.7896 - categorical_accuracy: 0.655067/67 [==============================] - ETA: 0s - loss: 0.7870 - categorical_accuracy: 0.653067/67 [==============================] - 0s 3ms/step - loss: 0.7868 - categorical_accuracy: 0.6529 - val_loss: 0.7226 - val_categorical_accuracy: 0.6535
Epoch 4/100
 1/67 [..............................] - ETA: 0s - loss: 0.7315 - categorical_accuracy: 0.720024/67 [=========>....................] - ETA: 0s - loss: 0.7398 - categorical_accuracy: 0.674247/67 [====================>.........] - ETA: 0s - loss: 0.7357 - categorical_accuracy: 0.670067/67 [==============================] - 0s 3ms/step - loss: 0.7321 - categorical_accuracy: 0.6698 - val_loss: 0.6442 - val_categorical_accuracy: 0.7024
Epoch 5/100
 1/67 [..............................] - ETA: 0s - loss: 0.7575 - categorical_accuracy: 0.640024/67 [=========>....................] - ETA: 0s - loss: 0.7319 - categorical_accuracy: 0.664547/67 [====================>.........] - ETA: 0s - loss: 0.7128 - categorical_accuracy: 0.675867/67 [==============================] - 0s 3ms/step - loss: 0.7034 - categorical_accuracy: 0.6799 - val_loss: 0.6706 - val_categorical_accuracy: 0.6753
Epoch 6/100
 1/67 [..............................] - ETA: 0s - loss: 0.6392 - categorical_accuracy: 0.680024/67 [=========>....................] - ETA: 0s - loss: 0.6530 - categorical_accuracy: 0.695746/67 [===================>..........] - ETA: 0s - loss: 0.6512 - categorical_accuracy: 0.698367/67 [==============================] - 0s 3ms/step - loss: 0.6493 - categorical_accuracy: 0.6990 - val_loss: 0.5835 - val_categorical_accuracy: 0.7174
Epoch 7/100
 1/67 [..............................] - ETA: 0s - loss: 0.6393 - categorical_accuracy: 0.720023/67 [=========>....................] - ETA: 0s - loss: 0.6260 - categorical_accuracy: 0.709145/67 [===================>..........] - ETA: 0s - loss: 0.6163 - categorical_accuracy: 0.715667/67 [==============================] - ETA: 0s - loss: 0.6150 - categorical_accuracy: 0.717367/67 [==============================] - 0s 3ms/step - loss: 0.6150 - categorical_accuracy: 0.7174 - val_loss: 0.5716 - val_categorical_accuracy: 0.7228
Epoch 8/100
 1/67 [..............................] - ETA: 0s - loss: 0.5801 - categorical_accuracy: 0.730024/67 [=========>....................] - ETA: 0s - loss: 0.6006 - categorical_accuracy: 0.718747/67 [====================>.........] - ETA: 0s - loss: 0.6004 - categorical_accuracy: 0.721367/67 [==============================] - 0s 3ms/step - loss: 0.6001 - categorical_accuracy: 0.7224 - val_loss: 0.5709 - val_categorical_accuracy: 0.7201
Epoch 9/100
 1/67 [..............................] - ETA: 0s - loss: 0.5823 - categorical_accuracy: 0.750024/67 [=========>....................] - ETA: 0s - loss: 0.5745 - categorical_accuracy: 0.737946/67 [===================>..........] - ETA: 0s - loss: 0.5824 - categorical_accuracy: 0.731367/67 [==============================] - 0s 3ms/step - loss: 0.5837 - categorical_accuracy: 0.7294 - val_loss: 0.5335 - val_categorical_accuracy: 0.7351
Epoch 10/100
 1/67 [..............................] - ETA: 0s - loss: 0.6573 - categorical_accuracy: 0.680024/67 [=========>....................] - ETA: 0s - loss: 0.5795 - categorical_accuracy: 0.726347/67 [====================>.........] - ETA: 0s - loss: 0.5819 - categorical_accuracy: 0.723667/67 [==============================] - 0s 3ms/step - loss: 0.5800 - categorical_accuracy: 0.7232 - val_loss: 0.5002 - val_categorical_accuracy: 0.7677
Epoch 11/100
 1/67 [..............................] - ETA: 0s - loss: 0.5358 - categorical_accuracy: 0.780023/67 [=========>....................] - ETA: 0s - loss: 0.5415 - categorical_accuracy: 0.739046/67 [===================>..........] - ETA: 0s - loss: 0.5451 - categorical_accuracy: 0.738167/67 [==============================] - 0s 3ms/step - loss: 0.5452 - categorical_accuracy: 0.7383 - val_loss: 0.4878 - val_categorical_accuracy: 0.7500
Epoch 12/100
 1/67 [..............................] - ETA: 0s - loss: 0.5737 - categorical_accuracy: 0.710024/67 [=========>....................] - ETA: 0s - loss: 0.5091 - categorical_accuracy: 0.755546/67 [===================>..........] - ETA: 0s - loss: 0.5176 - categorical_accuracy: 0.754467/67 [==============================] - 0s 3ms/step - loss: 0.5197 - categorical_accuracy: 0.7532 - val_loss: 0.4956 - val_categorical_accuracy: 0.7269
Epoch 13/100
 1/67 [..............................] - ETA: 0s - loss: 0.4143 - categorical_accuracy: 0.830024/67 [=========>....................] - ETA: 0s - loss: 0.5154 - categorical_accuracy: 0.754847/67 [====================>.........] - ETA: 0s - loss: 0.5168 - categorical_accuracy: 0.755167/67 [==============================] - 0s 3ms/step - loss: 0.5148 - categorical_accuracy: 0.7558 - val_loss: 0.4727 - val_categorical_accuracy: 0.7636
Epoch 14/100
 1/67 [..............................] - ETA: 0s - loss: 0.5859 - categorical_accuracy: 0.730024/67 [=========>....................] - ETA: 0s - loss: 0.5138 - categorical_accuracy: 0.754147/67 [====================>.........] - ETA: 0s - loss: 0.5110 - categorical_accuracy: 0.754967/67 [==============================] - 0s 3ms/step - loss: 0.5050 - categorical_accuracy: 0.7578 - val_loss: 0.4532 - val_categorical_accuracy: 0.7432
Epoch 15/100
 1/67 [..............................] - ETA: 0s - loss: 0.5128 - categorical_accuracy: 0.740024/67 [=========>....................] - ETA: 0s - loss: 0.5229 - categorical_accuracy: 0.741546/67 [===================>..........] - ETA: 0s - loss: 0.5205 - categorical_accuracy: 0.743967/67 [==============================] - 0s 3ms/step - loss: 0.5141 - categorical_accuracy: 0.7480 - val_loss: 0.4877 - val_categorical_accuracy: 0.7527
Epoch 16/100
 1/67 [..............................] - ETA: 0s - loss: 0.4091 - categorical_accuracy: 0.820024/67 [=========>....................] - ETA: 0s - loss: 0.4792 - categorical_accuracy: 0.767447/67 [====================>.........] - ETA: 0s - loss: 0.4777 - categorical_accuracy: 0.769867/67 [==============================] - 0s 3ms/step - loss: 0.4766 - categorical_accuracy: 0.7701 - val_loss: 0.4655 - val_categorical_accuracy: 0.7486
Epoch 17/100
 1/67 [..............................] - ETA: 0s - loss: 0.4510 - categorical_accuracy: 0.750024/67 [=========>....................] - ETA: 0s - loss: 0.4697 - categorical_accuracy: 0.768147/67 [====================>.........] - ETA: 0s - loss: 0.4712 - categorical_accuracy: 0.770067/67 [==============================] - 0s 3ms/step - loss: 0.4720 - categorical_accuracy: 0.7711 - val_loss: 0.4649 - val_categorical_accuracy: 0.7745
Epoch 18/100
 1/67 [..............................] - ETA: 0s - loss: 0.4698 - categorical_accuracy: 0.790024/67 [=========>....................] - ETA: 0s - loss: 0.5046 - categorical_accuracy: 0.750847/67 [====================>.........] - ETA: 0s - loss: 0.4941 - categorical_accuracy: 0.758667/67 [==============================] - 0s 3ms/step - loss: 0.4905 - categorical_accuracy: 0.7616 - val_loss: 0.4300 - val_categorical_accuracy: 0.7812
Epoch 19/100
 1/67 [..............................] - ETA: 0s - loss: 0.3496 - categorical_accuracy: 0.860024/67 [=========>....................] - ETA: 0s - loss: 0.5076 - categorical_accuracy: 0.763346/67 [===================>..........] - ETA: 0s - loss: 0.5161 - categorical_accuracy: 0.759167/67 [==============================] - 0s 3ms/step - loss: 0.5127 - categorical_accuracy: 0.7612 - val_loss: 0.4323 - val_categorical_accuracy: 0.8207
Epoch 20/100
 1/67 [..............................] - ETA: 0s - loss: 0.4452 - categorical_accuracy: 0.810023/67 [=========>....................] - ETA: 0s - loss: 0.4614 - categorical_accuracy: 0.785146/67 [===================>..........] - ETA: 0s - loss: 0.4521 - categorical_accuracy: 0.789167/67 [==============================] - 0s 3ms/step - loss: 0.4491 - categorical_accuracy: 0.7910 - val_loss: 0.4171 - val_categorical_accuracy: 0.8003
Epoch 21/100
 1/67 [..............................] - ETA: 0s - loss: 0.3907 - categorical_accuracy: 0.800023/67 [=========>....................] - ETA: 0s - loss: 0.4425 - categorical_accuracy: 0.781245/67 [===================>..........] - ETA: 0s - loss: 0.4432 - categorical_accuracy: 0.782067/67 [==============================] - 0s 3ms/step - loss: 0.4427 - categorical_accuracy: 0.7837 - val_loss: 0.4125 - val_categorical_accuracy: 0.8003
Epoch 22/100
 1/67 [..............................] - ETA: 0s - loss: 0.3710 - categorical_accuracy: 0.810023/67 [=========>....................] - ETA: 0s - loss: 0.3925 - categorical_accuracy: 0.812446/67 [===================>..........] - ETA: 0s - loss: 0.4111 - categorical_accuracy: 0.804367/67 [==============================] - 0s 3ms/step - loss: 0.4200 - categorical_accuracy: 0.7998 - val_loss: 0.4113 - val_categorical_accuracy: 0.8261
Epoch 23/100
 1/67 [..............................] - ETA: 0s - loss: 0.3241 - categorical_accuracy: 0.870024/67 [=========>....................] - ETA: 0s - loss: 0.3987 - categorical_accuracy: 0.822846/67 [===================>..........] - ETA: 0s - loss: 0.4082 - categorical_accuracy: 0.815667/67 [==============================] - 0s 3ms/step - loss: 0.4140 - categorical_accuracy: 0.8107 - val_loss: 0.4404 - val_categorical_accuracy: 0.7880
Epoch 24/100
 1/67 [..............................] - ETA: 0s - loss: 0.4256 - categorical_accuracy: 0.770023/67 [=========>....................] - ETA: 0s - loss: 0.4689 - categorical_accuracy: 0.768046/67 [===================>..........] - ETA: 0s - loss: 0.4578 - categorical_accuracy: 0.777267/67 [==============================] - 0s 3ms/step - loss: 0.4528 - categorical_accuracy: 0.7807 - val_loss: 0.4642 - val_categorical_accuracy: 0.7867
Epoch 25/100
 1/67 [..............................] - ETA: 0s - loss: 0.4413 - categorical_accuracy: 0.810024/67 [=========>....................] - ETA: 0s - loss: 0.4302 - categorical_accuracy: 0.787547/67 [====================>.........] - ETA: 0s - loss: 0.4272 - categorical_accuracy: 0.790567/67 [==============================] - 0s 3ms/step - loss: 0.4249 - categorical_accuracy: 0.7922 - val_loss: 0.3960 - val_categorical_accuracy: 0.7962
Epoch 26/100
 1/67 [..............................] - ETA: 0s - loss: 0.3051 - categorical_accuracy: 0.830024/67 [=========>....................] - ETA: 0s - loss: 0.3885 - categorical_accuracy: 0.810446/67 [===================>..........] - ETA: 0s - loss: 0.3987 - categorical_accuracy: 0.808467/67 [==============================] - 0s 3ms/step - loss: 0.4029 - categorical_accuracy: 0.8066 - val_loss: 0.4020 - val_categorical_accuracy: 0.7962
Epoch 27/100
 1/67 [..............................] - ETA: 0s - loss: 0.4236 - categorical_accuracy: 0.840024/67 [=========>....................] - ETA: 0s - loss: 0.4521 - categorical_accuracy: 0.792947/67 [====================>.........] - ETA: 0s - loss: 0.4418 - categorical_accuracy: 0.792467/67 [==============================] - 0s 3ms/step - loss: 0.4342 - categorical_accuracy: 0.7933 - val_loss: 0.4032 - val_categorical_accuracy: 0.8057
Epoch 28/100
 1/67 [..............................] - ETA: 0s - loss: 0.2835 - categorical_accuracy: 0.860024/67 [=========>....................] - ETA: 0s - loss: 0.4180 - categorical_accuracy: 0.803046/67 [===================>..........] - ETA: 0s - loss: 0.4252 - categorical_accuracy: 0.800067/67 [==============================] - 0s 3ms/step - loss: 0.4262 - categorical_accuracy: 0.7994 - val_loss: 0.4154 - val_categorical_accuracy: 0.8207
Epoch 29/100
 1/67 [..............................] - ETA: 0s - loss: 0.4337 - categorical_accuracy: 0.820024/67 [=========>....................] - ETA: 0s - loss: 0.4271 - categorical_accuracy: 0.799146/67 [===================>..........] - ETA: 0s - loss: 0.4150 - categorical_accuracy: 0.807067/67 [==============================] - 0s 3ms/step - loss: 0.4091 - categorical_accuracy: 0.8106 - val_loss: 0.4202 - val_categorical_accuracy: 0.7894
Epoch 30/100
 1/67 [..............................] - ETA: 0s - loss: 0.4076 - categorical_accuracy: 0.800023/67 [=========>....................] - ETA: 0s - loss: 0.4304 - categorical_accuracy: 0.789046/67 [===================>..........] - ETA: 0s - loss: 0.4236 - categorical_accuracy: 0.794267/67 [==============================] - 0s 3ms/step - loss: 0.4186 - categorical_accuracy: 0.7973 - val_loss: 0.3892 - val_categorical_accuracy: 0.8057
Epoch 31/100
 1/67 [..............................] - ETA: 0s - loss: 0.4024 - categorical_accuracy: 0.800024/67 [=========>....................] - ETA: 0s - loss: 0.3857 - categorical_accuracy: 0.812147/67 [====================>.........] - ETA: 0s - loss: 0.3844 - categorical_accuracy: 0.815567/67 [==============================] - 0s 3ms/step - loss: 0.3854 - categorical_accuracy: 0.8164 - val_loss: 0.4214 - val_categorical_accuracy: 0.7758
Epoch 32/100
 1/67 [..............................] - ETA: 0s - loss: 0.4265 - categorical_accuracy: 0.770024/67 [=========>....................] - ETA: 0s - loss: 0.4129 - categorical_accuracy: 0.797646/67 [===================>..........] - ETA: 0s - loss: 0.4135 - categorical_accuracy: 0.799067/67 [==============================] - 0s 3ms/step - loss: 0.4105 - categorical_accuracy: 0.8009 - val_loss: 0.4029 - val_categorical_accuracy: 0.7894
Epoch 33/100
 1/67 [..............................] - ETA: 0s - loss: 0.3638 - categorical_accuracy: 0.820024/67 [=========>....................] - ETA: 0s - loss: 0.3893 - categorical_accuracy: 0.810746/67 [===================>..........] - ETA: 0s - loss: 0.3854 - categorical_accuracy: 0.814667/67 [==============================] - 0s 3ms/step - loss: 0.3831 - categorical_accuracy: 0.8164 - val_loss: 0.4585 - val_categorical_accuracy: 0.7514
Epoch 34/100
 1/67 [..............................] - ETA: 0s - loss: 0.4451 - categorical_accuracy: 0.790023/67 [=========>....................] - ETA: 0s - loss: 0.4327 - categorical_accuracy: 0.786246/67 [===================>..........] - ETA: 0s - loss: 0.4239 - categorical_accuracy: 0.792967/67 [==============================] - 0s 3ms/step - loss: 0.4187 - categorical_accuracy: 0.7961 - val_loss: 0.3755 - val_categorical_accuracy: 0.8071
Epoch 35/100
 1/67 [..............................] - ETA: 0s - loss: 0.3597 - categorical_accuracy: 0.830024/67 [=========>....................] - ETA: 0s - loss: 0.3887 - categorical_accuracy: 0.811746/67 [===================>..........] - ETA: 0s - loss: 0.3811 - categorical_accuracy: 0.815267/67 [==============================] - 0s 3ms/step - loss: 0.3791 - categorical_accuracy: 0.8159 - val_loss: 0.3841 - val_categorical_accuracy: 0.8016
Epoch 36/100
 1/67 [..............................] - ETA: 0s - loss: 0.4394 - categorical_accuracy: 0.780024/67 [=========>....................] - ETA: 0s - loss: 0.3943 - categorical_accuracy: 0.816847/67 [====================>.........] - ETA: 0s - loss: 0.3872 - categorical_accuracy: 0.819367/67 [==============================] - 0s 3ms/step - loss: 0.3834 - categorical_accuracy: 0.8203 - val_loss: 0.3804 - val_categorical_accuracy: 0.8207
Epoch 37/100
 1/67 [..............................] - ETA: 0s - loss: 0.3586 - categorical_accuracy: 0.800024/67 [=========>....................] - ETA: 0s - loss: 0.3695 - categorical_accuracy: 0.824247/67 [====================>.........] - ETA: 0s - loss: 0.3717 - categorical_accuracy: 0.822967/67 [==============================] - 0s 3ms/step - loss: 0.3732 - categorical_accuracy: 0.8215 - val_loss: 0.3783 - val_categorical_accuracy: 0.8016
Epoch 38/100
 1/67 [..............................] - ETA: 0s - loss: 0.3876 - categorical_accuracy: 0.850024/67 [=========>....................] - ETA: 0s - loss: 0.3861 - categorical_accuracy: 0.823447/67 [====================>.........] - ETA: 0s - loss: 0.3815 - categorical_accuracy: 0.823067/67 [==============================] - 0s 3ms/step - loss: 0.3781 - categorical_accuracy: 0.8230 - val_loss: 0.4927 - val_categorical_accuracy: 0.7880
Epoch 39/100
 1/67 [..............................] - ETA: 0s - loss: 0.3879 - categorical_accuracy: 0.860024/67 [=========>....................] - ETA: 0s - loss: 0.4348 - categorical_accuracy: 0.794647/67 [====================>.........] - ETA: 0s - loss: 0.4315 - categorical_accuracy: 0.795367/67 [==============================] - 0s 3ms/step - loss: 0.4219 - categorical_accuracy: 0.8002 - val_loss: 0.3817 - val_categorical_accuracy: 0.8139
Epoch 40/100
 1/67 [..............................] - ETA: 0s - loss: 0.2643 - categorical_accuracy: 0.890023/67 [=========>....................] - ETA: 0s - loss: 0.3794 - categorical_accuracy: 0.814046/67 [===================>..........] - ETA: 0s - loss: 0.3799 - categorical_accuracy: 0.811967/67 [==============================] - 0s 3ms/step - loss: 0.3765 - categorical_accuracy: 0.8131 - val_loss: 0.4172 - val_categorical_accuracy: 0.7826
Epoch 41/100
 1/67 [..............................] - ETA: 0s - loss: 0.4091 - categorical_accuracy: 0.780024/67 [=========>....................] - ETA: 0s - loss: 0.3701 - categorical_accuracy: 0.804847/67 [====================>.........] - ETA: 0s - loss: 0.3676 - categorical_accuracy: 0.811567/67 [==============================] - 0s 3ms/step - loss: 0.3688 - categorical_accuracy: 0.8135 - val_loss: 0.3723 - val_categorical_accuracy: 0.8315
Epoch 42/100
 1/67 [..............................] - ETA: 0s - loss: 0.4143 - categorical_accuracy: 0.750024/67 [=========>....................] - ETA: 0s - loss: 0.3673 - categorical_accuracy: 0.811246/67 [===================>..........] - ETA: 0s - loss: 0.3684 - categorical_accuracy: 0.817167/67 [==============================] - 0s 3ms/step - loss: 0.3724 - categorical_accuracy: 0.8171 - val_loss: 0.3864 - val_categorical_accuracy: 0.7962
Epoch 43/100
 1/67 [..............................] - ETA: 0s - loss: 0.3754 - categorical_accuracy: 0.810023/67 [=========>....................] - ETA: 0s - loss: 0.3823 - categorical_accuracy: 0.806743/67 [==================>...........] - ETA: 0s - loss: 0.3767 - categorical_accuracy: 0.808963/67 [===========================>..] - ETA: 0s - loss: 0.3734 - categorical_accuracy: 0.812167/67 [==============================] - 0s 3ms/step - loss: 0.3730 - categorical_accuracy: 0.8127 - val_loss: 0.3603 - val_categorical_accuracy: 0.8288
Epoch 44/100
 1/67 [..............................] - ETA: 0s - loss: 0.4013 - categorical_accuracy: 0.790019/67 [=======>......................] - ETA: 0s - loss: 0.3796 - categorical_accuracy: 0.818040/67 [================>.............] - ETA: 0s - loss: 0.3733 - categorical_accuracy: 0.821661/67 [==========================>...] - ETA: 0s - loss: 0.3704 - categorical_accuracy: 0.823467/67 [==============================] - 0s 3ms/step - loss: 0.3704 - categorical_accuracy: 0.8235 - val_loss: 0.4149 - val_categorical_accuracy: 0.7853
Epoch 45/100
 1/67 [..............................] - ETA: 0s - loss: 0.3743 - categorical_accuracy: 0.800023/67 [=========>....................] - ETA: 0s - loss: 0.4115 - categorical_accuracy: 0.805046/67 [===================>..........] - ETA: 0s - loss: 0.3978 - categorical_accuracy: 0.813067/67 [==============================] - 0s 3ms/step - loss: 0.3902 - categorical_accuracy: 0.8171 - val_loss: 0.3749 - val_categorical_accuracy: 0.8342
Epoch 46/100
 1/67 [..............................] - ETA: 0s - loss: 0.2864 - categorical_accuracy: 0.890024/67 [=========>....................] - ETA: 0s - loss: 0.3321 - categorical_accuracy: 0.845647/67 [====================>.........] - ETA: 0s - loss: 0.3364 - categorical_accuracy: 0.840267/67 [==============================] - 0s 3ms/step - loss: 0.3406 - categorical_accuracy: 0.8359 - val_loss: 0.3617 - val_categorical_accuracy: 0.8207
Epoch 47/100
 1/67 [..............................] - ETA: 0s - loss: 0.2863 - categorical_accuracy: 0.860024/67 [=========>....................] - ETA: 0s - loss: 0.3338 - categorical_accuracy: 0.843946/67 [===================>..........] - ETA: 0s - loss: 0.3419 - categorical_accuracy: 0.840067/67 [==============================] - 0s 3ms/step - loss: 0.3449 - categorical_accuracy: 0.8379 - val_loss: 0.3698 - val_categorical_accuracy: 0.8410
Epoch 48/100
 1/67 [..............................] - ETA: 0s - loss: 0.3312 - categorical_accuracy: 0.870023/67 [=========>....................] - ETA: 0s - loss: 0.3823 - categorical_accuracy: 0.818346/67 [===================>..........] - ETA: 0s - loss: 0.3736 - categorical_accuracy: 0.821567/67 [==============================] - 0s 3ms/step - loss: 0.3676 - categorical_accuracy: 0.8241 - val_loss: 0.3703 - val_categorical_accuracy: 0.8492
Epoch 49/100
 1/67 [..............................] - ETA: 0s - loss: 0.3320 - categorical_accuracy: 0.850022/67 [========>.....................] - ETA: 0s - loss: 0.3422 - categorical_accuracy: 0.842845/67 [===================>..........] - ETA: 0s - loss: 0.3397 - categorical_accuracy: 0.843567/67 [==============================] - 0s 3ms/step - loss: 0.3432 - categorical_accuracy: 0.8416 - val_loss: 0.4551 - val_categorical_accuracy: 0.7799
Epoch 50/100
 1/67 [..............................] - ETA: 0s - loss: 0.3023 - categorical_accuracy: 0.840024/67 [=========>....................] - ETA: 0s - loss: 0.3683 - categorical_accuracy: 0.824846/67 [===================>..........] - ETA: 0s - loss: 0.3660 - categorical_accuracy: 0.825767/67 [==============================] - 0s 3ms/step - loss: 0.3614 - categorical_accuracy: 0.8280 - val_loss: 0.4304 - val_categorical_accuracy: 0.7690
Epoch 00050: early stopping
Experiment:  288  Set:  har2 Train Labels:  nnar10 Test Labels:  clean
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.85      0.72      0.78       496
           1       0.81      0.80      0.80       471
           2       0.78      0.94      0.85       420
           3       0.49      0.37      0.42       491
           4       0.75      0.83      0.79       532
           5       0.70      0.78      0.74       537

    accuracy                           0.74      2947
   macro avg       0.73      0.74      0.73      2947
weighted avg       0.73      0.74      0.73      2947

Confusion Matrix for this model: 
 [[355  72  68   0   1   0]
 [ 54 377  40   0   0   0]
 [ 10  17 393   0   0   0]
 [  0   0   0 180 131 180]
 [  0   0   0  89 441   2]
 [  0   0   0 101  15 421]]
Experiment:  289  Set:  har2 Train Labels:  nnar10 Test Labels:  ncar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.81      0.67      0.74       506
           1       0.77      0.77      0.77       468
           2       0.72      0.88      0.79       413
           3       0.47      0.35      0.40       489
           4       0.71      0.80      0.75       523
           5       0.68      0.74      0.71       548

    accuracy                           0.70      2947
   macro avg       0.69      0.70      0.69      2947
weighted avg       0.69      0.70      0.69      2947

Confusion Matrix for this model: 
 [[341  71  79   7   4   4]
 [ 53 359  42   3   6   5]
 [ 17  21 362   2   8   3]
 [  1   4   6 173 129 176]
 [  4   6   5  83 418   7]
 [  3   5   7 102  23 408]]
Experiment:  290  Set:  har2 Train Labels:  nnar10 Test Labels:  ncar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.77      0.66      0.71       491
           1       0.75      0.71      0.73       489
           2       0.71      0.83      0.77       426
           3       0.44      0.32      0.37       504
           4       0.66      0.75      0.70       512
           5       0.63      0.72      0.67       525

    accuracy                           0.66      2947
   macro avg       0.66      0.67      0.66      2947
weighted avg       0.66      0.66      0.65      2947

Confusion Matrix for this model: 
 [[322  69  70   6  16   8]
 [ 57 348  46   9  15  14]
 [ 14  22 355   7  13  15]
 [  7   9  16 163 136 173]
 [  5   6  11  90 386  14]
 [ 14  12   3  95  22 379]]
Experiment:  291  Set:  har2 Train Labels:  nnar10 Test Labels:  nar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.85      0.72      0.78       496
           1       0.81      0.80      0.80       471
           2       0.78      0.69      0.73       572
           3       0.49      0.37      0.42       491
           4       0.75      0.83      0.79       532
           5       0.50      0.78      0.61       385

    accuracy                           0.69      2947
   macro avg       0.70      0.70      0.69      2947
weighted avg       0.71      0.69      0.69      2947

Confusion Matrix for this model: 
 [[355  72  68   0   1   0]
 [ 54 377  40   0   0   0]
 [ 10  17 393  26   5 121]
 [  0   0   0 180 131 180]
 [  0   0   0  89 441   2]
 [  0   0   0  75  10 300]]
Experiment:  292  Set:  har2 Train Labels:  nnar10 Test Labels:  nar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.85      0.72      0.78       496
           1       0.81      0.80      0.80       471
           2       0.78      0.55      0.64       720
           3       0.49      0.37      0.42       491
           4       0.75      0.83      0.79       532
           5       0.30      0.76      0.43       237

    accuracy                           0.65      2947
   macro avg       0.66      0.67      0.64      2947
weighted avg       0.70      0.65      0.66      2947

Confusion Matrix for this model: 
 [[355  72  68   0   1   0]
 [ 54 377  40   0   0   0]
 [ 10  17 393  51   9 240]
 [  0   0   0 180 131 180]
 [  0   0   0  89 441   2]
 [  0   0   0  50   6 181]]
Experiment:  293  Set:  har2 Train Labels:  nnar10 Test Labels:  nnar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.85      0.69      0.76       512
           1       0.81      0.79      0.80       476
           2       0.78      0.87      0.82       453
           3       0.50      0.36      0.42       514
           4       0.75      0.76      0.76       582
           5       0.55      0.80      0.65       410

    accuracy                           0.71      2947
   macro avg       0.71      0.71      0.70      2947
weighted avg       0.71      0.71      0.70      2947

Confusion Matrix for this model: 
 [[355  72  68   4   2  11]
 [ 54 377  40   1   0   4]
 [ 10  17 393   9   1  23]
 [  0   0   0 186 133 195]
 [  0   0   0  98 443  41]
 [  0   0   0  72   9 329]]
Experiment:  294  Set:  har2 Train Labels:  nnar10 Test Labels:  nnar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: 
Shape of y predicted: 
Score for this model: 
               precision    recall  f1-score   support

           0       0.85      0.72      0.78       496
           1       0.81      0.80      0.80       471
           2       0.78      0.94      0.85       420
           3       0.58      0.32      0.42       666
           4       0.76      0.80      0.78       555
           5       0.46      0.83      0.59       339

    accuracy                           0.70      2947
   macro avg       0.71      0.73      0.70      2947
weighted avg       0.71      0.70      0.69      2947

Confusion Matrix for this model: 
 [[355  72  68   0   1   0]
 [ 54 377  40   0   0   0]
 [ 10  17 393   0   0   0]
 [  0   0   0 215 139 312]
 [  0   0   0 100 444  11]
 [  0   0   0  55   4 280]]
