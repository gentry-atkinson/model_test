Testing Transformer
2022-02-03
Input Shape:  (8000, 1, 150)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 1, 150)]     0           []                               
                                                                                                  
 batch_normalization (BatchNorm  (None, 1, 150)      600         ['input_1[0][0]']                
 alization)                                                                                       
                                                                                                  
 multi_head_attention (MultiHea  (None, 1, 150)      38742       ['batch_normalization[0][0]',    
 dAttention)                                                      'batch_normalization[0][0]']    
                                                                                                  
 dropout (Dropout)              (None, 1, 150)       0           ['multi_head_attention[0][0]']   
                                                                                                  
 tf.__operators__.add (TFOpLamb  (None, 1, 150)      0           ['dropout[0][0]',                
 da)                                                              'input_1[0][0]']                
                                                                                                  
 layer_normalization (LayerNorm  (None, 1, 150)      300         ['tf.__operators__.add[0][0]']   
 alization)                                                                                       
                                                                                                  
 conv1d (Conv1D)                (None, 1, 32)        4832        ['layer_normalization[0][0]']    
                                                                                                  
 dropout_1 (Dropout)            (None, 1, 32)        0           ['conv1d[0][0]']                 
                                                                                                  
 conv1d_1 (Conv1D)              (None, 1, 150)       4950        ['dropout_1[0][0]']              
                                                                                                  
 tf.__operators__.add_1 (TFOpLa  (None, 1, 150)      0           ['conv1d_1[0][0]',               
 mbda)                                                            'tf.__operators__.add[0][0]']   
                                                                                                  
 batch_normalization_1 (BatchNo  (None, 1, 150)      600         ['tf.__operators__.add_1[0][0]'] 
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_1 (MultiH  (None, 1, 150)      38742       ['batch_normalization_1[0][0]',  
 eadAttention)                                                    'batch_normalization_1[0][0]']  
                                                                                                  
 dropout_2 (Dropout)            (None, 1, 150)       0           ['multi_head_attention_1[0][0]'] 
                                                                                                  
 tf.__operators__.add_2 (TFOpLa  (None, 1, 150)      0           ['dropout_2[0][0]',              
 mbda)                                                            'tf.__operators__.add_1[0][0]'] 
                                                                                                  
 layer_normalization_1 (LayerNo  (None, 1, 150)      300         ['tf.__operators__.add_2[0][0]'] 
 rmalization)                                                                                     
                                                                                                  
 conv1d_2 (Conv1D)              (None, 1, 32)        4832        ['layer_normalization_1[0][0]']  
                                                                                                  
 dropout_3 (Dropout)            (None, 1, 32)        0           ['conv1d_2[0][0]']               
                                                                                                  
 conv1d_3 (Conv1D)              (None, 1, 150)       4950        ['dropout_3[0][0]']              
                                                                                                  
 tf.__operators__.add_3 (TFOpLa  (None, 1, 150)      0           ['conv1d_3[0][0]',               
 mbda)                                                            'tf.__operators__.add_2[0][0]'] 
                                                                                                  
 dense (Dense)                  (None, 1, 128)       19328       ['tf.__operators__.add_3[0][0]'] 
                                                                                                  
 flatten (Flatten)              (None, 128)          0           ['dense[0][0]']                  
                                                                                                  
 dense_1 (Dense)                (None, 2)            258         ['flatten[0][0]']                
                                                                                                  
==================================================================================================
Total params: 118,434
Trainable params: 117,834
Non-trainable params: 600
__________________________________________________________________________________________________
Epoch 00025: early stopping
Experiment:  1  Set:  ss1 Train Labels:  clean Test Labels:  clean
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
None None
Recording results in matrix at 0 0
AER:  0.2385
TER:  0.238, 0.238, 0.238
Score for this model: 
               precision    recall  f1-score   support

           0       0.82      0.68      0.75      1027
           1       0.72      0.84      0.78       973

    accuracy                           0.76      2000
   macro avg       0.77      0.76      0.76      2000
weighted avg       0.77      0.76      0.76      2000

Confusion Matrix for this model: 
 [[701 326]
 [151 822]]
Experiment:  2  Set:  ss1 Train Labels:  clean Test Labels:  ncar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 0 1
AER:  0.2695
TER:  0.244, 0.220, 0.320
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.65      0.71      1031
           1       0.69      0.81      0.75       969

    accuracy                           0.73      2000
   macro avg       0.74      0.73      0.73      2000
weighted avg       0.74      0.73      0.73      2000

Confusion Matrix for this model: 
 [[672 359]
 [180 789]]
Experiment:  3  Set:  ss1 Train Labels:  clean Test Labels:  ncar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 0 2
AER:  0.287
TER:  0.234, 0.187, 0.387
Score for this model: 
               precision    recall  f1-score   support

           0       0.76      0.64      0.69      1014
           1       0.68      0.79      0.73       986

    accuracy                           0.71      2000
   macro avg       0.72      0.71      0.71      2000
weighted avg       0.72      0.71      0.71      2000

Confusion Matrix for this model: 
 [[646 368]
 [206 780]]
Experiment:  4  Set:  ss1 Train Labels:  clean Test Labels:  nar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 0 3
AER:  0.2595
TER:  0.233, 0.210, 0.309
Score for this model: 
               precision    recall  f1-score   support

           0       0.73      0.68      0.71       917
           1       0.75      0.79      0.77      1083

    accuracy                           0.74      2000
   macro avg       0.74      0.74      0.74      2000
weighted avg       0.74      0.74      0.74      2000

Confusion Matrix for this model: 
 [[625 292]
 [227 856]]
Experiment:  5  Set:  ss1 Train Labels:  clean Test Labels:  nar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 0 4
AER:  0.277
TER:  0.221, 0.177, 0.377
Score for this model: 
               precision    recall  f1-score   support

           0       0.66      0.68      0.67       834
           1       0.77      0.75      0.76      1166

    accuracy                           0.72      2000
   macro avg       0.72      0.72      0.72      2000
weighted avg       0.72      0.72      0.72      2000

Confusion Matrix for this model: 
 [[566 268]
 [286 880]]
Experiment:  6  Set:  ss1 Train Labels:  clean Test Labels:  nnar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 0 5
AER:  0.2395
TER:  0.211, 0.190, 0.289
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.69      0.74       973
           1       0.74      0.83      0.78      1027

    accuracy                           0.76      2000
   macro avg       0.76      0.76      0.76      2000
weighted avg       0.76      0.76      0.76      2000

Confusion Matrix for this model: 
 [[673 300]
 [179 848]]
Experiment:  7  Set:  ss1 Train Labels:  clean Test Labels:  nnar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 0 6
AER:  0.2355
TER:  0.169, 0.135, 0.336
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.70      0.74       957
           1       0.75      0.82      0.79      1043

    accuracy                           0.76      2000
   macro avg       0.77      0.76      0.76      2000
weighted avg       0.77      0.76      0.76      2000

Confusion Matrix for this model: 
 [[669 288]
 [183 860]]
Input Shape:  (8000, 1, 150)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_2 (InputLayer)           [(None, 1, 150)]     0           []                               
                                                                                                  
 batch_normalization_2 (BatchNo  (None, 1, 150)      600         ['input_2[0][0]']                
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_2 (MultiH  (None, 1, 150)      38742       ['batch_normalization_2[0][0]',  
 eadAttention)                                                    'batch_normalization_2[0][0]']  
                                                                                                  
 dropout_4 (Dropout)            (None, 1, 150)       0           ['multi_head_attention_2[0][0]'] 
                                                                                                  
 tf.__operators__.add_4 (TFOpLa  (None, 1, 150)      0           ['dropout_4[0][0]',              
 mbda)                                                            'input_2[0][0]']                
                                                                                                  
 layer_normalization_2 (LayerNo  (None, 1, 150)      300         ['tf.__operators__.add_4[0][0]'] 
 rmalization)                                                                                     
                                                                                                  
 conv1d_4 (Conv1D)              (None, 1, 32)        4832        ['layer_normalization_2[0][0]']  
                                                                                                  
 dropout_5 (Dropout)            (None, 1, 32)        0           ['conv1d_4[0][0]']               
                                                                                                  
 conv1d_5 (Conv1D)              (None, 1, 150)       4950        ['dropout_5[0][0]']              
                                                                                                  
 tf.__operators__.add_5 (TFOpLa  (None, 1, 150)      0           ['conv1d_5[0][0]',               
 mbda)                                                            'tf.__operators__.add_4[0][0]'] 
                                                                                                  
 batch_normalization_3 (BatchNo  (None, 1, 150)      600         ['tf.__operators__.add_5[0][0]'] 
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_3 (MultiH  (None, 1, 150)      38742       ['batch_normalization_3[0][0]',  
 eadAttention)                                                    'batch_normalization_3[0][0]']  
                                                                                                  
 dropout_6 (Dropout)            (None, 1, 150)       0           ['multi_head_attention_3[0][0]'] 
                                                                                                  
 tf.__operators__.add_6 (TFOpLa  (None, 1, 150)      0           ['dropout_6[0][0]',              
 mbda)                                                            'tf.__operators__.add_5[0][0]'] 
                                                                                                  
 layer_normalization_3 (LayerNo  (None, 1, 150)      300         ['tf.__operators__.add_6[0][0]'] 
 rmalization)                                                                                     
                                                                                                  
 conv1d_6 (Conv1D)              (None, 1, 32)        4832        ['layer_normalization_3[0][0]']  
                                                                                                  
 dropout_7 (Dropout)            (None, 1, 32)        0           ['conv1d_6[0][0]']               
                                                                                                  
 conv1d_7 (Conv1D)              (None, 1, 150)       4950        ['dropout_7[0][0]']              
                                                                                                  
 tf.__operators__.add_7 (TFOpLa  (None, 1, 150)      0           ['conv1d_7[0][0]',               
 mbda)                                                            'tf.__operators__.add_6[0][0]'] 
                                                                                                  
 dense_2 (Dense)                (None, 1, 128)       19328       ['tf.__operators__.add_7[0][0]'] 
                                                                                                  
 flatten_1 (Flatten)            (None, 128)          0           ['dense_2[0][0]']                
                                                                                                  
 dense_3 (Dense)                (None, 2)            258         ['flatten_1[0][0]']              
                                                                                                  
==================================================================================================
Total params: 118,434
Trainable params: 117,834
Non-trainable params: 600
__________________________________________________________________________________________________
Epoch 00041: early stopping
Experiment:  8  Set:  ss1 Train Labels:  ncar5 Test Labels:  clean
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 1 0
AER:  0.2405
TER:  0.240, 0.240, 0.240
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.70      0.75      1027
           1       0.72      0.82      0.77       973

    accuracy                           0.76      2000
   macro avg       0.76      0.76      0.76      2000
weighted avg       0.76      0.76      0.76      2000

Confusion Matrix for this model: 
 [[724 303]
 [178 795]]
Experiment:  9  Set:  ss1 Train Labels:  ncar5 Test Labels:  ncar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 1 1
AER:  0.2735
TER:  0.248, 0.224, 0.324
Score for this model: 
               precision    recall  f1-score   support

           0       0.77      0.67      0.72      1031
           1       0.69      0.78      0.74       969

    accuracy                           0.73      2000
   macro avg       0.73      0.73      0.73      2000
weighted avg       0.73      0.73      0.73      2000

Confusion Matrix for this model: 
 [[693 338]
 [209 760]]
Experiment:  10  Set:  ss1 Train Labels:  ncar5 Test Labels:  ncar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 1 2
AER:  0.297
TER:  0.246, 0.197, 0.397
Score for this model: 
               precision    recall  f1-score   support

           0       0.73      0.65      0.69      1014
           1       0.68      0.76      0.71       986

    accuracy                           0.70      2000
   macro avg       0.71      0.70      0.70      2000
weighted avg       0.71      0.70      0.70      2000

Confusion Matrix for this model: 
 [[661 353]
 [241 745]]
Experiment:  11  Set:  ss1 Train Labels:  ncar5 Test Labels:  nar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 1 3
AER:  0.2675
TER:  0.242, 0.218, 0.318
Score for this model: 
               precision    recall  f1-score   support

           0       0.71      0.70      0.71       917
           1       0.75      0.76      0.75      1083

    accuracy                           0.73      2000
   macro avg       0.73      0.73      0.73      2000
weighted avg       0.73      0.73      0.73      2000

Confusion Matrix for this model: 
 [[642 275]
 [260 823]]
Experiment:  12  Set:  ss1 Train Labels:  ncar5 Test Labels:  nar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 1 4
AER:  0.288
TER:  0.235, 0.188, 0.388
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.70      0.67       834
           1       0.77      0.72      0.75      1166

    accuracy                           0.71      2000
   macro avg       0.71      0.71      0.71      2000
weighted avg       0.72      0.71      0.71      2000

Confusion Matrix for this model: 
 [[580 254]
 [322 844]]
Experiment:  13  Set:  ss1 Train Labels:  ncar5 Test Labels:  nnar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 1 5
AER:  0.2435
TER:  0.215, 0.194, 0.293
Score for this model: 
               precision    recall  f1-score   support

           0       0.77      0.71      0.74       973
           1       0.75      0.80      0.77      1027

    accuracy                           0.76      2000
   macro avg       0.76      0.76      0.76      2000
weighted avg       0.76      0.76      0.76      2000

Confusion Matrix for this model: 
 [[694 279]
 [208 819]]
Experiment:  14  Set:  ss1 Train Labels:  ncar5 Test Labels:  nnar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 1 6
AER:  0.2455
TER:  0.182, 0.145, 0.346
Score for this model: 
               precision    recall  f1-score   support

           0       0.76      0.71      0.74       957
           1       0.75      0.79      0.77      1043

    accuracy                           0.75      2000
   macro avg       0.75      0.75      0.75      2000
weighted avg       0.75      0.75      0.75      2000

Confusion Matrix for this model: 
 [[684 273]
 [218 825]]
Input Shape:  (8000, 1, 150)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_2"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_3 (InputLayer)           [(None, 1, 150)]     0           []                               
                                                                                                  
 batch_normalization_4 (BatchNo  (None, 1, 150)      600         ['input_3[0][0]']                
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_4 (MultiH  (None, 1, 150)      38742       ['batch_normalization_4[0][0]',  
 eadAttention)                                                    'batch_normalization_4[0][0]']  
                                                                                                  
 dropout_8 (Dropout)            (None, 1, 150)       0           ['multi_head_attention_4[0][0]'] 
                                                                                                  
 tf.__operators__.add_8 (TFOpLa  (None, 1, 150)      0           ['dropout_8[0][0]',              
 mbda)                                                            'input_3[0][0]']                
                                                                                                  
 layer_normalization_4 (LayerNo  (None, 1, 150)      300         ['tf.__operators__.add_8[0][0]'] 
 rmalization)                                                                                     
                                                                                                  
 conv1d_8 (Conv1D)              (None, 1, 32)        4832        ['layer_normalization_4[0][0]']  
                                                                                                  
 dropout_9 (Dropout)            (None, 1, 32)        0           ['conv1d_8[0][0]']               
                                                                                                  
 conv1d_9 (Conv1D)              (None, 1, 150)       4950        ['dropout_9[0][0]']              
                                                                                                  
 tf.__operators__.add_9 (TFOpLa  (None, 1, 150)      0           ['conv1d_9[0][0]',               
 mbda)                                                            'tf.__operators__.add_8[0][0]'] 
                                                                                                  
 batch_normalization_5 (BatchNo  (None, 1, 150)      600         ['tf.__operators__.add_9[0][0]'] 
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_5 (MultiH  (None, 1, 150)      38742       ['batch_normalization_5[0][0]',  
 eadAttention)                                                    'batch_normalization_5[0][0]']  
                                                                                                  
 dropout_10 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_5[0][0]'] 
                                                                                                  
 tf.__operators__.add_10 (TFOpL  (None, 1, 150)      0           ['dropout_10[0][0]',             
 ambda)                                                           'tf.__operators__.add_9[0][0]'] 
                                                                                                  
 layer_normalization_5 (LayerNo  (None, 1, 150)      300         ['tf.__operators__.add_10[0][0]']
 rmalization)                                                                                     
                                                                                                  
 conv1d_10 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_5[0][0]']  
                                                                                                  
 dropout_11 (Dropout)           (None, 1, 32)        0           ['conv1d_10[0][0]']              
                                                                                                  
 conv1d_11 (Conv1D)             (None, 1, 150)       4950        ['dropout_11[0][0]']             
                                                                                                  
 tf.__operators__.add_11 (TFOpL  (None, 1, 150)      0           ['conv1d_11[0][0]',              
 ambda)                                                           'tf.__operators__.add_10[0][0]']
                                                                                                  
 dense_4 (Dense)                (None, 1, 128)       19328       ['tf.__operators__.add_11[0][0]']
                                                                                                  
 flatten_2 (Flatten)            (None, 128)          0           ['dense_4[0][0]']                
                                                                                                  
 dense_5 (Dense)                (None, 2)            258         ['flatten_2[0][0]']              
                                                                                                  
==================================================================================================
Total params: 118,434
Trainable params: 117,834
Non-trainable params: 600
__________________________________________________________________________________________________
Epoch 00019: early stopping
Experiment:  15  Set:  ss1 Train Labels:  ncar10 Test Labels:  clean
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 2 0
AER:  0.239
TER:  0.239, 0.239, 0.239
Score for this model: 
               precision    recall  f1-score   support

           0       0.76      0.78      0.77      1027
           1       0.76      0.74      0.75       973

    accuracy                           0.76      2000
   macro avg       0.76      0.76      0.76      2000
weighted avg       0.76      0.76      0.76      2000

Confusion Matrix for this model: 
 [[802 225]
 [253 720]]
Experiment:  16  Set:  ss1 Train Labels:  ncar10 Test Labels:  ncar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 2 1
AER:  0.261
TER:  0.234, 0.211, 0.311
Score for this model: 
               precision    recall  f1-score   support

           0       0.74      0.76      0.75      1031
           1       0.74      0.72      0.73       969

    accuracy                           0.74      2000
   macro avg       0.74      0.74      0.74      2000
weighted avg       0.74      0.74      0.74      2000

Confusion Matrix for this model: 
 [[782 249]
 [273 696]]
Experiment:  17  Set:  ss1 Train Labels:  ncar10 Test Labels:  ncar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 2 2
AER:  0.2865
TER:  0.233, 0.186, 0.386
Score for this model: 
               precision    recall  f1-score   support

           0       0.71      0.74      0.72      1014
           1       0.72      0.69      0.70       986

    accuracy                           0.71      2000
   macro avg       0.71      0.71      0.71      2000
weighted avg       0.71      0.71      0.71      2000

Confusion Matrix for this model: 
 [[748 266]
 [307 679]]
Experiment:  18  Set:  ss1 Train Labels:  ncar10 Test Labels:  nar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 2 3
AER:  0.268
TER:  0.242, 0.218, 0.318
Score for this model: 
               precision    recall  f1-score   support

           0       0.68      0.78      0.73       917
           1       0.79      0.69      0.74      1083

    accuracy                           0.73      2000
   macro avg       0.73      0.74      0.73      2000
weighted avg       0.74      0.73      0.73      2000

Confusion Matrix for this model: 
 [[718 199]
 [337 746]]
Experiment:  19  Set:  ss1 Train Labels:  ncar10 Test Labels:  nar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 2 4
AER:  0.2955
TER:  0.244, 0.195, 0.395
Score for this model: 
               precision    recall  f1-score   support

           0       0.62      0.78      0.69       834
           1       0.80      0.65      0.72      1166

    accuracy                           0.70      2000
   macro avg       0.71      0.71      0.70      2000
weighted avg       0.73      0.70      0.71      2000

Confusion Matrix for this model: 
 [[649 185]
 [406 760]]
Experiment:  20  Set:  ss1 Train Labels:  ncar10 Test Labels:  nnar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 2 5
AER:  0.249
TER:  0.221, 0.199, 0.299
Score for this model: 
               precision    recall  f1-score   support

           0       0.73      0.79      0.75       973
           1       0.78      0.72      0.75      1027

    accuracy                           0.75      2000
   macro avg       0.75      0.75      0.75      2000
weighted avg       0.75      0.75      0.75      2000

Confusion Matrix for this model: 
 [[765 208]
 [290 737]]
Experiment:  21  Set:  ss1 Train Labels:  ncar10 Test Labels:  nnar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 2 6
AER:  0.253
TER:  0.191, 0.153, 0.353
Score for this model: 
               precision    recall  f1-score   support

           0       0.71      0.79      0.75       957
           1       0.78      0.71      0.75      1043

    accuracy                           0.75      2000
   macro avg       0.75      0.75      0.75      2000
weighted avg       0.75      0.75      0.75      2000

Confusion Matrix for this model: 
 [[753 204]
 [302 741]]
Input Shape:  (8000, 1, 150)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_3"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_4 (InputLayer)           [(None, 1, 150)]     0           []                               
                                                                                                  
 batch_normalization_6 (BatchNo  (None, 1, 150)      600         ['input_4[0][0]']                
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_6 (MultiH  (None, 1, 150)      38742       ['batch_normalization_6[0][0]',  
 eadAttention)                                                    'batch_normalization_6[0][0]']  
                                                                                                  
 dropout_12 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_6[0][0]'] 
                                                                                                  
 tf.__operators__.add_12 (TFOpL  (None, 1, 150)      0           ['dropout_12[0][0]',             
 ambda)                                                           'input_4[0][0]']                
                                                                                                  
 layer_normalization_6 (LayerNo  (None, 1, 150)      300         ['tf.__operators__.add_12[0][0]']
 rmalization)                                                                                     
                                                                                                  
 conv1d_12 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_6[0][0]']  
                                                                                                  
 dropout_13 (Dropout)           (None, 1, 32)        0           ['conv1d_12[0][0]']              
                                                                                                  
 conv1d_13 (Conv1D)             (None, 1, 150)       4950        ['dropout_13[0][0]']             
                                                                                                  
 tf.__operators__.add_13 (TFOpL  (None, 1, 150)      0           ['conv1d_13[0][0]',              
 ambda)                                                           'tf.__operators__.add_12[0][0]']
                                                                                                  
 batch_normalization_7 (BatchNo  (None, 1, 150)      600         ['tf.__operators__.add_13[0][0]']
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_7 (MultiH  (None, 1, 150)      38742       ['batch_normalization_7[0][0]',  
 eadAttention)                                                    'batch_normalization_7[0][0]']  
                                                                                                  
 dropout_14 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_7[0][0]'] 
                                                                                                  
 tf.__operators__.add_14 (TFOpL  (None, 1, 150)      0           ['dropout_14[0][0]',             
 ambda)                                                           'tf.__operators__.add_13[0][0]']
                                                                                                  
 layer_normalization_7 (LayerNo  (None, 1, 150)      300         ['tf.__operators__.add_14[0][0]']
 rmalization)                                                                                     
                                                                                                  
 conv1d_14 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_7[0][0]']  
                                                                                                  
 dropout_15 (Dropout)           (None, 1, 32)        0           ['conv1d_14[0][0]']              
                                                                                                  
 conv1d_15 (Conv1D)             (None, 1, 150)       4950        ['dropout_15[0][0]']             
                                                                                                  
 tf.__operators__.add_15 (TFOpL  (None, 1, 150)      0           ['conv1d_15[0][0]',              
 ambda)                                                           'tf.__operators__.add_14[0][0]']
                                                                                                  
 dense_6 (Dense)                (None, 1, 128)       19328       ['tf.__operators__.add_15[0][0]']
                                                                                                  
 flatten_3 (Flatten)            (None, 128)          0           ['dense_6[0][0]']                
                                                                                                  
 dense_7 (Dense)                (None, 2)            258         ['flatten_3[0][0]']              
                                                                                                  
==================================================================================================
Total params: 118,434
Trainable params: 117,834
Non-trainable params: 600
__________________________________________________________________________________________________
Epoch 00027: early stopping
Experiment:  22  Set:  ss1 Train Labels:  nar5 Test Labels:  clean
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 3 0
AER:  0.2175
TER:  0.217, 0.217, 0.217
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.77      0.78      1027
           1       0.77      0.79      0.78       973

    accuracy                           0.78      2000
   macro avg       0.78      0.78      0.78      2000
weighted avg       0.78      0.78      0.78      2000

Confusion Matrix for this model: 
 [[793 234]
 [201 772]]
Experiment:  23  Set:  ss1 Train Labels:  nar5 Test Labels:  ncar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 3 1
AER:  0.2445
TER:  0.216, 0.195, 0.294
Score for this model: 
               precision    recall  f1-score   support

           0       0.77      0.74      0.76      1031
           1       0.74      0.77      0.75       969

    accuracy                           0.76      2000
   macro avg       0.76      0.76      0.76      2000
weighted avg       0.76      0.76      0.76      2000

Confusion Matrix for this model: 
 [[768 263]
 [226 743]]
Experiment:  24  Set:  ss1 Train Labels:  nar5 Test Labels:  ncar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 3 2
AER:  0.276
TER:  0.220, 0.176, 0.376
Score for this model: 
               precision    recall  f1-score   support

           0       0.73      0.72      0.73      1014
           1       0.72      0.73      0.72       986

    accuracy                           0.72      2000
   macro avg       0.72      0.72      0.72      2000
weighted avg       0.72      0.72      0.72      2000

Confusion Matrix for this model: 
 [[728 286]
 [266 720]]
Experiment:  25  Set:  ss1 Train Labels:  nar5 Test Labels:  nar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 3 3
AER:  0.2445
TER:  0.216, 0.195, 0.294
Score for this model: 
               precision    recall  f1-score   support

           0       0.72      0.78      0.74       917
           1       0.80      0.74      0.77      1083

    accuracy                           0.76      2000
   macro avg       0.76      0.76      0.76      2000
weighted avg       0.76      0.76      0.76      2000

Confusion Matrix for this model: 
 [[711 206]
 [283 800]]
Experiment:  26  Set:  ss1 Train Labels:  nar5 Test Labels:  nar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 3 4
AER:  0.281
TER:  0.226, 0.181, 0.381
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.76      0.69       834
           1       0.80      0.69      0.74      1166

    accuracy                           0.72      2000
   macro avg       0.72      0.72      0.72      2000
weighted avg       0.73      0.72      0.72      2000

Confusion Matrix for this model: 
 [[633 201]
 [361 805]]
Experiment:  27  Set:  ss1 Train Labels:  nar5 Test Labels:  nnar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 3 5
AER:  0.2215
TER:  0.191, 0.171, 0.272
Score for this model: 
               precision    recall  f1-score   support

           0       0.77      0.78      0.77       973
           1       0.79      0.77      0.78      1027

    accuracy                           0.78      2000
   macro avg       0.78      0.78      0.78      2000
weighted avg       0.78      0.78      0.78      2000

Confusion Matrix for this model: 
 [[762 211]
 [232 795]]
Experiment:  28  Set:  ss1 Train Labels:  nar5 Test Labels:  nnar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 3 6
AER:  0.2235
TER:  0.154, 0.123, 0.324
Score for this model: 
               precision    recall  f1-score   support

           0       0.76      0.79      0.77       957
           1       0.80      0.77      0.78      1043

    accuracy                           0.78      2000
   macro avg       0.78      0.78      0.78      2000
weighted avg       0.78      0.78      0.78      2000

Confusion Matrix for this model: 
 [[752 205]
 [242 801]]
Input Shape:  (8000, 1, 150)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_4"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_5 (InputLayer)           [(None, 1, 150)]     0           []                               
                                                                                                  
 batch_normalization_8 (BatchNo  (None, 1, 150)      600         ['input_5[0][0]']                
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_8 (MultiH  (None, 1, 150)      38742       ['batch_normalization_8[0][0]',  
 eadAttention)                                                    'batch_normalization_8[0][0]']  
                                                                                                  
 dropout_16 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_8[0][0]'] 
                                                                                                  
 tf.__operators__.add_16 (TFOpL  (None, 1, 150)      0           ['dropout_16[0][0]',             
 ambda)                                                           'input_5[0][0]']                
                                                                                                  
 layer_normalization_8 (LayerNo  (None, 1, 150)      300         ['tf.__operators__.add_16[0][0]']
 rmalization)                                                                                     
                                                                                                  
 conv1d_16 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_8[0][0]']  
                                                                                                  
 dropout_17 (Dropout)           (None, 1, 32)        0           ['conv1d_16[0][0]']              
                                                                                                  
 conv1d_17 (Conv1D)             (None, 1, 150)       4950        ['dropout_17[0][0]']             
                                                                                                  
 tf.__operators__.add_17 (TFOpL  (None, 1, 150)      0           ['conv1d_17[0][0]',              
 ambda)                                                           'tf.__operators__.add_16[0][0]']
                                                                                                  
 batch_normalization_9 (BatchNo  (None, 1, 150)      600         ['tf.__operators__.add_17[0][0]']
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_9 (MultiH  (None, 1, 150)      38742       ['batch_normalization_9[0][0]',  
 eadAttention)                                                    'batch_normalization_9[0][0]']  
                                                                                                  
 dropout_18 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_9[0][0]'] 
                                                                                                  
 tf.__operators__.add_18 (TFOpL  (None, 1, 150)      0           ['dropout_18[0][0]',             
 ambda)                                                           'tf.__operators__.add_17[0][0]']
                                                                                                  
 layer_normalization_9 (LayerNo  (None, 1, 150)      300         ['tf.__operators__.add_18[0][0]']
 rmalization)                                                                                     
                                                                                                  
 conv1d_18 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_9[0][0]']  
                                                                                                  
 dropout_19 (Dropout)           (None, 1, 32)        0           ['conv1d_18[0][0]']              
                                                                                                  
 conv1d_19 (Conv1D)             (None, 1, 150)       4950        ['dropout_19[0][0]']             
                                                                                                  
 tf.__operators__.add_19 (TFOpL  (None, 1, 150)      0           ['conv1d_19[0][0]',              
 ambda)                                                           'tf.__operators__.add_18[0][0]']
                                                                                                  
 dense_8 (Dense)                (None, 1, 128)       19328       ['tf.__operators__.add_19[0][0]']
                                                                                                  
 flatten_4 (Flatten)            (None, 128)          0           ['dense_8[0][0]']                
                                                                                                  
 dense_9 (Dense)                (None, 2)            258         ['flatten_4[0][0]']              
                                                                                                  
==================================================================================================
Total params: 118,434
Trainable params: 117,834
Non-trainable params: 600
__________________________________________________________________________________________________
Epoch 00024: early stopping
Experiment:  29  Set:  ss1 Train Labels:  nar10 Test Labels:  clean
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 4 0
AER:  0.2435
TER:  0.243, 0.243, 0.243
Score for this model: 
               precision    recall  f1-score   support

           0       0.75      0.80      0.77      1027
           1       0.77      0.71      0.74       973

    accuracy                           0.76      2000
   macro avg       0.76      0.76      0.76      2000
weighted avg       0.76      0.76      0.76      2000

Confusion Matrix for this model: 
 [[821 206]
 [281 692]]
Experiment:  30  Set:  ss1 Train Labels:  nar10 Test Labels:  ncar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 4 1
AER:  0.2825
TER:  0.258, 0.232, 0.332
Score for this model: 
               precision    recall  f1-score   support

           0       0.71      0.76      0.74      1031
           1       0.72      0.67      0.70       969

    accuracy                           0.72      2000
   macro avg       0.72      0.72      0.72      2000
weighted avg       0.72      0.72      0.72      2000

Confusion Matrix for this model: 
 [[784 247]
 [318 651]]
Experiment:  31  Set:  ss1 Train Labels:  nar10 Test Labels:  ncar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 4 2
AER:  0.3
TER:  0.250, 0.200, 0.400
Score for this model: 
               precision    recall  f1-score   support

           0       0.69      0.75      0.72      1014
           1       0.71      0.65      0.68       986

    accuracy                           0.70      2000
   macro avg       0.70      0.70      0.70      2000
weighted avg       0.70      0.70      0.70      2000

Confusion Matrix for this model: 
 [[758 256]
 [344 642]]
Experiment:  32  Set:  ss1 Train Labels:  nar10 Test Labels:  nar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 4 3
AER:  0.2705
TER:  0.245, 0.221, 0.321
Score for this model: 
               precision    recall  f1-score   support

           0       0.67      0.81      0.73       917
           1       0.80      0.66      0.73      1083

    accuracy                           0.73      2000
   macro avg       0.74      0.74      0.73      2000
weighted avg       0.74      0.73      0.73      2000

Confusion Matrix for this model: 
 [[739 178]
 [363 720]]
Experiment:  33  Set:  ss1 Train Labels:  nar10 Test Labels:  nar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 4 4
AER:  0.3
TER:  0.250, 0.200, 0.400
Score for this model: 
               precision    recall  f1-score   support

           0       0.61      0.80      0.69       834
           1       0.82      0.63      0.71      1166

    accuracy                           0.70      2000
   macro avg       0.71      0.71      0.70      2000
weighted avg       0.73      0.70      0.70      2000

Confusion Matrix for this model: 
 [[668 166]
 [434 732]]
Experiment:  34  Set:  ss1 Train Labels:  nar10 Test Labels:  nnar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 4 5
AER:  0.2455
TER:  0.217, 0.196, 0.295
Score for this model: 
               precision    recall  f1-score   support

           0       0.72      0.81      0.76       973
           1       0.80      0.70      0.74      1027

    accuracy                           0.75      2000
   macro avg       0.76      0.76      0.75      2000
weighted avg       0.76      0.75      0.75      2000

Confusion Matrix for this model: 
 [[792 181]
 [310 717]]
Experiment:  35  Set:  ss1 Train Labels:  nar10 Test Labels:  nnar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 4 6
AER:  0.2495
TER:  0.187, 0.149, 0.350
Score for this model: 
               precision    recall  f1-score   support

           0       0.71      0.82      0.76       957
           1       0.80      0.69      0.74      1043

    accuracy                           0.75      2000
   macro avg       0.76      0.75      0.75      2000
weighted avg       0.76      0.75      0.75      2000

Confusion Matrix for this model: 
 [[780 177]
 [322 721]]
Input Shape:  (8000, 1, 150)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_5"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_6 (InputLayer)           [(None, 1, 150)]     0           []                               
                                                                                                  
 batch_normalization_10 (BatchN  (None, 1, 150)      600         ['input_6[0][0]']                
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_10 (Multi  (None, 1, 150)      38742       ['batch_normalization_10[0][0]', 
 HeadAttention)                                                   'batch_normalization_10[0][0]'] 
                                                                                                  
 dropout_20 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_10[0][0]']
                                                                                                  
 tf.__operators__.add_20 (TFOpL  (None, 1, 150)      0           ['dropout_20[0][0]',             
 ambda)                                                           'input_6[0][0]']                
                                                                                                  
 layer_normalization_10 (LayerN  (None, 1, 150)      300         ['tf.__operators__.add_20[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_20 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_10[0][0]'] 
                                                                                                  
 dropout_21 (Dropout)           (None, 1, 32)        0           ['conv1d_20[0][0]']              
                                                                                                  
 conv1d_21 (Conv1D)             (None, 1, 150)       4950        ['dropout_21[0][0]']             
                                                                                                  
 tf.__operators__.add_21 (TFOpL  (None, 1, 150)      0           ['conv1d_21[0][0]',              
 ambda)                                                           'tf.__operators__.add_20[0][0]']
                                                                                                  
 batch_normalization_11 (BatchN  (None, 1, 150)      600         ['tf.__operators__.add_21[0][0]']
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_11 (Multi  (None, 1, 150)      38742       ['batch_normalization_11[0][0]', 
 HeadAttention)                                                   'batch_normalization_11[0][0]'] 
                                                                                                  
 dropout_22 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_11[0][0]']
                                                                                                  
 tf.__operators__.add_22 (TFOpL  (None, 1, 150)      0           ['dropout_22[0][0]',             
 ambda)                                                           'tf.__operators__.add_21[0][0]']
                                                                                                  
 layer_normalization_11 (LayerN  (None, 1, 150)      300         ['tf.__operators__.add_22[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_22 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_11[0][0]'] 
                                                                                                  
 dropout_23 (Dropout)           (None, 1, 32)        0           ['conv1d_22[0][0]']              
                                                                                                  
 conv1d_23 (Conv1D)             (None, 1, 150)       4950        ['dropout_23[0][0]']             
                                                                                                  
 tf.__operators__.add_23 (TFOpL  (None, 1, 150)      0           ['conv1d_23[0][0]',              
 ambda)                                                           'tf.__operators__.add_22[0][0]']
                                                                                                  
 dense_10 (Dense)               (None, 1, 128)       19328       ['tf.__operators__.add_23[0][0]']
                                                                                                  
 flatten_5 (Flatten)            (None, 128)          0           ['dense_10[0][0]']               
                                                                                                  
 dense_11 (Dense)               (None, 2)            258         ['flatten_5[0][0]']              
                                                                                                  
==================================================================================================
Total params: 118,434
Trainable params: 117,834
Non-trainable params: 600
__________________________________________________________________________________________________
Epoch 00026: early stopping
Experiment:  36  Set:  ss1 Train Labels:  nnar5 Test Labels:  clean
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 5 0
AER:  0.2075
TER:  0.207, 0.207, 0.207
Score for this model: 
               precision    recall  f1-score   support

           0       0.78      0.82      0.80      1027
           1       0.80      0.76      0.78       973

    accuracy                           0.79      2000
   macro avg       0.79      0.79      0.79      2000
weighted avg       0.79      0.79      0.79      2000

Confusion Matrix for this model: 
 [[846 181]
 [234 739]]
Experiment:  37  Set:  ss1 Train Labels:  nnar5 Test Labels:  ncar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 5 1
AER:  0.2405
TER:  0.212, 0.191, 0.290
Score for this model: 
               precision    recall  f1-score   support

           0       0.75      0.79      0.77      1031
           1       0.77      0.73      0.75       969

    accuracy                           0.76      2000
   macro avg       0.76      0.76      0.76      2000
weighted avg       0.76      0.76      0.76      2000

Confusion Matrix for this model: 
 [[815 216]
 [265 704]]
Experiment:  38  Set:  ss1 Train Labels:  nnar5 Test Labels:  ncar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 5 2
AER:  0.258
TER:  0.197, 0.158, 0.358
Score for this model: 
               precision    recall  f1-score   support

           0       0.73      0.78      0.75      1014
           1       0.76      0.70      0.73       986

    accuracy                           0.74      2000
   macro avg       0.74      0.74      0.74      2000
weighted avg       0.74      0.74      0.74      2000

Confusion Matrix for this model: 
 [[789 225]
 [291 695]]
Experiment:  39  Set:  ss1 Train Labels:  nnar5 Test Labels:  nar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 5 3
AER:  0.2465
TER:  0.218, 0.197, 0.296
Score for this model: 
               precision    recall  f1-score   support

           0       0.70      0.82      0.75       917
           1       0.82      0.70      0.75      1083

    accuracy                           0.75      2000
   macro avg       0.76      0.76      0.75      2000
weighted avg       0.76      0.75      0.75      2000

Confusion Matrix for this model: 
 [[752 165]
 [328 755]]
Experiment:  40  Set:  ss1 Train Labels:  nnar5 Test Labels:  nar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 5 4
AER:  0.27
TER:  0.212, 0.170, 0.370
Score for this model: 
               precision    recall  f1-score   support

           0       0.64      0.82      0.72       834
           1       0.84      0.66      0.74      1166

    accuracy                           0.73      2000
   macro avg       0.74      0.74      0.73      2000
weighted avg       0.76      0.73      0.73      2000

Confusion Matrix for this model: 
 [[687 147]
 [393 773]]
Experiment:  41  Set:  ss1 Train Labels:  nnar5 Test Labels:  nnar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 5 5
AER:  0.2185
TER:  0.187, 0.168, 0.269
Score for this model: 
               precision    recall  f1-score   support

           0       0.75      0.83      0.79       973
           1       0.82      0.74      0.78      1027

    accuracy                           0.78      2000
   macro avg       0.78      0.78      0.78      2000
weighted avg       0.79      0.78      0.78      2000

Confusion Matrix for this model: 
 [[808 165]
 [272 755]]
Experiment:  42  Set:  ss1 Train Labels:  nnar5 Test Labels:  nnar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 5 6
AER:  0.2195
TER:  0.149, 0.119, 0.320
Score for this model: 
               precision    recall  f1-score   support

           0       0.74      0.83      0.78       957
           1       0.83      0.73      0.78      1043

    accuracy                           0.78      2000
   macro avg       0.78      0.78      0.78      2000
weighted avg       0.79      0.78      0.78      2000

Confusion Matrix for this model: 
 [[799 158]
 [281 762]]
Input Shape:  (8000, 1, 150)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_6"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_7 (InputLayer)           [(None, 1, 150)]     0           []                               
                                                                                                  
 batch_normalization_12 (BatchN  (None, 1, 150)      600         ['input_7[0][0]']                
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_12 (Multi  (None, 1, 150)      38742       ['batch_normalization_12[0][0]', 
 HeadAttention)                                                   'batch_normalization_12[0][0]'] 
                                                                                                  
 dropout_24 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_12[0][0]']
                                                                                                  
 tf.__operators__.add_24 (TFOpL  (None, 1, 150)      0           ['dropout_24[0][0]',             
 ambda)                                                           'input_7[0][0]']                
                                                                                                  
 layer_normalization_12 (LayerN  (None, 1, 150)      300         ['tf.__operators__.add_24[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_24 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_12[0][0]'] 
                                                                                                  
 dropout_25 (Dropout)           (None, 1, 32)        0           ['conv1d_24[0][0]']              
                                                                                                  
 conv1d_25 (Conv1D)             (None, 1, 150)       4950        ['dropout_25[0][0]']             
                                                                                                  
 tf.__operators__.add_25 (TFOpL  (None, 1, 150)      0           ['conv1d_25[0][0]',              
 ambda)                                                           'tf.__operators__.add_24[0][0]']
                                                                                                  
 batch_normalization_13 (BatchN  (None, 1, 150)      600         ['tf.__operators__.add_25[0][0]']
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_13 (Multi  (None, 1, 150)      38742       ['batch_normalization_13[0][0]', 
 HeadAttention)                                                   'batch_normalization_13[0][0]'] 
                                                                                                  
 dropout_26 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_13[0][0]']
                                                                                                  
 tf.__operators__.add_26 (TFOpL  (None, 1, 150)      0           ['dropout_26[0][0]',             
 ambda)                                                           'tf.__operators__.add_25[0][0]']
                                                                                                  
 layer_normalization_13 (LayerN  (None, 1, 150)      300         ['tf.__operators__.add_26[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_26 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_13[0][0]'] 
                                                                                                  
 dropout_27 (Dropout)           (None, 1, 32)        0           ['conv1d_26[0][0]']              
                                                                                                  
 conv1d_27 (Conv1D)             (None, 1, 150)       4950        ['dropout_27[0][0]']             
                                                                                                  
 tf.__operators__.add_27 (TFOpL  (None, 1, 150)      0           ['conv1d_27[0][0]',              
 ambda)                                                           'tf.__operators__.add_26[0][0]']
                                                                                                  
 dense_12 (Dense)               (None, 1, 128)       19328       ['tf.__operators__.add_27[0][0]']
                                                                                                  
 flatten_6 (Flatten)            (None, 128)          0           ['dense_12[0][0]']               
                                                                                                  
 dense_13 (Dense)               (None, 2)            258         ['flatten_6[0][0]']              
                                                                                                  
==================================================================================================
Total params: 118,434
Trainable params: 117,834
Non-trainable params: 600
__________________________________________________________________________________________________
Epoch 00027: early stopping
Experiment:  43  Set:  ss1 Train Labels:  nnar10 Test Labels:  clean
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 6 0
AER:  0.2225
TER:  0.223, 0.223, 0.223
Score for this model: 
               precision    recall  f1-score   support

           0       0.81      0.75      0.78      1027
           1       0.75      0.81      0.78       973

    accuracy                           0.78      2000
   macro avg       0.78      0.78      0.78      2000
weighted avg       0.78      0.78      0.78      2000

Confusion Matrix for this model: 
 [[768 259]
 [186 787]]
Experiment:  44  Set:  ss1 Train Labels:  nnar10 Test Labels:  ncar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 6 1
AER:  0.2595
TER:  0.233, 0.210, 0.309
Score for this model: 
               precision    recall  f1-score   support

           0       0.77      0.71      0.74      1031
           1       0.72      0.77      0.74       969

    accuracy                           0.74      2000
   macro avg       0.74      0.74      0.74      2000
weighted avg       0.74      0.74      0.74      2000

Confusion Matrix for this model: 
 [[733 298]
 [221 748]]
Experiment:  45  Set:  ss1 Train Labels:  nnar10 Test Labels:  ncar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 6 2
AER:  0.277
TER:  0.221, 0.177, 0.377
Score for this model: 
               precision    recall  f1-score   support

           0       0.74      0.70      0.72      1014
           1       0.71      0.75      0.73       986

    accuracy                           0.72      2000
   macro avg       0.72      0.72      0.72      2000
weighted avg       0.72      0.72      0.72      2000

Confusion Matrix for this model: 
 [[707 307]
 [247 739]]
Experiment:  46  Set:  ss1 Train Labels:  nnar10 Test Labels:  nar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 6 3
AER:  0.2525
TER:  0.225, 0.203, 0.302
Score for this model: 
               precision    recall  f1-score   support

           0       0.72      0.74      0.73       917
           1       0.78      0.75      0.76      1083

    accuracy                           0.75      2000
   macro avg       0.75      0.75      0.75      2000
weighted avg       0.75      0.75      0.75      2000

Confusion Matrix for this model: 
 [[683 234]
 [271 812]]
Experiment:  47  Set:  ss1 Train Labels:  nnar10 Test Labels:  nar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 6 4
AER:  0.268
TER:  0.210, 0.168, 0.368
Score for this model: 
               precision    recall  f1-score   support

           0       0.66      0.75      0.70       834
           1       0.80      0.72      0.76      1166

    accuracy                           0.73      2000
   macro avg       0.73      0.73      0.73      2000
weighted avg       0.74      0.73      0.73      2000

Confusion Matrix for this model: 
 [[626 208]
 [328 838]]
Experiment:  48  Set:  ss1 Train Labels:  nnar10 Test Labels:  nnar5
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 6 5
AER:  0.2235
TER:  0.193, 0.173, 0.274
Score for this model: 
               precision    recall  f1-score   support

           0       0.78      0.76      0.77       973
           1       0.78      0.79      0.78      1027

    accuracy                           0.78      2000
   macro avg       0.78      0.78      0.78      2000
weighted avg       0.78      0.78      0.78      2000

Confusion Matrix for this model: 
 [[740 233]
 [214 813]]
Experiment:  49  Set:  ss1 Train Labels:  nnar10 Test Labels:  nnar10
Shape of X_train:  (8000, 1, 150)
Shape of X_test:  (2000, 1, 150)
Shape of y_train:  (8000, 2)
Shape of y_test:  (2000, 2)
NUM_INSTANCES is  8000
instances should be  8000
Shape of y true: (2000,)
Shape of y predicted: (2000,)
[0.15519013 0.31742941] [0.31742941 0.15519013]
Recording results in matrix at 6 6
AER:  0.2245
TER:  0.156, 0.124, 0.325
Score for this model: 
               precision    recall  f1-score   support

           0       0.77      0.76      0.77       957
           1       0.78      0.79      0.79      1043

    accuracy                           0.78      2000
   macro avg       0.78      0.78      0.78      2000
weighted avg       0.78      0.78      0.78      2000

Confusion Matrix for this model: 
 [[731 226]
 [223 820]]
Input Shape:  (24000, 1, 150)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_7"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_8 (InputLayer)           [(None, 1, 150)]     0           []                               
                                                                                                  
 batch_normalization_14 (BatchN  (None, 1, 150)      600         ['input_8[0][0]']                
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_14 (Multi  (None, 1, 150)      38742       ['batch_normalization_14[0][0]', 
 HeadAttention)                                                   'batch_normalization_14[0][0]'] 
                                                                                                  
 dropout_28 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_14[0][0]']
                                                                                                  
 tf.__operators__.add_28 (TFOpL  (None, 1, 150)      0           ['dropout_28[0][0]',             
 ambda)                                                           'input_8[0][0]']                
                                                                                                  
 layer_normalization_14 (LayerN  (None, 1, 150)      300         ['tf.__operators__.add_28[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_28 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_14[0][0]'] 
                                                                                                  
 dropout_29 (Dropout)           (None, 1, 32)        0           ['conv1d_28[0][0]']              
                                                                                                  
 conv1d_29 (Conv1D)             (None, 1, 150)       4950        ['dropout_29[0][0]']             
                                                                                                  
 tf.__operators__.add_29 (TFOpL  (None, 1, 150)      0           ['conv1d_29[0][0]',              
 ambda)                                                           'tf.__operators__.add_28[0][0]']
                                                                                                  
 batch_normalization_15 (BatchN  (None, 1, 150)      600         ['tf.__operators__.add_29[0][0]']
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_15 (Multi  (None, 1, 150)      38742       ['batch_normalization_15[0][0]', 
 HeadAttention)                                                   'batch_normalization_15[0][0]'] 
                                                                                                  
 dropout_30 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_15[0][0]']
                                                                                                  
 tf.__operators__.add_30 (TFOpL  (None, 1, 150)      0           ['dropout_30[0][0]',             
 ambda)                                                           'tf.__operators__.add_29[0][0]']
                                                                                                  
 layer_normalization_15 (LayerN  (None, 1, 150)      300         ['tf.__operators__.add_30[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_30 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_15[0][0]'] 
                                                                                                  
 dropout_31 (Dropout)           (None, 1, 32)        0           ['conv1d_30[0][0]']              
                                                                                                  
 conv1d_31 (Conv1D)             (None, 1, 150)       4950        ['dropout_31[0][0]']             
                                                                                                  
 tf.__operators__.add_31 (TFOpL  (None, 1, 150)      0           ['conv1d_31[0][0]',              
 ambda)                                                           'tf.__operators__.add_30[0][0]']
                                                                                                  
 dense_14 (Dense)               (None, 1, 128)       19328       ['tf.__operators__.add_31[0][0]']
                                                                                                  
 flatten_7 (Flatten)            (None, 128)          0           ['dense_14[0][0]']               
                                                                                                  
 dense_15 (Dense)               (None, 5)            645         ['flatten_7[0][0]']              
                                                                                                  
==================================================================================================
Total params: 118,821
Trainable params: 118,221
Non-trainable params: 600
__________________________________________________________________________________________________
Epoch 00062: early stopping
Experiment:  50  Set:  ss2 Train Labels:  clean Test Labels:  clean
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
None None
Recording results in matrix at 0 0
AER:  0.318
TER:  0.318, 0.318, 0.318
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.76      0.81      1187
           1       0.62      0.69      0.65      1165
           2       0.61      0.61      0.61      1219
           3       0.58      0.57      0.57      1185
           4       0.76      0.78      0.77      1244

    accuracy                           0.68      6000
   macro avg       0.69      0.68      0.68      6000
weighted avg       0.69      0.68      0.68      6000

Confusion Matrix for this model: 
 [[902 283   2   0   0]
 [123 809 220  12   1]
 [  4 191 743 262  19]
 [  2  16 209 670 288]
 [  9   7  39 221 968]]
Experiment:  51  Set:  ss2 Train Labels:  clean Test Labels:  ncar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 0 1
AER:  0.3481666666666667
TER:  0.331, 0.298, 0.398
Score for this model: 
               precision    recall  f1-score   support

           0       0.82      0.73      0.77      1180
           1       0.60      0.67      0.63      1178
           2       0.59      0.58      0.59      1221
           3       0.55      0.54      0.55      1190
           4       0.72      0.74      0.73      1231

    accuracy                           0.65      6000
   macro avg       0.66      0.65      0.65      6000
weighted avg       0.66      0.65      0.65      6000

Confusion Matrix for this model: 
 [[856 277  14  15  18]
 [123 784 221  28  22]
 [ 21 194 713 259  34]
 [ 17  30 209 645 289]
 [ 23  21  56 218 913]]
Experiment:  52  Set:  ss2 Train Labels:  clean Test Labels:  ncar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 0 2
AER:  0.38466666666666666
TER:  0.356, 0.285, 0.485
Score for this model: 
               precision    recall  f1-score   support

           0       0.78      0.68      0.73      1180
           1       0.56      0.63      0.59      1165
           2       0.57      0.55      0.56      1243
           3       0.51      0.51      0.51      1169
           4       0.68      0.70      0.69      1243

    accuracy                           0.62      6000
   macro avg       0.62      0.61      0.62      6000
weighted avg       0.62      0.62      0.62      6000

Confusion Matrix for this model: 
 [[807 282  26  31  34]
 [138 731 219  48  29]
 [ 34 211 687 266  45]
 [ 33  43 206 593 294]
 [ 28  39  75 227 874]]
Experiment:  53  Set:  ss2 Train Labels:  clean Test Labels:  nar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 0 3
AER:  0.3565
TER:  0.341, 0.306, 0.406
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.76      0.81      1187
           1       0.62      0.56      0.59      1458
           2       0.61      0.61      0.61      1219
           3       0.58      0.57      0.57      1185
           4       0.58      0.77      0.66       951

    accuracy                           0.64      6000
   macro avg       0.65      0.65      0.65      6000
weighted avg       0.65      0.64      0.64      6000

Confusion Matrix for this model: 
 [[902 283   2   0   0]
 [125 812 228  58 235]
 [  4 191 743 262  19]
 [  2  16 209 670 288]
 [  7   4  31 175 734]]
Experiment:  54  Set:  ss2 Train Labels:  clean Test Labels:  nar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 0 4
AER:  0.397
TER:  0.371, 0.297, 0.497
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.76      0.81      1187
           1       0.62      0.46      0.53      1767
           2       0.61      0.61      0.61      1219
           3       0.58      0.57      0.57      1185
           4       0.38      0.76      0.51       642

    accuracy                           0.60      6000
   macro avg       0.61      0.63      0.61      6000
weighted avg       0.63      0.60      0.61      6000

Confusion Matrix for this model: 
 [[902 283   2   0   0]
 [126 813 235 114 479]
 [  4 191 743 262  19]
 [  2  16 209 670 288]
 [  6   3  24 119 490]]
Experiment:  55  Set:  ss2 Train Labels:  clean Test Labels:  nnar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 0 5
AER:  0.3445
TER:  0.327, 0.294, 0.394
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.76      0.81      1191
           1       0.62      0.69      0.65      1174
           2       0.62      0.59      0.60      1272
           3       0.61      0.51      0.55      1401
           4       0.59      0.79      0.68       962

    accuracy                           0.66      6000
   macro avg       0.66      0.67      0.66      6000
weighted avg       0.66      0.66      0.65      6000

Confusion Matrix for this model: 
 [[905 284   2   0   0]
 [123 812 220  13   6]
 [  4 191 748 275  54]
 [  2  16 217 709 457]
 [  6   3  26 168 759]]
Experiment:  56  Set:  ss2 Train Labels:  clean Test Labels:  nnar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 0 6
AER:  0.35633333333333334
TER:  0.320, 0.256, 0.456
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.76      0.81      1194
           1       0.62      0.69      0.65      1179
           2       0.62      0.58      0.60      1299
           3       0.65      0.48      0.55      1568
           4       0.50      0.83      0.62       760

    accuracy                           0.64      6000
   macro avg       0.65      0.67      0.65      6000
weighted avg       0.66      0.64      0.64      6000

Confusion Matrix for this model: 
 [[907 284   2   0   1]
 [123 812 221  14   9]
 [  4 192 753 280  70]
 [  2  16 228 758 564]
 [  4   2   9 113 632]]
Input Shape:  (24000, 1, 150)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_8"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_9 (InputLayer)           [(None, 1, 150)]     0           []                               
                                                                                                  
 batch_normalization_16 (BatchN  (None, 1, 150)      600         ['input_9[0][0]']                
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_16 (Multi  (None, 1, 150)      38742       ['batch_normalization_16[0][0]', 
 HeadAttention)                                                   'batch_normalization_16[0][0]'] 
                                                                                                  
 dropout_32 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_16[0][0]']
                                                                                                  
 tf.__operators__.add_32 (TFOpL  (None, 1, 150)      0           ['dropout_32[0][0]',             
 ambda)                                                           'input_9[0][0]']                
                                                                                                  
 layer_normalization_16 (LayerN  (None, 1, 150)      300         ['tf.__operators__.add_32[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_32 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_16[0][0]'] 
                                                                                                  
 dropout_33 (Dropout)           (None, 1, 32)        0           ['conv1d_32[0][0]']              
                                                                                                  
 conv1d_33 (Conv1D)             (None, 1, 150)       4950        ['dropout_33[0][0]']             
                                                                                                  
 tf.__operators__.add_33 (TFOpL  (None, 1, 150)      0           ['conv1d_33[0][0]',              
 ambda)                                                           'tf.__operators__.add_32[0][0]']
                                                                                                  
 batch_normalization_17 (BatchN  (None, 1, 150)      600         ['tf.__operators__.add_33[0][0]']
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_17 (Multi  (None, 1, 150)      38742       ['batch_normalization_17[0][0]', 
 HeadAttention)                                                   'batch_normalization_17[0][0]'] 
                                                                                                  
 dropout_34 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_17[0][0]']
                                                                                                  
 tf.__operators__.add_34 (TFOpL  (None, 1, 150)      0           ['dropout_34[0][0]',             
 ambda)                                                           'tf.__operators__.add_33[0][0]']
                                                                                                  
 layer_normalization_17 (LayerN  (None, 1, 150)      300         ['tf.__operators__.add_34[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_34 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_17[0][0]'] 
                                                                                                  
 dropout_35 (Dropout)           (None, 1, 32)        0           ['conv1d_34[0][0]']              
                                                                                                  
 conv1d_35 (Conv1D)             (None, 1, 150)       4950        ['dropout_35[0][0]']             
                                                                                                  
 tf.__operators__.add_35 (TFOpL  (None, 1, 150)      0           ['conv1d_35[0][0]',              
 ambda)                                                           'tf.__operators__.add_34[0][0]']
                                                                                                  
 dense_16 (Dense)               (None, 1, 128)       19328       ['tf.__operators__.add_35[0][0]']
                                                                                                  
 flatten_8 (Flatten)            (None, 128)          0           ['dense_16[0][0]']               
                                                                                                  
 dense_17 (Dense)               (None, 5)            645         ['flatten_8[0][0]']              
                                                                                                  
==================================================================================================
Total params: 118,821
Trainable params: 118,221
Non-trainable params: 600
__________________________________________________________________________________________________
Epoch 00058: early stopping
Experiment:  57  Set:  ss2 Train Labels:  ncar5 Test Labels:  clean
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 1 0
AER:  0.35533333333333333
TER:  0.355, 0.355, 0.355
Score for this model: 
               precision    recall  f1-score   support

           0       0.82      0.77      0.79      1187
           1       0.60      0.57      0.58      1165
           2       0.57      0.65      0.61      1219
           3       0.53      0.54      0.54      1185
           4       0.73      0.69      0.71      1244

    accuracy                           0.64      6000
   macro avg       0.65      0.64      0.65      6000
weighted avg       0.65      0.64      0.65      6000

Confusion Matrix for this model: 
 [[916 255  10   0   6]
 [181 663 297  15   9]
 [  7 158 792 230  32]
 [  1  24 251 640 269]
 [ 14  11  49 313 857]]
Experiment:  58  Set:  ss2 Train Labels:  ncar5 Test Labels:  ncar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 1 1
AER:  0.385
TER:  0.372, 0.335, 0.435
Score for this model: 
               precision    recall  f1-score   support

           0       0.77      0.73      0.75      1180
           1       0.57      0.54      0.56      1178
           2       0.54      0.62      0.58      1221
           3       0.51      0.52      0.52      1190
           4       0.70      0.66      0.68      1231

    accuracy                           0.61      6000
   macro avg       0.62      0.61      0.62      6000
weighted avg       0.62      0.61      0.62      6000

Confusion Matrix for this model: 
 [[862 256  24  23  15]
 [186 636 294  38  24]
 [ 25 161 761 232  42]
 [ 19  31 249 615 276]
 [ 27  27  71 290 816]]
Experiment:  59  Set:  ss2 Train Labels:  ncar5 Test Labels:  ncar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 1 2
AER:  0.4161666666666667
TER:  0.395, 0.316, 0.516
Score for this model: 
               precision    recall  f1-score   support

           0       0.74      0.70      0.72      1180
           1       0.54      0.51      0.52      1165
           2       0.52      0.58      0.55      1243
           3       0.49      0.50      0.49      1169
           4       0.66      0.62      0.64      1243

    accuracy                           0.58      6000
   macro avg       0.59      0.58      0.58      6000
weighted avg       0.59      0.58      0.59      6000

Confusion Matrix for this model: 
 [[824 250  38  26  42]
 [185 597 298  53  32]
 [ 36 186 726 233  62]
 [ 35  41 248 582 263]
 [ 39  37  89 304 774]]
Experiment:  60  Set:  ss2 Train Labels:  ncar5 Test Labels:  nar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 1 3
AER:  0.39016666666666666
TER:  0.378, 0.340, 0.440
Score for this model: 
               precision    recall  f1-score   support

           0       0.82      0.77      0.79      1187
           1       0.60      0.46      0.52      1458
           2       0.57      0.65      0.61      1219
           3       0.53      0.54      0.54      1185
           4       0.55      0.68      0.61       951

    accuracy                           0.61      6000
   macro avg       0.61      0.62      0.61      6000
weighted avg       0.62      0.61      0.61      6000

Confusion Matrix for this model: 
 [[916 255  10   0   6]
 [183 666 308  80 221]
 [  7 158 792 230  32]
 [  1  24 251 640 269]
 [ 12   8  38 248 645]]
Experiment:  61  Set:  ss2 Train Labels:  ncar5 Test Labels:  nar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 1 4
AER:  0.42733333333333334
TER:  0.409, 0.327, 0.527
Score for this model: 
               precision    recall  f1-score   support

           0       0.82      0.77      0.79      1187
           1       0.60      0.38      0.46      1767
           2       0.57      0.65      0.61      1219
           3       0.53      0.54      0.54      1185
           4       0.36      0.65      0.46       642

    accuracy                           0.57      6000
   macro avg       0.58      0.60      0.57      6000
weighted avg       0.60      0.57      0.57      6000

Confusion Matrix for this model: 
 [[916 255  10   0   6]
 [187 668 315 151 446]
 [  7 158 792 230  32]
 [  1  24 251 640 269]
 [  8   6  31 177 420]]
Experiment:  62  Set:  ss2 Train Labels:  ncar5 Test Labels:  nnar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 1 5
AER:  0.368
TER:  0.353, 0.318, 0.418
Score for this model: 
               precision    recall  f1-score   support

           0       0.82      0.77      0.80      1191
           1       0.60      0.57      0.58      1174
           2       0.57      0.63      0.60      1272
           3       0.60      0.51      0.55      1401
           4       0.59      0.72      0.65       962

    accuracy                           0.63      6000
   macro avg       0.64      0.64      0.64      6000
weighted avg       0.64      0.63      0.63      6000

Confusion Matrix for this model: 
 [[920 255  10   0   6]
 [183 664 297  16  14]
 [  7 160 800 244  61]
 [  1  26 262 714 398]
 [  8   6  30 224 694]]
Experiment:  63  Set:  ss2 Train Labels:  ncar5 Test Labels:  nnar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 1 6
AER:  0.37816666666666665
TER:  0.348, 0.278, 0.478
Score for this model: 
               precision    recall  f1-score   support

           0       0.82      0.77      0.80      1194
           1       0.60      0.56      0.58      1179
           2       0.57      0.62      0.60      1299
           3       0.64      0.49      0.56      1568
           4       0.49      0.75      0.59       760

    accuracy                           0.62      6000
   macro avg       0.63      0.64      0.62      6000
weighted avg       0.64      0.62      0.62      6000

Confusion Matrix for this model: 
 [[923 255  10   0   6]
 [183 664 297  16  19]
 [  7 160 804 253  75]
 [  1  26 270 769 502]
 [  5   6  18 160 571]]
Input Shape:  (24000, 1, 150)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_9"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_10 (InputLayer)          [(None, 1, 150)]     0           []                               
                                                                                                  
 batch_normalization_18 (BatchN  (None, 1, 150)      600         ['input_10[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_18 (Multi  (None, 1, 150)      38742       ['batch_normalization_18[0][0]', 
 HeadAttention)                                                   'batch_normalization_18[0][0]'] 
                                                                                                  
 dropout_36 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_18[0][0]']
                                                                                                  
 tf.__operators__.add_36 (TFOpL  (None, 1, 150)      0           ['dropout_36[0][0]',             
 ambda)                                                           'input_10[0][0]']               
                                                                                                  
 layer_normalization_18 (LayerN  (None, 1, 150)      300         ['tf.__operators__.add_36[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_36 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_18[0][0]'] 
                                                                                                  
 dropout_37 (Dropout)           (None, 1, 32)        0           ['conv1d_36[0][0]']              
                                                                                                  
 conv1d_37 (Conv1D)             (None, 1, 150)       4950        ['dropout_37[0][0]']             
                                                                                                  
 tf.__operators__.add_37 (TFOpL  (None, 1, 150)      0           ['conv1d_37[0][0]',              
 ambda)                                                           'tf.__operators__.add_36[0][0]']
                                                                                                  
 batch_normalization_19 (BatchN  (None, 1, 150)      600         ['tf.__operators__.add_37[0][0]']
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_19 (Multi  (None, 1, 150)      38742       ['batch_normalization_19[0][0]', 
 HeadAttention)                                                   'batch_normalization_19[0][0]'] 
                                                                                                  
 dropout_38 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_19[0][0]']
                                                                                                  
 tf.__operators__.add_38 (TFOpL  (None, 1, 150)      0           ['dropout_38[0][0]',             
 ambda)                                                           'tf.__operators__.add_37[0][0]']
                                                                                                  
 layer_normalization_19 (LayerN  (None, 1, 150)      300         ['tf.__operators__.add_38[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_38 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_19[0][0]'] 
                                                                                                  
 dropout_39 (Dropout)           (None, 1, 32)        0           ['conv1d_38[0][0]']              
                                                                                                  
 conv1d_39 (Conv1D)             (None, 1, 150)       4950        ['dropout_39[0][0]']             
                                                                                                  
 tf.__operators__.add_39 (TFOpL  (None, 1, 150)      0           ['conv1d_39[0][0]',              
 ambda)                                                           'tf.__operators__.add_38[0][0]']
                                                                                                  
 dense_18 (Dense)               (None, 1, 128)       19328       ['tf.__operators__.add_39[0][0]']
                                                                                                  
 flatten_9 (Flatten)            (None, 128)          0           ['dense_18[0][0]']               
                                                                                                  
 dense_19 (Dense)               (None, 5)            645         ['flatten_9[0][0]']              
                                                                                                  
==================================================================================================
Total params: 118,821
Trainable params: 118,221
Non-trainable params: 600
__________________________________________________________________________________________________
Epoch 00029: early stopping
Experiment:  64  Set:  ss2 Train Labels:  ncar10 Test Labels:  clean
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 2 0
AER:  0.3985
TER:  0.399, 0.399, 0.399
Score for this model: 
               precision    recall  f1-score   support

           0       0.83      0.66      0.74      1187
           1       0.54      0.54      0.54      1165
           2       0.52      0.58      0.55      1219
           3       0.49      0.44      0.46      1185
           4       0.65      0.78      0.71      1244

    accuracy                           0.60      6000
   macro avg       0.61      0.60      0.60      6000
weighted avg       0.61      0.60      0.60      6000

Confusion Matrix for this model: 
 [[787 374  21   2   3]
 [141 631 338  35  20]
 [ 10 139 704 286  80]
 [  3  14 235 518 415]
 [ 12   3  45 215 969]]
Experiment:  65  Set:  ss2 Train Labels:  ncar10 Test Labels:  ncar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 2 1
AER:  0.4235
TER:  0.415, 0.373, 0.473
Score for this model: 
               precision    recall  f1-score   support

           0       0.78      0.63      0.70      1180
           1       0.53      0.52      0.52      1178
           2       0.51      0.56      0.53      1221
           3       0.47      0.42      0.44      1190
           4       0.62      0.74      0.67      1231

    accuracy                           0.58      6000
   macro avg       0.58      0.58      0.58      6000
weighted avg       0.58      0.58      0.58      6000

Confusion Matrix for this model: 
 [[748 359  34  14  25]
 [142 612 327  52  45]
 [ 23 146 683 280  89]
 [ 19  23 238 499 411]
 [ 21  21  61 211 917]]
Experiment:  66  Set:  ss2 Train Labels:  ncar10 Test Labels:  ncar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 2 2
AER:  0.4513333333333333
TER:  0.439, 0.351, 0.551
Score for this model: 
               precision    recall  f1-score   support

           0       0.74      0.59      0.66      1180
           1       0.50      0.50      0.50      1165
           2       0.49      0.53      0.51      1243
           3       0.44      0.40      0.42      1169
           4       0.59      0.71      0.65      1243

    accuracy                           0.55      6000
   macro avg       0.55      0.55      0.55      6000
weighted avg       0.55      0.55      0.55      6000

Confusion Matrix for this model: 
 [[701 364  50  24  41]
 [154 578 314  56  63]
 [ 33 157 662 289 102]
 [ 31  34 236 469 399]
 [ 34  28  81 218 882]]
Experiment:  67  Set:  ss2 Train Labels:  ncar10 Test Labels:  nar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 2 3
AER:  0.438
TER:  0.431, 0.388, 0.488
Score for this model: 
               precision    recall  f1-score   support

           0       0.83      0.66      0.74      1187
           1       0.55      0.43      0.48      1458
           2       0.52      0.58      0.55      1219
           3       0.49      0.44      0.46      1185
           4       0.49      0.77      0.60       951

    accuracy                           0.56      6000
   macro avg       0.58      0.58      0.57      6000
weighted avg       0.58      0.56      0.56      6000

Confusion Matrix for this model: 
 [[787 374  21   2   3]
 [143 633 349  74 259]
 [ 10 139 704 286  80]
 [  3  14 235 518 415]
 [ 10   1  34 176 730]]
Experiment:  68  Set:  ss2 Train Labels:  ncar10 Test Labels:  nar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 2 4
AER:  0.47783333333333333
TER:  0.472, 0.378, 0.578
Score for this model: 
               precision    recall  f1-score   support

           0       0.83      0.66      0.74      1187
           1       0.55      0.36      0.43      1767
           2       0.52      0.58      0.55      1219
           3       0.49      0.44      0.46      1185
           4       0.33      0.76      0.46       642

    accuracy                           0.52      6000
   macro avg       0.54      0.56      0.53      6000
weighted avg       0.56      0.52      0.53      6000

Confusion Matrix for this model: 
 [[787 374  21   2   3]
 [146 633 363 127 498]
 [ 10 139 704 286  80]
 [  3  14 235 518 415]
 [  7   1  20 123 491]]
Experiment:  69  Set:  ss2 Train Labels:  ncar10 Test Labels:  nnar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 2 5
AER:  0.424
TER:  0.416, 0.374, 0.474
Score for this model: 
               precision    recall  f1-score   support

           0       0.83      0.66      0.74      1191
           1       0.54      0.54      0.54      1174
           2       0.53      0.56      0.54      1272
           3       0.53      0.40      0.46      1401
           4       0.51      0.80      0.62       962

    accuracy                           0.58      6000
   macro avg       0.59      0.59      0.58      6000
weighted avg       0.59      0.58      0.57      6000

Confusion Matrix for this model: 
 [[790 375  21   2   3]
 [143 632 338  36  25]
 [ 10 139 710 297 116]
 [  3  14 247 559 578]
 [  7   1  27 162 765]]
Experiment:  70  Set:  ss2 Train Labels:  ncar10 Test Labels:  nnar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 2 6
AER:  0.4355
TER:  0.419, 0.336, 0.535
Score for this model: 
               precision    recall  f1-score   support

           0       0.83      0.66      0.74      1194
           1       0.54      0.54      0.54      1179
           2       0.53      0.55      0.54      1299
           3       0.58      0.39      0.47      1568
           4       0.43      0.84      0.57       760

    accuracy                           0.56      6000
   macro avg       0.58      0.60      0.57      6000
weighted avg       0.59      0.56      0.56      6000

Confusion Matrix for this model: 
 [[792 375  21   2   4]
 [143 632 339  37  28]
 [ 10 140 715 299 135]
 [  3  14 257 611 683]
 [  5   0  11 107 637]]
Input Shape:  (24000, 1, 150)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_10"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_11 (InputLayer)          [(None, 1, 150)]     0           []                               
                                                                                                  
 batch_normalization_20 (BatchN  (None, 1, 150)      600         ['input_11[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_20 (Multi  (None, 1, 150)      38742       ['batch_normalization_20[0][0]', 
 HeadAttention)                                                   'batch_normalization_20[0][0]'] 
                                                                                                  
 dropout_40 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_20[0][0]']
                                                                                                  
 tf.__operators__.add_40 (TFOpL  (None, 1, 150)      0           ['dropout_40[0][0]',             
 ambda)                                                           'input_11[0][0]']               
                                                                                                  
 layer_normalization_20 (LayerN  (None, 1, 150)      300         ['tf.__operators__.add_40[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_40 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_20[0][0]'] 
                                                                                                  
 dropout_41 (Dropout)           (None, 1, 32)        0           ['conv1d_40[0][0]']              
                                                                                                  
 conv1d_41 (Conv1D)             (None, 1, 150)       4950        ['dropout_41[0][0]']             
                                                                                                  
 tf.__operators__.add_41 (TFOpL  (None, 1, 150)      0           ['conv1d_41[0][0]',              
 ambda)                                                           'tf.__operators__.add_40[0][0]']
                                                                                                  
 batch_normalization_21 (BatchN  (None, 1, 150)      600         ['tf.__operators__.add_41[0][0]']
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_21 (Multi  (None, 1, 150)      38742       ['batch_normalization_21[0][0]', 
 HeadAttention)                                                   'batch_normalization_21[0][0]'] 
                                                                                                  
 dropout_42 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_21[0][0]']
                                                                                                  
 tf.__operators__.add_42 (TFOpL  (None, 1, 150)      0           ['dropout_42[0][0]',             
 ambda)                                                           'tf.__operators__.add_41[0][0]']
                                                                                                  
 layer_normalization_21 (LayerN  (None, 1, 150)      300         ['tf.__operators__.add_42[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_42 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_21[0][0]'] 
                                                                                                  
 dropout_43 (Dropout)           (None, 1, 32)        0           ['conv1d_42[0][0]']              
                                                                                                  
 conv1d_43 (Conv1D)             (None, 1, 150)       4950        ['dropout_43[0][0]']             
                                                                                                  
 tf.__operators__.add_43 (TFOpL  (None, 1, 150)      0           ['conv1d_43[0][0]',              
 ambda)                                                           'tf.__operators__.add_42[0][0]']
                                                                                                  
 dense_20 (Dense)               (None, 1, 128)       19328       ['tf.__operators__.add_43[0][0]']
                                                                                                  
 flatten_10 (Flatten)           (None, 128)          0           ['dense_20[0][0]']               
                                                                                                  
 dense_21 (Dense)               (None, 5)            645         ['flatten_10[0][0]']             
                                                                                                  
==================================================================================================
Total params: 118,821
Trainable params: 118,221
Non-trainable params: 600
__________________________________________________________________________________________________
Epoch 00057: early stopping
Experiment:  71  Set:  ss2 Train Labels:  nar5 Test Labels:  clean
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 3 0
AER:  0.36816666666666664
TER:  0.368, 0.368, 0.368
Score for this model: 
               precision    recall  f1-score   support

           0       0.66      0.78      0.72      1187
           1       0.56      0.57      0.56      1165
           2       0.61      0.51      0.55      1219
           3       0.57      0.52      0.54      1185
           4       0.73      0.78      0.76      1244

    accuracy                           0.63      6000
   macro avg       0.63      0.63      0.63      6000
weighted avg       0.63      0.63      0.63      6000

Confusion Matrix for this model: 
 [[928 256   3   0   0]
 [341 661 150   5   8]
 [100 232 616 243  28]
 [ 23  25 206 616 315]
 [ 14   8  28 224 970]]
Experiment:  72  Set:  ss2 Train Labels:  nar5 Test Labels:  ncar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 3 1
AER:  0.3948333333333333
TER:  0.383, 0.345, 0.445
Score for this model: 
               precision    recall  f1-score   support

           0       0.63      0.75      0.69      1180
           1       0.54      0.54      0.54      1178
           2       0.59      0.49      0.53      1221
           3       0.54      0.50      0.52      1190
           4       0.69      0.75      0.72      1231

    accuracy                           0.61      6000
   macro avg       0.60      0.60      0.60      6000
weighted avg       0.60      0.61      0.60      6000

Confusion Matrix for this model: 
 [[887 248  12  16  17]
 [339 640 147  23  29]
 [109 234 594 242  42]
 [ 40  34 209 592 315]
 [ 31  26  41 215 918]]
Experiment:  73  Set:  ss2 Train Labels:  nar5 Test Labels:  ncar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 3 2
AER:  0.426
TER:  0.407, 0.326, 0.526
Score for this model: 
               precision    recall  f1-score   support

           0       0.60      0.72      0.66      1180
           1       0.51      0.52      0.51      1165
           2       0.57      0.46      0.51      1243
           3       0.51      0.47      0.49      1169
           4       0.66      0.70      0.68      1243

    accuracy                           0.57      6000
   macro avg       0.57      0.57      0.57      6000
weighted avg       0.57      0.57      0.57      6000

Confusion Matrix for this model: 
 [[848 245  21  27  39]
 [335 600 156  36  38]
 [115 258 569 241  60]
 [ 59  46 197 555 312]
 [ 49  33  60 229 872]]
Experiment:  74  Set:  ss2 Train Labels:  nar5 Test Labels:  nar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 3 3
AER:  0.4076666666666667
TER:  0.397, 0.358, 0.458
Score for this model: 
               precision    recall  f1-score   support

           0       0.66      0.78      0.72      1187
           1       0.56      0.45      0.50      1458
           2       0.61      0.51      0.55      1219
           3       0.57      0.52      0.54      1185
           4       0.55      0.77      0.64       951

    accuracy                           0.59      6000
   macro avg       0.59      0.61      0.59      6000
weighted avg       0.59      0.59      0.59      6000

Confusion Matrix for this model: 
 [[928 256   3   0   0]
 [343 663 155  50 247]
 [100 232 616 243  28]
 [ 23  25 206 616 315]
 [ 12   6  23 179 731]]
Experiment:  75  Set:  ss2 Train Labels:  nar5 Test Labels:  nar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 3 4
AER:  0.44816666666666666
TER:  0.435, 0.348, 0.548
Score for this model: 
               precision    recall  f1-score   support

           0       0.66      0.78      0.72      1187
           1       0.56      0.38      0.45      1767
           2       0.61      0.51      0.55      1219
           3       0.57      0.52      0.54      1185
           4       0.37      0.76      0.50       642

    accuracy                           0.55      6000
   macro avg       0.55      0.59      0.55      6000
weighted avg       0.57      0.55      0.55      6000

Confusion Matrix for this model: 
 [[928 256   3   0   0]
 [346 664 163 103 491]
 [100 232 616 243  28]
 [ 23  25 206 616 315]
 [  9   5  15 126 487]]
Experiment:  76  Set:  ss2 Train Labels:  nar5 Test Labels:  nnar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 3 5
AER:  0.39566666666666667
TER:  0.384, 0.346, 0.446
Score for this model: 
               precision    recall  f1-score   support

           0       0.66      0.78      0.72      1191
           1       0.56      0.56      0.56      1174
           2       0.62      0.49      0.54      1272
           3       0.60      0.47      0.53      1401
           4       0.57      0.79      0.66       962

    accuracy                           0.60      6000
   macro avg       0.60      0.62      0.60      6000
weighted avg       0.60      0.60      0.60      6000

Confusion Matrix for this model: 
 [[932 256   3   0   0]
 [342 662 150   5  15]
 [100 234 618 254  66]
 [ 24  25 214 656 482]
 [  8   5  18 173 758]]
Experiment:  77  Set:  ss2 Train Labels:  nar5 Test Labels:  nnar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 3 6
AER:  0.4105
TER:  0.388, 0.310, 0.510
Score for this model: 
               precision    recall  f1-score   support

           0       0.66      0.78      0.72      1194
           1       0.56      0.56      0.56      1179
           2       0.62      0.48      0.54      1299
           3       0.64      0.45      0.53      1568
           4       0.47      0.81      0.59       760

    accuracy                           0.59      6000
   macro avg       0.59      0.62      0.59      6000
weighted avg       0.60      0.59      0.58      6000

Confusion Matrix for this model: 
 [[934 256   3   0   1]
 [342 663 150   5  19]
 [100 236 621 259  83]
 [ 24  27 218 700 599]
 [  6   0  11 124 619]]
Input Shape:  (24000, 1, 150)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_11"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_12 (InputLayer)          [(None, 1, 150)]     0           []                               
                                                                                                  
 batch_normalization_22 (BatchN  (None, 1, 150)      600         ['input_12[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_22 (Multi  (None, 1, 150)      38742       ['batch_normalization_22[0][0]', 
 HeadAttention)                                                   'batch_normalization_22[0][0]'] 
                                                                                                  
 dropout_44 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_22[0][0]']
                                                                                                  
 tf.__operators__.add_44 (TFOpL  (None, 1, 150)      0           ['dropout_44[0][0]',             
 ambda)                                                           'input_12[0][0]']               
                                                                                                  
 layer_normalization_22 (LayerN  (None, 1, 150)      300         ['tf.__operators__.add_44[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_44 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_22[0][0]'] 
                                                                                                  
 dropout_45 (Dropout)           (None, 1, 32)        0           ['conv1d_44[0][0]']              
                                                                                                  
 conv1d_45 (Conv1D)             (None, 1, 150)       4950        ['dropout_45[0][0]']             
                                                                                                  
 tf.__operators__.add_45 (TFOpL  (None, 1, 150)      0           ['conv1d_45[0][0]',              
 ambda)                                                           'tf.__operators__.add_44[0][0]']
                                                                                                  
 batch_normalization_23 (BatchN  (None, 1, 150)      600         ['tf.__operators__.add_45[0][0]']
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_23 (Multi  (None, 1, 150)      38742       ['batch_normalization_23[0][0]', 
 HeadAttention)                                                   'batch_normalization_23[0][0]'] 
                                                                                                  
 dropout_46 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_23[0][0]']
                                                                                                  
 tf.__operators__.add_46 (TFOpL  (None, 1, 150)      0           ['dropout_46[0][0]',             
 ambda)                                                           'tf.__operators__.add_45[0][0]']
                                                                                                  
 layer_normalization_23 (LayerN  (None, 1, 150)      300         ['tf.__operators__.add_46[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_46 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_23[0][0]'] 
                                                                                                  
 dropout_47 (Dropout)           (None, 1, 32)        0           ['conv1d_46[0][0]']              
                                                                                                  
 conv1d_47 (Conv1D)             (None, 1, 150)       4950        ['dropout_47[0][0]']             
                                                                                                  
 tf.__operators__.add_47 (TFOpL  (None, 1, 150)      0           ['conv1d_47[0][0]',              
 ambda)                                                           'tf.__operators__.add_46[0][0]']
                                                                                                  
 dense_22 (Dense)               (None, 1, 128)       19328       ['tf.__operators__.add_47[0][0]']
                                                                                                  
 flatten_11 (Flatten)           (None, 128)          0           ['dense_22[0][0]']               
                                                                                                  
 dense_23 (Dense)               (None, 5)            645         ['flatten_11[0][0]']             
                                                                                                  
==================================================================================================
Total params: 118,821
Trainable params: 118,221
Non-trainable params: 600
__________________________________________________________________________________________________
Epoch 00039: early stopping
Experiment:  78  Set:  ss2 Train Labels:  nar10 Test Labels:  clean
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 4 0
AER:  0.4125
TER:  0.412, 0.412, 0.412
Score for this model: 
               precision    recall  f1-score   support

           0       0.55      0.77      0.64      1187
           1       0.52      0.54      0.53      1165
           2       0.67      0.23      0.34      1219
           3       0.54      0.58      0.56      1185
           4       0.71      0.82      0.76      1244

    accuracy                           0.59      6000
   macro avg       0.60      0.59      0.57      6000
weighted avg       0.60      0.59      0.57      6000

Confusion Matrix for this model: 
 [[ 909  277    1    0    0]
 [ 441  631   64   21    8]
 [ 251  260  282  386   40]
 [  33   31   67  684  370]
 [  22   10    7  186 1019]]
Experiment:  79  Set:  ss2 Train Labels:  nar10 Test Labels:  ncar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 4 1
AER:  0.44016666666666665
TER:  0.434, 0.390, 0.490
Score for this model: 
               precision    recall  f1-score   support

           0       0.52      0.73      0.61      1180
           1       0.50      0.51      0.50      1178
           2       0.64      0.22      0.33      1221
           3       0.52      0.56      0.54      1190
           4       0.67      0.78      0.72      1231

    accuracy                           0.56      6000
   macro avg       0.57      0.56      0.54      6000
weighted avg       0.57      0.56      0.54      6000

Confusion Matrix for this model: 
 [[862 276   6  13  23]
 [442 600  65  39  32]
 [259 259 270 377  56]
 [ 52  45  68 663 362]
 [ 41  29  12 185 964]]
Experiment:  80  Set:  ss2 Train Labels:  nar10 Test Labels:  ncar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 4 2
AER:  0.46366666666666667
TER:  0.455, 0.364, 0.564
Score for this model: 
               precision    recall  f1-score   support

           0       0.50      0.71      0.59      1180
           1       0.48      0.50      0.49      1165
           2       0.61      0.21      0.31      1243
           3       0.49      0.53      0.51      1169
           4       0.65      0.75      0.69      1243

    accuracy                           0.54      6000
   macro avg       0.55      0.54      0.52      6000
weighted avg       0.55      0.54      0.52      6000

Confusion Matrix for this model: 
 [[833 269  11  26  41]
 [424 577  62  57  45]
 [263 277 258 375  70]
 [ 77  48  67 623 354]
 [ 59  38  23 196 927]]
Experiment:  81  Set:  ss2 Train Labels:  nar10 Test Labels:  nar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 4 3
AER:  0.4528333333333333
TER:  0.448, 0.403, 0.503
Score for this model: 
               precision    recall  f1-score   support

           0       0.55      0.77      0.64      1187
           1       0.52      0.43      0.47      1458
           2       0.67      0.23      0.34      1219
           3       0.54      0.58      0.56      1185
           4       0.54      0.81      0.65       951

    accuracy                           0.55      6000
   macro avg       0.56      0.56      0.53      6000
weighted avg       0.56      0.55      0.52      6000

Confusion Matrix for this model: 
 [[909 277   1   0   0]
 [445 633  65  63 252]
 [251 260 282 386  40]
 [ 33  31  67 684 370]
 [ 18   8   6 144 775]]
Experiment:  82  Set:  ss2 Train Labels:  nar10 Test Labels:  nar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 4 4
AER:  0.49516666666666664
TER:  0.494, 0.395, 0.595
Score for this model: 
               precision    recall  f1-score   support

           0       0.55      0.77      0.64      1187
           1       0.53      0.36      0.43      1767
           2       0.67      0.23      0.34      1219
           3       0.54      0.58      0.56      1185
           4       0.36      0.81      0.50       642

    accuracy                           0.50      6000
   macro avg       0.53      0.55      0.49      6000
weighted avg       0.54      0.50      0.49      6000

Confusion Matrix for this model: 
 [[909 277   1   0   0]
 [451 635  66 107 508]
 [251 260 282 386  40]
 [ 33  31  67 684 370]
 [ 12   6   5 100 519]]
Experiment:  83  Set:  ss2 Train Labels:  nar10 Test Labels:  nnar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 4 5
AER:  0.44033333333333335
TER:  0.434, 0.390, 0.490
Score for this model: 
               precision    recall  f1-score   support

           0       0.55      0.77      0.64      1191
           1       0.52      0.54      0.53      1174
           2       0.67      0.22      0.34      1272
           3       0.57      0.52      0.54      1401
           4       0.56      0.83      0.67       962

    accuracy                           0.56      6000
   macro avg       0.58      0.58      0.54      6000
weighted avg       0.58      0.56      0.54      6000

Confusion Matrix for this model: 
 [[913 277   1   0   0]
 [441 633  64  21  15]
 [253 264 284 392  79]
 [ 35  31  68 726 541]
 [ 14   4   4 138 802]]
Experiment:  84  Set:  ss2 Train Labels:  nar10 Test Labels:  nnar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 4 6
AER:  0.45666666666666667
TER:  0.446, 0.357, 0.557
Score for this model: 
               precision    recall  f1-score   support

           0       0.55      0.77      0.64      1194
           1       0.52      0.54      0.53      1179
           2       0.67      0.22      0.33      1299
           3       0.60      0.49      0.54      1568
           4       0.46      0.87      0.60       760

    accuracy                           0.54      6000
   macro avg       0.56      0.58      0.53      6000
weighted avg       0.57      0.54      0.52      6000

Confusion Matrix for this model: 
 [[915 277   1   0   1]
 [442 633  64  22  18]
 [254 266 284 395 100]
 [ 38  31  69 770 660]
 [  7   2   3  90 658]]
Input Shape:  (24000, 1, 150)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_12"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_13 (InputLayer)          [(None, 1, 150)]     0           []                               
                                                                                                  
 batch_normalization_24 (BatchN  (None, 1, 150)      600         ['input_13[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_24 (Multi  (None, 1, 150)      38742       ['batch_normalization_24[0][0]', 
 HeadAttention)                                                   'batch_normalization_24[0][0]'] 
                                                                                                  
 dropout_48 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_24[0][0]']
                                                                                                  
 tf.__operators__.add_48 (TFOpL  (None, 1, 150)      0           ['dropout_48[0][0]',             
 ambda)                                                           'input_13[0][0]']               
                                                                                                  
 layer_normalization_24 (LayerN  (None, 1, 150)      300         ['tf.__operators__.add_48[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_48 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_24[0][0]'] 
                                                                                                  
 dropout_49 (Dropout)           (None, 1, 32)        0           ['conv1d_48[0][0]']              
                                                                                                  
 conv1d_49 (Conv1D)             (None, 1, 150)       4950        ['dropout_49[0][0]']             
                                                                                                  
 tf.__operators__.add_49 (TFOpL  (None, 1, 150)      0           ['conv1d_49[0][0]',              
 ambda)                                                           'tf.__operators__.add_48[0][0]']
                                                                                                  
 batch_normalization_25 (BatchN  (None, 1, 150)      600         ['tf.__operators__.add_49[0][0]']
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_25 (Multi  (None, 1, 150)      38742       ['batch_normalization_25[0][0]', 
 HeadAttention)                                                   'batch_normalization_25[0][0]'] 
                                                                                                  
 dropout_50 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_25[0][0]']
                                                                                                  
 tf.__operators__.add_50 (TFOpL  (None, 1, 150)      0           ['dropout_50[0][0]',             
 ambda)                                                           'tf.__operators__.add_49[0][0]']
                                                                                                  
 layer_normalization_25 (LayerN  (None, 1, 150)      300         ['tf.__operators__.add_50[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_50 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_25[0][0]'] 
                                                                                                  
 dropout_51 (Dropout)           (None, 1, 32)        0           ['conv1d_50[0][0]']              
                                                                                                  
 conv1d_51 (Conv1D)             (None, 1, 150)       4950        ['dropout_51[0][0]']             
                                                                                                  
 tf.__operators__.add_51 (TFOpL  (None, 1, 150)      0           ['conv1d_51[0][0]',              
 ambda)                                                           'tf.__operators__.add_50[0][0]']
                                                                                                  
 dense_24 (Dense)               (None, 1, 128)       19328       ['tf.__operators__.add_51[0][0]']
                                                                                                  
 flatten_12 (Flatten)           (None, 128)          0           ['dense_24[0][0]']               
                                                                                                  
 dense_25 (Dense)               (None, 5)            645         ['flatten_12[0][0]']             
                                                                                                  
==================================================================================================
Total params: 118,821
Trainable params: 118,221
Non-trainable params: 600
__________________________________________________________________________________________________
Epoch 00061: early stopping
Experiment:  85  Set:  ss2 Train Labels:  nnar5 Test Labels:  clean
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 5 0
AER:  0.3318333333333333
TER:  0.332, 0.332, 0.332
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      0.79      0.83      1187
           1       0.64      0.72      0.68      1165
           2       0.64      0.46      0.54      1219
           3       0.51      0.57      0.54      1185
           4       0.71      0.80      0.75      1244

    accuracy                           0.67      6000
   macro avg       0.67      0.67      0.67      6000
weighted avg       0.67      0.67      0.67      6000

Confusion Matrix for this model: 
 [[939 247   1   0   0]
 [122 836 177  26   4]
 [  0 201 564 407  47]
 [  2  20 125 671 367]
 [ 10   8  20 207 999]]
Experiment:  86  Set:  ss2 Train Labels:  nnar5 Test Labels:  ncar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 5 1
AER:  0.361
TER:  0.346, 0.311, 0.411
Score for this model: 
               precision    recall  f1-score   support

           0       0.83      0.75      0.79      1180
           1       0.62      0.69      0.65      1178
           2       0.61      0.44      0.51      1221
           3       0.50      0.55      0.52      1190
           4       0.67      0.77      0.71      1231

    accuracy                           0.64      6000
   macro avg       0.64      0.64      0.64      6000
weighted avg       0.64      0.64      0.64      6000

Confusion Matrix for this model: 
 [[889 245  10  17  19]
 [126 807 173  43  29]
 [ 16 205 542 396  62]
 [ 19  31 129 650 361]
 [ 23  24  33 205 946]]
Experiment:  87  Set:  ss2 Train Labels:  nnar5 Test Labels:  ncar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 5 2
AER:  0.39416666666666667
TER:  0.368, 0.294, 0.494
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.71      0.75      1180
           1       0.57      0.64      0.60      1165
           2       0.59      0.42      0.49      1243
           3       0.46      0.52      0.49      1169
           4       0.64      0.73      0.69      1243

    accuracy                           0.61      6000
   macro avg       0.61      0.61      0.60      6000
weighted avg       0.61      0.61      0.60      6000

Confusion Matrix for this model: 
 [[843 250  17  31  39]
 [144 748 174  61  38]
 [ 29 217 524 401  72]
 [ 27  53 125 608 356]
 [ 30  44  47 210 912]]
Experiment:  88  Set:  ss2 Train Labels:  nnar5 Test Labels:  nar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 5 3
AER:  0.371
TER:  0.357, 0.321, 0.421
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      0.79      0.83      1187
           1       0.64      0.58      0.61      1458
           2       0.64      0.46      0.54      1219
           3       0.51      0.57      0.54      1185
           4       0.54      0.80      0.64       951

    accuracy                           0.63      6000
   macro avg       0.64      0.64      0.63      6000
weighted avg       0.64      0.63      0.63      6000

Confusion Matrix for this model: 
 [[939 247   1   0   0]
 [124 840 181  70 243]
 [  0 201 564 407  47]
 [  2  20 125 671 367]
 [  8   4  16 163 760]]
Experiment:  89  Set:  ss2 Train Labels:  nnar5 Test Labels:  nar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 5 4
AER:  0.4141666666666667
TER:  0.393, 0.314, 0.514
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      0.79      0.83      1187
           1       0.64      0.48      0.55      1767
           2       0.64      0.46      0.54      1219
           3       0.51      0.57      0.54      1185
           4       0.35      0.78      0.49       642

    accuracy                           0.59      6000
   macro avg       0.60      0.61      0.59      6000
weighted avg       0.63      0.59      0.59      6000

Confusion Matrix for this model: 
 [[939 247   1   0   0]
 [126 841 188 109 503]
 [  0 201 564 407  47]
 [  2  20 125 671 367]
 [  6   3   9 124 500]]
Experiment:  90  Set:  ss2 Train Labels:  nnar5 Test Labels:  nnar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 5 5
AER:  0.35833333333333334
TER:  0.343, 0.308, 0.408
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      0.79      0.83      1191
           1       0.64      0.71      0.67      1174
           2       0.64      0.44      0.52      1272
           3       0.54      0.51      0.53      1401
           4       0.56      0.82      0.66       962

    accuracy                           0.64      6000
   macro avg       0.65      0.66      0.64      6000
weighted avg       0.65      0.64      0.64      6000

Confusion Matrix for this model: 
 [[943 247   1   0   0]
 [122 839 177  27   9]
 [  0 202 566 418  86]
 [  2  20 131 714 534]
 [  6   4  12 152 788]]
Experiment:  91  Set:  ss2 Train Labels:  nnar5 Test Labels:  nnar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 5 6
AER:  0.37633333333333335
TER:  0.345, 0.276, 0.476
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      0.79      0.83      1194
           1       0.64      0.71      0.67      1179
           2       0.64      0.44      0.52      1299
           3       0.57      0.48      0.52      1568
           4       0.45      0.84      0.59       760

    accuracy                           0.62      6000
   macro avg       0.64      0.65      0.63      6000
weighted avg       0.65      0.62      0.62      6000

Confusion Matrix for this model: 
 [[945 247   1   0   1]
 [122 840 177  27  13]
 [  0 203 568 424 104]
 [  2  20 136 750 660]
 [  4   2   5 110 639]]
Input Shape:  (24000, 1, 150)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_13"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_14 (InputLayer)          [(None, 1, 150)]     0           []                               
                                                                                                  
 batch_normalization_26 (BatchN  (None, 1, 150)      600         ['input_14[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_26 (Multi  (None, 1, 150)      38742       ['batch_normalization_26[0][0]', 
 HeadAttention)                                                   'batch_normalization_26[0][0]'] 
                                                                                                  
 dropout_52 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_26[0][0]']
                                                                                                  
 tf.__operators__.add_52 (TFOpL  (None, 1, 150)      0           ['dropout_52[0][0]',             
 ambda)                                                           'input_14[0][0]']               
                                                                                                  
 layer_normalization_26 (LayerN  (None, 1, 150)      300         ['tf.__operators__.add_52[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_52 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_26[0][0]'] 
                                                                                                  
 dropout_53 (Dropout)           (None, 1, 32)        0           ['conv1d_52[0][0]']              
                                                                                                  
 conv1d_53 (Conv1D)             (None, 1, 150)       4950        ['dropout_53[0][0]']             
                                                                                                  
 tf.__operators__.add_53 (TFOpL  (None, 1, 150)      0           ['conv1d_53[0][0]',              
 ambda)                                                           'tf.__operators__.add_52[0][0]']
                                                                                                  
 batch_normalization_27 (BatchN  (None, 1, 150)      600         ['tf.__operators__.add_53[0][0]']
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_27 (Multi  (None, 1, 150)      38742       ['batch_normalization_27[0][0]', 
 HeadAttention)                                                   'batch_normalization_27[0][0]'] 
                                                                                                  
 dropout_54 (Dropout)           (None, 1, 150)       0           ['multi_head_attention_27[0][0]']
                                                                                                  
 tf.__operators__.add_54 (TFOpL  (None, 1, 150)      0           ['dropout_54[0][0]',             
 ambda)                                                           'tf.__operators__.add_53[0][0]']
                                                                                                  
 layer_normalization_27 (LayerN  (None, 1, 150)      300         ['tf.__operators__.add_54[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_54 (Conv1D)             (None, 1, 32)        4832        ['layer_normalization_27[0][0]'] 
                                                                                                  
 dropout_55 (Dropout)           (None, 1, 32)        0           ['conv1d_54[0][0]']              
                                                                                                  
 conv1d_55 (Conv1D)             (None, 1, 150)       4950        ['dropout_55[0][0]']             
                                                                                                  
 tf.__operators__.add_55 (TFOpL  (None, 1, 150)      0           ['conv1d_55[0][0]',              
 ambda)                                                           'tf.__operators__.add_54[0][0]']
                                                                                                  
 dense_26 (Dense)               (None, 1, 128)       19328       ['tf.__operators__.add_55[0][0]']
                                                                                                  
 flatten_13 (Flatten)           (None, 128)          0           ['dense_26[0][0]']               
                                                                                                  
 dense_27 (Dense)               (None, 5)            645         ['flatten_13[0][0]']             
                                                                                                  
==================================================================================================
Total params: 118,821
Trainable params: 118,221
Non-trainable params: 600
__________________________________________________________________________________________________
Epoch 00042: early stopping
Experiment:  92  Set:  ss2 Train Labels:  nnar10 Test Labels:  clean
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 6 0
AER:  0.3675
TER:  0.367, 0.367, 0.367
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.71      0.78      1187
           1       0.57      0.73      0.64      1165
           2       0.63      0.34      0.44      1219
           3       0.47      0.59      0.52      1185
           4       0.70      0.80      0.75      1244

    accuracy                           0.63      6000
   macro avg       0.65      0.63      0.63      6000
weighted avg       0.65      0.63      0.63      6000

Confusion Matrix for this model: 
 [[839 346   1   1   0]
 [114 851 155  41   4]
 [  0 240 412 522  45]
 [  1  38  77 694 375]
 [ 10  13  11 211 999]]
Experiment:  93  Set:  ss2 Train Labels:  nnar10 Test Labels:  ncar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 6 1
AER:  0.3923333333333333
TER:  0.380, 0.342, 0.442
Score for this model: 
               precision    recall  f1-score   support

           0       0.83      0.68      0.75      1180
           1       0.56      0.70      0.62      1178
           2       0.60      0.32      0.42      1221
           3       0.46      0.57      0.51      1190
           4       0.66      0.77      0.71      1231

    accuracy                           0.61      6000
   macro avg       0.62      0.61      0.60      6000
weighted avg       0.62      0.61      0.60      6000

Confusion Matrix for this model: 
 [[802 332   9  15  22]
 [111 830 154  55  28]
 [ 15 241 396 506  63]
 [ 14  53  79 676 368]
 [ 22  32  18 217 942]]
Experiment:  94  Set:  ss2 Train Labels:  nnar10 Test Labels:  ncar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 6 2
AER:  0.42966666666666664
TER:  0.412, 0.330, 0.530
Score for this model: 
               precision    recall  f1-score   support

           0       0.77      0.63      0.70      1180
           1       0.51      0.66      0.58      1165
           2       0.59      0.31      0.41      1243
           3       0.43      0.53      0.47      1169
           4       0.63      0.72      0.68      1243

    accuracy                           0.57      6000
   macro avg       0.59      0.57      0.57      6000
weighted avg       0.59      0.57      0.57      6000

Confusion Matrix for this model: 
 [[746 346  14  33  41]
 [130 766 152  76  41]
 [ 27 260 385 499  72]
 [ 28  71  76 625 369]
 [ 33  45  29 236 900]]
Experiment:  95  Set:  ss2 Train Labels:  nnar10 Test Labels:  nar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 6 3
AER:  0.4075
TER:  0.397, 0.357, 0.457
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.71      0.78      1187
           1       0.57      0.59      0.58      1458
           2       0.63      0.34      0.44      1219
           3       0.47      0.59      0.52      1185
           4       0.53      0.80      0.64       951

    accuracy                           0.59      6000
   macro avg       0.62      0.60      0.59      6000
weighted avg       0.62      0.59      0.59      6000

Confusion Matrix for this model: 
 [[839 346   1   1   0]
 [116 853 158  85 246]
 [  0 240 412 522  45]
 [  1  38  77 694 375]
 [  8  11   8 167 757]]
Experiment:  96  Set:  ss2 Train Labels:  nnar10 Test Labels:  nar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 6 4
AER:  0.4508333333333333
TER:  0.439, 0.351, 0.551
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.71      0.78      1187
           1       0.58      0.48      0.53      1767
           2       0.63      0.34      0.44      1219
           3       0.47      0.59      0.52      1185
           4       0.35      0.77      0.48       642

    accuracy                           0.55      6000
   macro avg       0.58      0.58      0.55      6000
weighted avg       0.60      0.55      0.55      6000

Confusion Matrix for this model: 
 [[839 346   1   1   0]
 [119 856 159 124 509]
 [  0 240 412 522  45]
 [  1  38  77 694 375]
 [  5   8   7 128 494]]
Experiment:  97  Set:  ss2 Train Labels:  nnar10 Test Labels:  nnar5
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 6 5
AER:  0.39166666666666666
TER:  0.380, 0.342, 0.442
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.71      0.78      1191
           1       0.57      0.73      0.64      1174
           2       0.63      0.32      0.43      1272
           3       0.51      0.53      0.52      1401
           4       0.56      0.83      0.67       962

    accuracy                           0.61      6000
   macro avg       0.63      0.62      0.61      6000
weighted avg       0.63      0.61      0.60      6000

Confusion Matrix for this model: 
 [[841 348   1   1   0]
 [116 853 155  42   8]
 [  0 244 413 534  81]
 [  1  38  81 745 536]
 [  6   5   6 147 798]]
Experiment:  98  Set:  ss2 Train Labels:  nnar10 Test Labels:  nnar10
Shape of X_train:  (24000, 1, 150)
Shape of X_test:  (6000, 1, 150)
Shape of y_train:  (24000, 5)
Shape of y_test:  (6000, 5)
NUM_INSTANCES is  24000
instances should be  24000
Shape of y true: (6000,)
Shape of y predicted: (6000,)
[0.02867235 0.10279214 0.09830579 0.10280374 0.0647603 ] [0.2401011  0.3055794  0.390484   0.43459916 0.22186495]
Recording results in matrix at 6 6
AER:  0.407
TER:  0.384, 0.307, 0.507
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.71      0.78      1194
           1       0.57      0.72      0.64      1179
           2       0.63      0.32      0.42      1299
           3       0.54      0.50      0.52      1568
           4       0.46      0.87      0.60       760

    accuracy                           0.59      6000
   macro avg       0.62      0.62      0.59      6000
weighted avg       0.62      0.59      0.59      6000

Confusion Matrix for this model: 
 [[843 348   1   1   1]
 [116 854 156  42  11]
 [  0 245 413 541 100]
 [  1  40  84 790 653]
 [  4   1   2  95 658]]
Input Shape:  (2077, 1, 96)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_14"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_15 (InputLayer)          [(None, 1, 96)]      0           []                               
                                                                                                  
 batch_normalization_28 (BatchN  (None, 1, 96)       384         ['input_15[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_28 (Multi  (None, 1, 96)       24864       ['batch_normalization_28[0][0]', 
 HeadAttention)                                                   'batch_normalization_28[0][0]'] 
                                                                                                  
 dropout_56 (Dropout)           (None, 1, 96)        0           ['multi_head_attention_28[0][0]']
                                                                                                  
 tf.__operators__.add_56 (TFOpL  (None, 1, 96)       0           ['dropout_56[0][0]',             
 ambda)                                                           'input_15[0][0]']               
                                                                                                  
 layer_normalization_28 (LayerN  (None, 1, 96)       192         ['tf.__operators__.add_56[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_56 (Conv1D)             (None, 1, 32)        3104        ['layer_normalization_28[0][0]'] 
                                                                                                  
 dropout_57 (Dropout)           (None, 1, 32)        0           ['conv1d_56[0][0]']              
                                                                                                  
 conv1d_57 (Conv1D)             (None, 1, 96)        3168        ['dropout_57[0][0]']             
                                                                                                  
 tf.__operators__.add_57 (TFOpL  (None, 1, 96)       0           ['conv1d_57[0][0]',              
 ambda)                                                           'tf.__operators__.add_56[0][0]']
                                                                                                  
 batch_normalization_29 (BatchN  (None, 1, 96)       384         ['tf.__operators__.add_57[0][0]']
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_29 (Multi  (None, 1, 96)       24864       ['batch_normalization_29[0][0]', 
 HeadAttention)                                                   'batch_normalization_29[0][0]'] 
                                                                                                  
 dropout_58 (Dropout)           (None, 1, 96)        0           ['multi_head_attention_29[0][0]']
                                                                                                  
 tf.__operators__.add_58 (TFOpL  (None, 1, 96)       0           ['dropout_58[0][0]',             
 ambda)                                                           'tf.__operators__.add_57[0][0]']
                                                                                                  
 layer_normalization_29 (LayerN  (None, 1, 96)       192         ['tf.__operators__.add_58[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_58 (Conv1D)             (None, 1, 32)        3104        ['layer_normalization_29[0][0]'] 
                                                                                                  
 dropout_59 (Dropout)           (None, 1, 32)        0           ['conv1d_58[0][0]']              
                                                                                                  
 conv1d_59 (Conv1D)             (None, 1, 96)        3168        ['dropout_59[0][0]']             
                                                                                                  
 tf.__operators__.add_59 (TFOpL  (None, 1, 96)       0           ['conv1d_59[0][0]',              
 ambda)                                                           'tf.__operators__.add_58[0][0]']
                                                                                                  
 dense_28 (Dense)               (None, 1, 128)       12416       ['tf.__operators__.add_59[0][0]']
                                                                                                  
 flatten_14 (Flatten)           (None, 128)          0           ['dense_28[0][0]']               
                                                                                                  
 dense_29 (Dense)               (None, 6)            774         ['flatten_14[0][0]']             
                                                                                                  
==================================================================================================
Total params: 76,614
Trainable params: 76,230
Non-trainable params: 384
__________________________________________________________________________________________________
Epoch 00039: early stopping
Experiment:  99  Set:  har1 Train Labels:  clean Test Labels:  clean
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
None None
Recording results in matrix at 0 0
AER:  0.30980751604032997
TER:  0.310, 0.310, 0.310
Score for this model: 
               precision    recall  f1-score   support

           0       0.66      0.43      0.52       173
           1       0.92      0.64      0.76       173
           2       0.55      0.77      0.64       171
           3       0.71      0.60      0.65       186
           4       0.61      0.88      0.72       198
           5       0.85      0.79      0.82       190

    accuracy                           0.69      1091
   macro avg       0.72      0.69      0.68      1091
weighted avg       0.72      0.69      0.69      1091

Confusion Matrix for this model: 
 [[ 74   3   0   5  75  16]
 [  0 111  62   0   0   0]
 [  4   1 131  35   0   0]
 [ 25   3  30 112  14   2]
 [  9   1   0   5 174   9]
 [  0   2  15   1  21 151]]
Experiment:  100  Set:  har1 Train Labels:  clean Test Labels:  ncar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 0 1
AER:  0.34280476626947753
TER:  0.325, 0.293, 0.393
Score for this model: 
               precision    recall  f1-score   support

           0       0.61      0.41      0.49       165
           1       0.88      0.60      0.71       176
           2       0.54      0.72      0.62       179
           3       0.68      0.57      0.62       187
           4       0.59      0.84      0.69       199
           5       0.79      0.76      0.77       185

    accuracy                           0.66      1091
   macro avg       0.68      0.65      0.65      1091
weighted avg       0.68      0.66      0.65      1091

Confusion Matrix for this model: 
 [[ 68   3   2   5  71  16]
 [  2 106  60   1   5   2]
 [  7   5 129  34   3   1]
 [ 26   4  30 107  16   4]
 [  8   1   1   7 167  15]
 [  1   2  16   4  22 140]]
Experiment:  101  Set:  har1 Train Labels:  clean Test Labels:  ncar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 0 2
AER:  0.3767186067827681
TER:  0.346, 0.277, 0.477
Score for this model: 
               precision    recall  f1-score   support

           0       0.56      0.37      0.45       170
           1       0.80      0.56      0.66       172
           2       0.51      0.69      0.58       176
           3       0.64      0.54      0.58       188
           4       0.56      0.80      0.66       199
           5       0.78      0.75      0.76       186

    accuracy                           0.62      1091
   macro avg       0.64      0.62      0.62      1091
weighted avg       0.64      0.62      0.62      1091

Confusion Matrix for this model: 
 [[ 63   5   5   8  71  18]
 [  3  97  59   5   4   4]
 [  6   5 121  34   7   3]
 [ 26   5  33 101  20   3]
 [ 12   5   4   8 159  11]
 [  2   4  16   2  23 139]]
Experiment:  102  Set:  har1 Train Labels:  clean Test Labels:  nar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 0 3
AER:  0.3538038496791934
TER:  0.338, 0.304, 0.404
Score for this model: 
               precision    recall  f1-score   support

           0       0.66      0.43      0.52       173
           1       0.92      0.64      0.76       173
           2       0.55      0.59      0.57       223
           3       0.71      0.60      0.65       186
           4       0.44      0.86      0.59       146
           5       0.85      0.79      0.82       190

    accuracy                           0.65      1091
   macro avg       0.69      0.65      0.65      1091
weighted avg       0.69      0.65      0.65      1091

Confusion Matrix for this model: 
 [[ 74   3   0   5  75  16]
 [  0 111  62   0   0   0]
 [  5   1 131  37  48   1]
 [ 25   3  30 112  14   2]
 [  8   1   0   3 126   8]
 [  0   2  15   1  21 151]]
Experiment:  103  Set:  har1 Train Labels:  clean Test Labels:  nar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 0 4
AER:  0.39780018331805683
TER:  0.372, 0.298, 0.498
Score for this model: 
               precision    recall  f1-score   support

           0       0.66      0.43      0.52       173
           1       0.92      0.64      0.76       173
           2       0.55      0.46      0.50       282
           3       0.71      0.60      0.65       186
           4       0.27      0.90      0.42        87
           5       0.85      0.79      0.82       190

    accuracy                           0.60      1091
   macro avg       0.66      0.64      0.61      1091
weighted avg       0.68      0.60      0.62      1091

Confusion Matrix for this model: 
 [[ 74   3   0   5  75  16]
 [  0 111  62   0   0   0]
 [  9   1 131  38  96   7]
 [ 25   3  30 112  14   2]
 [  4   1   0   2  78   2]
 [  0   2  15   1  21 151]]
Experiment:  104  Set:  har1 Train Labels:  clean Test Labels:  nnar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 0 5
AER:  0.3483043079743355
TER:  0.331, 0.298, 0.398
Score for this model: 
               precision    recall  f1-score   support

           0       0.66      0.43      0.52       173
           1       0.92      0.64      0.76       173
           2       0.55      0.58      0.56       226
           3       0.71      0.60      0.65       186
           4       0.46      0.92      0.62       143
           5       0.85      0.79      0.82       190

    accuracy                           0.65      1091
   macro avg       0.69      0.66      0.65      1091
weighted avg       0.69      0.65      0.65      1091

Confusion Matrix for this model: 
 [[ 74   3   0   5  75  16]
 [  0 111  62   0   0   0]
 [  9   1 131  38  42   5]
 [ 25   3  30 112  14   2]
 [  4   1   0   2 132   4]
 [  0   2  15   1  21 151]]
Experiment:  105  Set:  har1 Train Labels:  clean Test Labels:  nnar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 0 6
AER:  0.3923006416131989
TER:  0.365, 0.292, 0.492
Score for this model: 
               precision    recall  f1-score   support

           0       0.66      0.43      0.52       173
           1       0.92      0.64      0.76       173
           2       0.55      0.47      0.50       281
           3       0.71      0.60      0.65       186
           4       0.30      0.95      0.45        88
           5       0.85      0.79      0.82       190

    accuracy                           0.61      1091
   macro avg       0.66      0.65      0.62      1091
weighted avg       0.68      0.61      0.62      1091

Confusion Matrix for this model: 
 [[ 74   3   0   5  75  16]
 [  0 111  62   0   0   0]
 [ 13   1 131  40  90   6]
 [ 25   3  30 112  14   2]
 [  0   1   0   0  84   3]
 [  0   2  15   1  21 151]]
Input Shape:  (2077, 1, 96)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_15"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_16 (InputLayer)          [(None, 1, 96)]      0           []                               
                                                                                                  
 batch_normalization_30 (BatchN  (None, 1, 96)       384         ['input_16[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_30 (Multi  (None, 1, 96)       24864       ['batch_normalization_30[0][0]', 
 HeadAttention)                                                   'batch_normalization_30[0][0]'] 
                                                                                                  
 dropout_60 (Dropout)           (None, 1, 96)        0           ['multi_head_attention_30[0][0]']
                                                                                                  
 tf.__operators__.add_60 (TFOpL  (None, 1, 96)       0           ['dropout_60[0][0]',             
 ambda)                                                           'input_16[0][0]']               
                                                                                                  
 layer_normalization_30 (LayerN  (None, 1, 96)       192         ['tf.__operators__.add_60[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_60 (Conv1D)             (None, 1, 32)        3104        ['layer_normalization_30[0][0]'] 
                                                                                                  
 dropout_61 (Dropout)           (None, 1, 32)        0           ['conv1d_60[0][0]']              
                                                                                                  
 conv1d_61 (Conv1D)             (None, 1, 96)        3168        ['dropout_61[0][0]']             
                                                                                                  
 tf.__operators__.add_61 (TFOpL  (None, 1, 96)       0           ['conv1d_61[0][0]',              
 ambda)                                                           'tf.__operators__.add_60[0][0]']
                                                                                                  
 batch_normalization_31 (BatchN  (None, 1, 96)       384         ['tf.__operators__.add_61[0][0]']
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_31 (Multi  (None, 1, 96)       24864       ['batch_normalization_31[0][0]', 
 HeadAttention)                                                   'batch_normalization_31[0][0]'] 
                                                                                                  
 dropout_62 (Dropout)           (None, 1, 96)        0           ['multi_head_attention_31[0][0]']
                                                                                                  
 tf.__operators__.add_62 (TFOpL  (None, 1, 96)       0           ['dropout_62[0][0]',             
 ambda)                                                           'tf.__operators__.add_61[0][0]']
                                                                                                  
 layer_normalization_31 (LayerN  (None, 1, 96)       192         ['tf.__operators__.add_62[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_62 (Conv1D)             (None, 1, 32)        3104        ['layer_normalization_31[0][0]'] 
                                                                                                  
 dropout_63 (Dropout)           (None, 1, 32)        0           ['conv1d_62[0][0]']              
                                                                                                  
 conv1d_63 (Conv1D)             (None, 1, 96)        3168        ['dropout_63[0][0]']             
                                                                                                  
 tf.__operators__.add_63 (TFOpL  (None, 1, 96)       0           ['conv1d_63[0][0]',              
 ambda)                                                           'tf.__operators__.add_62[0][0]']
                                                                                                  
 dense_30 (Dense)               (None, 1, 128)       12416       ['tf.__operators__.add_63[0][0]']
                                                                                                  
 flatten_15 (Flatten)           (None, 128)          0           ['dense_30[0][0]']               
                                                                                                  
 dense_31 (Dense)               (None, 6)            774         ['flatten_15[0][0]']             
                                                                                                  
==================================================================================================
Total params: 76,614
Trainable params: 76,230
Non-trainable params: 384
__________________________________________________________________________________________________
Epoch 00019: early stopping
Experiment:  106  Set:  har1 Train Labels:  ncar5 Test Labels:  clean
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 1 0
AER:  0.3629697525206233
TER:  0.363, 0.363, 0.363
Score for this model: 
               precision    recall  f1-score   support

           0       0.69      0.39      0.50       173
           1       0.84      0.51      0.63       173
           2       0.48      0.83      0.61       171
           3       0.70      0.48      0.57       186
           4       0.60      0.76      0.67       198
           5       0.74      0.82      0.78       190

    accuracy                           0.64      1091
   macro avg       0.67      0.63      0.63      1091
weighted avg       0.67      0.64      0.63      1091

Confusion Matrix for this model: 
 [[ 68   6   2   7  68  22]
 [  0  88  85   0   0   0]
 [  0   1 142  27   1   0]
 [ 21   9  45  90  20   1]
 [  7   1   1   5 151  33]
 [  3   0  19   0  12 156]]
Experiment:  107  Set:  har1 Train Labels:  ncar5 Test Labels:  ncar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 1 1
AER:  0.4005499541704858
TER:  0.389, 0.351, 0.451
Score for this model: 
               precision    recall  f1-score   support

           0       0.61      0.36      0.45       165
           1       0.79      0.47      0.59       176
           2       0.47      0.77      0.58       179
           3       0.67      0.46      0.54       187
           4       0.57      0.72      0.64       199
           5       0.68      0.78      0.73       185

    accuracy                           0.60      1091
   macro avg       0.63      0.59      0.59      1091
weighted avg       0.63      0.60      0.59      1091

Confusion Matrix for this model: 
 [[ 60   7   3   7  65  23]
 [  2  83  84   1   5   1]
 [  5   3 137  29   1   4]
 [ 20  11  45  86  22   3]
 [  7   1   4   6 144  37]
 [  5   0  21   0  15 144]]
Experiment:  108  Set:  har1 Train Labels:  ncar5 Test Labels:  ncar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 1 2
AER:  0.4271310724106325
TER:  0.409, 0.327, 0.527
Score for this model: 
               precision    recall  f1-score   support

           0       0.59      0.34      0.43       170
           1       0.72      0.44      0.55       172
           2       0.44      0.73      0.54       176
           3       0.62      0.43      0.50       188
           4       0.55      0.70      0.62       199
           5       0.68      0.77      0.72       186

    accuracy                           0.57      1091
   macro avg       0.60      0.57      0.56      1091
weighted avg       0.60      0.57      0.56      1091

Confusion Matrix for this model: 
 [[ 58   8   9   9  61  25]
 [  4  76  83   2   3   4]
 [  2   5 128  29   7   5]
 [ 20   9  51  80  27   1]
 [ 10   5   4   8 139  33]
 [  5   2  19   1  15 144]]
Experiment:  109  Set:  har1 Train Labels:  ncar5 Test Labels:  nar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 1 3
AER:  0.40238313473877174
TER:  0.392, 0.352, 0.452
Score for this model: 
               precision    recall  f1-score   support

           0       0.69      0.39      0.50       173
           1       0.84      0.51      0.63       173
           2       0.48      0.64      0.55       223
           3       0.70      0.48      0.57       186
           4       0.43      0.74      0.54       146
           5       0.74      0.82      0.78       190

    accuracy                           0.60      1091
   macro avg       0.65      0.60      0.60      1091
weighted avg       0.64      0.60      0.60      1091

Confusion Matrix for this model: 
 [[ 68   6   2   7  68  22]
 [  0  88  85   0   0   0]
 [  2   2 142  27  44   6]
 [ 21   9  45  90  20   1]
 [  5   0   1   5 108  27]
 [  3   0  19   0  12 156]]
Experiment:  110  Set:  har1 Train Labels:  ncar5 Test Labels:  nar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 1 4
AER:  0.44179651695692024
TER:  0.427, 0.342, 0.542
Score for this model: 
               precision    recall  f1-score   support

           0       0.69      0.39      0.50       173
           1       0.84      0.51      0.63       173
           2       0.48      0.50      0.49       282
           3       0.70      0.48      0.57       186
           4       0.26      0.75      0.38        87
           5       0.74      0.82      0.78       190

    accuracy                           0.56      1091
   macro avg       0.62      0.58      0.56      1091
weighted avg       0.63      0.56      0.57      1091

Confusion Matrix for this model: 
 [[ 68   6   2   7  68  22]
 [  0  88  85   0   0   0]
 [  5   1 142  30  87  17]
 [ 21   9  45  90  20   1]
 [  2   1   1   2  65  16]
 [  3   0  19   0  12 156]]
Experiment:  111  Set:  har1 Train Labels:  ncar5 Test Labels:  nnar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 1 5
AER:  0.3904674610449129
TER:  0.378, 0.340, 0.440
Score for this model: 
               precision    recall  f1-score   support

           0       0.69      0.39      0.50       173
           1       0.84      0.51      0.63       173
           2       0.48      0.63      0.55       226
           3       0.70      0.48      0.57       186
           4       0.48      0.85      0.61       143
           5       0.74      0.82      0.78       190

    accuracy                           0.61      1091
   macro avg       0.65      0.61      0.61      1091
weighted avg       0.65      0.61      0.61      1091

Confusion Matrix for this model: 
 [[ 68   6   2   7  68  22]
 [  0  88  85   0   0   0]
 [  5   2 142  29  31  17]
 [ 21   9  45  90  20   1]
 [  2   0   1   3 121  16]
 [  3   0  19   0  12 156]]
Experiment:  112  Set:  har1 Train Labels:  ncar5 Test Labels:  nnar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 1 6
AER:  0.43263061411549036
TER:  0.416, 0.333, 0.533
Score for this model: 
               precision    recall  f1-score   support

           0       0.69      0.39      0.50       173
           1       0.84      0.51      0.63       173
           2       0.48      0.51      0.49       281
           3       0.70      0.48      0.57       186
           4       0.30      0.85      0.44        88
           5       0.74      0.82      0.78       190

    accuracy                           0.57      1091
   macro avg       0.62      0.59      0.57      1091
weighted avg       0.64      0.57      0.58      1091

Confusion Matrix for this model: 
 [[ 68   6   2   7  68  22]
 [  0  88  85   0   0   0]
 [  7   2 142  29  77  24]
 [ 21   9  45  90  20   1]
 [  0   0   1   3  75   9]
 [  3   0  19   0  12 156]]
Input Shape:  (2077, 1, 96)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_16"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_17 (InputLayer)          [(None, 1, 96)]      0           []                               
                                                                                                  
 batch_normalization_32 (BatchN  (None, 1, 96)       384         ['input_17[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_32 (Multi  (None, 1, 96)       24864       ['batch_normalization_32[0][0]', 
 HeadAttention)                                                   'batch_normalization_32[0][0]'] 
                                                                                                  
 dropout_64 (Dropout)           (None, 1, 96)        0           ['multi_head_attention_32[0][0]']
                                                                                                  
 tf.__operators__.add_64 (TFOpL  (None, 1, 96)       0           ['dropout_64[0][0]',             
 ambda)                                                           'input_17[0][0]']               
                                                                                                  
 layer_normalization_32 (LayerN  (None, 1, 96)       192         ['tf.__operators__.add_64[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_64 (Conv1D)             (None, 1, 32)        3104        ['layer_normalization_32[0][0]'] 
                                                                                                  
 dropout_65 (Dropout)           (None, 1, 32)        0           ['conv1d_64[0][0]']              
                                                                                                  
 conv1d_65 (Conv1D)             (None, 1, 96)        3168        ['dropout_65[0][0]']             
                                                                                                  
 tf.__operators__.add_65 (TFOpL  (None, 1, 96)       0           ['conv1d_65[0][0]',              
 ambda)                                                           'tf.__operators__.add_64[0][0]']
                                                                                                  
 batch_normalization_33 (BatchN  (None, 1, 96)       384         ['tf.__operators__.add_65[0][0]']
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_33 (Multi  (None, 1, 96)       24864       ['batch_normalization_33[0][0]', 
 HeadAttention)                                                   'batch_normalization_33[0][0]'] 
                                                                                                  
 dropout_66 (Dropout)           (None, 1, 96)        0           ['multi_head_attention_33[0][0]']
                                                                                                  
 tf.__operators__.add_66 (TFOpL  (None, 1, 96)       0           ['dropout_66[0][0]',             
 ambda)                                                           'tf.__operators__.add_65[0][0]']
                                                                                                  
 layer_normalization_33 (LayerN  (None, 1, 96)       192         ['tf.__operators__.add_66[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_66 (Conv1D)             (None, 1, 32)        3104        ['layer_normalization_33[0][0]'] 
                                                                                                  
 dropout_67 (Dropout)           (None, 1, 32)        0           ['conv1d_66[0][0]']              
                                                                                                  
 conv1d_67 (Conv1D)             (None, 1, 96)        3168        ['dropout_67[0][0]']             
                                                                                                  
 tf.__operators__.add_67 (TFOpL  (None, 1, 96)       0           ['conv1d_67[0][0]',              
 ambda)                                                           'tf.__operators__.add_66[0][0]']
                                                                                                  
 dense_32 (Dense)               (None, 1, 128)       12416       ['tf.__operators__.add_67[0][0]']
                                                                                                  
 flatten_16 (Flatten)           (None, 128)          0           ['dense_32[0][0]']               
                                                                                                  
 dense_33 (Dense)               (None, 6)            774         ['flatten_16[0][0]']             
                                                                                                  
==================================================================================================
Total params: 76,614
Trainable params: 76,230
Non-trainable params: 384
__________________________________________________________________________________________________
Epoch 00022: early stopping
Experiment:  113  Set:  har1 Train Labels:  ncar10 Test Labels:  clean
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 2 0
AER:  0.3400549954170486
TER:  0.340, 0.340, 0.340
Score for this model: 
               precision    recall  f1-score   support

           0       0.61      0.46      0.53       173
           1       0.82      0.51      0.63       173
           2       0.49      0.74      0.59       171
           3       0.67      0.55      0.60       186
           4       0.68      0.85      0.76       198
           5       0.79      0.82      0.81       190

    accuracy                           0.66      1091
   macro avg       0.68      0.65      0.65      1091
weighted avg       0.68      0.66      0.66      1091

Confusion Matrix for this model: 
 [[ 80   5   0   8  61  19]
 [  0  88  85   0   0   0]
 [  4   1 127  36   1   2]
 [ 34   6  33 102   8   3]
 [  9   0   0   5 168  16]
 [  4   7  14   1   9 155]]
Experiment:  114  Set:  har1 Train Labels:  ncar10 Test Labels:  ncar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 2 1
AER:  0.3748854262144821
TER:  0.361, 0.325, 0.425
Score for this model: 
               precision    recall  f1-score   support

           0       0.56      0.44      0.49       165
           1       0.79      0.48      0.59       176
           2       0.48      0.69      0.57       179
           3       0.65      0.53      0.58       187
           4       0.65      0.81      0.72       199
           5       0.72      0.76      0.74       185

    accuracy                           0.63      1091
   macro avg       0.64      0.62      0.62      1091
weighted avg       0.64      0.63      0.62      1091

Confusion Matrix for this model: 
 [[ 73   4   2   8  58  20]
 [  2  84  82   1   5   2]
 [  9   4 124  35   1   6]
 [ 31   7  34  99  11   5]
 [  9   0   1   7 161  21]
 [  7   8  16   2  11 141]]
Experiment:  115  Set:  har1 Train Labels:  ncar10 Test Labels:  ncar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 2 2
AER:  0.40513290559120074
TER:  0.381, 0.305, 0.505
Score for this model: 
               precision    recall  f1-score   support

           0       0.52      0.40      0.45       170
           1       0.72      0.45      0.55       172
           2       0.46      0.68      0.55       176
           3       0.61      0.49      0.54       188
           4       0.61      0.76      0.68       199
           5       0.73      0.76      0.75       186

    accuracy                           0.59      1091
   macro avg       0.61      0.59      0.59      1091
weighted avg       0.61      0.59      0.59      1091

Confusion Matrix for this model: 
 [[ 68   6   6  11  59  20]
 [  2  77  79   6   4   4]
 [  6   4 119  33   8   6]
 [ 34   7  37  92  14   4]
 [ 14   4   3   8 151  19]
 [  7   9  15   2  11 142]]
Experiment:  116  Set:  har1 Train Labels:  ncar10 Test Labels:  nar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 2 3
AER:  0.383134738771769
TER:  0.370, 0.333, 0.433
Score for this model: 
               precision    recall  f1-score   support

           0       0.61      0.46      0.53       173
           1       0.82      0.51      0.63       173
           2       0.49      0.57      0.53       223
           3       0.67      0.55      0.60       186
           4       0.49      0.83      0.62       146
           5       0.79      0.82      0.81       190

    accuracy                           0.62      1091
   macro avg       0.65      0.62      0.62      1091
weighted avg       0.65      0.62      0.62      1091

Confusion Matrix for this model: 
 [[ 80   5   0   8  61  19]
 [  0  88  85   0   0   0]
 [  5   1 127  38  48   4]
 [ 34   6  33 102   8   3]
 [  8   0   0   3 121  14]
 [  4   7  14   1   9 155]]
Experiment:  117  Set:  har1 Train Labels:  ncar10 Test Labels:  nar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 2 4
AER:  0.42621448212648944
TER:  0.408, 0.326, 0.526
Score for this model: 
               precision    recall  f1-score   support

           0       0.61      0.46      0.53       173
           1       0.82      0.51      0.63       173
           2       0.49      0.45      0.47       282
           3       0.67      0.55      0.60       186
           4       0.30      0.85      0.44        87
           5       0.79      0.82      0.81       190

    accuracy                           0.57      1091
   macro avg       0.61      0.61      0.58      1091
weighted avg       0.63      0.57      0.58      1091

Confusion Matrix for this model: 
 [[ 80   5   0   8  61  19]
 [  0  88  85   0   0   0]
 [ 11   1 127  39  95   9]
 [ 34   6  33 102   8   3]
 [  2   0   0   2  74   9]
 [  4   7  14   1   9 155]]
Experiment:  118  Set:  har1 Train Labels:  ncar10 Test Labels:  nnar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 2 5
AER:  0.3767186067827681
TER:  0.363, 0.327, 0.427
Score for this model: 
               precision    recall  f1-score   support

           0       0.61      0.46      0.53       173
           1       0.82      0.51      0.63       173
           2       0.49      0.56      0.52       226
           3       0.67      0.55      0.60       186
           4       0.52      0.90      0.66       143
           5       0.79      0.82      0.81       190

    accuracy                           0.62      1091
   macro avg       0.65      0.63      0.62      1091
weighted avg       0.65      0.62      0.62      1091

Confusion Matrix for this model: 
 [[ 80   5   0   8  61  19]
 [  0  88  85   0   0   0]
 [  9   1 127  38  41  10]
 [ 34   6  33 102   8   3]
 [  4   0   0   3 128   8]
 [  4   7  14   1   9 155]]
Experiment:  119  Set:  har1 Train Labels:  ncar10 Test Labels:  nnar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 2 6
AER:  0.41979835013748856
TER:  0.400, 0.320, 0.520
Score for this model: 
               precision    recall  f1-score   support

           0       0.61      0.46      0.53       173
           1       0.82      0.51      0.63       173
           2       0.49      0.45      0.47       281
           3       0.67      0.55      0.60       186
           4       0.33      0.92      0.48        88
           5       0.79      0.82      0.81       190

    accuracy                           0.58      1091
   macro avg       0.62      0.62      0.59      1091
weighted avg       0.63      0.58      0.59      1091

Confusion Matrix for this model: 
 [[ 80   5   0   8  61  19]
 [  0  88  85   0   0   0]
 [ 11   1 127  40  88  14]
 [ 34   6  33 102   8   3]
 [  2   0   0   1  81   4]
 [  4   7  14   1   9 155]]
Input Shape:  (2077, 1, 96)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_17"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_18 (InputLayer)          [(None, 1, 96)]      0           []                               
                                                                                                  
 batch_normalization_34 (BatchN  (None, 1, 96)       384         ['input_18[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_34 (Multi  (None, 1, 96)       24864       ['batch_normalization_34[0][0]', 
 HeadAttention)                                                   'batch_normalization_34[0][0]'] 
                                                                                                  
 dropout_68 (Dropout)           (None, 1, 96)        0           ['multi_head_attention_34[0][0]']
                                                                                                  
 tf.__operators__.add_68 (TFOpL  (None, 1, 96)       0           ['dropout_68[0][0]',             
 ambda)                                                           'input_18[0][0]']               
                                                                                                  
 layer_normalization_34 (LayerN  (None, 1, 96)       192         ['tf.__operators__.add_68[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_68 (Conv1D)             (None, 1, 32)        3104        ['layer_normalization_34[0][0]'] 
                                                                                                  
 dropout_69 (Dropout)           (None, 1, 32)        0           ['conv1d_68[0][0]']              
                                                                                                  
 conv1d_69 (Conv1D)             (None, 1, 96)        3168        ['dropout_69[0][0]']             
                                                                                                  
 tf.__operators__.add_69 (TFOpL  (None, 1, 96)       0           ['conv1d_69[0][0]',              
 ambda)                                                           'tf.__operators__.add_68[0][0]']
                                                                                                  
 batch_normalization_35 (BatchN  (None, 1, 96)       384         ['tf.__operators__.add_69[0][0]']
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_35 (Multi  (None, 1, 96)       24864       ['batch_normalization_35[0][0]', 
 HeadAttention)                                                   'batch_normalization_35[0][0]'] 
                                                                                                  
 dropout_70 (Dropout)           (None, 1, 96)        0           ['multi_head_attention_35[0][0]']
                                                                                                  
 tf.__operators__.add_70 (TFOpL  (None, 1, 96)       0           ['dropout_70[0][0]',             
 ambda)                                                           'tf.__operators__.add_69[0][0]']
                                                                                                  
 layer_normalization_35 (LayerN  (None, 1, 96)       192         ['tf.__operators__.add_70[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_70 (Conv1D)             (None, 1, 32)        3104        ['layer_normalization_35[0][0]'] 
                                                                                                  
 dropout_71 (Dropout)           (None, 1, 32)        0           ['conv1d_70[0][0]']              
                                                                                                  
 conv1d_71 (Conv1D)             (None, 1, 96)        3168        ['dropout_71[0][0]']             
                                                                                                  
 tf.__operators__.add_71 (TFOpL  (None, 1, 96)       0           ['conv1d_71[0][0]',              
 ambda)                                                           'tf.__operators__.add_70[0][0]']
                                                                                                  
 dense_34 (Dense)               (None, 1, 128)       12416       ['tf.__operators__.add_71[0][0]']
                                                                                                  
 flatten_17 (Flatten)           (None, 128)          0           ['dense_34[0][0]']               
                                                                                                  
 dense_35 (Dense)               (None, 6)            774         ['flatten_17[0][0]']             
                                                                                                  
==================================================================================================
Total params: 76,614
Trainable params: 76,230
Non-trainable params: 384
__________________________________________________________________________________________________
Epoch 00038: early stopping
Experiment:  120  Set:  har1 Train Labels:  nar5 Test Labels:  clean
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 3 0
AER:  0.31347387717690195
TER:  0.313, 0.313, 0.313
Score for this model: 
               precision    recall  f1-score   support

           0       0.57      0.57      0.57       173
           1       0.88      0.65      0.75       173
           2       0.56      0.77      0.65       171
           3       0.69      0.51      0.59       186
           4       0.67      0.77      0.71       198
           5       0.84      0.83      0.83       190

    accuracy                           0.69      1091
   macro avg       0.70      0.68      0.68      1091
weighted avg       0.70      0.69      0.69      1091

Confusion Matrix for this model: 
 [[ 98   4   0   3  52  16]
 [  0 113  60   0   0   0]
 [  2   0 132  37   0   0]
 [ 42   6  33  95   8   2]
 [ 26   3   0   3 153  13]
 [  3   3   9   0  17 158]]
Experiment:  121  Set:  har1 Train Labels:  nar5 Test Labels:  ncar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 3 1
AER:  0.3528872593950504
TER:  0.337, 0.303, 0.403
Score for this model: 
               precision    recall  f1-score   support

           0       0.52      0.54      0.53       165
           1       0.84      0.61      0.71       176
           2       0.54      0.70      0.61       179
           3       0.67      0.49      0.57       187
           4       0.63      0.73      0.68       199
           5       0.77      0.79      0.78       185

    accuracy                           0.65      1091
   macro avg       0.66      0.64      0.65      1091
weighted avg       0.66      0.65      0.65      1091

Confusion Matrix for this model: 
 [[ 89   5   1   3  51  16]
 [  2 108  58   2   4   2]
 [  8   4 126  37   2   2]
 [ 41   7  34  92   9   4]
 [ 26   3   3   3 145  19]
 [  5   2  12   1  19 146]]
Experiment:  122  Set:  har1 Train Labels:  nar5 Test Labels:  ncar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 3 2
AER:  0.37763519706691107
TER:  0.347, 0.278, 0.478
Score for this model: 
               precision    recall  f1-score   support

           0       0.51      0.51      0.51       170
           1       0.76      0.57      0.65       172
           2       0.52      0.69      0.60       176
           3       0.63      0.46      0.53       188
           4       0.60      0.70      0.65       199
           5       0.77      0.78      0.78       186

    accuracy                           0.62      1091
   macro avg       0.63      0.62      0.62      1091
weighted avg       0.63      0.62      0.62      1091

Confusion Matrix for this model: 
 [[ 87   6   6   4  50  17]
 [  5  98  58   4   3   4]
 [  5   4 122  35   6   4]
 [ 40   8  36  87  14   3]
 [ 28   8   2   7 139  15]
 [  6   5  10   1  18 146]]
Experiment:  123  Set:  har1 Train Labels:  nar5 Test Labels:  nar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 3 3
AER:  0.3510540788267644
TER:  0.335, 0.301, 0.401
Score for this model: 
               precision    recall  f1-score   support

           0       0.57      0.57      0.57       173
           1       0.88      0.65      0.75       173
           2       0.56      0.59      0.58       223
           3       0.69      0.51      0.59       186
           4       0.49      0.77      0.60       146
           5       0.84      0.83      0.83       190

    accuracy                           0.65      1091
   macro avg       0.67      0.65      0.65      1091
weighted avg       0.67      0.65      0.65      1091

Confusion Matrix for this model: 
 [[ 98   4   0   3  52  16]
 [  0 113  60   0   0   0]
 [ 10   0 132  38  41   2]
 [ 42   6  33  95   8   2]
 [ 18   3   0   2 112  11]
 [  3   3   9   0  17 158]]
Experiment:  124  Set:  har1 Train Labels:  nar5 Test Labels:  nar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 3 4
AER:  0.39321723189734187
TER:  0.367, 0.293, 0.493
Score for this model: 
               precision    recall  f1-score   support

           0       0.57      0.57      0.57       173
           1       0.88      0.65      0.75       173
           2       0.56      0.47      0.51       282
           3       0.69      0.51      0.59       186
           4       0.29      0.76      0.42        87
           5       0.84      0.83      0.83       190

    accuracy                           0.61      1091
   macro avg       0.64      0.63      0.61      1091
weighted avg       0.66      0.61      0.62      1091

Confusion Matrix for this model: 
 [[ 98   4   0   3  52  16]
 [  0 113  60   0   0   0]
 [ 18   1 132  38  87   6]
 [ 42   6  33  95   8   2]
 [ 10   2   0   2  66   7]
 [  3   3   9   0  17 158]]
Experiment:  125  Set:  har1 Train Labels:  nar5 Test Labels:  nnar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 3 5
AER:  0.34555453712190654
TER:  0.328, 0.296, 0.396
Score for this model: 
               precision    recall  f1-score   support

           0       0.57      0.57      0.57       173
           1       0.88      0.65      0.75       173
           2       0.56      0.58      0.57       226
           3       0.69      0.51      0.59       186
           4       0.51      0.83      0.63       143
           5       0.84      0.83      0.83       190

    accuracy                           0.65      1091
   macro avg       0.68      0.66      0.66      1091
weighted avg       0.68      0.65      0.66      1091

Confusion Matrix for this model: 
 [[ 98   4   0   3  52  16]
 [  0 113  60   0   0   0]
 [ 15   1 132  38  35   5]
 [ 42   6  33  95   8   2]
 [ 13   2   0   2 118   8]
 [  3   3   9   0  17 158]]
Experiment:  126  Set:  har1 Train Labels:  nar5 Test Labels:  nnar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 3 6
AER:  0.383134738771769
TER:  0.354, 0.283, 0.483
Score for this model: 
               precision    recall  f1-score   support

           0       0.57      0.57      0.57       173
           1       0.88      0.65      0.75       173
           2       0.56      0.47      0.51       281
           3       0.69      0.51      0.59       186
           4       0.33      0.88      0.48        88
           5       0.84      0.83      0.83       190

    accuracy                           0.62      1091
   macro avg       0.65      0.65      0.62      1091
weighted avg       0.67      0.62      0.63      1091

Confusion Matrix for this model: 
 [[ 98   4   0   3  52  16]
 [  0 113  60   0   0   0]
 [ 23   1 132  39  76  10]
 [ 42   6  33  95   8   2]
 [  5   2   0   1  77   3]
 [  3   3   9   0  17 158]]
Input Shape:  (2077, 1, 96)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_18"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_19 (InputLayer)          [(None, 1, 96)]      0           []                               
                                                                                                  
 batch_normalization_36 (BatchN  (None, 1, 96)       384         ['input_19[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_36 (Multi  (None, 1, 96)       24864       ['batch_normalization_36[0][0]', 
 HeadAttention)                                                   'batch_normalization_36[0][0]'] 
                                                                                                  
 dropout_72 (Dropout)           (None, 1, 96)        0           ['multi_head_attention_36[0][0]']
                                                                                                  
 tf.__operators__.add_72 (TFOpL  (None, 1, 96)       0           ['dropout_72[0][0]',             
 ambda)                                                           'input_19[0][0]']               
                                                                                                  
 layer_normalization_36 (LayerN  (None, 1, 96)       192         ['tf.__operators__.add_72[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_72 (Conv1D)             (None, 1, 32)        3104        ['layer_normalization_36[0][0]'] 
                                                                                                  
 dropout_73 (Dropout)           (None, 1, 32)        0           ['conv1d_72[0][0]']              
                                                                                                  
 conv1d_73 (Conv1D)             (None, 1, 96)        3168        ['dropout_73[0][0]']             
                                                                                                  
 tf.__operators__.add_73 (TFOpL  (None, 1, 96)       0           ['conv1d_73[0][0]',              
 ambda)                                                           'tf.__operators__.add_72[0][0]']
                                                                                                  
 batch_normalization_37 (BatchN  (None, 1, 96)       384         ['tf.__operators__.add_73[0][0]']
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_37 (Multi  (None, 1, 96)       24864       ['batch_normalization_37[0][0]', 
 HeadAttention)                                                   'batch_normalization_37[0][0]'] 
                                                                                                  
 dropout_74 (Dropout)           (None, 1, 96)        0           ['multi_head_attention_37[0][0]']
                                                                                                  
 tf.__operators__.add_74 (TFOpL  (None, 1, 96)       0           ['dropout_74[0][0]',             
 ambda)                                                           'tf.__operators__.add_73[0][0]']
                                                                                                  
 layer_normalization_37 (LayerN  (None, 1, 96)       192         ['tf.__operators__.add_74[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_74 (Conv1D)             (None, 1, 32)        3104        ['layer_normalization_37[0][0]'] 
                                                                                                  
 dropout_75 (Dropout)           (None, 1, 32)        0           ['conv1d_74[0][0]']              
                                                                                                  
 conv1d_75 (Conv1D)             (None, 1, 96)        3168        ['dropout_75[0][0]']             
                                                                                                  
 tf.__operators__.add_75 (TFOpL  (None, 1, 96)       0           ['conv1d_75[0][0]',              
 ambda)                                                           'tf.__operators__.add_74[0][0]']
                                                                                                  
 dense_36 (Dense)               (None, 1, 128)       12416       ['tf.__operators__.add_75[0][0]']
                                                                                                  
 flatten_18 (Flatten)           (None, 128)          0           ['dense_36[0][0]']               
                                                                                                  
 dense_37 (Dense)               (None, 6)            774         ['flatten_18[0][0]']             
                                                                                                  
==================================================================================================
Total params: 76,614
Trainable params: 76,230
Non-trainable params: 384
__________________________________________________________________________________________________
Epoch 00023: early stopping
Experiment:  127  Set:  har1 Train Labels:  nar10 Test Labels:  clean
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 4 0
AER:  0.3712190650779102
TER:  0.371, 0.371, 0.371
Score for this model: 
               precision    recall  f1-score   support

           0       0.45      0.66      0.54       173
           1       0.95      0.54      0.69       173
           2       0.54      0.77      0.63       171
           3       0.69      0.58      0.63       186
           4       0.70      0.38      0.50       198
           5       0.70      0.86      0.77       190

    accuracy                           0.63      1091
   macro avg       0.67      0.63      0.63      1091
weighted avg       0.67      0.63      0.63      1091

Confusion Matrix for this model: 
 [[114   2   0   4  24  29]
 [  0  94  79   0   0   0]
 [  3   2 132  34   0   0]
 [ 48   1  25 107   2   3]
 [ 78   0   0   7  76  37]
 [  9   0   9   2   7 163]]
Experiment:  128  Set:  har1 Train Labels:  nar10 Test Labels:  ncar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 4 1
AER:  0.4060494958753437
TER:  0.396, 0.356, 0.456
Score for this model: 
               precision    recall  f1-score   support

           0       0.42      0.64      0.51       165
           1       0.91      0.51      0.65       176
           2       0.52      0.72      0.60       179
           3       0.68      0.56      0.61       187
           4       0.64      0.35      0.45       199
           5       0.65      0.81      0.72       185

    accuracy                           0.59      1091
   macro avg       0.64      0.60      0.59      1091
weighted avg       0.64      0.59      0.59      1091

Confusion Matrix for this model: 
 [[106   2   2   4  22  29]
 [  3  90  76   1   4   2]
 [  8   5 128  34   1   3]
 [ 46   2  26 104   4   5]
 [ 76   0   2   8  70  43]
 [ 13   0  11   3   8 150]]
Experiment:  129  Set:  har1 Train Labels:  nar10 Test Labels:  ncar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 4 2
AER:  0.4298808432630614
TER:  0.412, 0.330, 0.530
Score for this model: 
               precision    recall  f1-score   support

           0       0.41      0.61      0.49       170
           1       0.84      0.48      0.61       172
           2       0.49      0.69      0.57       176
           3       0.62      0.51      0.56       188
           4       0.64      0.35      0.45       199
           5       0.65      0.81      0.72       186

    accuracy                           0.57      1091
   macro avg       0.61      0.57      0.57      1091
weighted avg       0.61      0.57      0.57      1091

Confusion Matrix for this model: 
 [[103   4   6   5  21  31]
 [  4  83  73   6   2   4]
 [  6   4 121  36   3   6]
 [ 51   3  30  95   5   4]
 [ 74   3   5  10  70  37]
 [ 14   2  10   2   8 150]]
Experiment:  130  Set:  har1 Train Labels:  nar10 Test Labels:  nar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 4 3
AER:  0.3923006416131989
TER:  0.380, 0.342, 0.442
Score for this model: 
               precision    recall  f1-score   support

           0       0.45      0.66      0.54       173
           1       0.95      0.54      0.69       173
           2       0.54      0.59      0.56       223
           3       0.69      0.58      0.63       186
           4       0.49      0.36      0.42       146
           5       0.70      0.86      0.77       190

    accuracy                           0.61      1091
   macro avg       0.64      0.60      0.60      1091
weighted avg       0.64      0.61      0.61      1091

Confusion Matrix for this model: 
 [[114   2   0   4  24  29]
 [  0  94  79   0   0   0]
 [ 26   2 132  35  23   5]
 [ 48   1  25 107   2   3]
 [ 55   0   0   6  53  32]
 [  9   0   9   2   7 163]]
Experiment:  131  Set:  har1 Train Labels:  nar10 Test Labels:  nar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 4 4
AER:  0.41154903758020167
TER:  0.389, 0.312, 0.512
Score for this model: 
               precision    recall  f1-score   support

           0       0.45      0.66      0.54       173
           1       0.95      0.54      0.69       173
           2       0.54      0.47      0.50       282
           3       0.69      0.58      0.63       186
           4       0.29      0.37      0.33        87
           5       0.70      0.86      0.77       190

    accuracy                           0.59      1091
   macro avg       0.61      0.58      0.58      1091
weighted avg       0.63      0.59      0.59      1091

Confusion Matrix for this model: 
 [[114   2   0   4  24  29]
 [  0  94  79   0   0   0]
 [ 50   2 132  36  44  18]
 [ 48   1  25 107   2   3]
 [ 31   0   0   5  32  19]
 [  9   0   9   2   7 163]]
Experiment:  132  Set:  har1 Train Labels:  nar10 Test Labels:  nnar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 4 5
AER:  0.38588450962419796
TER:  0.373, 0.336, 0.436
Score for this model: 
               precision    recall  f1-score   support

           0       0.45      0.66      0.54       173
           1       0.95      0.54      0.69       173
           2       0.54      0.58      0.56       226
           3       0.69      0.58      0.63       186
           4       0.55      0.42      0.48       143
           5       0.70      0.86      0.77       190

    accuracy                           0.61      1091
   macro avg       0.65      0.61      0.61      1091
weighted avg       0.65      0.61      0.62      1091

Confusion Matrix for this model: 
 [[114   2   0   4  24  29]
 [  0  94  79   0   0   0]
 [ 24   2 132  37  16  15]
 [ 48   1  25 107   2   3]
 [ 57   0   0   4  60  22]
 [  9   0   9   2   7 163]]
Experiment:  133  Set:  har1 Train Labels:  nar10 Test Labels:  nnar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 4 6
AER:  0.3996333638863428
TER:  0.375, 0.300, 0.500
Score for this model: 
               precision    recall  f1-score   support

           0       0.45      0.66      0.54       173
           1       0.95      0.54      0.69       173
           2       0.54      0.47      0.50       281
           3       0.69      0.58      0.63       186
           4       0.41      0.51      0.46        88
           5       0.70      0.86      0.77       190

    accuracy                           0.60      1091
   macro avg       0.63      0.60      0.60      1091
weighted avg       0.64      0.60      0.60      1091

Confusion Matrix for this model: 
 [[114   2   0   4  24  29]
 [  0  94  79   0   0   0]
 [ 54   2 132  37  31  25]
 [ 48   1  25 107   2   3]
 [ 27   0   0   4  45  12]
 [  9   0   9   2   7 163]]
Input Shape:  (2077, 1, 96)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_19"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_20 (InputLayer)          [(None, 1, 96)]      0           []                               
                                                                                                  
 batch_normalization_38 (BatchN  (None, 1, 96)       384         ['input_20[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_38 (Multi  (None, 1, 96)       24864       ['batch_normalization_38[0][0]', 
 HeadAttention)                                                   'batch_normalization_38[0][0]'] 
                                                                                                  
 dropout_76 (Dropout)           (None, 1, 96)        0           ['multi_head_attention_38[0][0]']
                                                                                                  
 tf.__operators__.add_76 (TFOpL  (None, 1, 96)       0           ['dropout_76[0][0]',             
 ambda)                                                           'input_20[0][0]']               
                                                                                                  
 layer_normalization_38 (LayerN  (None, 1, 96)       192         ['tf.__operators__.add_76[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_76 (Conv1D)             (None, 1, 32)        3104        ['layer_normalization_38[0][0]'] 
                                                                                                  
 dropout_77 (Dropout)           (None, 1, 32)        0           ['conv1d_76[0][0]']              
                                                                                                  
 conv1d_77 (Conv1D)             (None, 1, 96)        3168        ['dropout_77[0][0]']             
                                                                                                  
 tf.__operators__.add_77 (TFOpL  (None, 1, 96)       0           ['conv1d_77[0][0]',              
 ambda)                                                           'tf.__operators__.add_76[0][0]']
                                                                                                  
 batch_normalization_39 (BatchN  (None, 1, 96)       384         ['tf.__operators__.add_77[0][0]']
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_39 (Multi  (None, 1, 96)       24864       ['batch_normalization_39[0][0]', 
 HeadAttention)                                                   'batch_normalization_39[0][0]'] 
                                                                                                  
 dropout_78 (Dropout)           (None, 1, 96)        0           ['multi_head_attention_39[0][0]']
                                                                                                  
 tf.__operators__.add_78 (TFOpL  (None, 1, 96)       0           ['dropout_78[0][0]',             
 ambda)                                                           'tf.__operators__.add_77[0][0]']
                                                                                                  
 layer_normalization_39 (LayerN  (None, 1, 96)       192         ['tf.__operators__.add_78[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_78 (Conv1D)             (None, 1, 32)        3104        ['layer_normalization_39[0][0]'] 
                                                                                                  
 dropout_79 (Dropout)           (None, 1, 32)        0           ['conv1d_78[0][0]']              
                                                                                                  
 conv1d_79 (Conv1D)             (None, 1, 96)        3168        ['dropout_79[0][0]']             
                                                                                                  
 tf.__operators__.add_79 (TFOpL  (None, 1, 96)       0           ['conv1d_79[0][0]',              
 ambda)                                                           'tf.__operators__.add_78[0][0]']
                                                                                                  
 dense_38 (Dense)               (None, 1, 128)       12416       ['tf.__operators__.add_79[0][0]']
                                                                                                  
 flatten_19 (Flatten)           (None, 128)          0           ['dense_38[0][0]']               
                                                                                                  
 dense_39 (Dense)               (None, 6)            774         ['flatten_19[0][0]']             
                                                                                                  
==================================================================================================
Total params: 76,614
Trainable params: 76,230
Non-trainable params: 384
__________________________________________________________________________________________________
Epoch 00037: early stopping
Experiment:  134  Set:  har1 Train Labels:  nnar5 Test Labels:  clean
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 5 0
AER:  0.307057745187901
TER:  0.307, 0.307, 0.307
Score for this model: 
               precision    recall  f1-score   support

           0       0.57      0.55      0.56       173
           1       0.94      0.58      0.72       173
           2       0.56      0.82      0.67       171
           3       0.73      0.58      0.65       186
           4       0.73      0.74      0.73       198
           5       0.76      0.87      0.81       190

    accuracy                           0.69      1091
   macro avg       0.72      0.69      0.69      1091
weighted avg       0.72      0.69      0.69      1091

Confusion Matrix for this model: 
 [[ 96   3   0   4  44  26]
 [  0 100  73   0   0   0]
 [  8   0 140  23   0   0]
 [ 42   2  26 108   3   5]
 [ 18   1   0  10 147  22]
 [  4   0  11   2   8 165]]
Experiment:  135  Set:  har1 Train Labels:  nnar5 Test Labels:  ncar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 5 1
AER:  0.35013748854262144
TER:  0.333, 0.300, 0.400
Score for this model: 
               precision    recall  f1-score   support

           0       0.51      0.52      0.51       165
           1       0.90      0.54      0.67       176
           2       0.54      0.75      0.63       179
           3       0.71      0.56      0.63       187
           4       0.68      0.69      0.69       199
           5       0.69      0.82      0.75       185

    accuracy                           0.65      1091
   macro avg       0.67      0.65      0.65      1091
weighted avg       0.67      0.65      0.65      1091

Confusion Matrix for this model: 
 [[ 85   3   2   4  44  27]
 [  2  95  72   0   5   2]
 [ 12   4 135  24   1   3]
 [ 41   3  26 105   5   7]
 [ 19   1   2  11 138  28]
 [  9   0  13   3   9 151]]
Experiment:  136  Set:  har1 Train Labels:  nnar5 Test Labels:  ncar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 5 2
AER:  0.3712190650779102
TER:  0.339, 0.271, 0.471
Score for this model: 
               precision    recall  f1-score   support

           0       0.48      0.48      0.48       170
           1       0.84      0.52      0.64       172
           2       0.52      0.73      0.61       176
           3       0.67      0.52      0.59       188
           4       0.67      0.68      0.68       199
           5       0.70      0.82      0.76       186

    accuracy                           0.63      1091
   macro avg       0.65      0.63      0.62      1091
weighted avg       0.65      0.63      0.63      1091

Confusion Matrix for this model: 
 [[ 81   4   7   7  43  28]
 [  3  89  70   2   4   4]
 [ 11   3 129  24   3   6]
 [ 45   3  29  98   6   7]
 [ 22   6   2  13 136  20]
 [  6   1  13   3  10 153]]
Experiment:  137  Set:  har1 Train Labels:  nnar5 Test Labels:  nar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 5 3
AER:  0.34555453712190654
TER:  0.328, 0.296, 0.396
Score for this model: 
               precision    recall  f1-score   support

           0       0.57      0.55      0.56       173
           1       0.94      0.58      0.72       173
           2       0.56      0.63      0.59       223
           3       0.73      0.58      0.65       186
           4       0.52      0.72      0.60       146
           5       0.76      0.87      0.81       190

    accuracy                           0.65      1091
   macro avg       0.68      0.65      0.66      1091
weighted avg       0.68      0.65      0.66      1091

Confusion Matrix for this model: 
 [[ 96   3   0   4  44  26]
 [  0 100  73   0   0   0]
 [ 13   0 140  25  42   3]
 [ 42   2  26 108   3   5]
 [ 13   1   0   8 105  19]
 [  4   0  11   2   8 165]]
Experiment:  138  Set:  har1 Train Labels:  nnar5 Test Labels:  nar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 5 4
AER:  0.383134738771769
TER:  0.354, 0.283, 0.483
Score for this model: 
               precision    recall  f1-score   support

           0       0.57      0.55      0.56       173
           1       0.94      0.58      0.72       173
           2       0.56      0.50      0.53       282
           3       0.73      0.58      0.65       186
           4       0.32      0.74      0.44        87
           5       0.76      0.87      0.81       190

    accuracy                           0.62      1091
   macro avg       0.65      0.64      0.62      1091
weighted avg       0.67      0.62      0.63      1091

Confusion Matrix for this model: 
 [[ 96   3   0   4  44  26]
 [  0 100  73   0   0   0]
 [ 21   0 140  29  83   9]
 [ 42   2  26 108   3   5]
 [  5   1   0   4  64  13]
 [  4   0  11   2   8 165]]
Experiment:  139  Set:  har1 Train Labels:  nnar5 Test Labels:  nnar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 5 5
AER:  0.3400549954170486
TER:  0.322, 0.290, 0.390
Score for this model: 
               precision    recall  f1-score   support

           0       0.57      0.55      0.56       173
           1       0.94      0.58      0.72       173
           2       0.56      0.62      0.59       226
           3       0.73      0.58      0.65       186
           4       0.55      0.78      0.64       143
           5       0.76      0.87      0.81       190

    accuracy                           0.66      1091
   macro avg       0.69      0.66      0.66      1091
weighted avg       0.69      0.66      0.66      1091

Confusion Matrix for this model: 
 [[ 96   3   0   4  44  26]
 [  0 100  73   0   0   0]
 [ 16   0 140  25  36   9]
 [ 42   2  26 108   3   5]
 [ 10   1   0   8 111  13]
 [  4   0  11   2   8 165]]
Experiment:  140  Set:  har1 Train Labels:  nnar5 Test Labels:  nnar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 5 6
AER:  0.3748854262144821
TER:  0.344, 0.275, 0.475
Score for this model: 
               precision    recall  f1-score   support

           0       0.57      0.55      0.56       173
           1       0.94      0.58      0.72       173
           2       0.56      0.50      0.53       281
           3       0.73      0.58      0.65       186
           4       0.36      0.83      0.50        88
           5       0.76      0.87      0.81       190

    accuracy                           0.63      1091
   macro avg       0.65      0.65      0.63      1091
weighted avg       0.67      0.63      0.63      1091

Confusion Matrix for this model: 
 [[ 96   3   0   4  44  26]
 [  0 100  73   0   0   0]
 [ 22   0 140  30  74  15]
 [ 42   2  26 108   3   5]
 [  4   1   0   3  73   7]
 [  4   0  11   2   8 165]]
Input Shape:  (2077, 1, 96)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_20"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_21 (InputLayer)          [(None, 1, 96)]      0           []                               
                                                                                                  
 batch_normalization_40 (BatchN  (None, 1, 96)       384         ['input_21[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_40 (Multi  (None, 1, 96)       24864       ['batch_normalization_40[0][0]', 
 HeadAttention)                                                   'batch_normalization_40[0][0]'] 
                                                                                                  
 dropout_80 (Dropout)           (None, 1, 96)        0           ['multi_head_attention_40[0][0]']
                                                                                                  
 tf.__operators__.add_80 (TFOpL  (None, 1, 96)       0           ['dropout_80[0][0]',             
 ambda)                                                           'input_21[0][0]']               
                                                                                                  
 layer_normalization_40 (LayerN  (None, 1, 96)       192         ['tf.__operators__.add_80[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_80 (Conv1D)             (None, 1, 32)        3104        ['layer_normalization_40[0][0]'] 
                                                                                                  
 dropout_81 (Dropout)           (None, 1, 32)        0           ['conv1d_80[0][0]']              
                                                                                                  
 conv1d_81 (Conv1D)             (None, 1, 96)        3168        ['dropout_81[0][0]']             
                                                                                                  
 tf.__operators__.add_81 (TFOpL  (None, 1, 96)       0           ['conv1d_81[0][0]',              
 ambda)                                                           'tf.__operators__.add_80[0][0]']
                                                                                                  
 batch_normalization_41 (BatchN  (None, 1, 96)       384         ['tf.__operators__.add_81[0][0]']
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_41 (Multi  (None, 1, 96)       24864       ['batch_normalization_41[0][0]', 
 HeadAttention)                                                   'batch_normalization_41[0][0]'] 
                                                                                                  
 dropout_82 (Dropout)           (None, 1, 96)        0           ['multi_head_attention_41[0][0]']
                                                                                                  
 tf.__operators__.add_82 (TFOpL  (None, 1, 96)       0           ['dropout_82[0][0]',             
 ambda)                                                           'tf.__operators__.add_81[0][0]']
                                                                                                  
 layer_normalization_41 (LayerN  (None, 1, 96)       192         ['tf.__operators__.add_82[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_82 (Conv1D)             (None, 1, 32)        3104        ['layer_normalization_41[0][0]'] 
                                                                                                  
 dropout_83 (Dropout)           (None, 1, 32)        0           ['conv1d_82[0][0]']              
                                                                                                  
 conv1d_83 (Conv1D)             (None, 1, 96)        3168        ['dropout_83[0][0]']             
                                                                                                  
 tf.__operators__.add_83 (TFOpL  (None, 1, 96)       0           ['conv1d_83[0][0]',              
 ambda)                                                           'tf.__operators__.add_82[0][0]']
                                                                                                  
 dense_40 (Dense)               (None, 1, 128)       12416       ['tf.__operators__.add_83[0][0]']
                                                                                                  
 flatten_20 (Flatten)           (None, 128)          0           ['dense_40[0][0]']               
                                                                                                  
 dense_41 (Dense)               (None, 6)            774         ['flatten_20[0][0]']             
                                                                                                  
==================================================================================================
Total params: 76,614
Trainable params: 76,230
Non-trainable params: 384
__________________________________________________________________________________________________
Epoch 00030: early stopping
Experiment:  141  Set:  har1 Train Labels:  nnar10 Test Labels:  clean
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 6 0
AER:  0.3208065994500458
TER:  0.321, 0.321, 0.321
Score for this model: 
               precision    recall  f1-score   support

           0       0.45      0.60      0.51       173
           1       0.89      0.74      0.81       173
           2       0.62      0.78      0.69       171
           3       0.74      0.56      0.64       186
           4       0.72      0.53      0.61       198
           5       0.77      0.88      0.83       190

    accuracy                           0.68      1091
   macro avg       0.70      0.68      0.68      1091
weighted avg       0.70      0.68      0.68      1091

Confusion Matrix for this model: 
 [[103   4   0   2  35  29]
 [  0 128  45   0   0   0]
 [  4   0 133  34   0   0]
 [ 43   7  23 105   4   4]
 [ 73   2   2   1 104  16]
 [  5   3  13   0   1 168]]
Experiment:  142  Set:  har1 Train Labels:  nnar10 Test Labels:  ncar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 6 1
AER:  0.3593033913840513
TER:  0.344, 0.309, 0.409
Score for this model: 
               precision    recall  f1-score   support

           0       0.41      0.56      0.47       165
           1       0.84      0.69      0.76       176
           2       0.59      0.72      0.65       179
           3       0.73      0.56      0.63       187
           4       0.69      0.50      0.58       199
           5       0.71      0.83      0.77       185

    accuracy                           0.64      1091
   macro avg       0.66      0.64      0.64      1091
weighted avg       0.67      0.64      0.64      1091

Confusion Matrix for this model: 
 [[ 93   5   1   2  34  30]
 [  4 121  45   1   3   2]
 [ 12   4 128  32   0   3]
 [ 37   9  24 104   7   6]
 [ 71   2   3   2  99  22]
 [ 11   3  15   1   1 154]]
Experiment:  143  Set:  har1 Train Labels:  nnar10 Test Labels:  ncar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 6 2
AER:  0.38038496791934007
TER:  0.350, 0.280, 0.480
Score for this model: 
               precision    recall  f1-score   support

           0       0.39      0.52      0.45       170
           1       0.80      0.67      0.73       172
           2       0.57      0.70      0.63       176
           3       0.68      0.52      0.59       188
           4       0.67      0.48      0.56       199
           5       0.71      0.83      0.77       186

    accuracy                           0.62      1091
   macro avg       0.64      0.62      0.62      1091
weighted avg       0.64      0.62      0.62      1091

Confusion Matrix for this model: 
 [[ 89   7   5   5  33  31]
 [  4 115  43   3   3   4]
 [  8   4 124  31   3   6]
 [ 47   7  25  97   7   5]
 [ 71   6   5   5  96  16]
 [  9   5  14   1   2 155]]
Experiment:  144  Set:  har1 Train Labels:  nnar10 Test Labels:  nar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 6 3
AER:  0.3473877176901925
TER:  0.330, 0.297, 0.397
Score for this model: 
               precision    recall  f1-score   support

           0       0.45      0.60      0.51       173
           1       0.89      0.74      0.81       173
           2       0.62      0.60      0.61       223
           3       0.74      0.56      0.64       186
           4       0.51      0.51      0.51       146
           5       0.77      0.88      0.83       190

    accuracy                           0.65      1091
   macro avg       0.66      0.65      0.65      1091
weighted avg       0.67      0.65      0.66      1091

Confusion Matrix for this model: 
 [[103   4   0   2  35  29]
 [  0 128  45   0   0   0]
 [ 23   0 134  34  30   2]
 [ 43   7  23 105   4   4]
 [ 54   2   1   1  74  14]
 [  5   3  13   0   1 168]]
Experiment:  145  Set:  har1 Train Labels:  nnar10 Test Labels:  nar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 6 4
AER:  0.37396883593033914
TER:  0.342, 0.274, 0.474
Score for this model: 
               precision    recall  f1-score   support

           0       0.45      0.60      0.51       173
           1       0.89      0.74      0.81       173
           2       0.62      0.48      0.54       282
           3       0.74      0.56      0.64       186
           4       0.31      0.51      0.38        87
           5       0.77      0.88      0.83       190

    accuracy                           0.63      1091
   macro avg       0.63      0.63      0.62      1091
weighted avg       0.66      0.63      0.63      1091

Confusion Matrix for this model: 
 [[103   4   0   2  35  29]
 [  0 128  45   0   0   0]
 [ 46   0 135  35  60   6]
 [ 43   7  23 105   4   4]
 [ 31   2   0   0  44  10]
 [  5   3  13   0   1 168]]
Experiment:  146  Set:  har1 Train Labels:  nnar10 Test Labels:  nnar5
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 6 5
AER:  0.3400549954170486
TER:  0.322, 0.290, 0.390
Score for this model: 
               precision    recall  f1-score   support

           0       0.45      0.60      0.51       173
           1       0.89      0.74      0.81       173
           2       0.62      0.59      0.61       226
           3       0.74      0.56      0.64       186
           4       0.57      0.57      0.57       143
           5       0.77      0.88      0.83       190

    accuracy                           0.66      1091
   macro avg       0.67      0.66      0.66      1091
weighted avg       0.68      0.66      0.66      1091

Confusion Matrix for this model: 
 [[103   4   0   2  35  29]
 [  0 128  45   0   0   0]
 [ 28   0 134  34  22   8]
 [ 43   7  23 105   4   4]
 [ 49   2   1   1  82   8]
 [  5   3  13   0   1 168]]
Experiment:  147  Set:  har1 Train Labels:  nnar10 Test Labels:  nnar10
Shape of X_train:  (2077, 1, 96)
Shape of X_test:  (1091, 1, 96)
Shape of y_train:  (2077, 6)
Shape of y_test:  (1091, 6)
NUM_INSTANCES is  2077
instances should be  2077
Shape of y true: (1091,)
Shape of y predicted: (1091,)
[0.04139434 0.01089325 0.11630435 0.05082873 0.12318029 0.0299667 ] [0.57225434 0.3583815  0.23391813 0.39784946 0.12121212 0.20526316]
Recording results in matrix at 6 6
AER:  0.3638863428047663
TER:  0.330, 0.264, 0.464
Score for this model: 
               precision    recall  f1-score   support

           0       0.45      0.60      0.51       173
           1       0.89      0.74      0.81       173
           2       0.62      0.48      0.54       281
           3       0.74      0.56      0.64       186
           4       0.38      0.62      0.47        88
           5       0.77      0.88      0.83       190

    accuracy                           0.64      1091
   macro avg       0.64      0.65      0.63      1091
weighted avg       0.67      0.64      0.64      1091

Confusion Matrix for this model: 
 [[103   4   0   2  35  29]
 [  0 128  45   0   0   0]
 [ 52   0 135  34  49  11]
 [ 43   7  23 105   4   4]
 [ 25   2   0   1  55   5]
 [  5   3  13   0   1 168]]
Input Shape:  (7352, 3, 128)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_21"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_22 (InputLayer)          [(None, 3, 128)]     0           []                               
                                                                                                  
 batch_normalization_42 (BatchN  (None, 3, 128)      512         ['input_22[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_42 (Multi  (None, 3, 128)      33088       ['batch_normalization_42[0][0]', 
 HeadAttention)                                                   'batch_normalization_42[0][0]'] 
                                                                                                  
 dropout_84 (Dropout)           (None, 3, 128)       0           ['multi_head_attention_42[0][0]']
                                                                                                  
 tf.__operators__.add_84 (TFOpL  (None, 3, 128)      0           ['dropout_84[0][0]',             
 ambda)                                                           'input_22[0][0]']               
                                                                                                  
 layer_normalization_42 (LayerN  (None, 3, 128)      256         ['tf.__operators__.add_84[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_84 (Conv1D)             (None, 3, 32)        4128        ['layer_normalization_42[0][0]'] 
                                                                                                  
 dropout_85 (Dropout)           (None, 3, 32)        0           ['conv1d_84[0][0]']              
                                                                                                  
 conv1d_85 (Conv1D)             (None, 3, 128)       4224        ['dropout_85[0][0]']             
                                                                                                  
 tf.__operators__.add_85 (TFOpL  (None, 3, 128)      0           ['conv1d_85[0][0]',              
 ambda)                                                           'tf.__operators__.add_84[0][0]']
                                                                                                  
 batch_normalization_43 (BatchN  (None, 3, 128)      512         ['tf.__operators__.add_85[0][0]']
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_43 (Multi  (None, 3, 128)      33088       ['batch_normalization_43[0][0]', 
 HeadAttention)                                                   'batch_normalization_43[0][0]'] 
                                                                                                  
 dropout_86 (Dropout)           (None, 3, 128)       0           ['multi_head_attention_43[0][0]']
                                                                                                  
 tf.__operators__.add_86 (TFOpL  (None, 3, 128)      0           ['dropout_86[0][0]',             
 ambda)                                                           'tf.__operators__.add_85[0][0]']
                                                                                                  
 layer_normalization_43 (LayerN  (None, 3, 128)      256         ['tf.__operators__.add_86[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_86 (Conv1D)             (None, 3, 32)        4128        ['layer_normalization_43[0][0]'] 
                                                                                                  
 dropout_87 (Dropout)           (None, 3, 32)        0           ['conv1d_86[0][0]']              
                                                                                                  
 conv1d_87 (Conv1D)             (None, 3, 128)       4224        ['dropout_87[0][0]']             
                                                                                                  
 tf.__operators__.add_87 (TFOpL  (None, 3, 128)      0           ['conv1d_87[0][0]',              
 ambda)                                                           'tf.__operators__.add_86[0][0]']
                                                                                                  
 dense_42 (Dense)               (None, 3, 128)       16512       ['tf.__operators__.add_87[0][0]']
                                                                                                  
 flatten_21 (Flatten)           (None, 384)          0           ['dense_42[0][0]']               
                                                                                                  
 dense_43 (Dense)               (None, 6)            2310        ['flatten_21[0][0]']             
                                                                                                  
==================================================================================================
Total params: 103,238
Trainable params: 102,726
Non-trainable params: 512
__________________________________________________________________________________________________
Epoch 00066: early stopping
Experiment:  148  Set:  har2 Train Labels:  clean Test Labels:  clean
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
None None
Recording results in matrix at 0 0
AER:  0.10519172039362062
TER:  0.105, 0.105, 0.105
Score for this model: 
               precision    recall  f1-score   support

           0       0.91      0.95      0.93       496
           1       0.95      0.89      0.92       471
           2       0.95      0.97      0.96       420
           3       0.85      0.67      0.75       491
           4       0.75      0.91      0.82       532
           5       1.00      0.98      0.99       537

    accuracy                           0.89      2947
   macro avg       0.90      0.89      0.89      2947
weighted avg       0.90      0.89      0.89      2947

Confusion Matrix for this model: 
 [[470  14  12   0   0   0]
 [ 43 419   9   0   0   0]
 [  3   9 408   0   0   0]
 [  0   0   0 330 161   0]
 [  0   0   0  50 482   0]
 [  0   0   0   9   0 528]]
Experiment:  149  Set:  har2 Train Labels:  clean Test Labels:  ncar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 0 1
AER:  0.14048184594502885
TER:  0.101, 0.090, 0.190
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      0.91      0.90       498
           1       0.91      0.84      0.88       476
           2       0.91      0.93      0.92       421
           3       0.83      0.64      0.72       498
           4       0.71      0.87      0.78       527
           5       0.96      0.96      0.96       527

    accuracy                           0.86      2947
   macro avg       0.87      0.86      0.86      2947
weighted avg       0.86      0.86      0.86      2947

Confusion Matrix for this model: 
 [[455  16  16   2   6   3]
 [ 45 402  13   3   7   6]
 [  7  12 391   1   7   3]
 [  5   2   4 321 160   6]
 [  3   7   3  50 459   5]
 [  1   3   2  12   4 505]]
Experiment:  150  Set:  har2 Train Labels:  clean Test Labels:  ncar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 0 2
AER:  0.19681031557516118
TER:  0.121, 0.097, 0.297
Score for this model: 
               precision    recall  f1-score   support

           0       0.81      0.85      0.83       488
           1       0.85      0.79      0.82       477
           2       0.86      0.84      0.85       439
           3       0.77      0.60      0.68       498
           4       0.68      0.84      0.75       525
           5       0.88      0.90      0.89       520

    accuracy                           0.80      2947
   macro avg       0.81      0.80      0.80      2947
weighted avg       0.81      0.80      0.80      2947

Confusion Matrix for this model: 
 [[416  24  18   9  11  10]
 [ 49 377  20   5  12  14]
 [ 18  16 368   9  15  13]
 [  5  12  11 300 158  12]
 [ 12   5   7  50 439  12]
 [ 16   8   5  16   8 467]]
Experiment:  151  Set:  har2 Train Labels:  clean Test Labels:  nar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 0 3
AER:  0.15575161180861893
TER:  0.118, 0.106, 0.206
Score for this model: 
               precision    recall  f1-score   support

           0       0.91      0.95      0.93       496
           1       0.95      0.89      0.92       471
           2       0.95      0.71      0.81       574
           3       0.85      0.67      0.75       491
           4       0.75      0.91      0.82       532
           5       0.72      0.99      0.83       383

    accuracy                           0.84      2947
   macro avg       0.85      0.85      0.84      2947
weighted avg       0.86      0.84      0.84      2947

Confusion Matrix for this model: 
 [[470  14  12   0   0   0]
 [ 43 419   9   0   0   0]
 [  3   9 408   5   0 149]
 [  0   0   0 330 161   0]
 [  0   0   0  50 482   0]
 [  0   0   0   4   0 379]]
Experiment:  152  Set:  har2 Train Labels:  clean Test Labels:  nar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 0 4
AER:  0.20800814387512725
TER:  0.135, 0.108, 0.308
Score for this model: 
               precision    recall  f1-score   support

           0       0.91      0.95      0.93       496
           1       0.95      0.89      0.92       471
           2       0.95      0.56      0.70       730
           3       0.85      0.67      0.75       491
           4       0.75      0.91      0.82       532
           5       0.43      0.99      0.60       227

    accuracy                           0.79      2947
   macro avg       0.81      0.83      0.79      2947
weighted avg       0.85      0.79      0.80      2947

Confusion Matrix for this model: 
 [[470  14  12   0   0   0]
 [ 43 419   9   0   0   0]
 [  3   9 408   7   0 303]
 [  0   0   0 330 161   0]
 [  0   0   0  50 482   0]
 [  0   0   0   2   0 225]]
Experiment:  153  Set:  har2 Train Labels:  clean Test Labels:  nnar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 0 5
AER:  0.15473362741771293
TER:  0.116, 0.105, 0.205
Score for this model: 
               precision    recall  f1-score   support

           0       0.91      0.95      0.93       496
           1       0.95      0.89      0.92       471
           2       0.95      0.72      0.82       568
           3       0.85      0.67      0.75       491
           4       0.75      0.91      0.82       532
           5       0.72      0.98      0.83       389

    accuracy                           0.85      2947
   macro avg       0.86      0.85      0.84      2947
weighted avg       0.86      0.85      0.84      2947

Confusion Matrix for this model: 
 [[470  14  12   0   0   0]
 [ 43 419   9   0   0   0]
 [  3   9 408   2   0 146]
 [  0   0   0 330 161   0]
 [  0   0   0  50 482   0]
 [  0   0   0   7   0 382]]
Experiment:  154  Set:  har2 Train Labels:  clean Test Labels:  nnar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 0 6
AER:  0.20359687818120123
TER:  0.129, 0.104, 0.304
Score for this model: 
               precision    recall  f1-score   support

           0       0.91      0.95      0.93       496
           1       0.95      0.89      0.92       471
           2       0.95      0.57      0.71       715
           3       0.85      0.67      0.75       491
           4       0.75      0.91      0.82       532
           5       0.45      0.98      0.62       242

    accuracy                           0.80      2947
   macro avg       0.81      0.83      0.79      2947
weighted avg       0.85      0.80      0.80      2947

Confusion Matrix for this model: 
 [[470  14  12   0   0   0]
 [ 43 419   9   0   0   0]
 [  3   9 408   5   0 290]
 [  0   0   0 330 161   0]
 [  0   0   0  50 482   0]
 [  0   0   0   4   0 238]]
Input Shape:  (7352, 3, 128)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_22"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_23 (InputLayer)          [(None, 3, 128)]     0           []                               
                                                                                                  
 batch_normalization_44 (BatchN  (None, 3, 128)      512         ['input_23[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_44 (Multi  (None, 3, 128)      33088       ['batch_normalization_44[0][0]', 
 HeadAttention)                                                   'batch_normalization_44[0][0]'] 
                                                                                                  
 dropout_88 (Dropout)           (None, 3, 128)       0           ['multi_head_attention_44[0][0]']
                                                                                                  
 tf.__operators__.add_88 (TFOpL  (None, 3, 128)      0           ['dropout_88[0][0]',             
 ambda)                                                           'input_23[0][0]']               
                                                                                                  
 layer_normalization_44 (LayerN  (None, 3, 128)      256         ['tf.__operators__.add_88[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_88 (Conv1D)             (None, 3, 32)        4128        ['layer_normalization_44[0][0]'] 
                                                                                                  
 dropout_89 (Dropout)           (None, 3, 32)        0           ['conv1d_88[0][0]']              
                                                                                                  
 conv1d_89 (Conv1D)             (None, 3, 128)       4224        ['dropout_89[0][0]']             
                                                                                                  
 tf.__operators__.add_89 (TFOpL  (None, 3, 128)      0           ['conv1d_89[0][0]',              
 ambda)                                                           'tf.__operators__.add_88[0][0]']
                                                                                                  
 batch_normalization_45 (BatchN  (None, 3, 128)      512         ['tf.__operators__.add_89[0][0]']
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_45 (Multi  (None, 3, 128)      33088       ['batch_normalization_45[0][0]', 
 HeadAttention)                                                   'batch_normalization_45[0][0]'] 
                                                                                                  
 dropout_90 (Dropout)           (None, 3, 128)       0           ['multi_head_attention_45[0][0]']
                                                                                                  
 tf.__operators__.add_90 (TFOpL  (None, 3, 128)      0           ['dropout_90[0][0]',             
 ambda)                                                           'tf.__operators__.add_89[0][0]']
                                                                                                  
 layer_normalization_45 (LayerN  (None, 3, 128)      256         ['tf.__operators__.add_90[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_90 (Conv1D)             (None, 3, 32)        4128        ['layer_normalization_45[0][0]'] 
                                                                                                  
 dropout_91 (Dropout)           (None, 3, 32)        0           ['conv1d_90[0][0]']              
                                                                                                  
 conv1d_91 (Conv1D)             (None, 3, 128)       4224        ['dropout_91[0][0]']             
                                                                                                  
 tf.__operators__.add_91 (TFOpL  (None, 3, 128)      0           ['conv1d_91[0][0]',              
 ambda)                                                           'tf.__operators__.add_90[0][0]']
                                                                                                  
 dense_44 (Dense)               (None, 3, 128)       16512       ['tf.__operators__.add_91[0][0]']
                                                                                                  
 flatten_22 (Flatten)           (None, 384)          0           ['dense_44[0][0]']               
                                                                                                  
 dense_45 (Dense)               (None, 6)            2310        ['flatten_22[0][0]']             
                                                                                                  
==================================================================================================
Total params: 103,238
Trainable params: 102,726
Non-trainable params: 512
__________________________________________________________________________________________________
Epoch 00054: early stopping
Experiment:  155  Set:  har2 Train Labels:  ncar5 Test Labels:  clean
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 1 0
AER:  0.1377672209026128
TER:  0.138, 0.138, 0.138
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.96      0.87       496
           1       0.97      0.72      0.83       471
           2       0.91      0.95      0.93       420
           3       0.80      0.71      0.75       491
           4       0.76      0.85      0.80       532
           5       0.99      0.99      0.99       537

    accuracy                           0.86      2947
   macro avg       0.87      0.86      0.86      2947
weighted avg       0.87      0.86      0.86      2947

Confusion Matrix for this model: 
 [[478   6  12   0   0   0]
 [105 339  24   0   3   0]
 [ 18   5 397   0   0   0]
 [  1   0   0 347 140   3]
 [  1   0   0  81 450   0]
 [  0   0   1   6   0 530]]
Experiment:  156  Set:  har2 Train Labels:  ncar5 Test Labels:  ncar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 1 1
AER:  0.17068204954190702
TER:  0.134, 0.121, 0.221
Score for this model: 
               precision    recall  f1-score   support

           0       0.77      0.93      0.84       498
           1       0.94      0.69      0.79       476
           2       0.88      0.90      0.89       421
           3       0.78      0.68      0.72       498
           4       0.72      0.81      0.76       527
           5       0.95      0.96      0.96       527

    accuracy                           0.83      2947
   macro avg       0.84      0.83      0.83      2947
weighted avg       0.84      0.83      0.83      2947

Confusion Matrix for this model: 
 [[465   7  15   3   5   3]
 [100 328  29   3  10   6]
 [ 21   9 380   1   7   3]
 [  8   1   3 337 140   9]
 [  8   3   3  81 427   5]
 [  1   2   4   9   4 507]]
Experiment:  157  Set:  har2 Train Labels:  ncar5 Test Labels:  ncar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 1 2
AER:  0.22463522225992535
TER:  0.156, 0.125, 0.325
Score for this model: 
               precision    recall  f1-score   support

           0       0.71      0.88      0.79       488
           1       0.87      0.64      0.74       477
           2       0.83      0.82      0.82       439
           3       0.72      0.63      0.67       498
           4       0.69      0.78      0.73       525
           5       0.88      0.90      0.89       520

    accuracy                           0.78      2947
   macro avg       0.78      0.77      0.77      2947
weighted avg       0.78      0.78      0.77      2947

Confusion Matrix for this model: 
 [[429  15  14  12   8  10]
 [104 304  35   6  14  14]
 [ 32  10 360  10  14  13]
 [  9   9  11 314 140  15]
 [ 14   4   7  79 409  12]
 [ 15   8   7  13   8 469]]
Experiment:  158  Set:  har2 Train Labels:  ncar5 Test Labels:  nar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 1 3
AER:  0.18866644044791314
TER:  0.154, 0.139, 0.239
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.96      0.87       496
           1       0.97      0.72      0.83       471
           2       0.91      0.69      0.79       574
           3       0.80      0.71      0.75       491
           4       0.76      0.85      0.80       532
           5       0.71      0.99      0.83       383

    accuracy                           0.81      2947
   macro avg       0.82      0.82      0.81      2947
weighted avg       0.83      0.81      0.81      2947

Confusion Matrix for this model: 
 [[478   6  12   0   0   0]
 [105 339  24   0   3   0]
 [ 18   5 397   4   0 150]
 [  1   0   0 347 140   3]
 [  1   0   0  81 450   0]
 [  0   0   1   2   0 380]]
Experiment:  159  Set:  har2 Train Labels:  ncar5 Test Labels:  nar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 1 4
AER:  0.24160162877502545
TER:  0.177, 0.142, 0.342
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.96      0.87       496
           1       0.97      0.72      0.83       471
           2       0.91      0.54      0.68       730
           3       0.80      0.71      0.75       491
           4       0.76      0.85      0.80       532
           5       0.42      0.99      0.59       227

    accuracy                           0.76      2947
   macro avg       0.78      0.79      0.75      2947
weighted avg       0.82      0.76      0.76      2947

Confusion Matrix for this model: 
 [[478   6  12   0   0   0]
 [105 339  24   0   3   0]
 [ 18   5 397   4   0 306]
 [  1   0   0 347 140   3]
 [  1   0   0  81 450   0]
 [  0   0   1   2   0 224]]
Experiment:  160  Set:  har2 Train Labels:  ncar5 Test Labels:  nnar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 1 5
AER:  0.1876484560570071
TER:  0.153, 0.138, 0.238
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.96      0.87       496
           1       0.97      0.72      0.83       471
           2       0.91      0.70      0.79       568
           3       0.80      0.71      0.75       491
           4       0.76      0.85      0.80       532
           5       0.72      0.98      0.83       389

    accuracy                           0.81      2947
   macro avg       0.83      0.82      0.81      2947
weighted avg       0.83      0.81      0.81      2947

Confusion Matrix for this model: 
 [[478   6  12   0   0   0]
 [105 339  24   0   3   0]
 [ 18   5 397   1   0 147]
 [  1   0   0 347 140   3]
 [  1   0   0  81 450   0]
 [  0   0   1   5   0 383]]
Experiment:  161  Set:  har2 Train Labels:  ncar5 Test Labels:  nnar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 1 6
AER:  0.23719036308109942
TER:  0.171, 0.137, 0.337
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.96      0.87       496
           1       0.97      0.72      0.83       471
           2       0.91      0.56      0.69       715
           3       0.80      0.71      0.75       491
           4       0.76      0.85      0.80       532
           5       0.44      0.98      0.61       242

    accuracy                           0.76      2947
   macro avg       0.78      0.80      0.76      2947
weighted avg       0.82      0.76      0.77      2947

Confusion Matrix for this model: 
 [[478   6  12   0   0   0]
 [105 339  24   0   3   0]
 [ 18   5 397   2   0 293]
 [  1   0   0 347 140   3]
 [  1   0   0  81 450   0]
 [  0   0   1   4   0 237]]
Input Shape:  (7352, 3, 128)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_23"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_24 (InputLayer)          [(None, 3, 128)]     0           []                               
                                                                                                  
 batch_normalization_46 (BatchN  (None, 3, 128)      512         ['input_24[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_46 (Multi  (None, 3, 128)      33088       ['batch_normalization_46[0][0]', 
 HeadAttention)                                                   'batch_normalization_46[0][0]'] 
                                                                                                  
 dropout_92 (Dropout)           (None, 3, 128)       0           ['multi_head_attention_46[0][0]']
                                                                                                  
 tf.__operators__.add_92 (TFOpL  (None, 3, 128)      0           ['dropout_92[0][0]',             
 ambda)                                                           'input_24[0][0]']               
                                                                                                  
 layer_normalization_46 (LayerN  (None, 3, 128)      256         ['tf.__operators__.add_92[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_92 (Conv1D)             (None, 3, 32)        4128        ['layer_normalization_46[0][0]'] 
                                                                                                  
 dropout_93 (Dropout)           (None, 3, 32)        0           ['conv1d_92[0][0]']              
                                                                                                  
 conv1d_93 (Conv1D)             (None, 3, 128)       4224        ['dropout_93[0][0]']             
                                                                                                  
 tf.__operators__.add_93 (TFOpL  (None, 3, 128)      0           ['conv1d_93[0][0]',              
 ambda)                                                           'tf.__operators__.add_92[0][0]']
                                                                                                  
 batch_normalization_47 (BatchN  (None, 3, 128)      512         ['tf.__operators__.add_93[0][0]']
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_47 (Multi  (None, 3, 128)      33088       ['batch_normalization_47[0][0]', 
 HeadAttention)                                                   'batch_normalization_47[0][0]'] 
                                                                                                  
 dropout_94 (Dropout)           (None, 3, 128)       0           ['multi_head_attention_47[0][0]']
                                                                                                  
 tf.__operators__.add_94 (TFOpL  (None, 3, 128)      0           ['dropout_94[0][0]',             
 ambda)                                                           'tf.__operators__.add_93[0][0]']
                                                                                                  
 layer_normalization_47 (LayerN  (None, 3, 128)      256         ['tf.__operators__.add_94[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_94 (Conv1D)             (None, 3, 32)        4128        ['layer_normalization_47[0][0]'] 
                                                                                                  
 dropout_95 (Dropout)           (None, 3, 32)        0           ['conv1d_94[0][0]']              
                                                                                                  
 conv1d_95 (Conv1D)             (None, 3, 128)       4224        ['dropout_95[0][0]']             
                                                                                                  
 tf.__operators__.add_95 (TFOpL  (None, 3, 128)      0           ['conv1d_95[0][0]',              
 ambda)                                                           'tf.__operators__.add_94[0][0]']
                                                                                                  
 dense_46 (Dense)               (None, 3, 128)       16512       ['tf.__operators__.add_95[0][0]']
                                                                                                  
 flatten_23 (Flatten)           (None, 384)          0           ['dense_46[0][0]']               
                                                                                                  
 dense_47 (Dense)               (None, 6)            2310        ['flatten_23[0][0]']             
                                                                                                  
==================================================================================================
Total params: 103,238
Trainable params: 102,726
Non-trainable params: 512
__________________________________________________________________________________________________
Epoch 00044: early stopping
Experiment:  162  Set:  har2 Train Labels:  ncar10 Test Labels:  clean
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 2 0
AER:  0.13844587716321682
TER:  0.138, 0.138, 0.138
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.96      0.88       496
           1       0.93      0.79      0.86       471
           2       0.94      0.87      0.90       420
           3       0.75      0.77      0.76       491
           4       0.79      0.82      0.80       532
           5       0.99      0.95      0.97       537

    accuracy                           0.86      2947
   macro avg       0.87      0.86      0.86      2947
weighted avg       0.87      0.86      0.86      2947

Confusion Matrix for this model: 
 [[478   5  13   0   0   0]
 [ 81 372  11   1   5   1]
 [ 32  22 365   0   1   0]
 [  1   0   0 379 109   2]
 [  2   0   0  95 435   0]
 [  0   0   0  27   0 510]]
Experiment:  163  Set:  har2 Train Labels:  ncar10 Test Labels:  ncar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 2 1
AER:  0.17136070580251103
TER:  0.135, 0.121, 0.221
Score for this model: 
               precision    recall  f1-score   support

           0       0.78      0.93      0.85       498
           1       0.90      0.75      0.82       476
           2       0.90      0.83      0.86       421
           3       0.74      0.74      0.74       498
           4       0.75      0.79      0.77       527
           5       0.95      0.93      0.94       527

    accuracy                           0.83      2947
   macro avg       0.84      0.83      0.83      2947
weighted avg       0.83      0.83      0.83      2947

Confusion Matrix for this model: 
 [[464   8  15   5   4   2]
 [ 79 358  16   4  12   7]
 [ 34  26 349   2   7   3]
 [  8   1   3 369 109   8]
 [  8   4   3  93 414   5]
 [  1   2   3  29   4 488]]
Experiment:  164  Set:  har2 Train Labels:  ncar10 Test Labels:  ncar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 2 2
AER:  0.22192059721750934
TER:  0.152, 0.122, 0.322
Score for this model: 
               precision    recall  f1-score   support

           0       0.72      0.88      0.79       488
           1       0.84      0.71      0.77       477
           2       0.85      0.76      0.80       439
           3       0.69      0.69      0.69       498
           4       0.73      0.76      0.74       525
           5       0.88      0.87      0.87       520

    accuracy                           0.78      2947
   macro avg       0.79      0.78      0.78      2947
weighted avg       0.78      0.78      0.78      2947

Confusion Matrix for this model: 
 [[427  17  14  13   8   9]
 [ 82 337  20  10  14  14]
 [ 42  27 332  11  14  13]
 [ 12   8   9 346 109  14]
 [ 15   3   8  87 400  12]
 [ 16   7   6  35   5 451]]
Experiment:  165  Set:  har2 Train Labels:  ncar10 Test Labels:  nar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 2 3
AER:  0.18696979979640313
TER:  0.152, 0.137, 0.237
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.96      0.88       496
           1       0.93      0.79      0.86       471
           2       0.94      0.64      0.76       574
           3       0.75      0.77      0.76       491
           4       0.79      0.82      0.80       532
           5       0.72      0.96      0.82       383

    accuracy                           0.81      2947
   macro avg       0.82      0.82      0.81      2947
weighted avg       0.83      0.81      0.81      2947

Confusion Matrix for this model: 
 [[478   5  13   0   0   0]
 [ 81 372  11   1   5   1]
 [ 32  22 365  11   1 143]
 [  1   0   0 379 109   2]
 [  2   0   0  95 435   0]
 [  0   0   0  16   0 367]]
Experiment:  166  Set:  har2 Train Labels:  ncar10 Test Labels:  nar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 2 4
AER:  0.2375296912114014
TER:  0.172, 0.138, 0.338
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.96      0.88       496
           1       0.93      0.79      0.86       471
           2       0.94      0.50      0.65       730
           3       0.75      0.77      0.76       491
           4       0.79      0.82      0.80       532
           5       0.42      0.96      0.59       227

    accuracy                           0.76      2947
   macro avg       0.77      0.80      0.76      2947
weighted avg       0.82      0.76      0.76      2947

Confusion Matrix for this model: 
 [[478   5  13   0   0   0]
 [ 81 372  11   1   5   1]
 [ 32  22 365  18   1 292]
 [  1   0   0 379 109   2]
 [  2   0   0  95 435   0]
 [  0   0   0   9   0 218]]
Experiment:  167  Set:  har2 Train Labels:  ncar10 Test Labels:  nnar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 2 5
AER:  0.18730912792670512
TER:  0.153, 0.137, 0.237
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.96      0.88       496
           1       0.93      0.79      0.86       471
           2       0.94      0.64      0.76       568
           3       0.75      0.77      0.76       491
           4       0.79      0.82      0.80       532
           5       0.71      0.94      0.81       389

    accuracy                           0.81      2947
   macro avg       0.82      0.82      0.81      2947
weighted avg       0.83      0.81      0.81      2947

Confusion Matrix for this model: 
 [[478   5  13   0   0   0]
 [ 81 372  11   1   5   1]
 [ 32  22 365   4   1 144]
 [  1   0   0 379 109   2]
 [  2   0   0  95 435   0]
 [  0   0   0  23   0 366]]
Experiment:  168  Set:  har2 Train Labels:  ncar10 Test Labels:  nnar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 2 6
AER:  0.2337970817780794
TER:  0.167, 0.134, 0.334
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.96      0.88       496
           1       0.93      0.79      0.86       471
           2       0.94      0.51      0.66       715
           3       0.75      0.77      0.76       491
           4       0.79      0.82      0.80       532
           5       0.45      0.95      0.61       242

    accuracy                           0.77      2947
   macro avg       0.78      0.80      0.76      2947
weighted avg       0.82      0.77      0.77      2947

Confusion Matrix for this model: 
 [[478   5  13   0   0   0]
 [ 81 372  11   1   5   1]
 [ 32  22 365  14   1 281]
 [  1   0   0 379 109   2]
 [  2   0   0  95 435   0]
 [  0   0   0  13   0 229]]
Input Shape:  (7352, 3, 128)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_24"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_25 (InputLayer)          [(None, 3, 128)]     0           []                               
                                                                                                  
 batch_normalization_48 (BatchN  (None, 3, 128)      512         ['input_25[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_48 (Multi  (None, 3, 128)      33088       ['batch_normalization_48[0][0]', 
 HeadAttention)                                                   'batch_normalization_48[0][0]'] 
                                                                                                  
 dropout_96 (Dropout)           (None, 3, 128)       0           ['multi_head_attention_48[0][0]']
                                                                                                  
 tf.__operators__.add_96 (TFOpL  (None, 3, 128)      0           ['dropout_96[0][0]',             
 ambda)                                                           'input_25[0][0]']               
                                                                                                  
 layer_normalization_48 (LayerN  (None, 3, 128)      256         ['tf.__operators__.add_96[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_96 (Conv1D)             (None, 3, 32)        4128        ['layer_normalization_48[0][0]'] 
                                                                                                  
 dropout_97 (Dropout)           (None, 3, 32)        0           ['conv1d_96[0][0]']              
                                                                                                  
 conv1d_97 (Conv1D)             (None, 3, 128)       4224        ['dropout_97[0][0]']             
                                                                                                  
 tf.__operators__.add_97 (TFOpL  (None, 3, 128)      0           ['conv1d_97[0][0]',              
 ambda)                                                           'tf.__operators__.add_96[0][0]']
                                                                                                  
 batch_normalization_49 (BatchN  (None, 3, 128)      512         ['tf.__operators__.add_97[0][0]']
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_49 (Multi  (None, 3, 128)      33088       ['batch_normalization_49[0][0]', 
 HeadAttention)                                                   'batch_normalization_49[0][0]'] 
                                                                                                  
 dropout_98 (Dropout)           (None, 3, 128)       0           ['multi_head_attention_49[0][0]']
                                                                                                  
 tf.__operators__.add_98 (TFOpL  (None, 3, 128)      0           ['dropout_98[0][0]',             
 ambda)                                                           'tf.__operators__.add_97[0][0]']
                                                                                                  
 layer_normalization_49 (LayerN  (None, 3, 128)      256         ['tf.__operators__.add_98[0][0]']
 ormalization)                                                                                    
                                                                                                  
 conv1d_98 (Conv1D)             (None, 3, 32)        4128        ['layer_normalization_49[0][0]'] 
                                                                                                  
 dropout_99 (Dropout)           (None, 3, 32)        0           ['conv1d_98[0][0]']              
                                                                                                  
 conv1d_99 (Conv1D)             (None, 3, 128)       4224        ['dropout_99[0][0]']             
                                                                                                  
 tf.__operators__.add_99 (TFOpL  (None, 3, 128)      0           ['conv1d_99[0][0]',              
 ambda)                                                           'tf.__operators__.add_98[0][0]']
                                                                                                  
 dense_48 (Dense)               (None, 3, 128)       16512       ['tf.__operators__.add_99[0][0]']
                                                                                                  
 flatten_24 (Flatten)           (None, 384)          0           ['dense_48[0][0]']               
                                                                                                  
 dense_49 (Dense)               (None, 6)            2310        ['flatten_24[0][0]']             
                                                                                                  
==================================================================================================
Total params: 103,238
Trainable params: 102,726
Non-trainable params: 512
__________________________________________________________________________________________________
Epoch 00058: early stopping
Experiment:  169  Set:  har2 Train Labels:  nar5 Test Labels:  clean
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 3 0
AER:  0.1174075330844927
TER:  0.117, 0.117, 0.117
Score for this model: 
               precision    recall  f1-score   support

           0       0.90      0.96      0.93       496
           1       0.92      0.90      0.91       471
           2       0.95      0.93      0.94       420
           3       0.77      0.73      0.75       491
           4       0.78      0.84      0.81       532
           5       1.00      0.94      0.97       537

    accuracy                           0.88      2947
   macro avg       0.89      0.88      0.88      2947
weighted avg       0.88      0.88      0.88      2947

Confusion Matrix for this model: 
 [[474  14   8   0   0   0]
 [ 44 425   2   0   0   0]
 [  7  22 391   0   0   0]
 [  1   0   0 359 129   2]
 [  0   0   0  86 446   0]
 [  0   0   9  22   0 506]]
Experiment:  170  Set:  har2 Train Labels:  nar5 Test Labels:  ncar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 3 1
AER:  0.15303698676620292
TER:  0.114, 0.103, 0.203
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.92      0.90       498
           1       0.88      0.86      0.87       476
           2       0.91      0.89      0.90       421
           3       0.75      0.70      0.72       498
           4       0.74      0.80      0.77       527
           5       0.95      0.92      0.94       527

    accuracy                           0.85      2947
   macro avg       0.85      0.85      0.85      2947
weighted avg       0.85      0.85      0.85      2947

Confusion Matrix for this model: 
 [[459  17  11   5   4   2]
 [ 46 407   7   3   7   6]
 [ 11  24 375   1   7   3]
 [  6   2   4 348 130   8]
 [  3   7   3  86 423   5]
 [  1   4  10  24   4 484]]
Experiment:  171  Set:  har2 Train Labels:  nar5 Test Labels:  ncar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 3 2
AER:  0.20732948761452324
TER:  0.134, 0.107, 0.307
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.86      0.83       488
           1       0.84      0.81      0.82       477
           2       0.86      0.80      0.83       439
           3       0.70      0.65      0.67       498
           4       0.71      0.77      0.74       525
           5       0.88      0.86      0.87       520

    accuracy                           0.79      2947
   macro avg       0.80      0.79      0.79      2947
weighted avg       0.79      0.79      0.79      2947

Confusion Matrix for this model: 
 [[421  24  13  12   8  10]
 [ 48 385  13   7  11  13]
 [ 23  26 353   9  15  13]
 [  7  12  10 325 130  14]
 [ 12   5   7  83 406  12]
 [ 15   9  14  31   5 446]]
Experiment:  172  Set:  har2 Train Labels:  nar5 Test Labels:  nar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 3 3
AER:  0.16457414319647098
TER:  0.127, 0.115, 0.215
Score for this model: 
               precision    recall  f1-score   support

           0       0.90      0.96      0.93       496
           1       0.92      0.90      0.91       471
           2       0.96      0.69      0.80       574
           3       0.77      0.73      0.75       491
           4       0.78      0.84      0.81       532
           5       0.72      0.95      0.82       383

    accuracy                           0.84      2947
   macro avg       0.84      0.84      0.84      2947
weighted avg       0.85      0.84      0.83      2947

Confusion Matrix for this model: 
 [[474  14   8   0   0   0]
 [ 44 425   2   0   0   0]
 [  7  22 394   9   0 142]
 [  1   0   0 359 129   2]
 [  0   0   0  86 446   0]
 [  0   0   6  13   0 364]]
Experiment:  173  Set:  har2 Train Labels:  nar5 Test Labels:  nar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 3 4
AER:  0.2141160502205633
TER:  0.143, 0.114, 0.314
Score for this model: 
               precision    recall  f1-score   support

           0       0.90      0.96      0.93       496
           1       0.92      0.90      0.91       471
           2       0.97      0.54      0.69       730
           3       0.77      0.73      0.75       491
           4       0.78      0.84      0.81       532
           5       0.43      0.95      0.59       227

    accuracy                           0.79      2947
   macro avg       0.79      0.82      0.78      2947
weighted avg       0.84      0.79      0.79      2947

Confusion Matrix for this model: 
 [[474  14   8   0   0   0]
 [ 44 425   2   0   0   0]
 [  7  22 396  15   0 290]
 [  1   0   0 359 129   2]
 [  0   0   0  86 446   0]
 [  0   0   4   7   0 216]]
Experiment:  174  Set:  har2 Train Labels:  nar5 Test Labels:  nnar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 3 5
AER:  0.165252799457075
TER:  0.128, 0.115, 0.215
Score for this model: 
               precision    recall  f1-score   support

           0       0.90      0.96      0.93       496
           1       0.92      0.90      0.91       471
           2       0.96      0.69      0.80       568
           3       0.77      0.73      0.75       491
           4       0.78      0.84      0.81       532
           5       0.71      0.93      0.81       389

    accuracy                           0.83      2947
   macro avg       0.84      0.84      0.83      2947
weighted avg       0.85      0.83      0.83      2947

Confusion Matrix for this model: 
 [[474  14   8   0   0   0]
 [ 44 425   2   0   0   0]
 [  7  22 393   3   0 143]
 [  1   0   0 359 129   2]
 [  0   0   0  86 446   0]
 [  0   0   7  19   0 363]]
Experiment:  175  Set:  har2 Train Labels:  nar5 Test Labels:  nnar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 3 6
AER:  0.20936545639633525
TER:  0.137, 0.109, 0.309
Score for this model: 
               precision    recall  f1-score   support

           0       0.90      0.96      0.93       496
           1       0.92      0.90      0.91       471
           2       0.97      0.56      0.71       715
           3       0.77      0.73      0.75       491
           4       0.78      0.84      0.81       532
           5       0.45      0.95      0.61       242

    accuracy                           0.79      2947
   macro avg       0.80      0.82      0.79      2947
weighted avg       0.84      0.79      0.79      2947

Confusion Matrix for this model: 
 [[474  14   8   0   0   0]
 [ 44 425   2   0   0   0]
 [  7  22 397  12   0 277]
 [  1   0   0 359 129   2]
 [  0   0   0  86 446   0]
 [  0   0   3  10   0 229]]
Input Shape:  (7352, 3, 128)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_25"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_26 (InputLayer)          [(None, 3, 128)]     0           []                               
                                                                                                  
 batch_normalization_50 (BatchN  (None, 3, 128)      512         ['input_26[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_50 (Multi  (None, 3, 128)      33088       ['batch_normalization_50[0][0]', 
 HeadAttention)                                                   'batch_normalization_50[0][0]'] 
                                                                                                  
 dropout_100 (Dropout)          (None, 3, 128)       0           ['multi_head_attention_50[0][0]']
                                                                                                  
 tf.__operators__.add_100 (TFOp  (None, 3, 128)      0           ['dropout_100[0][0]',            
 Lambda)                                                          'input_26[0][0]']               
                                                                                                  
 layer_normalization_50 (LayerN  (None, 3, 128)      256         ['tf.__operators__.add_100[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_100 (Conv1D)            (None, 3, 32)        4128        ['layer_normalization_50[0][0]'] 
                                                                                                  
 dropout_101 (Dropout)          (None, 3, 32)        0           ['conv1d_100[0][0]']             
                                                                                                  
 conv1d_101 (Conv1D)            (None, 3, 128)       4224        ['dropout_101[0][0]']            
                                                                                                  
 tf.__operators__.add_101 (TFOp  (None, 3, 128)      0           ['conv1d_101[0][0]',             
 Lambda)                                                          'tf.__operators__.add_100[0][0]'
                                                                 ]                                
                                                                                                  
 batch_normalization_51 (BatchN  (None, 3, 128)      512         ['tf.__operators__.add_101[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 multi_head_attention_51 (Multi  (None, 3, 128)      33088       ['batch_normalization_51[0][0]', 
 HeadAttention)                                                   'batch_normalization_51[0][0]'] 
                                                                                                  
 dropout_102 (Dropout)          (None, 3, 128)       0           ['multi_head_attention_51[0][0]']
                                                                                                  
 tf.__operators__.add_102 (TFOp  (None, 3, 128)      0           ['dropout_102[0][0]',            
 Lambda)                                                          'tf.__operators__.add_101[0][0]'
                                                                 ]                                
                                                                                                  
 layer_normalization_51 (LayerN  (None, 3, 128)      256         ['tf.__operators__.add_102[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_102 (Conv1D)            (None, 3, 32)        4128        ['layer_normalization_51[0][0]'] 
                                                                                                  
 dropout_103 (Dropout)          (None, 3, 32)        0           ['conv1d_102[0][0]']             
                                                                                                  
 conv1d_103 (Conv1D)            (None, 3, 128)       4224        ['dropout_103[0][0]']            
                                                                                                  
 tf.__operators__.add_103 (TFOp  (None, 3, 128)      0           ['conv1d_103[0][0]',             
 Lambda)                                                          'tf.__operators__.add_102[0][0]'
                                                                 ]                                
                                                                                                  
 dense_50 (Dense)               (None, 3, 128)       16512       ['tf.__operators__.add_103[0][0]'
                                                                 ]                                
                                                                                                  
 flatten_25 (Flatten)           (None, 384)          0           ['dense_50[0][0]']               
                                                                                                  
 dense_51 (Dense)               (None, 6)            2310        ['flatten_25[0][0]']             
                                                                                                  
==================================================================================================
Total params: 103,238
Trainable params: 102,726
Non-trainable params: 512
__________________________________________________________________________________________________
Epoch 00084: early stopping
Experiment:  176  Set:  har2 Train Labels:  nar10 Test Labels:  clean
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 4 0
AER:  0.17780794027824906
TER:  0.178, 0.178, 0.178
Score for this model: 
               precision    recall  f1-score   support

           0       0.85      0.99      0.91       496
           1       0.99      0.81      0.89       471
           2       0.66      0.97      0.79       420
           3       0.76      0.79      0.78       491
           4       0.80      0.78      0.79       532
           5       1.00      0.64      0.78       537

    accuracy                           0.82      2947
   macro avg       0.84      0.83      0.82      2947
weighted avg       0.85      0.82      0.82      2947

Confusion Matrix for this model: 
 [[489   2   5   0   0   0]
 [ 78 381  12   0   0   0]
 [ 11   3 406   0   0   0]
 [  0   0   0 389 102   0]
 [  0   0   0 115 417   0]
 [  0   0 190   6   0 341]]
Experiment:  177  Set:  har2 Train Labels:  nar10 Test Labels:  ncar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 4 1
AER:  0.20970478452663727
TER:  0.177, 0.160, 0.260
Score for this model: 
               precision    recall  f1-score   support

           0       0.82      0.95      0.88       498
           1       0.95      0.77      0.85       476
           2       0.64      0.93      0.76       421
           3       0.74      0.76      0.75       498
           4       0.76      0.75      0.76       527
           5       0.95      0.62      0.75       527

    accuracy                           0.79      2947
   macro avg       0.81      0.80      0.79      2947
weighted avg       0.81      0.79      0.79      2947

Confusion Matrix for this model: 
 [[475   4   8   5   3   3]
 [ 78 365  19   4   6   4]
 [ 14   7 392   1   7   0]
 [  6   2   4 376 105   5]
 [  4   6   4 113 396   4]
 [  1   2 186  11   2 325]]
Experiment:  178  Set:  har2 Train Labels:  nar10 Test Labels:  ncar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 4 2
AER:  0.25958601968103157
TER:  0.199, 0.160, 0.360
Score for this model: 
               precision    recall  f1-score   support

           0       0.75      0.89      0.81       488
           1       0.89      0.72      0.80       477
           2       0.61      0.85      0.71       439
           3       0.69      0.71      0.70       498
           4       0.73      0.72      0.72       525
           5       0.88      0.58      0.70       520

    accuracy                           0.74      2947
   macro avg       0.76      0.74      0.74      2947
weighted avg       0.76      0.74      0.74      2947

Confusion Matrix for this model: 
 [[434  14  15  12   8   5]
 [ 80 344  27   7  10   9]
 [ 26   8 372   9  15   9]
 [  7  10  13 354 104  10]
 [ 14   3  12 112 377   7]
 [ 17   7 174  16   5 301]]
Experiment:  179  Set:  har2 Train Labels:  nar10 Test Labels:  nar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 4 3
AER:  0.18968442483881914
TER:  0.155, 0.140, 0.240
Score for this model: 
               precision    recall  f1-score   support

           0       0.85      0.99      0.91       496
           1       0.99      0.81      0.89       471
           2       0.76      0.81      0.78       574
           3       0.76      0.79      0.78       491
           4       0.80      0.78      0.79       532
           5       0.73      0.65      0.69       383

    accuracy                           0.81      2947
   macro avg       0.81      0.80      0.81      2947
weighted avg       0.81      0.81      0.81      2947

Confusion Matrix for this model: 
 [[489   2   5   0   0   0]
 [ 78 381  12   0   0   0]
 [ 11   3 464   3   0  93]
 [  0   0   0 389 102   0]
 [  0   0   0 115 417   0]
 [  0   0 132   3   0 248]]
Experiment:  180  Set:  har2 Train Labels:  nar10 Test Labels:  nar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 4 4
AER:  0.21377672209026127
TER:  0.142, 0.114, 0.314
Score for this model: 
               precision    recall  f1-score   support

           0       0.85      0.99      0.91       496
           1       0.99      0.81      0.89       471
           2       0.83      0.69      0.75       730
           3       0.76      0.79      0.78       491
           4       0.80      0.78      0.79       532
           5       0.40      0.59      0.48       227

    accuracy                           0.79      2947
   macro avg       0.77      0.78      0.77      2947
weighted avg       0.81      0.79      0.79      2947

Confusion Matrix for this model: 
 [[489   2   5   0   0   0]
 [ 78 381  12   0   0   0]
 [ 11   3 506   4   0 206]
 [  0   0   0 389 102   0]
 [  0   0   0 115 417   0]
 [  0   0  90   2   0 135]]
Experiment:  181  Set:  har2 Train Labels:  nar10 Test Labels:  nnar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 4 5
AER:  0.1845945028842891
TER:  0.150, 0.135, 0.235
Score for this model: 
               precision    recall  f1-score   support

           0       0.85      0.99      0.91       496
           1       0.99      0.81      0.89       471
           2       0.77      0.83      0.79       568
           3       0.76      0.79      0.78       491
           4       0.80      0.78      0.79       532
           5       0.76      0.66      0.71       389

    accuracy                           0.82      2947
   macro avg       0.82      0.81      0.81      2947
weighted avg       0.82      0.82      0.81      2947

Confusion Matrix for this model: 
 [[489   2   5   0   0   0]
 [ 78 381  12   0   0   0]
 [ 11   3 469   2   0  83]
 [  0   0   0 389 102   0]
 [  0   0   0 115 417   0]
 [  0   0 127   4   0 258]]
Experiment:  182  Set:  har2 Train Labels:  nar10 Test Labels:  nnar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 4 6
AER:  0.20088225313878522
TER:  0.126, 0.101, 0.301
Score for this model: 
               precision    recall  f1-score   support

           0       0.85      0.99      0.91       496
           1       0.99      0.81      0.89       471
           2       0.85      0.72      0.78       715
           3       0.76      0.79      0.78       491
           4       0.80      0.78      0.79       532
           5       0.47      0.67      0.55       242

    accuracy                           0.80      2947
   macro avg       0.79      0.79      0.78      2947
weighted avg       0.82      0.80      0.80      2947

Confusion Matrix for this model: 
 [[489   2   5   0   0   0]
 [ 78 381  12   0   0   0]
 [ 11   3 518   3   0 180]
 [  0   0   0 389 102   0]
 [  0   0   0 115 417   0]
 [  0   0  78   3   0 161]]
Input Shape:  (7352, 3, 128)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_26"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_27 (InputLayer)          [(None, 3, 128)]     0           []                               
                                                                                                  
 batch_normalization_52 (BatchN  (None, 3, 128)      512         ['input_27[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_52 (Multi  (None, 3, 128)      33088       ['batch_normalization_52[0][0]', 
 HeadAttention)                                                   'batch_normalization_52[0][0]'] 
                                                                                                  
 dropout_104 (Dropout)          (None, 3, 128)       0           ['multi_head_attention_52[0][0]']
                                                                                                  
 tf.__operators__.add_104 (TFOp  (None, 3, 128)      0           ['dropout_104[0][0]',            
 Lambda)                                                          'input_27[0][0]']               
                                                                                                  
 layer_normalization_52 (LayerN  (None, 3, 128)      256         ['tf.__operators__.add_104[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_104 (Conv1D)            (None, 3, 32)        4128        ['layer_normalization_52[0][0]'] 
                                                                                                  
 dropout_105 (Dropout)          (None, 3, 32)        0           ['conv1d_104[0][0]']             
                                                                                                  
 conv1d_105 (Conv1D)            (None, 3, 128)       4224        ['dropout_105[0][0]']            
                                                                                                  
 tf.__operators__.add_105 (TFOp  (None, 3, 128)      0           ['conv1d_105[0][0]',             
 Lambda)                                                          'tf.__operators__.add_104[0][0]'
                                                                 ]                                
                                                                                                  
 batch_normalization_53 (BatchN  (None, 3, 128)      512         ['tf.__operators__.add_105[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 multi_head_attention_53 (Multi  (None, 3, 128)      33088       ['batch_normalization_53[0][0]', 
 HeadAttention)                                                   'batch_normalization_53[0][0]'] 
                                                                                                  
 dropout_106 (Dropout)          (None, 3, 128)       0           ['multi_head_attention_53[0][0]']
                                                                                                  
 tf.__operators__.add_106 (TFOp  (None, 3, 128)      0           ['dropout_106[0][0]',            
 Lambda)                                                          'tf.__operators__.add_105[0][0]'
                                                                 ]                                
                                                                                                  
 layer_normalization_53 (LayerN  (None, 3, 128)      256         ['tf.__operators__.add_106[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_106 (Conv1D)            (None, 3, 32)        4128        ['layer_normalization_53[0][0]'] 
                                                                                                  
 dropout_107 (Dropout)          (None, 3, 32)        0           ['conv1d_106[0][0]']             
                                                                                                  
 conv1d_107 (Conv1D)            (None, 3, 128)       4224        ['dropout_107[0][0]']            
                                                                                                  
 tf.__operators__.add_107 (TFOp  (None, 3, 128)      0           ['conv1d_107[0][0]',             
 Lambda)                                                          'tf.__operators__.add_106[0][0]'
                                                                 ]                                
                                                                                                  
 dense_52 (Dense)               (None, 3, 128)       16512       ['tf.__operators__.add_107[0][0]'
                                                                 ]                                
                                                                                                  
 flatten_26 (Flatten)           (None, 384)          0           ['dense_52[0][0]']               
                                                                                                  
 dense_53 (Dense)               (None, 6)            2310        ['flatten_26[0][0]']             
                                                                                                  
==================================================================================================
Total params: 103,238
Trainable params: 102,726
Non-trainable params: 512
__________________________________________________________________________________________________
Epoch 00062: early stopping
Experiment:  183  Set:  har2 Train Labels:  nnar5 Test Labels:  clean
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 5 0
AER:  0.1299626739056668
TER:  0.130, 0.130, 0.130
Score for this model: 
               precision    recall  f1-score   support

           0       0.89      0.96      0.92       496
           1       0.96      0.85      0.90       471
           2       0.83      0.96      0.89       420
           3       0.84      0.67      0.75       491
           4       0.75      0.90      0.82       532
           5       1.00      0.89      0.94       537

    accuracy                           0.87      2947
   macro avg       0.88      0.87      0.87      2947
weighted avg       0.88      0.87      0.87      2947

Confusion Matrix for this model: 
 [[474   6  16   0   0   0]
 [ 56 400  15   0   0   0]
 [  4  11 405   0   0   0]
 [  0   0   0 329 160   2]
 [  0   0   0  53 479   0]
 [  0   0  50  10   0 477]]
Experiment:  184  Set:  har2 Train Labels:  nnar5 Test Labels:  ncar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 5 1
AER:  0.16389548693586697
TER:  0.127, 0.114, 0.214
Score for this model: 
               precision    recall  f1-score   support

           0       0.86      0.92      0.89       498
           1       0.92      0.81      0.86       476
           2       0.80      0.92      0.86       421
           3       0.81      0.64      0.72       498
           4       0.71      0.87      0.78       527
           5       0.95      0.87      0.91       527

    accuracy                           0.84      2947
   macro avg       0.84      0.84      0.84      2947
weighted avg       0.84      0.84      0.84      2947

Confusion Matrix for this model: 
 [[460   9  18   3   5   3]
 [ 55 385  21   3   7   5]
 [  9  14 388   1   7   2]
 [  6   1   4 319 160   8]
 [  3   6   4  53 456   5]
 [  1   2  51  13   4 456]]
Experiment:  185  Set:  har2 Train Labels:  nnar5 Test Labels:  ncar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 5 2
AER:  0.22056328469630132
TER:  0.151, 0.121, 0.321
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.86      0.83       488
           1       0.86      0.75      0.80       477
           2       0.75      0.83      0.79       439
           3       0.76      0.59      0.67       498
           4       0.68      0.83      0.75       525
           5       0.88      0.81      0.84       520

    accuracy                           0.78      2947
   macro avg       0.79      0.78      0.78      2947
weighted avg       0.79      0.78      0.78      2947

Confusion Matrix for this model: 
 [[422  17  20  10  10   9]
 [ 60 359  29   6  11  12]
 [ 18  18 366  10  14  13]
 [  5  13  10 296 160  14]
 [ 12   4   9  55 434  11]
 [ 17   6  52  15  10 420]]
Experiment:  186  Set:  har2 Train Labels:  nnar5 Test Labels:  nar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 5 3
AER:  0.171021377672209
TER:  0.134, 0.121, 0.221
Score for this model: 
               precision    recall  f1-score   support

           0       0.89      0.96      0.92       496
           1       0.96      0.85      0.90       471
           2       0.86      0.73      0.79       574
           3       0.84      0.67      0.75       491
           4       0.75      0.90      0.82       532
           5       0.71      0.89      0.79       383

    accuracy                           0.83      2947
   macro avg       0.84      0.83      0.83      2947
weighted avg       0.84      0.83      0.83      2947

Confusion Matrix for this model: 
 [[474   6  16   0   0   0]
 [ 56 400  15   0   0   0]
 [  4  11 419   5   0 135]
 [  0   0   0 329 160   2]
 [  0   0   0  53 479   0]
 [  0   0  36   5   0 342]]
Experiment:  187  Set:  har2 Train Labels:  nnar5 Test Labels:  nar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 5 4
AER:  0.2188666440447913
TER:  0.149, 0.119, 0.319
Score for this model: 
               precision    recall  f1-score   support

           0       0.89      0.96      0.92       496
           1       0.96      0.85      0.90       471
           2       0.87      0.58      0.70       730
           3       0.84      0.67      0.75       491
           4       0.75      0.90      0.82       532
           5       0.41      0.86      0.55       227

    accuracy                           0.78      2947
   macro avg       0.79      0.80      0.77      2947
weighted avg       0.83      0.78      0.79      2947

Confusion Matrix for this model: 
 [[474   6  16   0   0   0]
 [ 56 400  15   0   0   0]
 [  4  11 425   8   0 282]
 [  0   0   0 329 160   2]
 [  0   0   0  53 479   0]
 [  0   0  30   2   0 195]]
Experiment:  188  Set:  har2 Train Labels:  nnar5 Test Labels:  nnar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 5 5
AER:  0.167967424499491
TER:  0.131, 0.118, 0.218
Score for this model: 
               precision    recall  f1-score   support

           0       0.89      0.96      0.92       496
           1       0.96      0.85      0.90       471
           2       0.87      0.74      0.80       568
           3       0.84      0.67      0.75       491
           4       0.75      0.90      0.82       532
           5       0.73      0.89      0.80       389

    accuracy                           0.83      2947
   macro avg       0.84      0.84      0.83      2947
weighted avg       0.84      0.83      0.83      2947

Confusion Matrix for this model: 
 [[474   6  16   0   0   0]
 [ 56 400  15   0   0   0]
 [  4  11 422   2   0 129]
 [  0   0   0 329 160   2]
 [  0   0   0  53 479   0]
 [  0   0  33   8   0 348]]
Experiment:  189  Set:  har2 Train Labels:  nnar5 Test Labels:  nnar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 5 6
AER:  0.20291822192059722
TER:  0.129, 0.103, 0.303
Score for this model: 
               precision    recall  f1-score   support

           0       0.89      0.96      0.92       496
           1       0.96      0.85      0.90       471
           2       0.91      0.62      0.74       715
           3       0.84      0.67      0.75       491
           4       0.75      0.90      0.82       532
           5       0.47      0.93      0.62       242

    accuracy                           0.80      2947
   macro avg       0.80      0.82      0.79      2947
weighted avg       0.84      0.80      0.80      2947

Confusion Matrix for this model: 
 [[474   6  16   0   0   0]
 [ 56 400  15   0   0   0]
 [  4  11 442   6   0 252]
 [  0   0   0 329 160   2]
 [  0   0   0  53 479   0]
 [  0   0  13   4   0 225]]
Input Shape:  (7352, 3, 128)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_27"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_28 (InputLayer)          [(None, 3, 128)]     0           []                               
                                                                                                  
 batch_normalization_54 (BatchN  (None, 3, 128)      512         ['input_28[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_54 (Multi  (None, 3, 128)      33088       ['batch_normalization_54[0][0]', 
 HeadAttention)                                                   'batch_normalization_54[0][0]'] 
                                                                                                  
 dropout_108 (Dropout)          (None, 3, 128)       0           ['multi_head_attention_54[0][0]']
                                                                                                  
 tf.__operators__.add_108 (TFOp  (None, 3, 128)      0           ['dropout_108[0][0]',            
 Lambda)                                                          'input_28[0][0]']               
                                                                                                  
 layer_normalization_54 (LayerN  (None, 3, 128)      256         ['tf.__operators__.add_108[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_108 (Conv1D)            (None, 3, 32)        4128        ['layer_normalization_54[0][0]'] 
                                                                                                  
 dropout_109 (Dropout)          (None, 3, 32)        0           ['conv1d_108[0][0]']             
                                                                                                  
 conv1d_109 (Conv1D)            (None, 3, 128)       4224        ['dropout_109[0][0]']            
                                                                                                  
 tf.__operators__.add_109 (TFOp  (None, 3, 128)      0           ['conv1d_109[0][0]',             
 Lambda)                                                          'tf.__operators__.add_108[0][0]'
                                                                 ]                                
                                                                                                  
 batch_normalization_55 (BatchN  (None, 3, 128)      512         ['tf.__operators__.add_109[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 multi_head_attention_55 (Multi  (None, 3, 128)      33088       ['batch_normalization_55[0][0]', 
 HeadAttention)                                                   'batch_normalization_55[0][0]'] 
                                                                                                  
 dropout_110 (Dropout)          (None, 3, 128)       0           ['multi_head_attention_55[0][0]']
                                                                                                  
 tf.__operators__.add_110 (TFOp  (None, 3, 128)      0           ['dropout_110[0][0]',            
 Lambda)                                                          'tf.__operators__.add_109[0][0]'
                                                                 ]                                
                                                                                                  
 layer_normalization_55 (LayerN  (None, 3, 128)      256         ['tf.__operators__.add_110[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_110 (Conv1D)            (None, 3, 32)        4128        ['layer_normalization_55[0][0]'] 
                                                                                                  
 dropout_111 (Dropout)          (None, 3, 32)        0           ['conv1d_110[0][0]']             
                                                                                                  
 conv1d_111 (Conv1D)            (None, 3, 128)       4224        ['dropout_111[0][0]']            
                                                                                                  
 tf.__operators__.add_111 (TFOp  (None, 3, 128)      0           ['conv1d_111[0][0]',             
 Lambda)                                                          'tf.__operators__.add_110[0][0]'
                                                                 ]                                
                                                                                                  
 dense_54 (Dense)               (None, 3, 128)       16512       ['tf.__operators__.add_111[0][0]'
                                                                 ]                                
                                                                                                  
 flatten_27 (Flatten)           (None, 384)          0           ['dense_54[0][0]']               
                                                                                                  
 dense_55 (Dense)               (None, 6)            2310        ['flatten_27[0][0]']             
                                                                                                  
==================================================================================================
Total params: 103,238
Trainable params: 102,726
Non-trainable params: 512
__________________________________________________________________________________________________
Epoch 00059: early stopping
Experiment:  190  Set:  har2 Train Labels:  nnar10 Test Labels:  clean
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 6 0
AER:  0.163216830675263
TER:  0.163, 0.163, 0.163
Score for this model: 
               precision    recall  f1-score   support

           0       0.90      0.98      0.94       496
           1       0.98      0.85      0.91       471
           2       0.68      0.99      0.81       420
           3       0.78      0.75      0.76       491
           4       0.79      0.86      0.82       532
           5       1.00      0.64      0.78       537

    accuracy                           0.84      2947
   macro avg       0.85      0.84      0.84      2947
weighted avg       0.86      0.84      0.84      2947

Confusion Matrix for this model: 
 [[485   4   7   0   0   0]
 [ 52 400  19   0   0   0]
 [  2   4 414   0   0   0]
 [  1   0   0 366 123   1]
 [  0   0   0  75 457   0]
 [  0   0 167  26   0 344]]
Experiment:  191  Set:  har2 Train Labels:  nnar10 Test Labels:  ncar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 6 1
AER:  0.19613165931455717
TER:  0.162, 0.146, 0.246
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.94      0.91       498
           1       0.94      0.80      0.87       476
           2       0.66      0.95      0.77       421
           3       0.76      0.71      0.74       498
           4       0.75      0.83      0.79       527
           5       0.95      0.62      0.75       527

    accuracy                           0.80      2947
   macro avg       0.82      0.81      0.80      2947
weighted avg       0.82      0.80      0.80      2947

Confusion Matrix for this model: 
 [[470   7  10   6   3   2]
 [ 54 383  25   3   7   4]
 [  6   8 398   1   7   1]
 [  6   2   5 355 124   6]
 [  3   6   5  74 435   4]
 [  1   2 164  28   4 328]]
Experiment:  192  Set:  har2 Train Labels:  nnar10 Test Labels:  ncar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 6 2
AER:  0.24703087885985747
TER:  0.184, 0.147, 0.347
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.88      0.84       488
           1       0.88      0.76      0.82       477
           2       0.62      0.86      0.72       439
           3       0.72      0.67      0.69       498
           4       0.72      0.80      0.76       525
           5       0.86      0.57      0.69       520

    accuracy                           0.75      2947
   macro avg       0.77      0.76      0.75      2947
weighted avg       0.77      0.75      0.75      2947

Confusion Matrix for this model: 
 [[431  15  14  11   9   8]
 [ 55 361  32   8  10  11]
 [ 18  10 377  11  13  10]
 [  8  10  13 335 121  11]
 [ 12   4  11  72 418   8]
 [ 16   8 160  30   9 297]]
Experiment:  193  Set:  har2 Train Labels:  nnar10 Test Labels:  nar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 6 3
AER:  0.17780794027824906
TER:  0.142, 0.128, 0.228
Score for this model: 
               precision    recall  f1-score   support

           0       0.90      0.98      0.94       496
           1       0.98      0.85      0.91       471
           2       0.77      0.81      0.79       574
           3       0.78      0.75      0.76       491
           4       0.79      0.86      0.82       532
           5       0.72      0.65      0.69       383

    accuracy                           0.82      2947
   macro avg       0.82      0.82      0.82      2947
weighted avg       0.82      0.82      0.82      2947

Confusion Matrix for this model: 
 [[485   4   7   0   0   0]
 [ 52 400  19   0   0   0]
 [  2   4 465   9   0  94]
 [  1   0   0 366 123   1]
 [  0   0   0  75 457   0]
 [  0   0 116  17   0 250]]
Experiment:  194  Set:  har2 Train Labels:  nnar10 Test Labels:  nar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 6 4
AER:  0.2005429250084832
TER:  0.126, 0.101, 0.301
Score for this model: 
               precision    recall  f1-score   support

           0       0.90      0.98      0.94       496
           1       0.98      0.85      0.91       471
           2       0.83      0.69      0.76       730
           3       0.78      0.75      0.76       491
           4       0.79      0.86      0.82       532
           5       0.41      0.63      0.50       227

    accuracy                           0.80      2947
   macro avg       0.78      0.79      0.78      2947
weighted avg       0.82      0.80      0.80      2947

Confusion Matrix for this model: 
 [[485   4   7   0   0   0]
 [ 52 400  19   0   0   0]
 [  2   4 505  18   0 201]
 [  1   0   0 366 123   1]
 [  0   0   0  75 457   0]
 [  0   0  76   8   0 143]]
Experiment:  195  Set:  har2 Train Labels:  nnar10 Test Labels:  nnar5
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 6 5
AER:  0.17882592466915506
TER:  0.143, 0.129, 0.229
Score for this model: 
               precision    recall  f1-score   support

           0       0.90      0.98      0.94       496
           1       0.98      0.85      0.91       471
           2       0.76      0.82      0.79       568
           3       0.78      0.75      0.76       491
           4       0.79      0.86      0.82       532
           5       0.72      0.64      0.68       389

    accuracy                           0.82      2947
   macro avg       0.82      0.81      0.82      2947
weighted avg       0.82      0.82      0.82      2947

Confusion Matrix for this model: 
 [[485   4   7   0   0   0]
 [ 52 400  19   0   0   0]
 [  2   4 463   4   0  95]
 [  1   0   0 366 123   1]
 [  0   0   0  75 457   0]
 [  0   0 118  22   0 249]]
Experiment:  196  Set:  har2 Train Labels:  nnar10 Test Labels:  nnar10
Shape of X_train:  (7352, 3, 128)
Shape of X_test:  (2947, 3, 128)
Shape of y_train:  (7352, 6)
Shape of y_test:  (2947, 6)
NUM_INSTANCES is  22056
instances should be  7352
Shape of y true: (2947,)
Shape of y predicted: (2947,)
[0.01876785 0.00928918 0.00831025 0.0240228  0.06666667 0.        ] [0.05241935 0.1104034  0.02857143 0.32790224 0.09398496 0.01675978]
Recording results in matrix at 6 6
AER:  0.19511367492365117
TER:  0.119, 0.095, 0.295
Score for this model: 
               precision    recall  f1-score   support

           0       0.90      0.98      0.94       496
           1       0.98      0.85      0.91       471
           2       0.84      0.71      0.77       715
           3       0.78      0.75      0.76       491
           4       0.79      0.86      0.82       532
           5       0.46      0.65      0.53       242

    accuracy                           0.80      2947
   macro avg       0.79      0.80      0.79      2947
weighted avg       0.82      0.80      0.81      2947

Confusion Matrix for this model: 
 [[485   4   7   0   0   0]
 [ 52 400  19   0   0   0]
 [  2   4 507  15   0 187]
 [  1   0   0 366 123   1]
 [  0   0   0  75 457   0]
 [  0   0  74  11   0 157]]
Input Shape:  (113739, 6, 30)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_28"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_29 (InputLayer)          [(None, 6, 30)]      0           []                               
                                                                                                  
 batch_normalization_56 (BatchN  (None, 6, 30)       120         ['input_29[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_56 (Multi  (None, 6, 30)       7902        ['batch_normalization_56[0][0]', 
 HeadAttention)                                                   'batch_normalization_56[0][0]'] 
                                                                                                  
 dropout_112 (Dropout)          (None, 6, 30)        0           ['multi_head_attention_56[0][0]']
                                                                                                  
 tf.__operators__.add_112 (TFOp  (None, 6, 30)       0           ['dropout_112[0][0]',            
 Lambda)                                                          'input_29[0][0]']               
                                                                                                  
 layer_normalization_56 (LayerN  (None, 6, 30)       60          ['tf.__operators__.add_112[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_112 (Conv1D)            (None, 6, 32)        992         ['layer_normalization_56[0][0]'] 
                                                                                                  
 dropout_113 (Dropout)          (None, 6, 32)        0           ['conv1d_112[0][0]']             
                                                                                                  
 conv1d_113 (Conv1D)            (None, 6, 30)        990         ['dropout_113[0][0]']            
                                                                                                  
 tf.__operators__.add_113 (TFOp  (None, 6, 30)       0           ['conv1d_113[0][0]',             
 Lambda)                                                          'tf.__operators__.add_112[0][0]'
                                                                 ]                                
                                                                                                  
 batch_normalization_57 (BatchN  (None, 6, 30)       120         ['tf.__operators__.add_113[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 multi_head_attention_57 (Multi  (None, 6, 30)       7902        ['batch_normalization_57[0][0]', 
 HeadAttention)                                                   'batch_normalization_57[0][0]'] 
                                                                                                  
 dropout_114 (Dropout)          (None, 6, 30)        0           ['multi_head_attention_57[0][0]']
                                                                                                  
 tf.__operators__.add_114 (TFOp  (None, 6, 30)       0           ['dropout_114[0][0]',            
 Lambda)                                                          'tf.__operators__.add_113[0][0]'
                                                                 ]                                
                                                                                                  
 layer_normalization_57 (LayerN  (None, 6, 30)       60          ['tf.__operators__.add_114[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_114 (Conv1D)            (None, 6, 32)        992         ['layer_normalization_57[0][0]'] 
                                                                                                  
 dropout_115 (Dropout)          (None, 6, 32)        0           ['conv1d_114[0][0]']             
                                                                                                  
 conv1d_115 (Conv1D)            (None, 6, 30)        990         ['dropout_115[0][0]']            
                                                                                                  
 tf.__operators__.add_115 (TFOp  (None, 6, 30)       0           ['conv1d_115[0][0]',             
 Lambda)                                                          'tf.__operators__.add_114[0][0]'
                                                                 ]                                
                                                                                                  
 dense_56 (Dense)               (None, 6, 128)       3968        ['tf.__operators__.add_115[0][0]'
                                                                 ]                                
                                                                                                  
 flatten_28 (Flatten)           (None, 768)          0           ['dense_56[0][0]']               
                                                                                                  
 dense_57 (Dense)               (None, 2)            1538        ['flatten_28[0][0]']             
                                                                                                  
==================================================================================================
Total params: 25,634
Trainable params: 25,514
Non-trainable params: 120
__________________________________________________________________________________________________
Epoch 00058: early stopping
Experiment:  197  Set:  sn1 Train Labels:  clean Test Labels:  clean
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
None None
Recording results in matrix at 0 0
AER:  0.22657102244553898
TER:  0.227, 0.227, 0.227
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.96      0.87     23175
           1       0.55      0.17      0.26      7076

    accuracy                           0.77     30251
   macro avg       0.67      0.56      0.56     30251
weighted avg       0.73      0.77      0.73     30251

Confusion Matrix for this model: 
 [[22171  1004]
 [ 5850  1226]]
Experiment:  198  Set:  sn1 Train Labels:  clean Test Labels:  ncar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 0 1
AER:  0.2543386995471224
TER:  0.227, 0.204, 0.304
Score for this model: 
               precision    recall  f1-score   support

           0       0.76      0.95      0.85     22375
           1       0.54      0.15      0.24      7876

    accuracy                           0.75     30251
   macro avg       0.65      0.55      0.54     30251
weighted avg       0.70      0.75      0.69     30251

Confusion Matrix for this model: 
 [[21351  1024]
 [ 6670  1206]]
Experiment:  199  Set:  sn1 Train Labels:  clean Test Labels:  ncar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 0 2
AER:  0.28121384417044065
TER:  0.227, 0.181, 0.381
Score for this model: 
               precision    recall  f1-score   support

           0       0.73      0.95      0.83     21532
           1       0.55      0.14      0.22      8719

    accuracy                           0.72     30251
   macro avg       0.64      0.55      0.53     30251
weighted avg       0.68      0.72      0.65     30251

Confusion Matrix for this model: 
 [[20523  1009]
 [ 7498  1221]]
Experiment:  200  Set:  sn1 Train Labels:  clean Test Labels:  nar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 0 3
AER:  0.2749000033056758
TER:  0.250, 0.225, 0.325
Score for this model: 
               precision    recall  f1-score   support

           0       0.74      0.96      0.83     21585
           1       0.58      0.15      0.24      8666

    accuracy                           0.73     30251
   macro avg       0.66      0.55      0.53     30251
weighted avg       0.69      0.73      0.66     30251

Confusion Matrix for this model: 
 [[20645   940]
 [ 7376  1290]]
Experiment:  201  Set:  sn1 Train Labels:  clean Test Labels:  nar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 0 4
AER:  0.32517933291461437
TER:  0.281, 0.225, 0.425
Score for this model: 
               precision    recall  f1-score   support

           0       0.68      0.96      0.79     19904
           1       0.61      0.13      0.22     10347

    accuracy                           0.67     30251
   macro avg       0.65      0.54      0.51     30251
weighted avg       0.66      0.67      0.60     30251

Confusion Matrix for this model: 
 [[19044   860]
 [ 8977  1370]]
Experiment:  202  Set:  sn1 Train Labels:  clean Test Labels:  nnar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 0 5
AER:  0.2713629301510694
TER:  0.246, 0.221, 0.321
Score for this model: 
               precision    recall  f1-score   support

           0       0.74      0.96      0.83     21662
           1       0.59      0.15      0.24      8589

    accuracy                           0.73     30251
   macro avg       0.66      0.55      0.54     30251
weighted avg       0.70      0.73      0.67     30251

Confusion Matrix for this model: 
 [[20737   925]
 [ 7284  1305]]
Experiment:  203  Set:  sn1 Train Labels:  clean Test Labels:  nnar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 0 6
AER:  0.31668374599186805
TER:  0.271, 0.217, 0.417
Score for this model: 
               precision    recall  f1-score   support

           0       0.69      0.96      0.80     20149
           1       0.62      0.14      0.22     10102

    accuracy                           0.68     30251
   macro avg       0.65      0.55      0.51     30251
weighted avg       0.66      0.68      0.61     30251

Confusion Matrix for this model: 
 [[19295   854]
 [ 8726  1376]]
Input Shape:  (113739, 6, 30)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_29"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_30 (InputLayer)          [(None, 6, 30)]      0           []                               
                                                                                                  
 batch_normalization_58 (BatchN  (None, 6, 30)       120         ['input_30[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_58 (Multi  (None, 6, 30)       7902        ['batch_normalization_58[0][0]', 
 HeadAttention)                                                   'batch_normalization_58[0][0]'] 
                                                                                                  
 dropout_116 (Dropout)          (None, 6, 30)        0           ['multi_head_attention_58[0][0]']
                                                                                                  
 tf.__operators__.add_116 (TFOp  (None, 6, 30)       0           ['dropout_116[0][0]',            
 Lambda)                                                          'input_30[0][0]']               
                                                                                                  
 layer_normalization_58 (LayerN  (None, 6, 30)       60          ['tf.__operators__.add_116[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_116 (Conv1D)            (None, 6, 32)        992         ['layer_normalization_58[0][0]'] 
                                                                                                  
 dropout_117 (Dropout)          (None, 6, 32)        0           ['conv1d_116[0][0]']             
                                                                                                  
 conv1d_117 (Conv1D)            (None, 6, 30)        990         ['dropout_117[0][0]']            
                                                                                                  
 tf.__operators__.add_117 (TFOp  (None, 6, 30)       0           ['conv1d_117[0][0]',             
 Lambda)                                                          'tf.__operators__.add_116[0][0]'
                                                                 ]                                
                                                                                                  
 batch_normalization_59 (BatchN  (None, 6, 30)       120         ['tf.__operators__.add_117[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 multi_head_attention_59 (Multi  (None, 6, 30)       7902        ['batch_normalization_59[0][0]', 
 HeadAttention)                                                   'batch_normalization_59[0][0]'] 
                                                                                                  
 dropout_118 (Dropout)          (None, 6, 30)        0           ['multi_head_attention_59[0][0]']
                                                                                                  
 tf.__operators__.add_118 (TFOp  (None, 6, 30)       0           ['dropout_118[0][0]',            
 Lambda)                                                          'tf.__operators__.add_117[0][0]'
                                                                 ]                                
                                                                                                  
 layer_normalization_59 (LayerN  (None, 6, 30)       60          ['tf.__operators__.add_118[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_118 (Conv1D)            (None, 6, 32)        992         ['layer_normalization_59[0][0]'] 
                                                                                                  
 dropout_119 (Dropout)          (None, 6, 32)        0           ['conv1d_118[0][0]']             
                                                                                                  
 conv1d_119 (Conv1D)            (None, 6, 30)        990         ['dropout_119[0][0]']            
                                                                                                  
 tf.__operators__.add_119 (TFOp  (None, 6, 30)       0           ['conv1d_119[0][0]',             
 Lambda)                                                          'tf.__operators__.add_118[0][0]'
                                                                 ]                                
                                                                                                  
 dense_58 (Dense)               (None, 6, 128)       3968        ['tf.__operators__.add_119[0][0]'
                                                                 ]                                
                                                                                                  
 flatten_29 (Flatten)           (None, 768)          0           ['dense_58[0][0]']               
                                                                                                  
 dense_59 (Dense)               (None, 2)            1538        ['flatten_29[0][0]']             
                                                                                                  
==================================================================================================
Total params: 25,634
Trainable params: 25,514
Non-trainable params: 120
__________________________________________________________________________________________________
Epoch 00052: early stopping
Experiment:  204  Set:  sn1 Train Labels:  ncar5 Test Labels:  clean
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 1 0
AER:  0.2318931605566758
TER:  0.232, 0.232, 0.232
Score for this model: 
               precision    recall  f1-score   support

           0       0.78      0.98      0.87     23175
           1       0.53      0.08      0.13      7076

    accuracy                           0.77     30251
   macro avg       0.65      0.53      0.50     30251
weighted avg       0.72      0.77      0.69     30251

Confusion Matrix for this model: 
 [[22691   484]
 [ 6531   545]]
Experiment:  205  Set:  sn1 Train Labels:  ncar5 Test Labels:  ncar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 1 1
AER:  0.25807411325245444
TER:  0.231, 0.208, 0.308
Score for this model: 
               precision    recall  f1-score   support

           0       0.75      0.98      0.85     22375
           1       0.53      0.07      0.12      7876

    accuracy                           0.74     30251
   macro avg       0.64      0.52      0.49     30251
weighted avg       0.69      0.74      0.66     30251

Confusion Matrix for this model: 
 [[21895   480]
 [ 7327   549]]
Experiment:  206  Set:  sn1 Train Labels:  ncar5 Test Labels:  ncar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 1 2
AER:  0.285478166011041
TER:  0.232, 0.185, 0.385
Score for this model: 
               precision    recall  f1-score   support

           0       0.72      0.98      0.83     21532
           1       0.54      0.06      0.11      8719

    accuracy                           0.71     30251
   macro avg       0.63      0.52      0.47     30251
weighted avg       0.67      0.71      0.62     30251

Confusion Matrix for this model: 
 [[21059   473]
 [ 8163   556]]
Experiment:  207  Set:  sn1 Train Labels:  ncar5 Test Labels:  nar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 1 3
AER:  0.2822716604409772
TER:  0.258, 0.232, 0.332
Score for this model: 
               precision    recall  f1-score   support

           0       0.72      0.98      0.83     21585
           1       0.56      0.07      0.12      8666

    accuracy                           0.72     30251
   macro avg       0.64      0.52      0.48     30251
weighted avg       0.68      0.72      0.63     30251

Confusion Matrix for this model: 
 [[21134   451]
 [ 8088   578]]
Experiment:  208  Set:  sn1 Train Labels:  ncar5 Test Labels:  nar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 1 4
AER:  0.3347327361078973
TER:  0.293, 0.235, 0.435
Score for this model: 
               precision    recall  f1-score   support

           0       0.67      0.98      0.79     19904
           1       0.61      0.06      0.11     10347

    accuracy                           0.67     30251
   macro avg       0.64      0.52      0.45     30251
weighted avg       0.65      0.67      0.56     30251

Confusion Matrix for this model: 
 [[19500   404]
 [ 9722   625]]
Experiment:  209  Set:  sn1 Train Labels:  ncar5 Test Labels:  nnar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 1 5
AER:  0.27985851707381576
TER:  0.255, 0.230, 0.330
Score for this model: 
               precision    recall  f1-score   support

           0       0.73      0.98      0.83     21662
           1       0.56      0.07      0.12      8589

    accuracy                           0.72     30251
   macro avg       0.64      0.52      0.48     30251
weighted avg       0.68      0.72      0.63     30251

Confusion Matrix for this model: 
 [[21209   453]
 [ 8013   576]]
Experiment:  210  Set:  sn1 Train Labels:  ncar5 Test Labels:  nnar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 1 6
AER:  0.32696439787114473
TER:  0.284, 0.227, 0.427
Score for this model: 
               precision    recall  f1-score   support

           0       0.68      0.98      0.80     20149
           1       0.60      0.06      0.11     10102

    accuracy                           0.67     30251
   macro avg       0.64      0.52      0.46     30251
weighted avg       0.65      0.67      0.57     30251

Confusion Matrix for this model: 
 [[19740   409]
 [ 9482   620]]
Input Shape:  (113739, 6, 30)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_30"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_31 (InputLayer)          [(None, 6, 30)]      0           []                               
                                                                                                  
 batch_normalization_60 (BatchN  (None, 6, 30)       120         ['input_31[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_60 (Multi  (None, 6, 30)       7902        ['batch_normalization_60[0][0]', 
 HeadAttention)                                                   'batch_normalization_60[0][0]'] 
                                                                                                  
 dropout_120 (Dropout)          (None, 6, 30)        0           ['multi_head_attention_60[0][0]']
                                                                                                  
 tf.__operators__.add_120 (TFOp  (None, 6, 30)       0           ['dropout_120[0][0]',            
 Lambda)                                                          'input_31[0][0]']               
                                                                                                  
 layer_normalization_60 (LayerN  (None, 6, 30)       60          ['tf.__operators__.add_120[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_120 (Conv1D)            (None, 6, 32)        992         ['layer_normalization_60[0][0]'] 
                                                                                                  
 dropout_121 (Dropout)          (None, 6, 32)        0           ['conv1d_120[0][0]']             
                                                                                                  
 conv1d_121 (Conv1D)            (None, 6, 30)        990         ['dropout_121[0][0]']            
                                                                                                  
 tf.__operators__.add_121 (TFOp  (None, 6, 30)       0           ['conv1d_121[0][0]',             
 Lambda)                                                          'tf.__operators__.add_120[0][0]'
                                                                 ]                                
                                                                                                  
 batch_normalization_61 (BatchN  (None, 6, 30)       120         ['tf.__operators__.add_121[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 multi_head_attention_61 (Multi  (None, 6, 30)       7902        ['batch_normalization_61[0][0]', 
 HeadAttention)                                                   'batch_normalization_61[0][0]'] 
                                                                                                  
 dropout_122 (Dropout)          (None, 6, 30)        0           ['multi_head_attention_61[0][0]']
                                                                                                  
 tf.__operators__.add_122 (TFOp  (None, 6, 30)       0           ['dropout_122[0][0]',            
 Lambda)                                                          'tf.__operators__.add_121[0][0]'
                                                                 ]                                
                                                                                                  
 layer_normalization_61 (LayerN  (None, 6, 30)       60          ['tf.__operators__.add_122[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_122 (Conv1D)            (None, 6, 32)        992         ['layer_normalization_61[0][0]'] 
                                                                                                  
 dropout_123 (Dropout)          (None, 6, 32)        0           ['conv1d_122[0][0]']             
                                                                                                  
 conv1d_123 (Conv1D)            (None, 6, 30)        990         ['dropout_123[0][0]']            
                                                                                                  
 tf.__operators__.add_123 (TFOp  (None, 6, 30)       0           ['conv1d_123[0][0]',             
 Lambda)                                                          'tf.__operators__.add_122[0][0]'
                                                                 ]                                
                                                                                                  
 dense_60 (Dense)               (None, 6, 128)       3968        ['tf.__operators__.add_123[0][0]'
                                                                 ]                                
                                                                                                  
 flatten_30 (Flatten)           (None, 768)          0           ['dense_60[0][0]']               
                                                                                                  
 dense_61 (Dense)               (None, 2)            1538        ['flatten_30[0][0]']             
                                                                                                  
==================================================================================================
Total params: 25,634
Trainable params: 25,514
Non-trainable params: 120
__________________________________________________________________________________________________
Epoch 00035: early stopping
Experiment:  211  Set:  sn1 Train Labels:  ncar10 Test Labels:  clean
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 2 0
AER:  0.2340418498562031
TER:  0.234, 0.234, 0.234
Score for this model: 
               precision    recall  f1-score   support

           0       0.78      0.98      0.86     23175
           1       0.50      0.08      0.13      7076

    accuracy                           0.77     30251
   macro avg       0.64      0.53      0.50     30251
weighted avg       0.71      0.77      0.69     30251

Confusion Matrix for this model: 
 [[22636   539]
 [ 6541   535]]
Experiment:  212  Set:  sn1 Train Labels:  ncar10 Test Labels:  ncar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 2 1
AER:  0.25976000793362203
TER:  0.233, 0.210, 0.310
Score for this model: 
               precision    recall  f1-score   support

           0       0.75      0.98      0.85     22375
           1       0.51      0.07      0.12      7876

    accuracy                           0.74     30251
   macro avg       0.63      0.52      0.48     30251
weighted avg       0.69      0.74      0.66     30251

Confusion Matrix for this model: 
 [[21847   528]
 [ 7330   546]]
Experiment:  213  Set:  sn1 Train Labels:  ncar10 Test Labels:  ncar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 2 2
AER:  0.2874946282767512
TER:  0.234, 0.187, 0.387
Score for this model: 
               precision    recall  f1-score   support

           0       0.72      0.98      0.83     21532
           1       0.51      0.06      0.11      8719

    accuracy                           0.71     30251
   macro avg       0.62      0.52      0.47     30251
weighted avg       0.66      0.71      0.62     30251

Confusion Matrix for this model: 
 [[21006   526]
 [ 8171   548]]
Experiment:  214  Set:  sn1 Train Labels:  ncar10 Test Labels:  nar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 2 3
AER:  0.2834286469868765
TER:  0.259, 0.233, 0.333
Score for this model: 
               precision    recall  f1-score   support

           0       0.72      0.98      0.83     21585
           1       0.54      0.07      0.12      8666

    accuracy                           0.72     30251
   macro avg       0.63      0.52      0.48     30251
weighted avg       0.67      0.72      0.63     30251

Confusion Matrix for this model: 
 [[21094   491]
 [ 8083   583]]
Experiment:  215  Set:  sn1 Train Labels:  ncar10 Test Labels:  nar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 2 4
AER:  0.3376086740934184
TER:  0.297, 0.238, 0.438
Score for this model: 
               precision    recall  f1-score   support

           0       0.67      0.98      0.79     19904
           1       0.56      0.06      0.11     10347

    accuracy                           0.66     30251
   macro avg       0.61      0.52      0.45     30251
weighted avg       0.63      0.66      0.56     30251

Confusion Matrix for this model: 
 [[19434   470]
 [ 9743   604]]
Experiment:  216  Set:  sn1 Train Labels:  ncar10 Test Labels:  nnar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 2 5
AER:  0.28180886582261744
TER:  0.258, 0.232, 0.332
Score for this model: 
               precision    recall  f1-score   support

           0       0.73      0.98      0.83     21662
           1       0.53      0.07      0.12      8589

    accuracy                           0.72     30251
   macro avg       0.63      0.52      0.48     30251
weighted avg       0.67      0.72      0.63     30251

Confusion Matrix for this model: 
 [[21157   505]
 [ 8020   569]]
Experiment:  217  Set:  sn1 Train Labels:  ncar10 Test Labels:  nnar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 2 6
AER:  0.3275924762817758
TER:  0.284, 0.228, 0.428
Score for this model: 
               precision    recall  f1-score   support

           0       0.68      0.98      0.80     20149
           1       0.59      0.06      0.11     10102

    accuracy                           0.67     30251
   macro avg       0.63      0.52      0.46     30251
weighted avg       0.65      0.67      0.57     30251

Confusion Matrix for this model: 
 [[19708   441]
 [ 9469   633]]
Input Shape:  (113739, 6, 30)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_31"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_32 (InputLayer)          [(None, 6, 30)]      0           []                               
                                                                                                  
 batch_normalization_62 (BatchN  (None, 6, 30)       120         ['input_32[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_62 (Multi  (None, 6, 30)       7902        ['batch_normalization_62[0][0]', 
 HeadAttention)                                                   'batch_normalization_62[0][0]'] 
                                                                                                  
 dropout_124 (Dropout)          (None, 6, 30)        0           ['multi_head_attention_62[0][0]']
                                                                                                  
 tf.__operators__.add_124 (TFOp  (None, 6, 30)       0           ['dropout_124[0][0]',            
 Lambda)                                                          'input_32[0][0]']               
                                                                                                  
 layer_normalization_62 (LayerN  (None, 6, 30)       60          ['tf.__operators__.add_124[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_124 (Conv1D)            (None, 6, 32)        992         ['layer_normalization_62[0][0]'] 
                                                                                                  
 dropout_125 (Dropout)          (None, 6, 32)        0           ['conv1d_124[0][0]']             
                                                                                                  
 conv1d_125 (Conv1D)            (None, 6, 30)        990         ['dropout_125[0][0]']            
                                                                                                  
 tf.__operators__.add_125 (TFOp  (None, 6, 30)       0           ['conv1d_125[0][0]',             
 Lambda)                                                          'tf.__operators__.add_124[0][0]'
                                                                 ]                                
                                                                                                  
 batch_normalization_63 (BatchN  (None, 6, 30)       120         ['tf.__operators__.add_125[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 multi_head_attention_63 (Multi  (None, 6, 30)       7902        ['batch_normalization_63[0][0]', 
 HeadAttention)                                                   'batch_normalization_63[0][0]'] 
                                                                                                  
 dropout_126 (Dropout)          (None, 6, 30)        0           ['multi_head_attention_63[0][0]']
                                                                                                  
 tf.__operators__.add_126 (TFOp  (None, 6, 30)       0           ['dropout_126[0][0]',            
 Lambda)                                                          'tf.__operators__.add_125[0][0]'
                                                                 ]                                
                                                                                                  
 layer_normalization_63 (LayerN  (None, 6, 30)       60          ['tf.__operators__.add_126[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_126 (Conv1D)            (None, 6, 32)        992         ['layer_normalization_63[0][0]'] 
                                                                                                  
 dropout_127 (Dropout)          (None, 6, 32)        0           ['conv1d_126[0][0]']             
                                                                                                  
 conv1d_127 (Conv1D)            (None, 6, 30)        990         ['dropout_127[0][0]']            
                                                                                                  
 tf.__operators__.add_127 (TFOp  (None, 6, 30)       0           ['conv1d_127[0][0]',             
 Lambda)                                                          'tf.__operators__.add_126[0][0]'
                                                                 ]                                
                                                                                                  
 dense_62 (Dense)               (None, 6, 128)       3968        ['tf.__operators__.add_127[0][0]'
                                                                 ]                                
                                                                                                  
 flatten_31 (Flatten)           (None, 768)          0           ['dense_62[0][0]']               
                                                                                                  
 dense_63 (Dense)               (None, 2)            1538        ['flatten_31[0][0]']             
                                                                                                  
==================================================================================================
Total params: 25,634
Trainable params: 25,514
Non-trainable params: 120
__________________________________________________________________________________________________
Epoch 00043: early stopping
Experiment:  218  Set:  sn1 Train Labels:  nar5 Test Labels:  clean
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 3 0
AER:  0.23619053915573038
TER:  0.236, 0.236, 0.236
Score for this model: 
               precision    recall  f1-score   support

           0       0.78      0.95      0.86     23175
           1       0.48      0.14      0.22      7076

    accuracy                           0.76     30251
   macro avg       0.63      0.55      0.54     30251
weighted avg       0.71      0.76      0.71     30251

Confusion Matrix for this model: 
 [[22095  1080]
 [ 6065  1011]]
Experiment:  219  Set:  sn1 Train Labels:  nar5 Test Labels:  ncar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 3 1
AER:  0.26217315130078345
TER:  0.236, 0.212, 0.312
Score for this model: 
               precision    recall  f1-score   support

           0       0.76      0.95      0.84     22375
           1       0.49      0.13      0.20      7876

    accuracy                           0.74     30251
   macro avg       0.62      0.54      0.52     30251
weighted avg       0.69      0.74      0.68     30251

Confusion Matrix for this model: 
 [[21302  1073]
 [ 6858  1018]]
Experiment:  220  Set:  sn1 Train Labels:  nar5 Test Labels:  ncar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 3 2
AER:  0.2889160688902846
TER:  0.236, 0.189, 0.389
Score for this model: 
               precision    recall  f1-score   support

           0       0.73      0.95      0.82     21532
           1       0.49      0.12      0.19      8719

    accuracy                           0.71     30251
   macro avg       0.61      0.53      0.51     30251
weighted avg       0.66      0.71      0.64     30251

Confusion Matrix for this model: 
 [[20476  1056]
 [ 7684  1035]]
Experiment:  221  Set:  sn1 Train Labels:  nar5 Test Labels:  nar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 3 3
AER:  0.28385838484678194
TER:  0.260, 0.234, 0.334
Score for this model: 
               precision    recall  f1-score   support

           0       0.73      0.95      0.83     21585
           1       0.52      0.13      0.20      8666

    accuracy                           0.72     30251
   macro avg       0.62      0.54      0.51     30251
weighted avg       0.67      0.72      0.65     30251

Confusion Matrix for this model: 
 [[20579  1006]
 [ 7581  1085]]
Experiment:  222  Set:  sn1 Train Labels:  nar5 Test Labels:  nar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 3 4
AER:  0.3345343955571717
TER:  0.293, 0.235, 0.435
Score for this model: 
               precision    recall  f1-score   support

           0       0.67      0.95      0.79     19904
           1       0.55      0.11      0.19     10347

    accuracy                           0.67     30251
   macro avg       0.61      0.53      0.49     30251
weighted avg       0.63      0.67      0.58     30251

Confusion Matrix for this model: 
 [[18972   932]
 [ 9188  1159]]
Experiment:  223  Set:  sn1 Train Labels:  nar5 Test Labels:  nnar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 3 5
AER:  0.2805857657598096
TER:  0.256, 0.231, 0.331
Score for this model: 
               precision    recall  f1-score   support

           0       0.73      0.95      0.83     21662
           1       0.52      0.13      0.21      8589

    accuracy                           0.72     30251
   macro avg       0.63      0.54      0.52     30251
weighted avg       0.67      0.72      0.65     30251

Confusion Matrix for this model: 
 [[20667   995]
 [ 7493  1096]]
Experiment:  224  Set:  sn1 Train Labels:  nar5 Test Labels:  nnar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 3 6
AER:  0.3247826518131632
TER:  0.281, 0.225, 0.425
Score for this model: 
               precision    recall  f1-score   support

           0       0.68      0.95      0.80     20149
           1       0.57      0.12      0.19     10102

    accuracy                           0.68     30251
   macro avg       0.62      0.54      0.50     30251
weighted avg       0.64      0.68      0.60     30251

Confusion Matrix for this model: 
 [[19242   907]
 [ 8918  1184]]
Input Shape:  (113739, 6, 30)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_32"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_33 (InputLayer)          [(None, 6, 30)]      0           []                               
                                                                                                  
 batch_normalization_64 (BatchN  (None, 6, 30)       120         ['input_33[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_64 (Multi  (None, 6, 30)       7902        ['batch_normalization_64[0][0]', 
 HeadAttention)                                                   'batch_normalization_64[0][0]'] 
                                                                                                  
 dropout_128 (Dropout)          (None, 6, 30)        0           ['multi_head_attention_64[0][0]']
                                                                                                  
 tf.__operators__.add_128 (TFOp  (None, 6, 30)       0           ['dropout_128[0][0]',            
 Lambda)                                                          'input_33[0][0]']               
                                                                                                  
 layer_normalization_64 (LayerN  (None, 6, 30)       60          ['tf.__operators__.add_128[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_128 (Conv1D)            (None, 6, 32)        992         ['layer_normalization_64[0][0]'] 
                                                                                                  
 dropout_129 (Dropout)          (None, 6, 32)        0           ['conv1d_128[0][0]']             
                                                                                                  
 conv1d_129 (Conv1D)            (None, 6, 30)        990         ['dropout_129[0][0]']            
                                                                                                  
 tf.__operators__.add_129 (TFOp  (None, 6, 30)       0           ['conv1d_129[0][0]',             
 Lambda)                                                          'tf.__operators__.add_128[0][0]'
                                                                 ]                                
                                                                                                  
 batch_normalization_65 (BatchN  (None, 6, 30)       120         ['tf.__operators__.add_129[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 multi_head_attention_65 (Multi  (None, 6, 30)       7902        ['batch_normalization_65[0][0]', 
 HeadAttention)                                                   'batch_normalization_65[0][0]'] 
                                                                                                  
 dropout_130 (Dropout)          (None, 6, 30)        0           ['multi_head_attention_65[0][0]']
                                                                                                  
 tf.__operators__.add_130 (TFOp  (None, 6, 30)       0           ['dropout_130[0][0]',            
 Lambda)                                                          'tf.__operators__.add_129[0][0]'
                                                                 ]                                
                                                                                                  
 layer_normalization_65 (LayerN  (None, 6, 30)       60          ['tf.__operators__.add_130[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_130 (Conv1D)            (None, 6, 32)        992         ['layer_normalization_65[0][0]'] 
                                                                                                  
 dropout_131 (Dropout)          (None, 6, 32)        0           ['conv1d_130[0][0]']             
                                                                                                  
 conv1d_131 (Conv1D)            (None, 6, 30)        990         ['dropout_131[0][0]']            
                                                                                                  
 tf.__operators__.add_131 (TFOp  (None, 6, 30)       0           ['conv1d_131[0][0]',             
 Lambda)                                                          'tf.__operators__.add_130[0][0]'
                                                                 ]                                
                                                                                                  
 dense_64 (Dense)               (None, 6, 128)       3968        ['tf.__operators__.add_131[0][0]'
                                                                 ]                                
                                                                                                  
 flatten_32 (Flatten)           (None, 768)          0           ['dense_64[0][0]']               
                                                                                                  
 dense_65 (Dense)               (None, 2)            1538        ['flatten_32[0][0]']             
                                                                                                  
==================================================================================================
Total params: 25,634
Trainable params: 25,514
Non-trainable params: 120
__________________________________________________________________________________________________
Epoch 00040: early stopping
Experiment:  225  Set:  sn1 Train Labels:  nar10 Test Labels:  clean
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 4 0
AER:  0.2552312320253876
TER:  0.255, 0.255, 0.255
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      0.90      0.84     23175
           1       0.42      0.23      0.30      7076

    accuracy                           0.74     30251
   macro avg       0.61      0.57      0.57     30251
weighted avg       0.71      0.74      0.72     30251

Confusion Matrix for this model: 
 [[20910  2265]
 [ 5456  1620]]
Experiment:  226  Set:  sn1 Train Labels:  nar10 Test Labels:  ncar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 4 1
AER:  0.2790982116293676
TER:  0.255, 0.229, 0.329
Score for this model: 
               precision    recall  f1-score   support

           0       0.76      0.90      0.83     22375
           1       0.43      0.21      0.28      7876

    accuracy                           0.72     30251
   macro avg       0.60      0.56      0.55     30251
weighted avg       0.68      0.72      0.68     30251

Confusion Matrix for this model: 
 [[20149  2226]
 [ 6217  1659]]
Experiment:  227  Set:  sn1 Train Labels:  nar10 Test Labels:  ncar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 4 2
AER:  0.3060394697695944
TER:  0.258, 0.206, 0.406
Score for this model: 
               precision    recall  f1-score   support

           0       0.73      0.90      0.81     21532
           1       0.43      0.19      0.27      8719

    accuracy                           0.69     30251
   macro avg       0.58      0.54      0.54     30251
weighted avg       0.65      0.69      0.65     30251

Confusion Matrix for this model: 
 [[19320  2212]
 [ 7046  1673]]
Experiment:  228  Set:  sn1 Train Labels:  nar10 Test Labels:  nar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 4 3
AER:  0.2982711315328419
TER:  0.276, 0.248, 0.348
Score for this model: 
               precision    recall  f1-score   support

           0       0.74      0.90      0.81     21585
           1       0.45      0.20      0.28      8666

    accuracy                           0.70     30251
   macro avg       0.60      0.55      0.55     30251
weighted avg       0.66      0.70      0.66     30251

Confusion Matrix for this model: 
 [[19464  2121]
 [ 6902  1764]]
Experiment:  229  Set:  sn1 Train Labels:  nar10 Test Labels:  nar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 4 4
AER:  0.34293081220455524
TER:  0.304, 0.243, 0.443
Score for this model: 
               precision    recall  f1-score   support

           0       0.68      0.90      0.78     19904
           1       0.50      0.19      0.27     10347

    accuracy                           0.66     30251
   macro avg       0.59      0.54      0.52     30251
weighted avg       0.62      0.66      0.60     30251

Confusion Matrix for this model: 
 [[17948  1956]
 [ 8418  1929]]
Experiment:  230  Set:  sn1 Train Labels:  nar10 Test Labels:  nnar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 4 5
AER:  0.29480017189514396
TER:  0.272, 0.245, 0.345
Score for this model: 
               precision    recall  f1-score   support

           0       0.74      0.90      0.81     21662
           1       0.46      0.21      0.29      8589

    accuracy                           0.71     30251
   macro avg       0.60      0.55      0.55     30251
weighted avg       0.66      0.71      0.66     30251

Confusion Matrix for this model: 
 [[19555  2107]
 [ 6811  1778]]
Experiment:  231  Set:  sn1 Train Labels:  nar10 Test Labels:  nnar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 4 6
AER:  0.33218736570691876
TER:  0.290, 0.232, 0.432
Score for this model: 
               precision    recall  f1-score   support

           0       0.69      0.90      0.78     20149
           1       0.51      0.19      0.28     10102

    accuracy                           0.67     30251
   macro avg       0.60      0.55      0.53     30251
weighted avg       0.63      0.67      0.62     30251

Confusion Matrix for this model: 
 [[18233  1916]
 [ 8133  1969]]
Input Shape:  (113739, 6, 30)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_33"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_34 (InputLayer)          [(None, 6, 30)]      0           []                               
                                                                                                  
 batch_normalization_66 (BatchN  (None, 6, 30)       120         ['input_34[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_66 (Multi  (None, 6, 30)       7902        ['batch_normalization_66[0][0]', 
 HeadAttention)                                                   'batch_normalization_66[0][0]'] 
                                                                                                  
 dropout_132 (Dropout)          (None, 6, 30)        0           ['multi_head_attention_66[0][0]']
                                                                                                  
 tf.__operators__.add_132 (TFOp  (None, 6, 30)       0           ['dropout_132[0][0]',            
 Lambda)                                                          'input_34[0][0]']               
                                                                                                  
 layer_normalization_66 (LayerN  (None, 6, 30)       60          ['tf.__operators__.add_132[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_132 (Conv1D)            (None, 6, 32)        992         ['layer_normalization_66[0][0]'] 
                                                                                                  
 dropout_133 (Dropout)          (None, 6, 32)        0           ['conv1d_132[0][0]']             
                                                                                                  
 conv1d_133 (Conv1D)            (None, 6, 30)        990         ['dropout_133[0][0]']            
                                                                                                  
 tf.__operators__.add_133 (TFOp  (None, 6, 30)       0           ['conv1d_133[0][0]',             
 Lambda)                                                          'tf.__operators__.add_132[0][0]'
                                                                 ]                                
                                                                                                  
 batch_normalization_67 (BatchN  (None, 6, 30)       120         ['tf.__operators__.add_133[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 multi_head_attention_67 (Multi  (None, 6, 30)       7902        ['batch_normalization_67[0][0]', 
 HeadAttention)                                                   'batch_normalization_67[0][0]'] 
                                                                                                  
 dropout_134 (Dropout)          (None, 6, 30)        0           ['multi_head_attention_67[0][0]']
                                                                                                  
 tf.__operators__.add_134 (TFOp  (None, 6, 30)       0           ['dropout_134[0][0]',            
 Lambda)                                                          'tf.__operators__.add_133[0][0]'
                                                                 ]                                
                                                                                                  
 layer_normalization_67 (LayerN  (None, 6, 30)       60          ['tf.__operators__.add_134[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_134 (Conv1D)            (None, 6, 32)        992         ['layer_normalization_67[0][0]'] 
                                                                                                  
 dropout_135 (Dropout)          (None, 6, 32)        0           ['conv1d_134[0][0]']             
                                                                                                  
 conv1d_135 (Conv1D)            (None, 6, 30)        990         ['dropout_135[0][0]']            
                                                                                                  
 tf.__operators__.add_135 (TFOp  (None, 6, 30)       0           ['conv1d_135[0][0]',             
 Lambda)                                                          'tf.__operators__.add_134[0][0]'
                                                                 ]                                
                                                                                                  
 dense_66 (Dense)               (None, 6, 128)       3968        ['tf.__operators__.add_135[0][0]'
                                                                 ]                                
                                                                                                  
 flatten_33 (Flatten)           (None, 768)          0           ['dense_66[0][0]']               
                                                                                                  
 dense_67 (Dense)               (None, 2)            1538        ['flatten_33[0][0]']             
                                                                                                  
==================================================================================================
Total params: 25,634
Trainable params: 25,514
Non-trainable params: 120
__________________________________________________________________________________________________
Epoch 00045: early stopping
Experiment:  232  Set:  sn1 Train Labels:  nnar5 Test Labels:  clean
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 5 0
AER:  0.24032263396251363
TER:  0.240, 0.240, 0.240
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.91      0.85     23175
           1       0.48      0.28      0.35      7076

    accuracy                           0.76     30251
   macro avg       0.64      0.59      0.60     30251
weighted avg       0.73      0.76      0.74     30251

Confusion Matrix for this model: 
 [[21003  2172]
 [ 5098  1978]]
Experiment:  233  Set:  sn1 Train Labels:  nnar5 Test Labels:  ncar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 5 1
AER:  0.26577633797229844
TER:  0.240, 0.216, 0.316
Score for this model: 
               precision    recall  f1-score   support

           0       0.77      0.90      0.83     22375
           1       0.48      0.25      0.33      7876

    accuracy                           0.73     30251
   macro avg       0.63      0.58      0.58     30251
weighted avg       0.70      0.73      0.70     30251

Confusion Matrix for this model: 
 [[20218  2157]
 [ 5883  1993]]
Experiment:  234  Set:  sn1 Train Labels:  nnar5 Test Labels:  ncar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 5 2
AER:  0.2931803907308849
TER:  0.241, 0.193, 0.393
Score for this model: 
               precision    recall  f1-score   support

           0       0.74      0.90      0.81     21532
           1       0.48      0.23      0.31      8719

    accuracy                           0.71     30251
   macro avg       0.61      0.56      0.56     30251
weighted avg       0.67      0.71      0.67     30251

Confusion Matrix for this model: 
 [[19382  2150]
 [ 6719  2000]]
Experiment:  235  Set:  sn1 Train Labels:  nnar5 Test Labels:  nar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 5 3
AER:  0.2824369442332485
TER:  0.258, 0.232, 0.332
Score for this model: 
               precision    recall  f1-score   support

           0       0.75      0.91      0.82     21585
           1       0.51      0.25      0.33      8666

    accuracy                           0.72     30251
   macro avg       0.63      0.58      0.58     30251
weighted avg       0.68      0.72      0.68     30251

Confusion Matrix for this model: 
 [[19571  2014]
 [ 6530  2136]]
Experiment:  236  Set:  sn1 Train Labels:  nnar5 Test Labels:  nar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 5 4
AER:  0.328485008760041
TER:  0.286, 0.228, 0.428
Score for this model: 
               precision    recall  f1-score   support

           0       0.69      0.91      0.78     19904
           1       0.55      0.22      0.31     10347

    accuracy                           0.67     30251
   macro avg       0.62      0.56      0.55     30251
weighted avg       0.64      0.67      0.62     30251

Confusion Matrix for this model: 
 [[18034  1870]
 [ 8067  2280]]
Experiment:  237  Set:  sn1 Train Labels:  nnar5 Test Labels:  nnar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 5 5
AER:  0.27916432514627615
TER:  0.255, 0.229, 0.329
Score for this model: 
               precision    recall  f1-score   support

           0       0.75      0.91      0.82     21662
           1       0.52      0.25      0.34      8589

    accuracy                           0.72     30251
   macro avg       0.64      0.58      0.58     30251
weighted avg       0.69      0.72      0.69     30251

Confusion Matrix for this model: 
 [[19659  2003]
 [ 6442  2147]]
Experiment:  238  Set:  sn1 Train Labels:  nnar5 Test Labels:  nnar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 5 6
AER:  0.3166176324749595
TER:  0.271, 0.217, 0.417
Score for this model: 
               precision    recall  f1-score   support

           0       0.70      0.91      0.79     20149
           1       0.56      0.23      0.33     10102

    accuracy                           0.68     30251
   macro avg       0.63      0.57      0.56     30251
weighted avg       0.66      0.68      0.64     30251

Confusion Matrix for this model: 
 [[18336  1813]
 [ 7765  2337]]
Input Shape:  (113739, 6, 30)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_34"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_35 (InputLayer)          [(None, 6, 30)]      0           []                               
                                                                                                  
 batch_normalization_68 (BatchN  (None, 6, 30)       120         ['input_35[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_68 (Multi  (None, 6, 30)       7902        ['batch_normalization_68[0][0]', 
 HeadAttention)                                                   'batch_normalization_68[0][0]'] 
                                                                                                  
 dropout_136 (Dropout)          (None, 6, 30)        0           ['multi_head_attention_68[0][0]']
                                                                                                  
 tf.__operators__.add_136 (TFOp  (None, 6, 30)       0           ['dropout_136[0][0]',            
 Lambda)                                                          'input_35[0][0]']               
                                                                                                  
 layer_normalization_68 (LayerN  (None, 6, 30)       60          ['tf.__operators__.add_136[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_136 (Conv1D)            (None, 6, 32)        992         ['layer_normalization_68[0][0]'] 
                                                                                                  
 dropout_137 (Dropout)          (None, 6, 32)        0           ['conv1d_136[0][0]']             
                                                                                                  
 conv1d_137 (Conv1D)            (None, 6, 30)        990         ['dropout_137[0][0]']            
                                                                                                  
 tf.__operators__.add_137 (TFOp  (None, 6, 30)       0           ['conv1d_137[0][0]',             
 Lambda)                                                          'tf.__operators__.add_136[0][0]'
                                                                 ]                                
                                                                                                  
 batch_normalization_69 (BatchN  (None, 6, 30)       120         ['tf.__operators__.add_137[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 multi_head_attention_69 (Multi  (None, 6, 30)       7902        ['batch_normalization_69[0][0]', 
 HeadAttention)                                                   'batch_normalization_69[0][0]'] 
                                                                                                  
 dropout_138 (Dropout)          (None, 6, 30)        0           ['multi_head_attention_69[0][0]']
                                                                                                  
 tf.__operators__.add_138 (TFOp  (None, 6, 30)       0           ['dropout_138[0][0]',            
 Lambda)                                                          'tf.__operators__.add_137[0][0]'
                                                                 ]                                
                                                                                                  
 layer_normalization_69 (LayerN  (None, 6, 30)       60          ['tf.__operators__.add_138[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_138 (Conv1D)            (None, 6, 32)        992         ['layer_normalization_69[0][0]'] 
                                                                                                  
 dropout_139 (Dropout)          (None, 6, 32)        0           ['conv1d_138[0][0]']             
                                                                                                  
 conv1d_139 (Conv1D)            (None, 6, 30)        990         ['dropout_139[0][0]']            
                                                                                                  
 tf.__operators__.add_139 (TFOp  (None, 6, 30)       0           ['conv1d_139[0][0]',             
 Lambda)                                                          'tf.__operators__.add_138[0][0]'
                                                                 ]                                
                                                                                                  
 dense_68 (Dense)               (None, 6, 128)       3968        ['tf.__operators__.add_139[0][0]'
                                                                 ]                                
                                                                                                  
 flatten_34 (Flatten)           (None, 768)          0           ['dense_68[0][0]']               
                                                                                                  
 dense_69 (Dense)               (None, 2)            1538        ['flatten_34[0][0]']             
                                                                                                  
==================================================================================================
Total params: 25,634
Trainable params: 25,514
Non-trainable params: 120
__________________________________________________________________________________________________
Epoch 00044: early stopping
Experiment:  239  Set:  sn1 Train Labels:  nnar10 Test Labels:  clean
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 6 0
AER:  0.25685101318964665
TER:  0.257, 0.257, 0.257
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      0.89      0.84     23175
           1       0.42      0.25      0.31      7076

    accuracy                           0.74     30251
   macro avg       0.61      0.57      0.58     30251
weighted avg       0.71      0.74      0.72     30251

Confusion Matrix for this model: 
 [[20698  2477]
 [ 5293  1783]]
Experiment:  240  Set:  sn1 Train Labels:  nnar10 Test Labels:  ncar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 6 1
AER:  0.2816435820303461
TER:  0.257, 0.232, 0.332
Score for this model: 
               precision    recall  f1-score   support

           0       0.77      0.89      0.82     22375
           1       0.42      0.23      0.30      7876

    accuracy                           0.72     30251
   macro avg       0.60      0.56      0.56     30251
weighted avg       0.68      0.72      0.69     30251

Confusion Matrix for this model: 
 [[19923  2452]
 [ 6068  1808]]
Experiment:  241  Set:  sn1 Train Labels:  nnar10 Test Labels:  ncar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 6 2
AER:  0.30686588873095105
TER:  0.259, 0.207, 0.407
Score for this model: 
               precision    recall  f1-score   support

           0       0.74      0.89      0.80     21532
           1       0.43      0.21      0.28      8719

    accuracy                           0.69     30251
   macro avg       0.58      0.55      0.54     30251
weighted avg       0.65      0.69      0.65     30251

Confusion Matrix for this model: 
 [[19120  2412]
 [ 6871  1848]]
Experiment:  242  Set:  sn1 Train Labels:  nnar10 Test Labels:  nar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 6 3
AER:  0.29903143697729
TER:  0.277, 0.249, 0.349
Score for this model: 
               precision    recall  f1-score   support

           0       0.74      0.89      0.81     21585
           1       0.46      0.22      0.30      8666

    accuracy                           0.70     30251
   macro avg       0.60      0.56      0.56     30251
weighted avg       0.66      0.70      0.66     30251

Confusion Matrix for this model: 
 [[19265  2320]
 [ 6726  1940]]
Experiment:  243  Set:  sn1 Train Labels:  nnar10 Test Labels:  nar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 6 4
AER:  0.3417077121417474
TER:  0.302, 0.242, 0.442
Score for this model: 
               precision    recall  f1-score   support

           0       0.68      0.89      0.77     19904
           1       0.50      0.21      0.29     10347

    accuracy                           0.66     30251
   macro avg       0.59      0.55      0.53     30251
weighted avg       0.62      0.66      0.61     30251

Confusion Matrix for this model: 
 [[17779  2125]
 [ 8212  2135]]
Experiment:  244  Set:  sn1 Train Labels:  nnar10 Test Labels:  nnar5
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 6 5
AER:  0.2937754123830617
TER:  0.271, 0.244, 0.344
Score for this model: 
               precision    recall  f1-score   support

           0       0.75      0.89      0.81     21662
           1       0.47      0.23      0.31      8589

    accuracy                           0.71     30251
   macro avg       0.61      0.56      0.56     30251
weighted avg       0.67      0.71      0.67     30251

Confusion Matrix for this model: 
 [[19383  2279]
 [ 6608  1981]]
Experiment:  245  Set:  sn1 Train Labels:  nnar10 Test Labels:  nnar10
Shape of X_train:  (113739, 6, 30)
Shape of X_test:  (30251, 6, 30)
Shape of y_train:  (113739, 2)
Shape of y_test:  (30251, 2)
NUM_INSTANCES is  682434
instances should be  113739
Shape of y true: (30251,)
Shape of y predicted: (30251,)
[0.82673827 0.04332255] [0.04332255 0.82673827]
Recording results in matrix at 6 6
AER:  0.33142706026247065
TER:  0.289, 0.231, 0.431
Score for this model: 
               precision    recall  f1-score   support

           0       0.69      0.90      0.78     20149
           1       0.51      0.21      0.30     10102

    accuracy                           0.67     30251
   macro avg       0.60      0.56      0.54     30251
weighted avg       0.63      0.67      0.62     30251

Confusion Matrix for this model: 
 [[18057  2092]
 [ 7934  2168]]
Input Shape:  (8112, 5, 30)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_35"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_36 (InputLayer)          [(None, 5, 30)]      0           []                               
                                                                                                  
 batch_normalization_70 (BatchN  (None, 5, 30)       120         ['input_36[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_70 (Multi  (None, 5, 30)       7902        ['batch_normalization_70[0][0]', 
 HeadAttention)                                                   'batch_normalization_70[0][0]'] 
                                                                                                  
 dropout_140 (Dropout)          (None, 5, 30)        0           ['multi_head_attention_70[0][0]']
                                                                                                  
 tf.__operators__.add_140 (TFOp  (None, 5, 30)       0           ['dropout_140[0][0]',            
 Lambda)                                                          'input_36[0][0]']               
                                                                                                  
 layer_normalization_70 (LayerN  (None, 5, 30)       60          ['tf.__operators__.add_140[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_140 (Conv1D)            (None, 5, 32)        992         ['layer_normalization_70[0][0]'] 
                                                                                                  
 dropout_141 (Dropout)          (None, 5, 32)        0           ['conv1d_140[0][0]']             
                                                                                                  
 conv1d_141 (Conv1D)            (None, 5, 30)        990         ['dropout_141[0][0]']            
                                                                                                  
 tf.__operators__.add_141 (TFOp  (None, 5, 30)       0           ['conv1d_141[0][0]',             
 Lambda)                                                          'tf.__operators__.add_140[0][0]'
                                                                 ]                                
                                                                                                  
 batch_normalization_71 (BatchN  (None, 5, 30)       120         ['tf.__operators__.add_141[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 multi_head_attention_71 (Multi  (None, 5, 30)       7902        ['batch_normalization_71[0][0]', 
 HeadAttention)                                                   'batch_normalization_71[0][0]'] 
                                                                                                  
 dropout_142 (Dropout)          (None, 5, 30)        0           ['multi_head_attention_71[0][0]']
                                                                                                  
 tf.__operators__.add_142 (TFOp  (None, 5, 30)       0           ['dropout_142[0][0]',            
 Lambda)                                                          'tf.__operators__.add_141[0][0]'
                                                                 ]                                
                                                                                                  
 layer_normalization_71 (LayerN  (None, 5, 30)       60          ['tf.__operators__.add_142[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_142 (Conv1D)            (None, 5, 32)        992         ['layer_normalization_71[0][0]'] 
                                                                                                  
 dropout_143 (Dropout)          (None, 5, 32)        0           ['conv1d_142[0][0]']             
                                                                                                  
 conv1d_143 (Conv1D)            (None, 5, 30)        990         ['dropout_143[0][0]']            
                                                                                                  
 tf.__operators__.add_143 (TFOp  (None, 5, 30)       0           ['conv1d_143[0][0]',             
 Lambda)                                                          'tf.__operators__.add_142[0][0]'
                                                                 ]                                
                                                                                                  
 dense_70 (Dense)               (None, 5, 128)       3968        ['tf.__operators__.add_143[0][0]'
                                                                 ]                                
                                                                                                  
 flatten_35 (Flatten)           (None, 640)          0           ['dense_70[0][0]']               
                                                                                                  
 dense_71 (Dense)               (None, 5)            3205        ['flatten_35[0][0]']             
                                                                                                  
==================================================================================================
Total params: 27,301
Trainable params: 27,181
Non-trainable params: 120
__________________________________________________________________________________________________
Epoch 00076: early stopping
Experiment:  246  Set:  sn2 Train Labels:  clean Test Labels:  clean
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
None None
Recording results in matrix at 0 0
AER:  0.1560364464692483
TER:  0.156, 0.156, 0.156
Score for this model: 
               precision    recall  f1-score   support

           0       0.98      1.00      0.99      1558
           1       0.78      0.92      0.84       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00         1
           4       0.59      0.12      0.20       401

    accuracy                           0.84      2634
   macro avg       0.47      0.41      0.41      2634
weighted avg       0.87      0.84      0.83      2634

Confusion Matrix for this model: 
 [[1558    0    0    0    0]
 [   6  616   13    1   34]
 [   0    2    0    2    0]
 [   0    1    0    0    0]
 [  28  172   68   84   49]]
Experiment:  247  Set:  sn2 Train Labels:  clean Test Labels:  ncar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 0 1
AER:  0.1909643128321944
TER:  0.157, 0.141, 0.241
Score for this model: 
               precision    recall  f1-score   support

           0       0.94      0.99      0.96      1501
           1       0.74      0.89      0.81       660
           2       0.04      0.10      0.05        30
           3       0.02      0.06      0.03        31
           4       0.59      0.12      0.20       412

    accuracy                           0.81      2634
   macro avg       0.47      0.43      0.41      2634
weighted avg       0.81      0.81      0.78      2634

Confusion Matrix for this model: 
 [[1489    9    2    0    1]
 [  23  588   14    3   32]
 [  19    6    3    2    0]
 [  19    8    1    2    1]
 [  42  180   61   80   49]]
Experiment:  248  Set:  sn2 Train Labels:  clean Test Labels:  ncar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 0 2
AER:  0.22892938496583143
TER:  0.161, 0.129, 0.329
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      0.98      0.93      1433
           1       0.73      0.86      0.79       670
           2       0.02      0.03      0.03        66
           3       0.02      0.03      0.03        61
           4       0.53      0.11      0.18       404

    accuracy                           0.77      2634
   macro avg       0.44      0.40      0.39      2634
weighted avg       0.75      0.77      0.74      2634

Confusion Matrix for this model: 
 [[1406   22    2    1    2]
 [  45  577   13    2   33]
 [  42   15    2    5    2]
 [  40   16    1    2    2]
 [  59  161   63   77   44]]
Experiment:  249  Set:  sn2 Train Labels:  clean Test Labels:  nar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 0 3
AER:  0.20273348519362186
TER:  0.170, 0.153, 0.253
Score for this model: 
               precision    recall  f1-score   support

           0       0.90      1.00      0.95      1435
           1       0.78      0.92      0.84       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00       124
           4       0.59      0.12      0.20       401

    accuracy                           0.80      2634
   macro avg       0.45      0.41      0.40      2634
weighted avg       0.78      0.80      0.76      2634

Confusion Matrix for this model: 
 [[1435    0    0    0    0]
 [   6  616   13    1   34]
 [   0    2    0    2    0]
 [ 123    1    0    0    0]
 [  28  172   68   84   49]]
Experiment:  250  Set:  sn2 Train Labels:  clean Test Labels:  nar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 0 4
AER:  0.2539863325740319
TER:  0.192, 0.154, 0.354
Score for this model: 
               precision    recall  f1-score   support

           0       0.82      1.00      0.90      1300
           1       0.78      0.92      0.84       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00       259
           4       0.59      0.12      0.20       401

    accuracy                           0.75      2634
   macro avg       0.44      0.41      0.39      2634
weighted avg       0.69      0.75      0.69      2634

Confusion Matrix for this model: 
 [[1300    0    0    0    0]
 [   6  616   13    1   34]
 [   0    2    0    2    0]
 [ 258    1    0    0    0]
 [  28  172   68   84   49]]
Experiment:  251  Set:  sn2 Train Labels:  clean Test Labels:  nnar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 0 5
AER:  0.2061503416856492
TER:  0.174, 0.156, 0.256
Score for this model: 
               precision    recall  f1-score   support

           0       0.90      1.00      0.94      1426
           1       0.78      0.92      0.84       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00       133
           4       0.59      0.12      0.20       401

    accuracy                           0.79      2634
   macro avg       0.45      0.41      0.40      2634
weighted avg       0.77      0.79      0.76      2634

Confusion Matrix for this model: 
 [[1426    0    0    0    0]
 [   6  616   13    1   34]
 [   0    2    0    2    0]
 [ 132    1    0    0    0]
 [  28  172   68   84   49]]
Experiment:  252  Set:  sn2 Train Labels:  clean Test Labels:  nnar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 0 6
AER:  0.25626423690205014
TER:  0.195, 0.156, 0.356
Score for this model: 
               precision    recall  f1-score   support

           0       0.81      1.00      0.90      1294
           1       0.78      0.92      0.84       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00       265
           4       0.59      0.12      0.20       401

    accuracy                           0.74      2634
   macro avg       0.44      0.41      0.39      2634
weighted avg       0.69      0.74      0.69      2634

Confusion Matrix for this model: 
 [[1294    0    0    0    0]
 [   6  616   13    1   34]
 [   0    2    0    2    0]
 [ 264    1    0    0    0]
 [  28  172   68   84   49]]
Input Shape:  (8112, 5, 30)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_36"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_37 (InputLayer)          [(None, 5, 30)]      0           []                               
                                                                                                  
 batch_normalization_72 (BatchN  (None, 5, 30)       120         ['input_37[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_72 (Multi  (None, 5, 30)       7902        ['batch_normalization_72[0][0]', 
 HeadAttention)                                                   'batch_normalization_72[0][0]'] 
                                                                                                  
 dropout_144 (Dropout)          (None, 5, 30)        0           ['multi_head_attention_72[0][0]']
                                                                                                  
 tf.__operators__.add_144 (TFOp  (None, 5, 30)       0           ['dropout_144[0][0]',            
 Lambda)                                                          'input_37[0][0]']               
                                                                                                  
 layer_normalization_72 (LayerN  (None, 5, 30)       60          ['tf.__operators__.add_144[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_144 (Conv1D)            (None, 5, 32)        992         ['layer_normalization_72[0][0]'] 
                                                                                                  
 dropout_145 (Dropout)          (None, 5, 32)        0           ['conv1d_144[0][0]']             
                                                                                                  
 conv1d_145 (Conv1D)            (None, 5, 30)        990         ['dropout_145[0][0]']            
                                                                                                  
 tf.__operators__.add_145 (TFOp  (None, 5, 30)       0           ['conv1d_145[0][0]',             
 Lambda)                                                          'tf.__operators__.add_144[0][0]'
                                                                 ]                                
                                                                                                  
 batch_normalization_73 (BatchN  (None, 5, 30)       120         ['tf.__operators__.add_145[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 multi_head_attention_73 (Multi  (None, 5, 30)       7902        ['batch_normalization_73[0][0]', 
 HeadAttention)                                                   'batch_normalization_73[0][0]'] 
                                                                                                  
 dropout_146 (Dropout)          (None, 5, 30)        0           ['multi_head_attention_73[0][0]']
                                                                                                  
 tf.__operators__.add_146 (TFOp  (None, 5, 30)       0           ['dropout_146[0][0]',            
 Lambda)                                                          'tf.__operators__.add_145[0][0]'
                                                                 ]                                
                                                                                                  
 layer_normalization_73 (LayerN  (None, 5, 30)       60          ['tf.__operators__.add_146[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_146 (Conv1D)            (None, 5, 32)        992         ['layer_normalization_73[0][0]'] 
                                                                                                  
 dropout_147 (Dropout)          (None, 5, 32)        0           ['conv1d_146[0][0]']             
                                                                                                  
 conv1d_147 (Conv1D)            (None, 5, 30)        990         ['dropout_147[0][0]']            
                                                                                                  
 tf.__operators__.add_147 (TFOp  (None, 5, 30)       0           ['conv1d_147[0][0]',             
 Lambda)                                                          'tf.__operators__.add_146[0][0]'
                                                                 ]                                
                                                                                                  
 dense_72 (Dense)               (None, 5, 128)       3968        ['tf.__operators__.add_147[0][0]'
                                                                 ]                                
                                                                                                  
 flatten_36 (Flatten)           (None, 640)          0           ['dense_72[0][0]']               
                                                                                                  
 dense_73 (Dense)               (None, 5)            3205        ['flatten_36[0][0]']             
                                                                                                  
==================================================================================================
Total params: 27,301
Trainable params: 27,181
Non-trainable params: 120
__________________________________________________________________________________________________
Epoch 00068: early stopping
Experiment:  253  Set:  sn2 Train Labels:  ncar5 Test Labels:  clean
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 1 0
AER:  0.14882308276385725
TER:  0.149, 0.149, 0.149
Score for this model: 
               precision    recall  f1-score   support

           0       0.97      1.00      0.98      1558
           1       0.78      0.92      0.84       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00         1
           4       0.65      0.16      0.26       401

    accuracy                           0.85      2634
   macro avg       0.48      0.42      0.42      2634
weighted avg       0.87      0.85      0.84      2634

Confusion Matrix for this model: 
 [[1558    0    0    0    0]
 [  12  618    4    0   36]
 [   2    2    0    0    0]
 [   0    1    0    0    0]
 [  35  173   56   71   66]]
Experiment:  254  Set:  sn2 Train Labels:  ncar5 Test Labels:  ncar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 1 1
AER:  0.1852695520121488
TER:  0.150, 0.135, 0.235
Score for this model: 
               precision    recall  f1-score   support

           0       0.93      0.99      0.96      1501
           1       0.74      0.89      0.81       660
           2       0.05      0.10      0.07        30
           3       0.01      0.03      0.02        31
           4       0.63      0.16      0.25       412

    accuracy                           0.81      2634
   macro avg       0.47      0.43      0.42      2634
weighted avg       0.81      0.81      0.79      2634

Confusion Matrix for this model: 
 [[1489    9    0    0    3]
 [  30  589    5    2   34]
 [  21    6    3    0    0]
 [  18   10    1    1    1]
 [  49  180   51   68   64]]
Experiment:  255  Set:  sn2 Train Labels:  ncar5 Test Labels:  ncar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 1 2
AER:  0.22285497342444952
TER:  0.154, 0.123, 0.323
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.98      0.93      1433
           1       0.73      0.86      0.79       670
           2       0.02      0.02      0.02        66
           3       0.03      0.03      0.03        61
           4       0.59      0.15      0.24       404

    accuracy                           0.78      2634
   macro avg       0.45      0.41      0.40      2634
weighted avg       0.75      0.78      0.74      2634

Confusion Matrix for this model: 
 [[1406   22    1    1    3]
 [  52  578    4    1   35]
 [  45   15    1    3    2]
 [  40   16    1    2    2]
 [  64  163   53   64   60]]
Experiment:  256  Set:  sn2 Train Labels:  ncar5 Test Labels:  nar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 1 3
AER:  0.19552012148823084
TER:  0.162, 0.146, 0.246
Score for this model: 
               precision    recall  f1-score   support

           0       0.89      1.00      0.94      1435
           1       0.78      0.92      0.84       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00       124
           4       0.65      0.16      0.26       401

    accuracy                           0.80      2634
   macro avg       0.46      0.42      0.41      2634
weighted avg       0.78      0.80      0.77      2634

Confusion Matrix for this model: 
 [[1435    0    0    0    0]
 [  12  618    4    0   36]
 [   2    2    0    0    0]
 [ 123    1    0    0    0]
 [  35  173   56   71   66]]
Experiment:  257  Set:  sn2 Train Labels:  ncar5 Test Labels:  nar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 1 4
AER:  0.24677296886864086
TER:  0.183, 0.147, 0.347
Score for this model: 
               precision    recall  f1-score   support

           0       0.81      1.00      0.89      1300
           1       0.78      0.92      0.84       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00       259
           4       0.65      0.16      0.26       401

    accuracy                           0.75      2634
   macro avg       0.45      0.42      0.40      2634
weighted avg       0.70      0.75      0.70      2634

Confusion Matrix for this model: 
 [[1300    0    0    0    0]
 [  12  618    4    0   36]
 [   2    2    0    0    0]
 [ 258    1    0    0    0]
 [  35  173   56   71   66]]
Experiment:  258  Set:  sn2 Train Labels:  ncar5 Test Labels:  nnar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 1 5
AER:  0.19893697798025817
TER:  0.165, 0.149, 0.249
Score for this model: 
               precision    recall  f1-score   support

           0       0.89      1.00      0.94      1426
           1       0.78      0.92      0.84       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00       133
           4       0.65      0.16      0.26       401

    accuracy                           0.80      2634
   macro avg       0.46      0.42      0.41      2634
weighted avg       0.78      0.80      0.76      2634

Confusion Matrix for this model: 
 [[1426    0    0    0    0]
 [  12  618    4    0   36]
 [   2    2    0    0    0]
 [ 132    1    0    0    0]
 [  35  173   56   71   66]]
Experiment:  259  Set:  sn2 Train Labels:  ncar5 Test Labels:  nnar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 1 6
AER:  0.24905087319665908
TER:  0.186, 0.149, 0.349
Score for this model: 
               precision    recall  f1-score   support

           0       0.81      1.00      0.89      1294
           1       0.78      0.92      0.84       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00       265
           4       0.65      0.16      0.26       401

    accuracy                           0.75      2634
   macro avg       0.45      0.42      0.40      2634
weighted avg       0.69      0.75      0.69      2634

Confusion Matrix for this model: 
 [[1294    0    0    0    0]
 [  12  618    4    0   36]
 [   2    2    0    0    0]
 [ 264    1    0    0    0]
 [  35  173   56   71   66]]
Input Shape:  (8112, 5, 30)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_37"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_38 (InputLayer)          [(None, 5, 30)]      0           []                               
                                                                                                  
 batch_normalization_74 (BatchN  (None, 5, 30)       120         ['input_38[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_74 (Multi  (None, 5, 30)       7902        ['batch_normalization_74[0][0]', 
 HeadAttention)                                                   'batch_normalization_74[0][0]'] 
                                                                                                  
 dropout_148 (Dropout)          (None, 5, 30)        0           ['multi_head_attention_74[0][0]']
                                                                                                  
 tf.__operators__.add_148 (TFOp  (None, 5, 30)       0           ['dropout_148[0][0]',            
 Lambda)                                                          'input_38[0][0]']               
                                                                                                  
 layer_normalization_74 (LayerN  (None, 5, 30)       60          ['tf.__operators__.add_148[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_148 (Conv1D)            (None, 5, 32)        992         ['layer_normalization_74[0][0]'] 
                                                                                                  
 dropout_149 (Dropout)          (None, 5, 32)        0           ['conv1d_148[0][0]']             
                                                                                                  
 conv1d_149 (Conv1D)            (None, 5, 30)        990         ['dropout_149[0][0]']            
                                                                                                  
 tf.__operators__.add_149 (TFOp  (None, 5, 30)       0           ['conv1d_149[0][0]',             
 Lambda)                                                          'tf.__operators__.add_148[0][0]'
                                                                 ]                                
                                                                                                  
 batch_normalization_75 (BatchN  (None, 5, 30)       120         ['tf.__operators__.add_149[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 multi_head_attention_75 (Multi  (None, 5, 30)       7902        ['batch_normalization_75[0][0]', 
 HeadAttention)                                                   'batch_normalization_75[0][0]'] 
                                                                                                  
 dropout_150 (Dropout)          (None, 5, 30)        0           ['multi_head_attention_75[0][0]']
                                                                                                  
 tf.__operators__.add_150 (TFOp  (None, 5, 30)       0           ['dropout_150[0][0]',            
 Lambda)                                                          'tf.__operators__.add_149[0][0]'
                                                                 ]                                
                                                                                                  
 layer_normalization_75 (LayerN  (None, 5, 30)       60          ['tf.__operators__.add_150[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_150 (Conv1D)            (None, 5, 32)        992         ['layer_normalization_75[0][0]'] 
                                                                                                  
 dropout_151 (Dropout)          (None, 5, 32)        0           ['conv1d_150[0][0]']             
                                                                                                  
 conv1d_151 (Conv1D)            (None, 5, 30)        990         ['dropout_151[0][0]']            
                                                                                                  
 tf.__operators__.add_151 (TFOp  (None, 5, 30)       0           ['conv1d_151[0][0]',             
 Lambda)                                                          'tf.__operators__.add_150[0][0]'
                                                                 ]                                
                                                                                                  
 dense_74 (Dense)               (None, 5, 128)       3968        ['tf.__operators__.add_151[0][0]'
                                                                 ]                                
                                                                                                  
 flatten_37 (Flatten)           (None, 640)          0           ['dense_74[0][0]']               
                                                                                                  
 dense_75 (Dense)               (None, 5)            3205        ['flatten_37[0][0]']             
                                                                                                  
==================================================================================================
Total params: 27,301
Trainable params: 27,181
Non-trainable params: 120
__________________________________________________________________________________________________
Epoch 00111: early stopping
Experiment:  260  Set:  sn2 Train Labels:  ncar10 Test Labels:  clean
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 2 0
AER:  0.1469248291571754
TER:  0.147, 0.147, 0.147
Score for this model: 
               precision    recall  f1-score   support

           0       0.95      1.00      0.98      1558
           1       0.80      0.91      0.85       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00         1
           4       0.80      0.20      0.32       401

    accuracy                           0.85      2634
   macro avg       0.51      0.42      0.43      2634
weighted avg       0.89      0.85      0.84      2634

Confusion Matrix for this model: 
 [[1558    0    0    0    0]
 [  35  609    6    0   20]
 [   2    2    0    0    0]
 [   0    1    0    0    0]
 [  40  152   63   66   80]]
Experiment:  261  Set:  sn2 Train Labels:  ncar10 Test Labels:  ncar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 2 1
AER:  0.18261199696279423
TER:  0.147, 0.133, 0.233
Score for this model: 
               precision    recall  f1-score   support

           0       0.91      0.99      0.95      1501
           1       0.76      0.88      0.82       660
           2       0.04      0.10      0.06        30
           3       0.02      0.03      0.02        31
           4       0.78      0.19      0.30       412

    accuracy                           0.82      2634
   macro avg       0.50      0.44      0.43      2634
weighted avg       0.83      0.82      0.79      2634

Confusion Matrix for this model: 
 [[1489    9    1    0    2]
 [  51  582    6    2   19]
 [  21    6    3    0    0]
 [  19    9    1    1    1]
 [  55  158   58   63   78]]
Experiment:  262  Set:  sn2 Train Labels:  ncar10 Test Labels:  ncar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 2 2
AER:  0.2205770690964313
TER:  0.151, 0.121, 0.321
Score for this model: 
               precision    recall  f1-score   support

           0       0.86      0.98      0.92      1433
           1       0.75      0.85      0.79       670
           2       0.03      0.03      0.03        66
           3       0.03      0.03      0.03        61
           4       0.72      0.18      0.29       404

    accuracy                           0.78      2634
   macro avg       0.48      0.41      0.41      2634
weighted avg       0.77      0.78      0.75      2634

Confusion Matrix for this model: 
 [[1407   20    1    1    4]
 [  73  570    6    1   20]
 [  45   14    2    3    2]
 [  40   16    1    2    2]
 [  70  144   59   59   72]]
Experiment:  263  Set:  sn2 Train Labels:  ncar10 Test Labels:  nar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 2 3
AER:  0.19362186788154898
TER:  0.160, 0.144, 0.244
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      1.00      0.93      1435
           1       0.80      0.91      0.85       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00       124
           4       0.80      0.20      0.32       401

    accuracy                           0.81      2634
   macro avg       0.49      0.42      0.42      2634
weighted avg       0.80      0.81      0.77      2634

Confusion Matrix for this model: 
 [[1435    0    0    0    0]
 [  35  609    6    0   20]
 [   2    2    0    0    0]
 [ 123    1    0    0    0]
 [  40  152   63   66   80]]
Experiment:  264  Set:  sn2 Train Labels:  ncar10 Test Labels:  nar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 2 4
AER:  0.244874715261959
TER:  0.181, 0.145, 0.345
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      1.00      0.89      1300
           1       0.80      0.91      0.85       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00       259
           4       0.80      0.20      0.32       401

    accuracy                           0.76      2634
   macro avg       0.48      0.42      0.41      2634
weighted avg       0.72      0.76      0.70      2634

Confusion Matrix for this model: 
 [[1300    0    0    0    0]
 [  35  609    6    0   20]
 [   2    2    0    0    0]
 [ 258    1    0    0    0]
 [  40  152   63   66   80]]
Experiment:  265  Set:  sn2 Train Labels:  ncar10 Test Labels:  nnar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 2 5
AER:  0.1970387243735763
TER:  0.163, 0.147, 0.247
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      1.00      0.93      1426
           1       0.80      0.91      0.85       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00       133
           4       0.80      0.20      0.32       401

    accuracy                           0.80      2634
   macro avg       0.49      0.42      0.42      2634
weighted avg       0.80      0.80      0.77      2634

Confusion Matrix for this model: 
 [[1426    0    0    0    0]
 [  35  609    6    0   20]
 [   2    2    0    0    0]
 [ 132    1    0    0    0]
 [  40  152   63   66   80]]
Experiment:  266  Set:  sn2 Train Labels:  ncar10 Test Labels:  nnar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 2 6
AER:  0.24715261958997722
TER:  0.184, 0.147, 0.347
Score for this model: 
               precision    recall  f1-score   support

           0       0.79      1.00      0.88      1294
           1       0.80      0.91      0.85       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00       265
           4       0.80      0.20      0.32       401

    accuracy                           0.75      2634
   macro avg       0.48      0.42      0.41      2634
weighted avg       0.71      0.75      0.70      2634

Confusion Matrix for this model: 
 [[1294    0    0    0    0]
 [  35  609    6    0   20]
 [   2    2    0    0    0]
 [ 264    1    0    0    0]
 [  40  152   63   66   80]]
Input Shape:  (8112, 5, 30)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_38"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_39 (InputLayer)          [(None, 5, 30)]      0           []                               
                                                                                                  
 batch_normalization_76 (BatchN  (None, 5, 30)       120         ['input_39[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_76 (Multi  (None, 5, 30)       7902        ['batch_normalization_76[0][0]', 
 HeadAttention)                                                   'batch_normalization_76[0][0]'] 
                                                                                                  
 dropout_152 (Dropout)          (None, 5, 30)        0           ['multi_head_attention_76[0][0]']
                                                                                                  
 tf.__operators__.add_152 (TFOp  (None, 5, 30)       0           ['dropout_152[0][0]',            
 Lambda)                                                          'input_39[0][0]']               
                                                                                                  
 layer_normalization_76 (LayerN  (None, 5, 30)       60          ['tf.__operators__.add_152[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_152 (Conv1D)            (None, 5, 32)        992         ['layer_normalization_76[0][0]'] 
                                                                                                  
 dropout_153 (Dropout)          (None, 5, 32)        0           ['conv1d_152[0][0]']             
                                                                                                  
 conv1d_153 (Conv1D)            (None, 5, 30)        990         ['dropout_153[0][0]']            
                                                                                                  
 tf.__operators__.add_153 (TFOp  (None, 5, 30)       0           ['conv1d_153[0][0]',             
 Lambda)                                                          'tf.__operators__.add_152[0][0]'
                                                                 ]                                
                                                                                                  
 batch_normalization_77 (BatchN  (None, 5, 30)       120         ['tf.__operators__.add_153[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 multi_head_attention_77 (Multi  (None, 5, 30)       7902        ['batch_normalization_77[0][0]', 
 HeadAttention)                                                   'batch_normalization_77[0][0]'] 
                                                                                                  
 dropout_154 (Dropout)          (None, 5, 30)        0           ['multi_head_attention_77[0][0]']
                                                                                                  
 tf.__operators__.add_154 (TFOp  (None, 5, 30)       0           ['dropout_154[0][0]',            
 Lambda)                                                          'tf.__operators__.add_153[0][0]'
                                                                 ]                                
                                                                                                  
 layer_normalization_77 (LayerN  (None, 5, 30)       60          ['tf.__operators__.add_154[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_154 (Conv1D)            (None, 5, 32)        992         ['layer_normalization_77[0][0]'] 
                                                                                                  
 dropout_155 (Dropout)          (None, 5, 32)        0           ['conv1d_154[0][0]']             
                                                                                                  
 conv1d_155 (Conv1D)            (None, 5, 30)        990         ['dropout_155[0][0]']            
                                                                                                  
 tf.__operators__.add_155 (TFOp  (None, 5, 30)       0           ['conv1d_155[0][0]',             
 Lambda)                                                          'tf.__operators__.add_154[0][0]'
                                                                 ]                                
                                                                                                  
 dense_76 (Dense)               (None, 5, 128)       3968        ['tf.__operators__.add_155[0][0]'
                                                                 ]                                
                                                                                                  
 flatten_38 (Flatten)           (None, 640)          0           ['dense_76[0][0]']               
                                                                                                  
 dense_77 (Dense)               (None, 5)            3205        ['flatten_38[0][0]']             
                                                                                                  
==================================================================================================
Total params: 27,301
Trainable params: 27,181
Non-trainable params: 120
__________________________________________________________________________________________________
Epoch 00064: early stopping
Experiment:  267  Set:  sn2 Train Labels:  nar5 Test Labels:  clean
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 3 0
AER:  0.1556567957479119
TER:  0.156, 0.156, 0.156
Score for this model: 
               precision    recall  f1-score   support

           0       0.97      1.00      0.99      1558
           1       0.78      0.89      0.83       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00         1
           4       0.66      0.18      0.28       401

    accuracy                           0.84      2634
   macro avg       0.48      0.41      0.42      2634
weighted avg       0.88      0.84      0.84      2634

Confusion Matrix for this model: 
 [[1558    0    0    0    0]
 [  16  594   16    7   37]
 [   0    2    0    2    0]
 [   0    1    0    0    0]
 [  24  160   71   74   72]]
Experiment:  268  Set:  sn2 Train Labels:  nar5 Test Labels:  ncar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 3 1
AER:  0.19172361427486712
TER:  0.157, 0.142, 0.242
Score for this model: 
               precision    recall  f1-score   support

           0       0.93      0.99      0.96      1501
           1       0.75      0.86      0.80       660
           2       0.03      0.10      0.05        30
           3       0.01      0.03      0.02        31
           4       0.63      0.17      0.26       412

    accuracy                           0.81      2634
   macro avg       0.47      0.43      0.42      2634
weighted avg       0.82      0.81      0.79      2634

Confusion Matrix for this model: 
 [[1489    8    1    0    3]
 [  32  567   16    9   36]
 [  19    6    3    2    0]
 [  19    9    1    1    1]
 [  39  167   66   71   69]]
Experiment:  269  Set:  sn2 Train Labels:  nar5 Test Labels:  ncar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 3 2
AER:  0.22892938496583143
TER:  0.161, 0.129, 0.329
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      0.98      0.93      1433
           1       0.73      0.83      0.78       670
           2       0.02      0.03      0.03        66
           3       0.02      0.03      0.03        61
           4       0.60      0.16      0.25       404

    accuracy                           0.77      2634
   macro avg       0.45      0.41      0.40      2634
weighted avg       0.76      0.77      0.74      2634

Confusion Matrix for this model: 
 [[1407   20    1    1    4]
 [  54  555   17    8   36]
 [  42   15    2    5    2]
 [  40   16    1    2    2]
 [  55  151   66   67   65]]
Experiment:  270  Set:  sn2 Train Labels:  nar5 Test Labels:  nar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 3 3
AER:  0.2023538344722855
TER:  0.169, 0.152, 0.252
Score for this model: 
               precision    recall  f1-score   support

           0       0.90      1.00      0.95      1435
           1       0.78      0.89      0.83       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00       124
           4       0.66      0.18      0.28       401

    accuracy                           0.80      2634
   macro avg       0.47      0.41      0.41      2634
weighted avg       0.79      0.80      0.77      2634

Confusion Matrix for this model: 
 [[1435    0    0    0    0]
 [  16  594   16    7   37]
 [   0    2    0    2    0]
 [ 123    1    0    0    0]
 [  24  160   71   74   72]]
Experiment:  271  Set:  sn2 Train Labels:  nar5 Test Labels:  nar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 3 4
AER:  0.2536066818526955
TER:  0.192, 0.154, 0.354
Score for this model: 
               precision    recall  f1-score   support

           0       0.81      1.00      0.90      1300
           1       0.78      0.89      0.83       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00       259
           4       0.66      0.18      0.28       401

    accuracy                           0.75      2634
   macro avg       0.45      0.41      0.40      2634
weighted avg       0.70      0.75      0.70      2634

Confusion Matrix for this model: 
 [[1300    0    0    0    0]
 [  16  594   16    7   37]
 [   0    2    0    2    0]
 [ 258    1    0    0    0]
 [  24  160   71   74   72]]
Experiment:  272  Set:  sn2 Train Labels:  nar5 Test Labels:  nnar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 3 5
AER:  0.20577069096431283
TER:  0.173, 0.156, 0.256
Score for this model: 
               precision    recall  f1-score   support

           0       0.89      1.00      0.94      1426
           1       0.78      0.89      0.83       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00       133
           4       0.66      0.18      0.28       401

    accuracy                           0.79      2634
   macro avg       0.47      0.41      0.41      2634
weighted avg       0.78      0.79      0.77      2634

Confusion Matrix for this model: 
 [[1426    0    0    0    0]
 [  16  594   16    7   37]
 [   0    2    0    2    0]
 [ 132    1    0    0    0]
 [  24  160   71   74   72]]
Experiment:  273  Set:  sn2 Train Labels:  nar5 Test Labels:  nnar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 3 6
AER:  0.25588458618071375
TER:  0.195, 0.156, 0.356
Score for this model: 
               precision    recall  f1-score   support

           0       0.81      1.00      0.89      1294
           1       0.78      0.89      0.83       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00       265
           4       0.66      0.18      0.28       401

    accuracy                           0.74      2634
   macro avg       0.45      0.41      0.40      2634
weighted avg       0.70      0.74      0.69      2634

Confusion Matrix for this model: 
 [[1294    0    0    0    0]
 [  16  594   16    7   37]
 [   0    2    0    2    0]
 [ 264    1    0    0    0]
 [  24  160   71   74   72]]
Input Shape:  (8112, 5, 30)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_39"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_40 (InputLayer)          [(None, 5, 30)]      0           []                               
                                                                                                  
 batch_normalization_78 (BatchN  (None, 5, 30)       120         ['input_40[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_78 (Multi  (None, 5, 30)       7902        ['batch_normalization_78[0][0]', 
 HeadAttention)                                                   'batch_normalization_78[0][0]'] 
                                                                                                  
 dropout_156 (Dropout)          (None, 5, 30)        0           ['multi_head_attention_78[0][0]']
                                                                                                  
 tf.__operators__.add_156 (TFOp  (None, 5, 30)       0           ['dropout_156[0][0]',            
 Lambda)                                                          'input_40[0][0]']               
                                                                                                  
 layer_normalization_78 (LayerN  (None, 5, 30)       60          ['tf.__operators__.add_156[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_156 (Conv1D)            (None, 5, 32)        992         ['layer_normalization_78[0][0]'] 
                                                                                                  
 dropout_157 (Dropout)          (None, 5, 32)        0           ['conv1d_156[0][0]']             
                                                                                                  
 conv1d_157 (Conv1D)            (None, 5, 30)        990         ['dropout_157[0][0]']            
                                                                                                  
 tf.__operators__.add_157 (TFOp  (None, 5, 30)       0           ['conv1d_157[0][0]',             
 Lambda)                                                          'tf.__operators__.add_156[0][0]'
                                                                 ]                                
                                                                                                  
 batch_normalization_79 (BatchN  (None, 5, 30)       120         ['tf.__operators__.add_157[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 multi_head_attention_79 (Multi  (None, 5, 30)       7902        ['batch_normalization_79[0][0]', 
 HeadAttention)                                                   'batch_normalization_79[0][0]'] 
                                                                                                  
 dropout_158 (Dropout)          (None, 5, 30)        0           ['multi_head_attention_79[0][0]']
                                                                                                  
 tf.__operators__.add_158 (TFOp  (None, 5, 30)       0           ['dropout_158[0][0]',            
 Lambda)                                                          'tf.__operators__.add_157[0][0]'
                                                                 ]                                
                                                                                                  
 layer_normalization_79 (LayerN  (None, 5, 30)       60          ['tf.__operators__.add_158[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_158 (Conv1D)            (None, 5, 32)        992         ['layer_normalization_79[0][0]'] 
                                                                                                  
 dropout_159 (Dropout)          (None, 5, 32)        0           ['conv1d_158[0][0]']             
                                                                                                  
 conv1d_159 (Conv1D)            (None, 5, 30)        990         ['dropout_159[0][0]']            
                                                                                                  
 tf.__operators__.add_159 (TFOp  (None, 5, 30)       0           ['conv1d_159[0][0]',             
 Lambda)                                                          'tf.__operators__.add_158[0][0]'
                                                                 ]                                
                                                                                                  
 dense_78 (Dense)               (None, 5, 128)       3968        ['tf.__operators__.add_159[0][0]'
                                                                 ]                                
                                                                                                  
 flatten_39 (Flatten)           (None, 640)          0           ['dense_78[0][0]']               
                                                                                                  
 dense_79 (Dense)               (None, 5)            3205        ['flatten_39[0][0]']             
                                                                                                  
==================================================================================================
Total params: 27,301
Trainable params: 27,181
Non-trainable params: 120
__________________________________________________________________________________________________
Epoch 00059: early stopping
Experiment:  274  Set:  sn2 Train Labels:  nar10 Test Labels:  clean
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 4 0
AER:  0.14958238420653
TER:  0.150, 0.150, 0.150
Score for this model: 
               precision    recall  f1-score   support

           0       0.98      1.00      0.99      1558
           1       0.76      0.93      0.84       670
           2       0.02      0.25      0.03         4
           3       0.00      0.00      0.00         1
           4       0.69      0.15      0.24       401

    accuracy                           0.85      2634
   macro avg       0.49      0.47      0.42      2634
weighted avg       0.88      0.85      0.83      2634

Confusion Matrix for this model: 
 [[1558    0    0    0    0]
 [   8  622    9    4   27]
 [   0    2    1    1    0]
 [   0    1    0    0    0]
 [  30  194   48   70   59]]
Experiment:  275  Set:  sn2 Train Labels:  nar10 Test Labels:  ncar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 4 1
AER:  0.1867881548974943
TER:  0.152, 0.137, 0.237
Score for this model: 
               precision    recall  f1-score   support

           0       0.93      0.99      0.96      1501
           1       0.73      0.90      0.80       660
           2       0.05      0.10      0.07        30
           3       0.01      0.03      0.02        31
           4       0.64      0.13      0.22       412

    accuracy                           0.81      2634
   macro avg       0.47      0.43      0.41      2634
weighted avg       0.81      0.81      0.78      2634

Confusion Matrix for this model: 
 [[1489    9    0    0    3]
 [  24  594   10    6   26]
 [  19    6    3    1    1]
 [  19    9    1    1    1]
 [  45  201   44   67   55]]
Experiment:  276  Set:  sn2 Train Labels:  nar10 Test Labels:  ncar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 4 2
AER:  0.22285497342444952
TER:  0.154, 0.123, 0.323
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      0.98      0.93      1433
           1       0.71      0.87      0.78       670
           2       0.05      0.05      0.05        66
           3       0.03      0.03      0.03        61
           4       0.62      0.13      0.22       404

    accuracy                           0.78      2634
   macro avg       0.46      0.41      0.40      2634
weighted avg       0.76      0.78      0.74      2634

Confusion Matrix for this model: 
 [[1406   22    1    2    2]
 [  48  583    9    3   27]
 [  42   15    3    4    2]
 [  40   16    1    2    2]
 [  60  183   44   64   53]]
Experiment:  277  Set:  sn2 Train Labels:  nar10 Test Labels:  nar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 4 3
AER:  0.19627942293090356
TER:  0.163, 0.146, 0.246
Score for this model: 
               precision    recall  f1-score   support

           0       0.90      1.00      0.95      1435
           1       0.76      0.93      0.84       670
           2       0.02      0.25      0.03         4
           3       0.00      0.00      0.00       124
           4       0.69      0.15      0.24       401

    accuracy                           0.80      2634
   macro avg       0.47      0.47      0.41      2634
weighted avg       0.79      0.80      0.77      2634

Confusion Matrix for this model: 
 [[1435    0    0    0    0]
 [   8  622    9    4   27]
 [   0    2    1    1    0]
 [ 123    1    0    0    0]
 [  30  194   48   70   59]]
Experiment:  278  Set:  sn2 Train Labels:  nar10 Test Labels:  nar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 4 4
AER:  0.24753227031131358
TER:  0.184, 0.148, 0.348
Score for this model: 
               precision    recall  f1-score   support

           0       0.81      1.00      0.90      1300
           1       0.76      0.93      0.84       670
           2       0.02      0.25      0.03         4
           3       0.00      0.00      0.00       259
           4       0.69      0.15      0.24       401

    accuracy                           0.75      2634
   macro avg       0.46      0.47      0.40      2634
weighted avg       0.70      0.75      0.69      2634

Confusion Matrix for this model: 
 [[1300    0    0    0    0]
 [   8  622    9    4   27]
 [   0    2    1    1    0]
 [ 258    1    0    0    0]
 [  30  194   48   70   59]]
Experiment:  279  Set:  sn2 Train Labels:  nar10 Test Labels:  nnar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 4 5
AER:  0.19969627942293092
TER:  0.166, 0.150, 0.250
Score for this model: 
               precision    recall  f1-score   support

           0       0.89      1.00      0.94      1426
           1       0.76      0.93      0.84       670
           2       0.02      0.25      0.03         4
           3       0.00      0.00      0.00       133
           4       0.69      0.15      0.24       401

    accuracy                           0.80      2634
   macro avg       0.47      0.47      0.41      2634
weighted avg       0.78      0.80      0.76      2634

Confusion Matrix for this model: 
 [[1426    0    0    0    0]
 [   8  622    9    4   27]
 [   0    2    1    1    0]
 [ 132    1    0    0    0]
 [  30  194   48   70   59]]
Experiment:  280  Set:  sn2 Train Labels:  nar10 Test Labels:  nnar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 4 6
AER:  0.2498101746393318
TER:  0.187, 0.150, 0.350
Score for this model: 
               precision    recall  f1-score   support

           0       0.81      1.00      0.90      1294
           1       0.76      0.93      0.84       670
           2       0.02      0.25      0.03         4
           3       0.00      0.00      0.00       265
           4       0.69      0.15      0.24       401

    accuracy                           0.75      2634
   macro avg       0.45      0.47      0.40      2634
weighted avg       0.70      0.75      0.69      2634

Confusion Matrix for this model: 
 [[1294    0    0    0    0]
 [   8  622    9    4   27]
 [   0    2    1    1    0]
 [ 264    1    0    0    0]
 [  30  194   48   70   59]]
Input Shape:  (8112, 5, 30)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_40"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_41 (InputLayer)          [(None, 5, 30)]      0           []                               
                                                                                                  
 batch_normalization_80 (BatchN  (None, 5, 30)       120         ['input_41[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_80 (Multi  (None, 5, 30)       7902        ['batch_normalization_80[0][0]', 
 HeadAttention)                                                   'batch_normalization_80[0][0]'] 
                                                                                                  
 dropout_160 (Dropout)          (None, 5, 30)        0           ['multi_head_attention_80[0][0]']
                                                                                                  
 tf.__operators__.add_160 (TFOp  (None, 5, 30)       0           ['dropout_160[0][0]',            
 Lambda)                                                          'input_41[0][0]']               
                                                                                                  
 layer_normalization_80 (LayerN  (None, 5, 30)       60          ['tf.__operators__.add_160[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_160 (Conv1D)            (None, 5, 32)        992         ['layer_normalization_80[0][0]'] 
                                                                                                  
 dropout_161 (Dropout)          (None, 5, 32)        0           ['conv1d_160[0][0]']             
                                                                                                  
 conv1d_161 (Conv1D)            (None, 5, 30)        990         ['dropout_161[0][0]']            
                                                                                                  
 tf.__operators__.add_161 (TFOp  (None, 5, 30)       0           ['conv1d_161[0][0]',             
 Lambda)                                                          'tf.__operators__.add_160[0][0]'
                                                                 ]                                
                                                                                                  
 batch_normalization_81 (BatchN  (None, 5, 30)       120         ['tf.__operators__.add_161[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 multi_head_attention_81 (Multi  (None, 5, 30)       7902        ['batch_normalization_81[0][0]', 
 HeadAttention)                                                   'batch_normalization_81[0][0]'] 
                                                                                                  
 dropout_162 (Dropout)          (None, 5, 30)        0           ['multi_head_attention_81[0][0]']
                                                                                                  
 tf.__operators__.add_162 (TFOp  (None, 5, 30)       0           ['dropout_162[0][0]',            
 Lambda)                                                          'tf.__operators__.add_161[0][0]'
                                                                 ]                                
                                                                                                  
 layer_normalization_81 (LayerN  (None, 5, 30)       60          ['tf.__operators__.add_162[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_162 (Conv1D)            (None, 5, 32)        992         ['layer_normalization_81[0][0]'] 
                                                                                                  
 dropout_163 (Dropout)          (None, 5, 32)        0           ['conv1d_162[0][0]']             
                                                                                                  
 conv1d_163 (Conv1D)            (None, 5, 30)        990         ['dropout_163[0][0]']            
                                                                                                  
 tf.__operators__.add_163 (TFOp  (None, 5, 30)       0           ['conv1d_163[0][0]',             
 Lambda)                                                          'tf.__operators__.add_162[0][0]'
                                                                 ]                                
                                                                                                  
 dense_80 (Dense)               (None, 5, 128)       3968        ['tf.__operators__.add_163[0][0]'
                                                                 ]                                
                                                                                                  
 flatten_40 (Flatten)           (None, 640)          0           ['dense_80[0][0]']               
                                                                                                  
 dense_81 (Dense)               (None, 5)            3205        ['flatten_40[0][0]']             
                                                                                                  
==================================================================================================
Total params: 27,301
Trainable params: 27,181
Non-trainable params: 120
__________________________________________________________________________________________________
Epoch 00058: early stopping
Experiment:  281  Set:  sn2 Train Labels:  nnar5 Test Labels:  clean
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 5 0
AER:  0.15907365223993924
TER:  0.159, 0.159, 0.159
Score for this model: 
               precision    recall  f1-score   support

           0       0.96      1.00      0.98      1558
           1       0.76      0.90      0.82       670
           2       0.01      0.25      0.03         4
           3       0.00      0.00      0.00         1
           4       0.74      0.13      0.23       401

    accuracy                           0.84      2634
   macro avg       0.49      0.46      0.41      2634
weighted avg       0.87      0.84      0.82      2634

Confusion Matrix for this model: 
 [[1558    0    0    0    0]
 [  29  602   20    0   19]
 [   1    2    1    0    0]
 [   0    1    0    0    0]
 [  39  186   48   74   54]]
Experiment:  282  Set:  sn2 Train Labels:  nnar5 Test Labels:  ncar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 5 1
AER:  0.19552012148823084
TER:  0.162, 0.146, 0.246
Score for this model: 
               precision    recall  f1-score   support

           0       0.92      0.99      0.95      1501
           1       0.73      0.87      0.79       660
           2       0.04      0.10      0.06        30
           3       0.01      0.03      0.02        31
           4       0.68      0.12      0.21       412

    accuracy                           0.80      2634
   macro avg       0.48      0.42      0.41      2634
weighted avg       0.81      0.80      0.77      2634

Confusion Matrix for this model: 
 [[1489    9    0    0    3]
 [  45  576   19    2   18]
 [  20    6    3    0    1]
 [  19    9    1    1    1]
 [  54  191   46   71   50]]
Experiment:  283  Set:  sn2 Train Labels:  nnar5 Test Labels:  ncar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 5 2
AER:  0.2308276385725133
TER:  0.164, 0.131, 0.331
Score for this model: 
               precision    recall  f1-score   support

           0       0.87      0.98      0.92      1433
           1       0.71      0.84      0.77       670
           2       0.03      0.03      0.03        66
           3       0.03      0.03      0.03        61
           4       0.68      0.12      0.21       404

    accuracy                           0.77      2634
   macro avg       0.46      0.40      0.39      2634
weighted avg       0.76      0.77      0.73      2634

Confusion Matrix for this model: 
 [[1408   21    1    1    2]
 [  66  564   20    1   19]
 [  44   16    2    3    1]
 [  41   16    1    2    1]
 [  68  174   45   67   50]]
Experiment:  284  Set:  sn2 Train Labels:  nnar5 Test Labels:  nar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 5 3
AER:  0.20577069096431283
TER:  0.173, 0.156, 0.256
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      1.00      0.94      1435
           1       0.76      0.90      0.82       670
           2       0.01      0.25      0.03         4
           3       0.00      0.00      0.00       124
           4       0.74      0.13      0.23       401

    accuracy                           0.79      2634
   macro avg       0.48      0.46      0.40      2634
weighted avg       0.79      0.79      0.75      2634

Confusion Matrix for this model: 
 [[1435    0    0    0    0]
 [  29  602   20    0   19]
 [   1    2    1    0    0]
 [ 123    1    0    0    0]
 [  39  186   48   74   54]]
Experiment:  285  Set:  sn2 Train Labels:  nnar5 Test Labels:  nar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 5 4
AER:  0.25702353834472286
TER:  0.196, 0.157, 0.357
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      1.00      0.89      1300
           1       0.76      0.90      0.82       670
           2       0.01      0.25      0.03         4
           3       0.00      0.00      0.00       259
           4       0.74      0.13      0.23       401

    accuracy                           0.74      2634
   macro avg       0.46      0.46      0.39      2634
weighted avg       0.70      0.74      0.68      2634

Confusion Matrix for this model: 
 [[1300    0    0    0    0]
 [  29  602   20    0   19]
 [   1    2    1    0    0]
 [ 258    1    0    0    0]
 [  39  186   48   74   54]]
Experiment:  286  Set:  sn2 Train Labels:  nnar5 Test Labels:  nnar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 5 5
AER:  0.20918754745634016
TER:  0.177, 0.159, 0.259
Score for this model: 
               precision    recall  f1-score   support

           0       0.88      1.00      0.93      1426
           1       0.76      0.90      0.82       670
           2       0.01      0.25      0.03         4
           3       0.00      0.00      0.00       133
           4       0.74      0.13      0.23       401

    accuracy                           0.79      2634
   macro avg       0.48      0.46      0.40      2634
weighted avg       0.78      0.79      0.75      2634

Confusion Matrix for this model: 
 [[1426    0    0    0    0]
 [  29  602   20    0   19]
 [   1    2    1    0    0]
 [ 132    1    0    0    0]
 [  39  186   48   74   54]]
Experiment:  287  Set:  sn2 Train Labels:  nnar5 Test Labels:  nnar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 5 6
AER:  0.2593014426727411
TER:  0.199, 0.159, 0.359
Score for this model: 
               precision    recall  f1-score   support

           0       0.80      1.00      0.89      1294
           1       0.76      0.90      0.82       670
           2       0.01      0.25      0.03         4
           3       0.00      0.00      0.00       265
           4       0.74      0.13      0.23       401

    accuracy                           0.74      2634
   macro avg       0.46      0.46      0.39      2634
weighted avg       0.70      0.74      0.68      2634

Confusion Matrix for this model: 
 [[1294    0    0    0    0]
 [  29  602   20    0   19]
 [   1    2    1    0    0]
 [ 264    1    0    0    0]
 [  39  186   48   74   54]]
Input Shape:  (8112, 5, 30)
<class 'keras.engine.keras_tensor.KerasTensor'>
<class 'keras.engine.keras_tensor.KerasTensor'>
Model: "model_41"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_42 (InputLayer)          [(None, 5, 30)]      0           []                               
                                                                                                  
 batch_normalization_82 (BatchN  (None, 5, 30)       120         ['input_42[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_82 (Multi  (None, 5, 30)       7902        ['batch_normalization_82[0][0]', 
 HeadAttention)                                                   'batch_normalization_82[0][0]'] 
                                                                                                  
 dropout_164 (Dropout)          (None, 5, 30)        0           ['multi_head_attention_82[0][0]']
                                                                                                  
 tf.__operators__.add_164 (TFOp  (None, 5, 30)       0           ['dropout_164[0][0]',            
 Lambda)                                                          'input_42[0][0]']               
                                                                                                  
 layer_normalization_82 (LayerN  (None, 5, 30)       60          ['tf.__operators__.add_164[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_164 (Conv1D)            (None, 5, 32)        992         ['layer_normalization_82[0][0]'] 
                                                                                                  
 dropout_165 (Dropout)          (None, 5, 32)        0           ['conv1d_164[0][0]']             
                                                                                                  
 conv1d_165 (Conv1D)            (None, 5, 30)        990         ['dropout_165[0][0]']            
                                                                                                  
 tf.__operators__.add_165 (TFOp  (None, 5, 30)       0           ['conv1d_165[0][0]',             
 Lambda)                                                          'tf.__operators__.add_164[0][0]'
                                                                 ]                                
                                                                                                  
 batch_normalization_83 (BatchN  (None, 5, 30)       120         ['tf.__operators__.add_165[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 multi_head_attention_83 (Multi  (None, 5, 30)       7902        ['batch_normalization_83[0][0]', 
 HeadAttention)                                                   'batch_normalization_83[0][0]'] 
                                                                                                  
 dropout_166 (Dropout)          (None, 5, 30)        0           ['multi_head_attention_83[0][0]']
                                                                                                  
 tf.__operators__.add_166 (TFOp  (None, 5, 30)       0           ['dropout_166[0][0]',            
 Lambda)                                                          'tf.__operators__.add_165[0][0]'
                                                                 ]                                
                                                                                                  
 layer_normalization_83 (LayerN  (None, 5, 30)       60          ['tf.__operators__.add_166[0][0]'
 ormalization)                                                   ]                                
                                                                                                  
 conv1d_166 (Conv1D)            (None, 5, 32)        992         ['layer_normalization_83[0][0]'] 
                                                                                                  
 dropout_167 (Dropout)          (None, 5, 32)        0           ['conv1d_166[0][0]']             
                                                                                                  
 conv1d_167 (Conv1D)            (None, 5, 30)        990         ['dropout_167[0][0]']            
                                                                                                  
 tf.__operators__.add_167 (TFOp  (None, 5, 30)       0           ['conv1d_167[0][0]',             
 Lambda)                                                          'tf.__operators__.add_166[0][0]'
                                                                 ]                                
                                                                                                  
 dense_82 (Dense)               (None, 5, 128)       3968        ['tf.__operators__.add_167[0][0]'
                                                                 ]                                
                                                                                                  
 flatten_41 (Flatten)           (None, 640)          0           ['dense_82[0][0]']               
                                                                                                  
 dense_83 (Dense)               (None, 5)            3205        ['flatten_41[0][0]']             
                                                                                                  
==================================================================================================
Total params: 27,301
Trainable params: 27,181
Non-trainable params: 120
__________________________________________________________________________________________________
Epoch 00064: early stopping
Experiment:  288  Set:  sn2 Train Labels:  nnar10 Test Labels:  clean
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 6 0
AER:  0.15413819286256644
TER:  0.154, 0.154, 0.154
Score for this model: 
               precision    recall  f1-score   support

           0       0.99      1.00      0.99      1558
           1       0.77      0.92      0.84       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00         1
           4       0.57      0.13      0.22       401

    accuracy                           0.85      2634
   macro avg       0.47      0.41      0.41      2634
weighted avg       0.87      0.85      0.84      2634

Confusion Matrix for this model: 
 [[1558    0    0    0    0]
 [   1  616    4    9   40]
 [   0    2    0    2    0]
 [   0    1    0    0    0]
 [  16  178   55   98   54]]
Experiment:  289  Set:  sn2 Train Labels:  nnar10 Test Labels:  ncar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 6 1
AER:  0.1894457099468489
TER:  0.155, 0.139, 0.239
Score for this model: 
               precision    recall  f1-score   support

           0       0.95      0.99      0.97      1501
           1       0.74      0.89      0.81       660
           2       0.05      0.10      0.07        30
           3       0.01      0.03      0.01        31
           4       0.57      0.13      0.21       412

    accuracy                           0.81      2634
   macro avg       0.46      0.43      0.41      2634
weighted avg       0.81      0.81      0.79      2634

Confusion Matrix for this model: 
 [[1489    9    2    0    1]
 [  18  588    5   12   37]
 [  19    6    3    2    0]
 [  18    9    1    1    2]
 [  31  185   48   94   54]]
Experiment:  290  Set:  sn2 Train Labels:  nnar10 Test Labels:  ncar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 6 2
AER:  0.22627182991647685
TER:  0.158, 0.126, 0.326
Score for this model: 
               precision    recall  f1-score   support

           0       0.89      0.98      0.93      1433
           1       0.72      0.86      0.79       670
           2       0.03      0.03      0.03        66
           3       0.03      0.05      0.04        61
           4       0.53      0.12      0.20       404

    accuracy                           0.77      2634
   macro avg       0.44      0.41      0.40      2634
weighted avg       0.75      0.77      0.74      2634

Confusion Matrix for this model: 
 [[1406   22    2    1    2]
 [  40  577    4   11   38]
 [  44   14    2    4    2]
 [  39   16    1    3    2]
 [  46  168   50   90   50]]
Experiment:  291  Set:  sn2 Train Labels:  nnar10 Test Labels:  nar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 6 3
AER:  0.20083523158694003
TER:  0.168, 0.151, 0.251
Score for this model: 
               precision    recall  f1-score   support

           0       0.91      1.00      0.95      1435
           1       0.77      0.92      0.84       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00       124
           4       0.57      0.13      0.22       401

    accuracy                           0.80      2634
   macro avg       0.45      0.41      0.40      2634
weighted avg       0.78      0.80      0.77      2634

Confusion Matrix for this model: 
 [[1435    0    0    0    0]
 [   1  616    4    9   40]
 [   0    2    0    2    0]
 [ 123    1    0    0    0]
 [  16  178   55   98   54]]
Experiment:  292  Set:  sn2 Train Labels:  nnar10 Test Labels:  nar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 6 4
AER:  0.25208807896735
TER:  0.190, 0.152, 0.352
Score for this model: 
               precision    recall  f1-score   support

           0       0.83      1.00      0.90      1300
           1       0.77      0.92      0.84       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00       259
           4       0.57      0.13      0.22       401

    accuracy                           0.75      2634
   macro avg       0.43      0.41      0.39      2634
weighted avg       0.69      0.75      0.69      2634

Confusion Matrix for this model: 
 [[1300    0    0    0    0]
 [   1  616    4    9   40]
 [   0    2    0    2    0]
 [ 258    1    0    0    0]
 [  16  178   55   98   54]]
Experiment:  293  Set:  sn2 Train Labels:  nnar10 Test Labels:  nnar5
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 6 5
AER:  0.20425208807896736
TER:  0.171, 0.154, 0.254
Score for this model: 
               precision    recall  f1-score   support

           0       0.91      1.00      0.95      1426
           1       0.77      0.92      0.84       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00       133
           4       0.57      0.13      0.22       401

    accuracy                           0.80      2634
   macro avg       0.45      0.41      0.40      2634
weighted avg       0.77      0.80      0.76      2634

Confusion Matrix for this model: 
 [[1426    0    0    0    0]
 [   1  616    4    9   40]
 [   0    2    0    2    0]
 [ 132    1    0    0    0]
 [  16  178   55   98   54]]
Experiment:  294  Set:  sn2 Train Labels:  nnar10 Test Labels:  nnar10
Shape of X_train:  (8112, 5, 30)
Shape of X_test:  (2634, 5, 30)
Shape of y_train:  (8112, 5)
Shape of y_test:  (2634, 5)
NUM_INSTANCES is  40560
instances should be  8112
Shape of y true: (2634,)
Shape of y predicted: (2634,)
[0.03159851 0.08910387 0.03079848 0.03304216 0.01522615] [0.         0.08059701 1.         1.         0.87780549]
Recording results in matrix at 6 6
AER:  0.25436598329536825
TER:  0.193, 0.154, 0.354
Score for this model: 
               precision    recall  f1-score   support

           0       0.82      1.00      0.90      1294
           1       0.77      0.92      0.84       670
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00       265
           4       0.57      0.13      0.22       401

    accuracy                           0.75      2634
   macro avg       0.43      0.41      0.39      2634
weighted avg       0.69      0.75      0.69      2634

Confusion Matrix for this model: 
 [[1294    0    0    0    0]
 [   1  616    4    9   40]
 [   0    2    0    2    0]
 [ 264    1    0    0    0]
 [  16  178   55   98   54]]
